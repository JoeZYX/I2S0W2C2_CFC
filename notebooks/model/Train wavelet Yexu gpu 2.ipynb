{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "894e2c21",
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "import sys\n",
    "sys.path.append(\"../../\")\n",
    "\n",
    "from experiment import Exp\n",
    "\n",
    "from dataloaders import data_set,data_dict\n",
    "import torch\n",
    "import yaml\n",
    "import os"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bcc56bc7",
   "metadata": {},
   "source": [
    "# 参数设置"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dcc5bcbc",
   "metadata": {
    "tags": []
   },
   "source": [
    "# 训练参数 \n",
    "除了路径 其他不要变"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "86004ce0",
   "metadata": {},
   "outputs": [],
   "source": [
    "class dotdict(dict):\n",
    "    \"\"\"dot.notation access to dictionary attributes\"\"\"\n",
    "    __getattr__ = dict.get\n",
    "    __setattr__ = dict.__setitem__\n",
    "    __delattr__ = dict.__delitem__\n",
    "\n",
    "args = dotdict()   \n",
    "# TODO change the path as relative path\n",
    "args.to_save_path     = \"../../../Run_logs\"              \n",
    "args.freq_save_path   = \"../../../Freq_data\"\n",
    "args.window_save_path = \"../../../Sliding_window\"\n",
    "args.root_path        = \"../../../datasets\"\n",
    "\n",
    "\n",
    "args.drop_transition  = False\n",
    "args.datanorm_type    = \"standardization\" # None ,\"standardization\", \"minmax\"\n",
    "\n",
    "\n",
    "args.batch_size       = 256                                                    \n",
    "args.shuffle          = True\n",
    "args.drop_last        = False\n",
    "args.train_vali_quote = 0.90                                           \n",
    "\n",
    "\n",
    "# training setting \n",
    "args.train_epochs            = 150\n",
    "\n",
    "args.learning_rate           = 0.001  \n",
    "args.learning_rate_patience  = 5\n",
    "args.learning_rate_factor    = 0.1\n",
    "\n",
    "\n",
    "args.early_stop_patience     = 15\n",
    "\n",
    "args.use_gpu                 = True if torch.cuda.is_available() else False\n",
    "args.gpu                     = 2\n",
    "args.use_multi_gpu           = False\n",
    "\n",
    "args.optimizer               = \"Adam\"\n",
    "args.criterion               = \"CrossEntropy\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c282cbcb",
   "metadata": {},
   "source": [
    "## 数据参数\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "c6cd147b",
   "metadata": {},
   "outputs": [],
   "source": [
    "args.data_name                        =  \"uschad\"\n",
    "\n",
    "args.wavelet_filtering                = True\n",
    "args.wavelet_filtering_regularization = True\n",
    "args.wavelet_filtering_finetuning     = True\n",
    "args.wavelet_filtering_finetuning_percent = 1\n",
    "args.wavelet_filtering_learnable      = False\n",
    "args.wavelet_filtering_layernorm      = False\n",
    "\n",
    "args.regulatization_tradeoff          = 0\n",
    "args.number_wavelet_filtering         = 10\n",
    "\n",
    "args.difference       = False \n",
    "args.filtering        = False\n",
    "args.magnitude        = False\n",
    "args.weighted_sampler = False\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "args.pos_select       = None\n",
    "args.sensor_select    = None\n",
    "\n",
    "\n",
    "args.representation_type = \"time\"\n",
    "args.exp_mode            = \"LOCV\"\n",
    "if args.data_name      ==  \"skodar\":\n",
    "    args.exp_mode            = \"SOCV\"\n",
    "\n",
    "config_file = open('../../configs/data.yaml', mode='r')\n",
    "data_config = yaml.load(config_file, Loader=yaml.FullLoader)\n",
    "config = data_config[args.data_name]\n",
    "\n",
    "args.root_path       = os.path.join(args.root_path,config[\"filename\"])\n",
    "args.sampling_freq   = config[\"sampling_freq\"]\n",
    "args.num_classes     =  config[\"num_classes\"]\n",
    "window_seconds       = config[\"window_seconds\"]\n",
    "args.windowsize      =   int(window_seconds * args.sampling_freq) \n",
    "args.input_length    =  args.windowsize\n",
    "# input information\n",
    "args.c_in            = config[\"num_channels\"]\n",
    "\n",
    "if args.difference:\n",
    "    args.c_in = args.c_in*2\n",
    "\n",
    "if args.wavelet_filtering :\n",
    "    \n",
    "    if args.windowsize%2==1:\n",
    "        N_ds = int(torch.log2(torch.tensor(args.windowsize-1)).floor()) - 2\n",
    "    else:\n",
    "        N_ds = int(torch.log2(torch.tensor(args.windowsize)).floor()) - 2\n",
    "\n",
    "    args.f_in            =  args.number_wavelet_filtering*N_ds+1\n",
    "else:\n",
    "    args.f_in            =  1"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4d435a4c",
   "metadata": {},
   "source": [
    "## 模型参数"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "de2f4d16",
   "metadata": {},
   "outputs": [],
   "source": [
    "args.filter_scaling_factor = 0.75\n",
    "args.model_type            = \"deepconvlstm\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cada66dd",
   "metadata": {},
   "source": [
    "# 实验"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2e3f2fad",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Use GPU: cuda:2\n",
      "clone the  wavefiler weight\n",
      "Wavelet Filtering Regularization\n",
      "Build the DeepConvLSTM model!\n",
      "Done!\n",
      "Parameter : 194021\n",
      "Set the seed as :  1\n",
      " ----------------------- load all the data -------------------\n",
      "-----------------------Sliding file are generated -----------------------\n",
      "-----------------------Sliding file are generated -----------------------\n",
      "================ LOCV Mode ====================\n",
      "================ 7 CV ======================\n",
      "================ the 0 th CV Experiment ================ \n",
      "Leave one Out Experiment : The 1 Part as the test\n",
      "[-] Target sampling weights:  [0.00015738 0.00024728 0.00023403 0.00035575 0.00038835 0.00035436\n",
      " 0.00061275 0.0002426  0.00026076 0.00017167 0.00039573 0.00040486]\n",
      "Train data number :  43290\n",
      "The number of classes is :  12\n",
      "The input_length  is :  100\n",
      "The channel_in is :  6\n",
      "Validation data number :  4810\n",
      "Test data number :  35662\n",
      "================ Build the model ================ \n",
      "clone the  wavefiler weight\n",
      "Wavelet Filtering Regularization\n",
      "Build the DeepConvLSTM model!\n",
      "Epoch: 1 cost time: 21.693771600723267\n",
      "VALI: Epoch: 1, Steps: 170 | Train Loss: 0.9681840  Vali Loss: 0.4960232 Vali Accuracy: 0.8035343  Vali weighted F1: 0.7851427  Vali macro F1 0.7656279 \n",
      "Validation loss decreased (inf --> 0.496023).  Saving model ...\n",
      "Epoch: 2 cost time: 16.378110885620117\n",
      "VALI: Epoch: 2, Steps: 170 | Train Loss: 0.3981932  Vali Loss: 0.3491588 Vali Accuracy: 0.8611227  Vali weighted F1: 0.8411917  Vali macro F1 0.8144657 \n",
      "new best score!!!!\n",
      "Validation loss decreased (0.496023 --> 0.349159).  Saving model ...\n",
      "new best score!!!!\n",
      "Epoch: 3 cost time: 16.308558464050293\n",
      "VALI: Epoch: 3, Steps: 170 | Train Loss: 0.3234483  Vali Loss: 0.2931260 Vali Accuracy: 0.8735967  Vali weighted F1: 0.8594604  Vali macro F1 0.8372955 \n",
      "new best score!!!!\n",
      "Validation loss decreased (0.349159 --> 0.293126).  Saving model ...\n",
      "new best score!!!!\n",
      "Epoch: 4 cost time: 16.34762930870056\n",
      "VALI: Epoch: 4, Steps: 170 | Train Loss: 0.2807646  Vali Loss: 0.2589822 Vali Accuracy: 0.8866944  Vali weighted F1: 0.8689251  Vali macro F1 0.8443549 \n",
      "new best score!!!!\n",
      "Validation loss decreased (0.293126 --> 0.258982).  Saving model ...\n",
      "new best score!!!!\n",
      "Epoch: 5 cost time: 16.28212261199951\n",
      "VALI: Epoch: 5, Steps: 170 | Train Loss: 0.2487493  Vali Loss: 0.2402891 Vali Accuracy: 0.8952183  Vali weighted F1: 0.8876081  Vali macro F1 0.8658907 \n",
      "new best score!!!!\n",
      "Validation loss decreased (0.258982 --> 0.240289).  Saving model ...\n",
      "new best score!!!!\n",
      "Epoch: 6 cost time: 16.294869661331177\n",
      "VALI: Epoch: 6, Steps: 170 | Train Loss: 0.2323737  Vali Loss: 0.2279462 Vali Accuracy: 0.8960499  Vali weighted F1: 0.8926731  Vali macro F1 0.8729403 \n",
      "new best score!!!!\n",
      "Validation loss decreased (0.240289 --> 0.227946).  Saving model ...\n",
      "new best score!!!!\n",
      "Epoch: 7 cost time: 16.360366582870483\n",
      "VALI: Epoch: 7, Steps: 170 | Train Loss: 0.2232184  Vali Loss: 0.2216131 Vali Accuracy: 0.8997921  Vali weighted F1: 0.8908982  Vali macro F1 0.8718671 \n",
      "new best score!!!!\n",
      "Validation loss decreased (0.227946 --> 0.221613).  Saving model ...\n",
      "new best score!!!!\n",
      "Epoch: 8 cost time: 16.292486667633057\n",
      "VALI: Epoch: 8, Steps: 170 | Train Loss: 0.2140589  Vali Loss: 0.2175895 Vali Accuracy: 0.8995842  Vali weighted F1: 0.9002718  Vali macro F1 0.8836495 \n",
      "new best score!!!!\n",
      "Validation loss decreased (0.221613 --> 0.217589).  Saving model ...\n",
      "new best score!!!!\n",
      "Epoch: 9 cost time: 16.29750418663025\n",
      "VALI: Epoch: 9, Steps: 170 | Train Loss: 0.2035743  Vali Loss: 0.2216699 Vali Accuracy: 0.8960499  Vali weighted F1: 0.8947216  Vali macro F1 0.8765750 \n",
      "EarlyStopping counter: 1 out of 15\n",
      "Learning rate adjusting counter: 1 out of 5\n",
      "Epoch: 10 cost time: 16.34105134010315\n",
      "VALI: Epoch: 10, Steps: 170 | Train Loss: 0.1936527  Vali Loss: 0.2091477 Vali Accuracy: 0.8987526  Vali weighted F1: 0.8785158  Vali macro F1 0.8551679 \n",
      "new best score!!!!\n",
      "Validation loss decreased (0.217589 --> 0.209148).  Saving model ...\n",
      "new best score!!!!\n",
      "Epoch: 11 cost time: 16.290574312210083\n",
      "VALI: Epoch: 11, Steps: 170 | Train Loss: 0.1858753  Vali Loss: 0.1999265 Vali Accuracy: 0.9064449  Vali weighted F1: 0.9042905  Vali macro F1 0.8855724 \n",
      "new best score!!!!\n",
      "Validation loss decreased (0.209148 --> 0.199927).  Saving model ...\n",
      "new best score!!!!\n",
      "Epoch: 12 cost time: 16.354647159576416\n",
      "VALI: Epoch: 12, Steps: 170 | Train Loss: 0.1807495  Vali Loss: 0.1948489 Vali Accuracy: 0.9087318  Vali weighted F1: 0.9043723  Vali macro F1 0.8846114 \n",
      "new best score!!!!\n",
      "Validation loss decreased (0.199927 --> 0.194849).  Saving model ...\n",
      "new best score!!!!\n",
      "Epoch: 13 cost time: 16.285722494125366\n",
      "VALI: Epoch: 13, Steps: 170 | Train Loss: 0.1756334  Vali Loss: 0.2032974 Vali Accuracy: 0.9016632  Vali weighted F1: 0.9006571  Vali macro F1 0.8814508 \n",
      "EarlyStopping counter: 1 out of 15\n",
      "Learning rate adjusting counter: 1 out of 5\n",
      "Epoch: 14 cost time: 16.276654958724976\n",
      "VALI: Epoch: 14, Steps: 170 | Train Loss: 0.1732982  Vali Loss: 0.1887763 Vali Accuracy: 0.9093555  Vali weighted F1: 0.9076979  Vali macro F1 0.8883597 \n",
      "new best score!!!!\n",
      "Validation loss decreased (0.194849 --> 0.188776).  Saving model ...\n",
      "new best score!!!!\n",
      "Epoch: 15 cost time: 16.357632160186768\n",
      "VALI: Epoch: 15, Steps: 170 | Train Loss: 0.1668183  Vali Loss: 0.1870581 Vali Accuracy: 0.9058212  Vali weighted F1: 0.9045112  Vali macro F1 0.8847538 \n",
      "new best score!!!!\n",
      "Validation loss decreased (0.188776 --> 0.187058).  Saving model ...\n",
      "new best score!!!!\n",
      "Epoch: 16 cost time: 16.298184394836426\n",
      "VALI: Epoch: 16, Steps: 170 | Train Loss: 0.1671459  Vali Loss: 0.1848603 Vali Accuracy: 0.9072765  Vali weighted F1: 0.9047324  Vali macro F1 0.8849807 \n",
      "new best score!!!!\n",
      "Validation loss decreased (0.187058 --> 0.184860).  Saving model ...\n",
      "new best score!!!!\n",
      "Epoch: 17 cost time: 16.308352947235107\n",
      "VALI: Epoch: 17, Steps: 170 | Train Loss: 0.1619592  Vali Loss: 0.1837950 Vali Accuracy: 0.9108108  Vali weighted F1: 0.9051720  Vali macro F1 0.8847214 \n",
      "new best score!!!!\n",
      "Validation loss decreased (0.184860 --> 0.183795).  Saving model ...\n",
      "new best score!!!!\n",
      "Epoch: 18 cost time: 16.338619232177734\n",
      "VALI: Epoch: 18, Steps: 170 | Train Loss: 0.1562029  Vali Loss: 0.1905849 Vali Accuracy: 0.9089397  Vali weighted F1: 0.9062831  Vali macro F1 0.8879911 \n",
      "EarlyStopping counter: 1 out of 15\n",
      "Learning rate adjusting counter: 1 out of 5\n",
      "Epoch: 19 cost time: 16.273207902908325\n",
      "VALI: Epoch: 19, Steps: 170 | Train Loss: 0.1541247  Vali Loss: 0.1886065 Vali Accuracy: 0.9141372  Vali weighted F1: 0.9096499  Vali macro F1 0.8904528 \n",
      "EarlyStopping counter: 2 out of 15\n",
      "Learning rate adjusting counter: 2 out of 5\n",
      "Epoch: 20 cost time: 16.27657127380371\n",
      "VALI: Epoch: 20, Steps: 170 | Train Loss: 0.1547978  Vali Loss: 0.1823480 Vali Accuracy: 0.9056133  Vali weighted F1: 0.9043048  Vali macro F1 0.8841470 \n",
      "new best score!!!!\n",
      "Validation loss decreased (0.183795 --> 0.182348).  Saving model ...\n",
      "new best score!!!!\n",
      "Epoch: 21 cost time: 16.29978108406067\n",
      "VALI: Epoch: 21, Steps: 170 | Train Loss: 0.1596765  Vali Loss: 0.1713196 Vali Accuracy: 0.9124740  Vali weighted F1: 0.9104538  Vali macro F1 0.8896247 \n",
      "new best score!!!!\n",
      "Validation loss decreased (0.182348 --> 0.171320).  Saving model ...\n",
      "new best score!!!!\n",
      "Epoch: 22 cost time: 16.27295207977295\n",
      "VALI: Epoch: 22, Steps: 170 | Train Loss: 0.1450893  Vali Loss: 0.1769316 Vali Accuracy: 0.9093555  Vali weighted F1: 0.9067660  Vali macro F1 0.8873087 \n",
      "EarlyStopping counter: 1 out of 15\n",
      "Learning rate adjusting counter: 1 out of 5\n",
      "Epoch: 23 cost time: 16.319968461990356\n",
      "VALI: Epoch: 23, Steps: 170 | Train Loss: 0.1467280  Vali Loss: 0.1709201 Vali Accuracy: 0.9137214  Vali weighted F1: 0.9102529  Vali macro F1 0.8912219 \n",
      "new best score!!!!\n",
      "Validation loss decreased (0.171320 --> 0.170920).  Saving model ...\n",
      "new best score!!!!\n",
      "Epoch: 24 cost time: 16.272603750228882\n",
      "VALI: Epoch: 24, Steps: 170 | Train Loss: 0.1395529  Vali Loss: 0.1727788 Vali Accuracy: 0.9130977  Vali weighted F1: 0.9117318  Vali macro F1 0.8928585 \n",
      "EarlyStopping counter: 1 out of 15\n",
      "Learning rate adjusting counter: 1 out of 5\n",
      "Epoch: 25 cost time: 16.265600442886353\n",
      "VALI: Epoch: 25, Steps: 170 | Train Loss: 0.1424238  Vali Loss: 0.1749086 Vali Accuracy: 0.9164241  Vali weighted F1: 0.9159826  Vali macro F1 0.8980790 \n",
      "EarlyStopping counter: 2 out of 15\n",
      "Learning rate adjusting counter: 2 out of 5\n",
      "Epoch: 26 cost time: 16.320425271987915\n",
      "VALI: Epoch: 26, Steps: 170 | Train Loss: 0.1380537  Vali Loss: 0.1648820 Vali Accuracy: 0.9199584  Vali weighted F1: 0.9171906  Vali macro F1 0.8983234 \n",
      "new best score!!!!\n",
      "Validation loss decreased (0.170920 --> 0.164882).  Saving model ...\n",
      "new best score!!!!\n",
      "Epoch: 27 cost time: 16.255876302719116\n",
      "VALI: Epoch: 27, Steps: 170 | Train Loss: 0.1375153  Vali Loss: 0.1728883 Vali Accuracy: 0.9130977  Vali weighted F1: 0.9086992  Vali macro F1 0.8892480 \n",
      "EarlyStopping counter: 1 out of 15\n",
      "Learning rate adjusting counter: 1 out of 5\n",
      "Epoch: 28 cost time: 16.243497848510742\n",
      "VALI: Epoch: 28, Steps: 170 | Train Loss: 0.1322213  Vali Loss: 0.1703545 Vali Accuracy: 0.9143451  Vali weighted F1: 0.9108276  Vali macro F1 0.8913765 \n",
      "EarlyStopping counter: 2 out of 15\n",
      "Learning rate adjusting counter: 2 out of 5\n",
      "Epoch: 29 cost time: 16.300967931747437\n",
      "VALI: Epoch: 29, Steps: 170 | Train Loss: 0.1354503  Vali Loss: 0.1760735 Vali Accuracy: 0.9191268  Vali weighted F1: 0.9139759  Vali macro F1 0.8958419 \n",
      "EarlyStopping counter: 3 out of 15\n",
      "Learning rate adjusting counter: 3 out of 5\n",
      "Epoch: 30 cost time: 16.252041578292847\n",
      "VALI: Epoch: 30, Steps: 170 | Train Loss: 0.1410973  Vali Loss: 0.1733553 Vali Accuracy: 0.9118503  Vali weighted F1: 0.9108953  Vali macro F1 0.8917920 \n",
      "EarlyStopping counter: 4 out of 15\n",
      "Learning rate adjusting counter: 4 out of 5\n",
      "Epoch: 31 cost time: 16.252570390701294\n",
      "VALI: Epoch: 31, Steps: 170 | Train Loss: 0.1318375  Vali Loss: 0.1702408 Vali Accuracy: 0.9160083  Vali weighted F1: 0.9161796  Vali macro F1 0.8980487 \n",
      "EarlyStopping counter: 5 out of 15\n",
      "Learning rate adjusting counter: 5 out of 5\n",
      "Updating learning rate to 0.0001\n",
      "Epoch: 32 cost time: 16.320645332336426\n",
      "VALI: Epoch: 32, Steps: 170 | Train Loss: 0.1182745  Vali Loss: 0.1563484 Vali Accuracy: 0.9214137  Vali weighted F1: 0.9213094  Vali macro F1 0.9035402 \n",
      "new best score!!!!\n",
      "Validation loss decreased (0.164882 --> 0.156348).  Saving model ...\n",
      "new best score!!!!\n",
      "Epoch: 33 cost time: 16.263792514801025\n",
      "VALI: Epoch: 33, Steps: 170 | Train Loss: 0.1135105  Vali Loss: 0.1563369 Vali Accuracy: 0.9178794  Vali weighted F1: 0.9172395  Vali macro F1 0.8983942 \n",
      "new best score!!!!\n",
      "Validation loss decreased (0.156348 --> 0.156337).  Saving model ...\n",
      "new best score!!!!\n",
      "Epoch: 34 cost time: 16.403831005096436\n",
      "VALI: Epoch: 34, Steps: 170 | Train Loss: 0.1125410  Vali Loss: 0.1573349 Vali Accuracy: 0.9207900  Vali weighted F1: 0.9206375  Vali macro F1 0.9026953 \n",
      "EarlyStopping counter: 1 out of 15\n",
      "Learning rate adjusting counter: 1 out of 5\n",
      "Epoch: 35 cost time: 16.335970640182495\n",
      "VALI: Epoch: 35, Steps: 170 | Train Loss: 0.1113082  Vali Loss: 0.1564837 Vali Accuracy: 0.9195426  Vali weighted F1: 0.9191709  Vali macro F1 0.9007068 \n",
      "EarlyStopping counter: 2 out of 15\n",
      "Learning rate adjusting counter: 2 out of 5\n",
      "Epoch: 36 cost time: 16.327245950698853\n",
      "VALI: Epoch: 36, Steps: 170 | Train Loss: 0.1106450  Vali Loss: 0.1546137 Vali Accuracy: 0.9216216  Vali weighted F1: 0.9213086  Vali macro F1 0.9036138 \n",
      "new best score!!!!\n",
      "Validation loss decreased (0.156337 --> 0.154614).  Saving model ...\n",
      "new best score!!!!\n",
      "Epoch: 37 cost time: 16.407181978225708\n",
      "VALI: Epoch: 37, Steps: 170 | Train Loss: 0.1104123  Vali Loss: 0.1564319 Vali Accuracy: 0.9216216  Vali weighted F1: 0.9212057  Vali macro F1 0.9039936 \n",
      "EarlyStopping counter: 1 out of 15\n",
      "Learning rate adjusting counter: 1 out of 5\n",
      "Epoch: 38 cost time: 16.318060159683228\n",
      "VALI: Epoch: 38, Steps: 170 | Train Loss: 0.1097947  Vali Loss: 0.1553305 Vali Accuracy: 0.9203742  Vali weighted F1: 0.9206522  Vali macro F1 0.9025287 \n",
      "EarlyStopping counter: 2 out of 15\n",
      "Learning rate adjusting counter: 2 out of 5\n",
      "Epoch: 39 cost time: 16.318927764892578\n",
      "VALI: Epoch: 39, Steps: 170 | Train Loss: 0.1082882  Vali Loss: 0.1565689 Vali Accuracy: 0.9216216  Vali weighted F1: 0.9215819  Vali macro F1 0.9036250 \n",
      "EarlyStopping counter: 3 out of 15\n",
      "Learning rate adjusting counter: 3 out of 5\n",
      "Epoch: 40 cost time: 16.375378131866455\n",
      "VALI: Epoch: 40, Steps: 170 | Train Loss: 0.1078838  Vali Loss: 0.1554268 Vali Accuracy: 0.9216216  Vali weighted F1: 0.9210592  Vali macro F1 0.9033840 \n",
      "EarlyStopping counter: 4 out of 15\n",
      "Learning rate adjusting counter: 4 out of 5\n",
      "Epoch: 41 cost time: 16.298845052719116\n",
      "VALI: Epoch: 41, Steps: 170 | Train Loss: 0.1070952  Vali Loss: 0.1559127 Vali Accuracy: 0.9189189  Vali weighted F1: 0.9174658  Vali macro F1 0.8990413 \n",
      "EarlyStopping counter: 5 out of 15\n",
      "Learning rate adjusting counter: 5 out of 5\n",
      "Updating learning rate to 1e-05\n",
      "Epoch: 42 cost time: 16.315924406051636\n",
      "VALI: Epoch: 42, Steps: 170 | Train Loss: 0.1057811  Vali Loss: 0.1551820 Vali Accuracy: 0.9199584  Vali weighted F1: 0.9191685  Vali macro F1 0.9012723 \n",
      "EarlyStopping counter: 6 out of 15\n",
      "Learning rate adjusting counter: 1 out of 5\n",
      "Epoch: 43 cost time: 16.378854036331177\n",
      "VALI: Epoch: 43, Steps: 170 | Train Loss: 0.1067275  Vali Loss: 0.1551608 Vali Accuracy: 0.9195426  Vali weighted F1: 0.9189525  Vali macro F1 0.9010737 \n",
      "EarlyStopping counter: 7 out of 15\n",
      "Learning rate adjusting counter: 2 out of 5\n",
      "Epoch: 44 cost time: 16.304970741271973\n",
      "VALI: Epoch: 44, Steps: 170 | Train Loss: 0.1058693  Vali Loss: 0.1554678 Vali Accuracy: 0.9199584  Vali weighted F1: 0.9193207  Vali macro F1 0.9013888 \n",
      "EarlyStopping counter: 8 out of 15\n",
      "Learning rate adjusting counter: 3 out of 5\n",
      "Epoch: 45 cost time: 16.388770580291748\n",
      "VALI: Epoch: 45, Steps: 170 | Train Loss: 0.1053111  Vali Loss: 0.1550604 Vali Accuracy: 0.9203742  Vali weighted F1: 0.9198443  Vali macro F1 0.9020552 \n",
      "EarlyStopping counter: 9 out of 15\n",
      "Learning rate adjusting counter: 4 out of 5\n",
      "Epoch: 46 cost time: 16.282145738601685\n",
      "VALI: Epoch: 46, Steps: 170 | Train Loss: 0.1060573  Vali Loss: 0.1548473 Vali Accuracy: 0.9205821  Vali weighted F1: 0.9201248  Vali macro F1 0.9023859 \n",
      "EarlyStopping counter: 10 out of 15\n",
      "Learning rate adjusting counter: 5 out of 5\n",
      "Updating learning rate to 1.0000000000000002e-06\n",
      "Epoch: 47 cost time: 16.28603768348694\n",
      "VALI: Epoch: 47, Steps: 170 | Train Loss: 0.1049772  Vali Loss: 0.1548592 Vali Accuracy: 0.9207900  Vali weighted F1: 0.9204000  Vali macro F1 0.9026990 \n",
      "EarlyStopping counter: 11 out of 15\n",
      "Learning rate adjusting counter: 1 out of 5\n",
      "Epoch: 48 cost time: 16.36461615562439\n",
      "VALI: Epoch: 48, Steps: 170 | Train Loss: 0.1050993  Vali Loss: 0.1548425 Vali Accuracy: 0.9205821  Vali weighted F1: 0.9200942  Vali macro F1 0.9021254 \n",
      "EarlyStopping counter: 12 out of 15\n",
      "Learning rate adjusting counter: 2 out of 5\n",
      "Epoch: 49 cost time: 16.274640560150146\n",
      "VALI: Epoch: 49, Steps: 170 | Train Loss: 0.1046349  Vali Loss: 0.1548695 Vali Accuracy: 0.9209979  Vali weighted F1: 0.9205139  Vali macro F1 0.9026804 \n",
      "EarlyStopping counter: 13 out of 15\n",
      "Learning rate adjusting counter: 3 out of 5\n",
      "Epoch: 50 cost time: 16.294623136520386\n",
      "VALI: Epoch: 50, Steps: 170 | Train Loss: 0.1056486  Vali Loss: 0.1548822 Vali Accuracy: 0.9212058  Vali weighted F1: 0.9207383  Vali macro F1 0.9029732 \n",
      "EarlyStopping counter: 14 out of 15\n",
      "Learning rate adjusting counter: 4 out of 5\n",
      "Epoch: 51 cost time: 16.34982395172119\n",
      "VALI: Epoch: 51, Steps: 170 | Train Loss: 0.1048862  Vali Loss: 0.1548418 Vali Accuracy: 0.9209979  Vali weighted F1: 0.9205139  Vali macro F1 0.9026804 \n",
      "EarlyStopping counter: 15 out of 15\n",
      "Early stopping\n",
      "Loading the best validation model!\n",
      "Final Test Performance : Test Accuracy: 0.7918793  Test weighted F1: 0.7873153  Test macro F1 0.7311738 \n",
      "clone the  wavefiler weight\n",
      "Wavelet Filtering Regularization\n",
      "Build the DeepConvLSTM model!\n",
      "Wavelet Filtering Regularization\n",
      "Build the DeepConvLSTM model!\n",
      "------------Fine Tuning  :  1   will be pruned   -----------------------------------------\n",
      "old model Parameter : 194021\n",
      "pruned model Parameter : 197780\n",
      "----------------------------------------------------------------------------------------\n",
      "Fine Tuning Epoch: 1 cost time: 16.2044358253479\n",
      "Fine Tuning VALI: Epoch: 1, Steps: 170 | Train Loss: 0.1103525  Vali Loss: 0.1567316 Vali Accuracy: 0.9214137  Vali weighted F1: 0.9206994  Vali macro F1 0.9027226 \n",
      "Validation loss decreased (inf --> 0.156732).  Saving model ...\n",
      "Fine Tuning Epoch: 2 cost time: 16.207815170288086\n",
      "Fine Tuning VALI: Epoch: 2, Steps: 170 | Train Loss: 0.1093992  Vali Loss: 0.1563699 Vali Accuracy: 0.9207900  Vali weighted F1: 0.9206023  Vali macro F1 0.9030046 \n",
      "new best score!!!!\n",
      "Validation loss decreased (0.156732 --> 0.156370).  Saving model ...\n",
      "new best score!!!!\n",
      "Fine Tuning Epoch: 3 cost time: 16.192351818084717\n",
      "Fine Tuning VALI: Epoch: 3, Steps: 170 | Train Loss: 0.1081686  Vali Loss: 0.1568069 Vali Accuracy: 0.9168399  Vali weighted F1: 0.9164763  Vali macro F1 0.8975389 \n",
      "EarlyStopping counter: 1 out of 15\n",
      "Learning rate adjusting counter: 1 out of 5\n",
      "Fine Tuning Epoch: 4 cost time: 16.253611087799072\n",
      "Fine Tuning VALI: Epoch: 4, Steps: 170 | Train Loss: 0.1083749  Vali Loss: 0.1550338 Vali Accuracy: 0.9203742  Vali weighted F1: 0.9200311  Vali macro F1 0.9019493 \n",
      "new best score!!!!\n",
      "Validation loss decreased (0.156370 --> 0.155034).  Saving model ...\n",
      "new best score!!!!\n",
      "Fine Tuning Epoch: 5 cost time: 16.148676872253418\n",
      "Fine Tuning VALI: Epoch: 5, Steps: 170 | Train Loss: 0.1075142  Vali Loss: 0.1573720 Vali Accuracy: 0.9187110  Vali weighted F1: 0.9179491  Vali macro F1 0.8994399 \n",
      "EarlyStopping counter: 1 out of 15\n",
      "Learning rate adjusting counter: 1 out of 5\n",
      "Fine Tuning Epoch: 6 cost time: 16.157272577285767\n",
      "Fine Tuning VALI: Epoch: 6, Steps: 170 | Train Loss: 0.1062264  Vali Loss: 0.1575114 Vali Accuracy: 0.9182952  Vali weighted F1: 0.9181507  Vali macro F1 0.8996429 \n",
      "EarlyStopping counter: 2 out of 15\n",
      "Learning rate adjusting counter: 2 out of 5\n",
      "Fine Tuning Epoch: 7 cost time: 16.261069774627686\n",
      "Fine Tuning VALI: Epoch: 7, Steps: 170 | Train Loss: 0.1057729  Vali Loss: 0.1579907 Vali Accuracy: 0.9222453  Vali weighted F1: 0.9211347  Vali macro F1 0.9031635 \n",
      "EarlyStopping counter: 3 out of 15\n",
      "Learning rate adjusting counter: 3 out of 5\n",
      "Fine Tuning Epoch: 8 cost time: 16.181476354599\n",
      "Fine Tuning VALI: Epoch: 8, Steps: 170 | Train Loss: 0.1059376  Vali Loss: 0.1569904 Vali Accuracy: 0.9205821  Vali weighted F1: 0.9200309  Vali macro F1 0.9022242 \n",
      "EarlyStopping counter: 4 out of 15\n",
      "Learning rate adjusting counter: 4 out of 5\n",
      "Fine Tuning Epoch: 9 cost time: 16.166179418563843\n",
      "Fine Tuning VALI: Epoch: 9, Steps: 170 | Train Loss: 0.1062760  Vali Loss: 0.1583416 Vali Accuracy: 0.9189189  Vali weighted F1: 0.9183050  Vali macro F1 0.9000601 \n",
      "EarlyStopping counter: 5 out of 15\n",
      "Learning rate adjusting counter: 5 out of 5\n",
      "Updating learning rate to 0.0001\n",
      "Fine Tuning Epoch: 10 cost time: 16.263248443603516\n",
      "Fine Tuning VALI: Epoch: 10, Steps: 170 | Train Loss: 0.1052366  Vali Loss: 0.1571804 Vali Accuracy: 0.9203742  Vali weighted F1: 0.9198671  Vali macro F1 0.9015772 \n",
      "EarlyStopping counter: 6 out of 15\n",
      "Learning rate adjusting counter: 1 out of 5\n",
      "Fine Tuning Epoch: 11 cost time: 16.174601554870605\n",
      "Fine Tuning VALI: Epoch: 11, Steps: 170 | Train Loss: 0.1040284  Vali Loss: 0.1585632 Vali Accuracy: 0.9199584  Vali weighted F1: 0.9196501  Vali macro F1 0.9013579 \n",
      "EarlyStopping counter: 7 out of 15\n",
      "Learning rate adjusting counter: 2 out of 5\n",
      "Fine Tuning Epoch: 12 cost time: 16.23838472366333\n",
      "Fine Tuning VALI: Epoch: 12, Steps: 170 | Train Loss: 0.1038233  Vali Loss: 0.1560823 Vali Accuracy: 0.9226611  Vali weighted F1: 0.9217965  Vali macro F1 0.9037131 \n",
      "EarlyStopping counter: 8 out of 15\n",
      "Learning rate adjusting counter: 3 out of 5\n",
      "Fine Tuning Epoch: 13 cost time: 16.189204931259155\n",
      "Fine Tuning VALI: Epoch: 13, Steps: 170 | Train Loss: 0.1037509  Vali Loss: 0.1542173 Vali Accuracy: 0.9214137  Vali weighted F1: 0.9208520  Vali macro F1 0.9032637 \n",
      "new best score!!!!\n",
      "Validation loss decreased (0.155034 --> 0.154217).  Saving model ...\n",
      "new best score!!!!\n",
      "Fine Tuning Epoch: 14 cost time: 16.166154146194458\n",
      "Fine Tuning VALI: Epoch: 14, Steps: 170 | Train Loss: 0.1035607  Vali Loss: 0.1539865 Vali Accuracy: 0.9220374  Vali weighted F1: 0.9212355  Vali macro F1 0.9035210 \n",
      "new best score!!!!\n",
      "Validation loss decreased (0.154217 --> 0.153986).  Saving model ...\n",
      "new best score!!!!\n",
      "Fine Tuning Epoch: 15 cost time: 16.251685857772827\n",
      "Fine Tuning VALI: Epoch: 15, Steps: 170 | Train Loss: 0.1027837  Vali Loss: 0.1561231 Vali Accuracy: 0.9212058  Vali weighted F1: 0.9207571  Vali macro F1 0.9023803 \n",
      "EarlyStopping counter: 1 out of 15\n",
      "Learning rate adjusting counter: 1 out of 5\n",
      "Fine Tuning Epoch: 16 cost time: 16.1614031791687\n",
      "Fine Tuning VALI: Epoch: 16, Steps: 170 | Train Loss: 0.1048159  Vali Loss: 0.1541858 Vali Accuracy: 0.9224532  Vali weighted F1: 0.9222305  Vali macro F1 0.9042721 \n",
      "EarlyStopping counter: 2 out of 15\n",
      "Learning rate adjusting counter: 2 out of 5\n",
      "Fine Tuning Epoch: 17 cost time: 16.144453287124634\n",
      "Fine Tuning VALI: Epoch: 17, Steps: 170 | Train Loss: 0.1034618  Vali Loss: 0.1565332 Vali Accuracy: 0.9214137  Vali weighted F1: 0.9211037  Vali macro F1 0.9030830 \n",
      "EarlyStopping counter: 3 out of 15\n",
      "Learning rate adjusting counter: 3 out of 5\n",
      "Fine Tuning Epoch: 18 cost time: 16.240434646606445\n",
      "Fine Tuning VALI: Epoch: 18, Steps: 170 | Train Loss: 0.1018602  Vali Loss: 0.1566084 Vali Accuracy: 0.9216216  Vali weighted F1: 0.9207363  Vali macro F1 0.9030169 \n",
      "EarlyStopping counter: 4 out of 15\n",
      "Learning rate adjusting counter: 4 out of 5\n",
      "Fine Tuning Epoch: 19 cost time: 16.11653423309326\n",
      "Fine Tuning VALI: Epoch: 19, Steps: 170 | Train Loss: 0.1015049  Vali Loss: 0.1570277 Vali Accuracy: 0.9214137  Vali weighted F1: 0.9208528  Vali macro F1 0.9029690 \n",
      "EarlyStopping counter: 5 out of 15\n",
      "Learning rate adjusting counter: 5 out of 5\n",
      "Updating learning rate to 1e-05\n",
      "Fine Tuning Epoch: 20 cost time: 16.1544291973114\n",
      "Fine Tuning VALI: Epoch: 20, Steps: 170 | Train Loss: 0.0996364  Vali Loss: 0.1550551 Vali Accuracy: 0.9234927  Vali weighted F1: 0.9231166  Vali macro F1 0.9052224 \n",
      "EarlyStopping counter: 6 out of 15\n",
      "Learning rate adjusting counter: 1 out of 5\n"
     ]
    }
   ],
   "source": [
    "for seed in [1,2,3,4,5]:\n",
    "    args.seed = seed\n",
    "    exp = Exp(args)\n",
    "    exp.train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "85dd817c-865b-4ef9-9cfb-b73b3da137af",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "iswc",
   "language": "python",
   "name": "iswc"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.13"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": true
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
