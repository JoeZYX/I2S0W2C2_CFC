{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "894e2c21",
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "import sys\n",
    "sys.path.append(\"../../\")\n",
    "\n",
    "from experiment import Exp\n",
    "\n",
    "from dataloaders import data_set,data_dict\n",
    "import torch\n",
    "import yaml\n",
    "import os"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bcc56bc7",
   "metadata": {},
   "source": [
    "# 参数设置"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dcc5bcbc",
   "metadata": {},
   "source": [
    "# 训练参数 \n",
    "除了路径 其他不要变"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "86004ce0",
   "metadata": {},
   "outputs": [],
   "source": [
    "class dotdict(dict):\n",
    "    \"\"\"dot.notation access to dictionary attributes\"\"\"\n",
    "    __getattr__ = dict.get\n",
    "    __setattr__ = dict.__setitem__\n",
    "    __delattr__ = dict.__delitem__\n",
    "\n",
    "args = dotdict()   \n",
    "# TODO change the path as relative path\n",
    "args.to_save_path     = r\"E:\\TECO_Works\\Conference\\ISWC2022\\Run_logs\"              \n",
    "args.freq_save_path   = r\"E:\\TECO_Works\\Conference\\ISWC2022\\Freq_data\"\n",
    "args.window_save_path = r\"E:\\TECO_Works\\Conference\\ISWC2022\\Sliding_window\"\n",
    "args.root_path        = r\"E:\\datasets\"\n",
    "\n",
    "\n",
    "args.drop_transition  = False\n",
    "args.datanorm_type    = \"standardization\" # None ,\"standardization\", \"minmax\"\n",
    "\n",
    "\n",
    "args.batch_size       = 256                                                     \n",
    "args.shuffle          = True\n",
    "args.drop_last        = False\n",
    "args.train_vali_quote = 0.90                                           \n",
    "\n",
    "\n",
    "# training setting \n",
    "args.train_epochs            = 150\n",
    "\n",
    "args.learning_rate           = 0.001  \n",
    "args.learning_rate_patience  = 7\n",
    "args.learning_rate_factor    = 0.1\n",
    "\n",
    "\n",
    "args.early_stop_patience     = 15\n",
    "\n",
    "args.use_gpu                 = True if torch.cuda.is_available() else False\n",
    "args.gpu                     = 0\n",
    "args.use_multi_gpu           = False\n",
    "\n",
    "args.optimizer               = \"Adam\"\n",
    "args.criterion               = \"CrossEntropy\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c282cbcb",
   "metadata": {},
   "source": [
    "## 数据参数\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "c6cd147b",
   "metadata": {},
   "outputs": [],
   "source": [
    "args.seed                             = 1\n",
    "\n",
    "\n",
    "args.data_name                        =  \"wisdm\"\n",
    "\n",
    "args.wavelet_filtering                = False\n",
    "args.wavelet_filtering_regularization = False\n",
    "args.wavelet_filtering_finetuning     = False\n",
    "args.wavelet_filtering_finetuning_percent = 0.5\n",
    "args.wavelet_filtering_learnable      = False\n",
    "args.wavelet_filtering_layernorm      = False\n",
    "\n",
    "args.regulatization_tradeoff          = 0\n",
    "args.number_wavelet_filtering         = 6\n",
    "\n",
    "\n",
    "args.difference       = False \n",
    "args.filtering        =  False\n",
    "args.magnitude        =  False\n",
    "args.weighted_sampler = False\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "args.pos_select       = None\n",
    "args.sensor_select    = None\n",
    "\n",
    "\n",
    "args.representation_type = \"time\"\n",
    "args.exp_mode            = \"LOCV\"\n",
    "if args.data_name      ==  \"skodar\":\n",
    "    args.exp_mode            = \"SOCV\"\n",
    "config_file = open('../../configs/data.yaml', mode='r')\n",
    "data_config = yaml.load(config_file, Loader=yaml.FullLoader)\n",
    "config = data_config[args.data_name]\n",
    "\n",
    "args.root_path       = os.path.join(args.root_path,config[\"filename\"])\n",
    "args.sampling_freq   = config[\"sampling_freq\"]\n",
    "args.num_classes     =  config[\"num_classes\"]\n",
    "window_seconds       = config[\"window_seconds\"]\n",
    "args.windowsize      =   int(window_seconds * args.sampling_freq) \n",
    "args.input_length    =  args.windowsize\n",
    "# input information\n",
    "args.c_in            = config[\"num_channels\"]\n",
    "\n",
    "\n",
    "if args.difference:\n",
    "    args.c_in = args.c_in*2\n",
    "\n",
    "if args.wavelet_filtering :\n",
    "    \n",
    "    if args.windowsize%2==1:\n",
    "        N_ds = int(torch.log2(torch.tensor(args.windowsize-1)).floor()) - 2\n",
    "    else:\n",
    "        N_ds = int(torch.log2(torch.tensor(args.windowsize)).floor()) - 2\n",
    "\n",
    "    args.f_in            =  args.number_wavelet_filtering*N_ds+1\n",
    "else:\n",
    "    args.f_in            =  1\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4d435a4c",
   "metadata": {},
   "source": [
    "## 模型参数"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "de2f4d16",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Use GPU: cuda:0\n",
      "Build the deepconvlstm_attn model!\n",
      "Done!\n",
      "Parameter : 24214\n",
      "Set the seed as :  1\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "model_builder(\n",
       "  (model): DeepConvLSTM_ATTN(\n",
       "    (conv_blocks): ModuleList(\n",
       "      (0): ConvBlock(\n",
       "        (conv1): Conv2d(1, 16, kernel_size=(5, 1), stride=(1, 1))\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(16, 16, kernel_size=(5, 1), stride=(2, 1))\n",
       "      )\n",
       "      (1): ConvBlock(\n",
       "        (conv1): Conv2d(16, 16, kernel_size=(5, 1), stride=(1, 1))\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(16, 16, kernel_size=(5, 1), stride=(2, 1))\n",
       "      )\n",
       "    )\n",
       "    (lstm_layers): ModuleList(\n",
       "      (0): LSTM(48, 32, batch_first=True)\n",
       "      (1): LSTM(32, 32, batch_first=True)\n",
       "    )\n",
       "    (dropout): Dropout(p=0.5, inplace=False)\n",
       "    (linear_1): Linear(in_features=32, out_features=32, bias=True)\n",
       "    (tanh): Tanh()\n",
       "    (dropout_2): Dropout(p=0.2, inplace=False)\n",
       "    (linear_2): Linear(in_features=32, out_features=1, bias=False)\n",
       "    (fc): Linear(in_features=32, out_features=6, bias=True)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "args.filter_scaling_factor = 0.25\n",
    "args.model_type              = \"deepconvlstm_attn\"#\"deepconvlstm\"#\"sahar\" #\"deepconvlstm\"\n",
    "exp = Exp(args)\n",
    "exp.model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "bc1595a6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# cross_channel_interaction_type = \"attn\",    # attn  transformer  identity\n",
    "# cross_channel_aggregation_type = \"filter\",  # filter  naive  FC  \"SFCC\", \"SFCF\"\n",
    "# temporal_info_interaction_type = \"gru\",     # gru  lstm  attn  transformer  identity  conv\n",
    "# temporal_info_aggregation_type = \"FC\",      # naive  filter  FC  tnaive"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cada66dd",
   "metadata": {},
   "source": [
    "# 实验"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "2e3f2fad",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Use GPU: cuda:0\n",
      "Build the TinyHAR model!\n",
      "Done!\n",
      "Parameter : 370082\n",
      "Set the seed as :  1\n"
     ]
    }
   ],
   "source": [
    "# 如果我们设置为 \n",
    "\n",
    "\n",
    "args.model_type              = \"tinyhar\"#\"deepconvlstm\"#\"sahar\" #\"deepconvlstm\"\n",
    "\n",
    "args.cross_channel_interaction_type = \"attn\"\n",
    "args.cross_channel_aggregation_type = \"FC\"\n",
    "args.temporal_info_interaction_type = \"lstm\"\n",
    "args.temporal_info_aggregation_type = \"tnaive\"\n",
    "\n",
    "exp = Exp(args)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "20d58f10",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "model_builder(\n",
       "  (model): TinyHAR_Model(\n",
       "    (layers_conv): ModuleList(\n",
       "      (0): Sequential(\n",
       "        (0): Conv2d(1, 26, kernel_size=(5, 1), stride=(2, 1))\n",
       "        (1): ReLU(inplace=True)\n",
       "        (2): BatchNorm2d(26, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "      (1): Sequential(\n",
       "        (0): Conv2d(26, 26, kernel_size=(5, 1), stride=(2, 1))\n",
       "        (1): ReLU(inplace=True)\n",
       "        (2): BatchNorm2d(26, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "      (2): Sequential(\n",
       "        (0): Conv2d(26, 26, kernel_size=(5, 1), stride=(2, 1))\n",
       "        (1): ReLU(inplace=True)\n",
       "        (2): BatchNorm2d(26, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "      (3): Sequential(\n",
       "        (0): Conv2d(26, 26, kernel_size=(5, 1), stride=(2, 1))\n",
       "        (1): ReLU(inplace=True)\n",
       "        (2): BatchNorm2d(26, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "    )\n",
       "    (channel_interaction): SelfAttention_interaction(\n",
       "      (query): Linear(in_features=26, out_features=26, bias=False)\n",
       "      (key): Linear(in_features=26, out_features=26, bias=False)\n",
       "      (value): Linear(in_features=26, out_features=26, bias=False)\n",
       "    )\n",
       "    (channel_fusion): FC(\n",
       "      (fc): Linear(in_features=1170, out_features=52, bias=True)\n",
       "    )\n",
       "    (activation): ReLU()\n",
       "    (temporal_interaction): temporal_LSTM(\n",
       "      (lstm): LSTM(52, 52, batch_first=True)\n",
       "    )\n",
       "    (dropout): Dropout(p=0.1, inplace=False)\n",
       "    (temporal_fusion): Temporal_Weighted_Aggregation(\n",
       "      (fc_1): Linear(in_features=52, out_features=52, bias=True)\n",
       "      (weighs_activation): Tanh()\n",
       "      (fc_2): Linear(in_features=52, out_features=1, bias=False)\n",
       "      (sm): Softmax(dim=1)\n",
       "    )\n",
       "    (prediction): Linear(in_features=52, out_features=19, bias=True)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "exp.model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "f8aed663",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " ----------------------- load all the data -------------------\n",
      "-----------------------Sliding file are generated -----------------------\n",
      "-----------------------Sliding file are generated -----------------------\n",
      "================ LOCV Mode ====================\n",
      "================ 10 CV ======================\n",
      "================ the 0 th CV Experiment ================ \n",
      "Leave one Out Experiment : The 1 Part as the test\n",
      "[-] Target sampling weights:  [0.0001465  0.000181   0.00097182 0.00123001 0.0004852  0.00060716]\n",
      "Train data number :  17901\n",
      "The number of classes is :  6\n",
      "The input_length  is :  100\n",
      "The channel_in is :  3\n",
      "Validation data number :  1989\n",
      "Test data number :  9947\n",
      "================ Build the model ================ \n",
      "Build the deepconvlstm_attn model!\n",
      "Epoch: 1 cost time: 8.872799396514893\n",
      "VALI: Epoch: 1, Steps: 70 | Train Loss: 1.4261068  Vali Loss: 0.9187394 Vali Accuracy: 0.6666667  Vali weighted F1: 0.5601250  Vali macro F1 0.2728398 \n",
      "Validation loss decreased (inf --> 0.918739).  Saving model ...\n",
      "Epoch: 2 cost time: 5.911638975143433\n",
      "VALI: Epoch: 2, Steps: 70 | Train Loss: 0.7448222  Vali Loss: 0.6180082 Vali Accuracy: 0.8044243  Vali weighted F1: 0.7610832  Vali macro F1 0.6626473 \n",
      "new best score!!!!\n",
      "Validation loss decreased (0.918739 --> 0.618008).  Saving model ...\n",
      "new best score!!!!\n",
      "Epoch: 3 cost time: 5.9561240673065186\n",
      "VALI: Epoch: 3, Steps: 70 | Train Loss: 0.5380621  Vali Loss: 0.4813532 Vali Accuracy: 0.8285571  Vali weighted F1: 0.7991938  Vali macro F1 0.7322538 \n",
      "new best score!!!!\n",
      "Validation loss decreased (0.618008 --> 0.481353).  Saving model ...\n",
      "new best score!!!!\n",
      "Epoch: 4 cost time: 5.952929496765137\n",
      "VALI: Epoch: 4, Steps: 70 | Train Loss: 0.4530909  Vali Loss: 0.4340987 Vali Accuracy: 0.8441428  Vali weighted F1: 0.8267667  Vali macro F1 0.7741428 \n",
      "new best score!!!!\n",
      "Validation loss decreased (0.481353 --> 0.434099).  Saving model ...\n",
      "new best score!!!!\n",
      "Epoch: 5 cost time: 5.9069647789001465\n",
      "VALI: Epoch: 5, Steps: 70 | Train Loss: 0.4261591  Vali Loss: 0.4241734 Vali Accuracy: 0.8506787  Vali weighted F1: 0.8308367  Vali macro F1 0.7838883 \n",
      "new best score!!!!\n",
      "Validation loss decreased (0.434099 --> 0.424173).  Saving model ...\n",
      "new best score!!!!\n",
      "Epoch: 6 cost time: 5.859914541244507\n",
      "VALI: Epoch: 6, Steps: 70 | Train Loss: 0.4024689  Vali Loss: 0.4069874 Vali Accuracy: 0.8521870  Vali weighted F1: 0.8391677  Vali macro F1 0.7916222 \n",
      "new best score!!!!\n",
      "Validation loss decreased (0.424173 --> 0.406987).  Saving model ...\n",
      "new best score!!!!\n",
      "Epoch: 7 cost time: 5.901015043258667\n",
      "VALI: Epoch: 7, Steps: 70 | Train Loss: 0.3906465  Vali Loss: 0.3835403 Vali Accuracy: 0.8602313  Vali weighted F1: 0.8453813  Vali macro F1 0.8033719 \n",
      "new best score!!!!\n",
      "Validation loss decreased (0.406987 --> 0.383540).  Saving model ...\n",
      "new best score!!!!\n",
      "Epoch: 8 cost time: 5.9242424964904785\n",
      "VALI: Epoch: 8, Steps: 70 | Train Loss: 0.3675731  Vali Loss: 0.3518409 Vali Accuracy: 0.8788336  Vali weighted F1: 0.8731358  Vali macro F1 0.8457736 \n",
      "new best score!!!!\n",
      "Validation loss decreased (0.383540 --> 0.351841).  Saving model ...\n",
      "new best score!!!!\n",
      "Epoch: 9 cost time: 5.9648497104644775\n",
      "VALI: Epoch: 9, Steps: 70 | Train Loss: 0.3488516  Vali Loss: 0.3371263 Vali Accuracy: 0.8813474  Vali weighted F1: 0.8763545  Vali macro F1 0.8525594 \n",
      "new best score!!!!\n",
      "Validation loss decreased (0.351841 --> 0.337126).  Saving model ...\n",
      "new best score!!!!\n",
      "Epoch: 10 cost time: 5.921966314315796\n",
      "VALI: Epoch: 10, Steps: 70 | Train Loss: 0.3331916  Vali Loss: 0.3589924 Vali Accuracy: 0.8677728  Vali weighted F1: 0.8624862  Vali macro F1 0.8295452 \n",
      "EarlyStopping counter: 1 out of 15\n",
      "Learning rate adjusting counter: 1 out of 7\n",
      "Epoch: 11 cost time: 5.881261110305786\n",
      "VALI: Epoch: 11, Steps: 70 | Train Loss: 0.3239874  Vali Loss: 0.3111861 Vali Accuracy: 0.8914027  Vali weighted F1: 0.8865235  Vali macro F1 0.8642998 \n",
      "new best score!!!!\n",
      "Validation loss decreased (0.337126 --> 0.311186).  Saving model ...\n",
      "new best score!!!!\n",
      "Epoch: 12 cost time: 5.924992799758911\n",
      "VALI: Epoch: 12, Steps: 70 | Train Loss: 0.2977879  Vali Loss: 0.3216272 Vali Accuracy: 0.8773253  Vali weighted F1: 0.8716943  Vali macro F1 0.8421023 \n",
      "EarlyStopping counter: 1 out of 15\n",
      "Learning rate adjusting counter: 1 out of 7\n",
      "Epoch: 13 cost time: 5.98807430267334\n",
      "VALI: Epoch: 13, Steps: 70 | Train Loss: 0.2781627  Vali Loss: 0.2979203 Vali Accuracy: 0.8888889  Vali weighted F1: 0.8826354  Vali macro F1 0.8548702 \n",
      "new best score!!!!\n",
      "Validation loss decreased (0.311186 --> 0.297920).  Saving model ...\n",
      "new best score!!!!\n",
      "Epoch: 14 cost time: 5.99836277961731\n",
      "VALI: Epoch: 14, Steps: 70 | Train Loss: 0.2612923  Vali Loss: 0.2389751 Vali Accuracy: 0.9180493  Vali weighted F1: 0.9154967  Vali macro F1 0.8952392 \n",
      "new best score!!!!\n",
      "Validation loss decreased (0.297920 --> 0.238975).  Saving model ...\n",
      "new best score!!!!\n",
      "Epoch: 15 cost time: 5.9258997440338135\n",
      "VALI: Epoch: 15, Steps: 70 | Train Loss: 0.2468788  Vali Loss: 0.2296893 Vali Accuracy: 0.9205631  Vali weighted F1: 0.9183022  Vali macro F1 0.9001899 \n",
      "new best score!!!!\n",
      "Validation loss decreased (0.238975 --> 0.229689).  Saving model ...\n",
      "new best score!!!!\n",
      "Epoch: 16 cost time: 5.893884181976318\n",
      "VALI: Epoch: 16, Steps: 70 | Train Loss: 0.2329619  Vali Loss: 0.2159429 Vali Accuracy: 0.9245852  Vali weighted F1: 0.9227827  Vali macro F1 0.9018739 \n",
      "new best score!!!!\n",
      "Validation loss decreased (0.229689 --> 0.215943).  Saving model ...\n",
      "new best score!!!!\n",
      "Epoch: 17 cost time: 5.868209362030029\n",
      "VALI: Epoch: 17, Steps: 70 | Train Loss: 0.2193251  Vali Loss: 0.1985424 Vali Accuracy: 0.9306184  Vali weighted F1: 0.9291178  Vali macro F1 0.9082231 \n",
      "new best score!!!!\n",
      "Validation loss decreased (0.215943 --> 0.198542).  Saving model ...\n",
      "new best score!!!!\n",
      "Epoch: 18 cost time: 5.903625965118408\n",
      "VALI: Epoch: 18, Steps: 70 | Train Loss: 0.2118217  Vali Loss: 0.1992649 Vali Accuracy: 0.9306184  Vali weighted F1: 0.9291723  Vali macro F1 0.9076221 \n",
      "EarlyStopping counter: 1 out of 15\n",
      "Learning rate adjusting counter: 1 out of 7\n",
      "Epoch: 19 cost time: 5.911926507949829\n",
      "VALI: Epoch: 19, Steps: 70 | Train Loss: 0.2023352  Vali Loss: 0.1832022 Vali Accuracy: 0.9391654  Vali weighted F1: 0.9393634  Vali macro F1 0.9219313 \n",
      "new best score!!!!\n",
      "Validation loss decreased (0.198542 --> 0.183202).  Saving model ...\n",
      "new best score!!!!\n",
      "Epoch: 20 cost time: 5.946325302124023\n",
      "VALI: Epoch: 20, Steps: 70 | Train Loss: 0.2010241  Vali Loss: 0.2090030 Vali Accuracy: 0.9286073  Vali weighted F1: 0.9254665  Vali macro F1 0.9029785 \n",
      "EarlyStopping counter: 1 out of 15\n",
      "Learning rate adjusting counter: 1 out of 7\n",
      "Epoch: 21 cost time: 5.887198209762573\n",
      "VALI: Epoch: 21, Steps: 70 | Train Loss: 0.1839095  Vali Loss: 0.1799007 Vali Accuracy: 0.9376571  Vali weighted F1: 0.9377839  Vali macro F1 0.9200112 \n",
      "new best score!!!!\n",
      "Validation loss decreased (0.183202 --> 0.179901).  Saving model ...\n",
      "new best score!!!!\n",
      "Epoch: 22 cost time: 5.867222547531128\n",
      "VALI: Epoch: 22, Steps: 70 | Train Loss: 0.1740445  Vali Loss: 0.1676881 Vali Accuracy: 0.9457014  Vali weighted F1: 0.9460148  Vali macro F1 0.9291448 \n",
      "new best score!!!!\n",
      "Validation loss decreased (0.179901 --> 0.167688).  Saving model ...\n",
      "new best score!!!!\n",
      "Epoch: 23 cost time: 5.960291624069214\n",
      "VALI: Epoch: 23, Steps: 70 | Train Loss: 0.1699769  Vali Loss: 0.1534633 Vali Accuracy: 0.9487179  Vali weighted F1: 0.9489446  Vali macro F1 0.9309055 \n",
      "new best score!!!!\n",
      "Validation loss decreased (0.167688 --> 0.153463).  Saving model ...\n",
      "new best score!!!!\n",
      "Epoch: 24 cost time: 5.9759581089019775\n",
      "VALI: Epoch: 24, Steps: 70 | Train Loss: 0.1625227  Vali Loss: 0.1528881 Vali Accuracy: 0.9487179  Vali weighted F1: 0.9483215  Vali macro F1 0.9351078 \n",
      "new best score!!!!\n",
      "Validation loss decreased (0.153463 --> 0.152888).  Saving model ...\n",
      "new best score!!!!\n",
      "Epoch: 25 cost time: 5.842911958694458\n",
      "VALI: Epoch: 25, Steps: 70 | Train Loss: 0.1638170  Vali Loss: 0.1667181 Vali Accuracy: 0.9386626  Vali weighted F1: 0.9372071  Vali macro F1 0.9215179 \n",
      "EarlyStopping counter: 1 out of 15\n",
      "Learning rate adjusting counter: 1 out of 7\n",
      "Epoch: 26 cost time: 5.894514083862305\n",
      "VALI: Epoch: 26, Steps: 70 | Train Loss: 0.1554409  Vali Loss: 0.1561837 Vali Accuracy: 0.9477124  Vali weighted F1: 0.9471762  Vali macro F1 0.9302978 \n",
      "EarlyStopping counter: 2 out of 15\n",
      "Learning rate adjusting counter: 2 out of 7\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 27 cost time: 5.887208938598633\n",
      "VALI: Epoch: 27, Steps: 70 | Train Loss: 0.1490125  Vali Loss: 0.1374897 Vali Accuracy: 0.9557567  Vali weighted F1: 0.9557492  Vali macro F1 0.9429980 \n",
      "new best score!!!!\n",
      "Validation loss decreased (0.152888 --> 0.137490).  Saving model ...\n",
      "new best score!!!!\n",
      "Epoch: 28 cost time: 5.914208650588989\n",
      "VALI: Epoch: 28, Steps: 70 | Train Loss: 0.1451581  Vali Loss: 0.1515220 Vali Accuracy: 0.9487179  Vali weighted F1: 0.9489136  Vali macro F1 0.9274779 \n",
      "EarlyStopping counter: 1 out of 15\n",
      "Learning rate adjusting counter: 1 out of 7\n",
      "Epoch: 29 cost time: 5.895998001098633\n",
      "VALI: Epoch: 29, Steps: 70 | Train Loss: 0.1435276  Vali Loss: 0.1531321 Vali Accuracy: 0.9487179  Vali weighted F1: 0.9489196  Vali macro F1 0.9374913 \n",
      "EarlyStopping counter: 2 out of 15\n",
      "Learning rate adjusting counter: 2 out of 7\n",
      "Epoch: 30 cost time: 5.94869065284729\n",
      "VALI: Epoch: 30, Steps: 70 | Train Loss: 0.1426989  Vali Loss: 0.1392635 Vali Accuracy: 0.9537456  Vali weighted F1: 0.9529937  Vali macro F1 0.9412876 \n",
      "EarlyStopping counter: 3 out of 15\n",
      "Learning rate adjusting counter: 3 out of 7\n",
      "Epoch: 31 cost time: 5.960584878921509\n",
      "VALI: Epoch: 31, Steps: 70 | Train Loss: 0.1322153  Vali Loss: 0.1329802 Vali Accuracy: 0.9527401  Vali weighted F1: 0.9523147  Vali macro F1 0.9401294 \n",
      "new best score!!!!\n",
      "Validation loss decreased (0.137490 --> 0.132980).  Saving model ...\n",
      "new best score!!!!\n",
      "Epoch: 32 cost time: 5.968915224075317\n",
      "VALI: Epoch: 32, Steps: 70 | Train Loss: 0.1361198  Vali Loss: 0.1319634 Vali Accuracy: 0.9572650  Vali weighted F1: 0.9568695  Vali macro F1 0.9452942 \n",
      "new best score!!!!\n",
      "Validation loss decreased (0.132980 --> 0.131963).  Saving model ...\n",
      "new best score!!!!\n",
      "Epoch: 33 cost time: 6.023652791976929\n",
      "VALI: Epoch: 33, Steps: 70 | Train Loss: 0.1357623  Vali Loss: 0.1118857 Vali Accuracy: 0.9648064  Vali weighted F1: 0.9648045  Vali macro F1 0.9574366 \n",
      "new best score!!!!\n",
      "Validation loss decreased (0.131963 --> 0.111886).  Saving model ...\n",
      "new best score!!!!\n",
      "Epoch: 34 cost time: 5.962932586669922\n",
      "VALI: Epoch: 34, Steps: 70 | Train Loss: 0.1268404  Vali Loss: 0.1214988 Vali Accuracy: 0.9552539  Vali weighted F1: 0.9550329  Vali macro F1 0.9438883 \n",
      "EarlyStopping counter: 1 out of 15\n",
      "Learning rate adjusting counter: 1 out of 7\n",
      "Epoch: 35 cost time: 5.90973973274231\n",
      "VALI: Epoch: 35, Steps: 70 | Train Loss: 0.1195985  Vali Loss: 0.1768134 Vali Accuracy: 0.9356461  Vali weighted F1: 0.9363455  Vali macro F1 0.9271611 \n",
      "EarlyStopping counter: 2 out of 15\n",
      "Learning rate adjusting counter: 2 out of 7\n",
      "Epoch: 36 cost time: 5.9628989696502686\n",
      "VALI: Epoch: 36, Steps: 70 | Train Loss: 0.1230429  Vali Loss: 0.1287622 Vali Accuracy: 0.9567622  Vali weighted F1: 0.9567876  Vali macro F1 0.9448807 \n",
      "EarlyStopping counter: 3 out of 15\n",
      "Learning rate adjusting counter: 3 out of 7\n",
      "Epoch: 37 cost time: 6.026014566421509\n",
      "VALI: Epoch: 37, Steps: 70 | Train Loss: 0.1235479  Vali Loss: 0.1218504 Vali Accuracy: 0.9582705  Vali weighted F1: 0.9584977  Vali macro F1 0.9474184 \n",
      "EarlyStopping counter: 4 out of 15\n",
      "Learning rate adjusting counter: 4 out of 7\n",
      "Epoch: 38 cost time: 5.890348434448242\n",
      "VALI: Epoch: 38, Steps: 70 | Train Loss: 0.1145475  Vali Loss: 0.1266735 Vali Accuracy: 0.9572650  Vali weighted F1: 0.9574238  Vali macro F1 0.9437955 \n",
      "EarlyStopping counter: 5 out of 15\n",
      "Learning rate adjusting counter: 5 out of 7\n",
      "Epoch: 39 cost time: 5.899155855178833\n",
      "VALI: Epoch: 39, Steps: 70 | Train Loss: 0.1144415  Vali Loss: 0.1138016 Vali Accuracy: 0.9612871  Vali weighted F1: 0.9617183  Vali macro F1 0.9506901 \n",
      "EarlyStopping counter: 6 out of 15\n",
      "Learning rate adjusting counter: 6 out of 7\n",
      "Epoch: 40 cost time: 5.882395505905151\n",
      "VALI: Epoch: 40, Steps: 70 | Train Loss: 0.1101253  Vali Loss: 0.1248590 Vali Accuracy: 0.9572650  Vali weighted F1: 0.9578211  Vali macro F1 0.9368998 \n",
      "EarlyStopping counter: 7 out of 15\n",
      "Learning rate adjusting counter: 7 out of 7\n",
      "Updating learning rate to 0.0001\n",
      "Epoch: 41 cost time: 5.893447399139404\n",
      "VALI: Epoch: 41, Steps: 70 | Train Loss: 0.1018622  Vali Loss: 0.1019030 Vali Accuracy: 0.9673203  Vali weighted F1: 0.9674035  Vali macro F1 0.9597911 \n",
      "new best score!!!!\n",
      "Validation loss decreased (0.111886 --> 0.101903).  Saving model ...\n",
      "new best score!!!!\n",
      "Epoch: 42 cost time: 5.850032091140747\n",
      "VALI: Epoch: 42, Steps: 70 | Train Loss: 0.0990141  Vali Loss: 0.0995402 Vali Accuracy: 0.9643037  Vali weighted F1: 0.9643852  Vali macro F1 0.9549705 \n",
      "new best score!!!!\n",
      "Validation loss decreased (0.101903 --> 0.099540).  Saving model ...\n",
      "new best score!!!!\n",
      "Epoch: 43 cost time: 5.878974437713623\n",
      "VALI: Epoch: 43, Steps: 70 | Train Loss: 0.0928433  Vali Loss: 0.1005853 Vali Accuracy: 0.9678230  Vali weighted F1: 0.9678331  Vali macro F1 0.9589633 \n",
      "EarlyStopping counter: 1 out of 15\n",
      "Learning rate adjusting counter: 1 out of 7\n",
      "Epoch: 44 cost time: 5.946331739425659\n",
      "VALI: Epoch: 44, Steps: 70 | Train Loss: 0.0976111  Vali Loss: 0.1137221 Vali Accuracy: 0.9602815  Vali weighted F1: 0.9606379  Vali macro F1 0.9530434 \n",
      "EarlyStopping counter: 2 out of 15\n",
      "Learning rate adjusting counter: 2 out of 7\n",
      "Epoch: 45 cost time: 5.8548219203948975\n",
      "VALI: Epoch: 45, Steps: 70 | Train Loss: 0.0949598  Vali Loss: 0.1072761 Vali Accuracy: 0.9648064  Vali weighted F1: 0.9649033  Vali macro F1 0.9570417 \n",
      "EarlyStopping counter: 3 out of 15\n",
      "Learning rate adjusting counter: 3 out of 7\n",
      "Epoch: 46 cost time: 5.839639902114868\n",
      "VALI: Epoch: 46, Steps: 70 | Train Loss: 0.0968919  Vali Loss: 0.0933360 Vali Accuracy: 0.9693313  Vali weighted F1: 0.9693801  Vali macro F1 0.9617407 \n",
      "new best score!!!!\n",
      "Validation loss decreased (0.099540 --> 0.093336).  Saving model ...\n",
      "new best score!!!!\n",
      "Epoch: 47 cost time: 5.883645296096802\n",
      "VALI: Epoch: 47, Steps: 70 | Train Loss: 0.0951826  Vali Loss: 0.1045106 Vali Accuracy: 0.9668175  Vali weighted F1: 0.9668895  Vali macro F1 0.9591471 \n",
      "EarlyStopping counter: 1 out of 15\n",
      "Learning rate adjusting counter: 1 out of 7\n",
      "Epoch: 48 cost time: 5.893888473510742\n",
      "VALI: Epoch: 48, Steps: 70 | Train Loss: 0.0962935  Vali Loss: 0.0980437 Vali Accuracy: 0.9668175  Vali weighted F1: 0.9668970  Vali macro F1 0.9565437 \n",
      "EarlyStopping counter: 2 out of 15\n",
      "Learning rate adjusting counter: 2 out of 7\n",
      "Epoch: 49 cost time: 5.887264728546143\n",
      "VALI: Epoch: 49, Steps: 70 | Train Loss: 0.0978235  Vali Loss: 0.0968695 Vali Accuracy: 0.9683258  Vali weighted F1: 0.9683460  Vali macro F1 0.9592947 \n",
      "EarlyStopping counter: 3 out of 15\n",
      "Learning rate adjusting counter: 3 out of 7\n",
      "Epoch: 50 cost time: 5.871649265289307\n",
      "VALI: Epoch: 50, Steps: 70 | Train Loss: 0.0920576  Vali Loss: 0.1014472 Vali Accuracy: 0.9658120  Vali weighted F1: 0.9659208  Vali macro F1 0.9551895 \n",
      "EarlyStopping counter: 4 out of 15\n",
      "Learning rate adjusting counter: 4 out of 7\n",
      "Epoch: 51 cost time: 5.866617679595947\n",
      "VALI: Epoch: 51, Steps: 70 | Train Loss: 0.0948297  Vali Loss: 0.1000420 Vali Accuracy: 0.9658120  Vali weighted F1: 0.9658966  Vali macro F1 0.9552276 \n",
      "EarlyStopping counter: 5 out of 15\n",
      "Learning rate adjusting counter: 5 out of 7\n",
      "Epoch: 52 cost time: 5.8541975021362305\n",
      "VALI: Epoch: 52, Steps: 70 | Train Loss: 0.0955916  Vali Loss: 0.0988383 Vali Accuracy: 0.9663147  Vali weighted F1: 0.9663999  Vali macro F1 0.9559951 \n",
      "EarlyStopping counter: 6 out of 15\n",
      "Learning rate adjusting counter: 6 out of 7\n",
      "Epoch: 53 cost time: 5.892528057098389\n",
      "VALI: Epoch: 53, Steps: 70 | Train Loss: 0.0906587  Vali Loss: 0.0980829 Vali Accuracy: 0.9653092  Vali weighted F1: 0.9653624  Vali macro F1 0.9569546 \n",
      "EarlyStopping counter: 7 out of 15\n",
      "Learning rate adjusting counter: 7 out of 7\n",
      "Updating learning rate to 1e-05\n",
      "Epoch: 54 cost time: 5.949256181716919\n",
      "VALI: Epoch: 54, Steps: 70 | Train Loss: 0.0904713  Vali Loss: 0.0993395 Vali Accuracy: 0.9643037  Vali weighted F1: 0.9644038  Vali macro F1 0.9548338 \n",
      "EarlyStopping counter: 8 out of 15\n",
      "Learning rate adjusting counter: 1 out of 7\n",
      "Epoch: 55 cost time: 5.844086170196533\n",
      "VALI: Epoch: 55, Steps: 70 | Train Loss: 0.0912466  Vali Loss: 0.1002522 Vali Accuracy: 0.9643037  Vali weighted F1: 0.9644051  Vali macro F1 0.9538037 \n",
      "EarlyStopping counter: 9 out of 15\n",
      "Learning rate adjusting counter: 2 out of 7\n",
      "Epoch: 56 cost time: 5.870774984359741\n",
      "VALI: Epoch: 56, Steps: 70 | Train Loss: 0.0909479  Vali Loss: 0.0995733 Vali Accuracy: 0.9648064  Vali weighted F1: 0.9648851  Vali macro F1 0.9543471 \n",
      "EarlyStopping counter: 10 out of 15\n",
      "Learning rate adjusting counter: 3 out of 7\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 57 cost time: 5.87454628944397\n",
      "VALI: Epoch: 57, Steps: 70 | Train Loss: 0.0930029  Vali Loss: 0.0989069 Vali Accuracy: 0.9648064  Vali weighted F1: 0.9648581  Vali macro F1 0.9540406 \n",
      "EarlyStopping counter: 11 out of 15\n",
      "Learning rate adjusting counter: 4 out of 7\n",
      "Epoch: 58 cost time: 5.8681418895721436\n",
      "VALI: Epoch: 58, Steps: 70 | Train Loss: 0.0905418  Vali Loss: 0.0983680 Vali Accuracy: 0.9658120  Vali weighted F1: 0.9658731  Vali macro F1 0.9553079 \n",
      "EarlyStopping counter: 12 out of 15\n",
      "Learning rate adjusting counter: 5 out of 7\n",
      "Epoch: 59 cost time: 5.841885805130005\n",
      "VALI: Epoch: 59, Steps: 70 | Train Loss: 0.0910993  Vali Loss: 0.0978276 Vali Accuracy: 0.9653092  Vali weighted F1: 0.9653767  Vali macro F1 0.9545238 \n",
      "EarlyStopping counter: 13 out of 15\n",
      "Learning rate adjusting counter: 6 out of 7\n",
      "Epoch: 60 cost time: 5.9304585456848145\n",
      "VALI: Epoch: 60, Steps: 70 | Train Loss: 0.0922838  Vali Loss: 0.0987113 Vali Accuracy: 0.9663147  Vali weighted F1: 0.9663999  Vali macro F1 0.9559951 \n",
      "EarlyStopping counter: 14 out of 15\n",
      "Learning rate adjusting counter: 7 out of 7\n",
      "Updating learning rate to 1.0000000000000002e-06\n",
      "Epoch: 61 cost time: 5.890783786773682\n",
      "VALI: Epoch: 61, Steps: 70 | Train Loss: 0.0921213  Vali Loss: 0.0988217 Vali Accuracy: 0.9663147  Vali weighted F1: 0.9663898  Vali macro F1 0.9557882 \n",
      "EarlyStopping counter: 15 out of 15\n",
      "Early stopping\n",
      "Loading the best validation model!\n",
      "Final Test Performance : Test Accuracy: 0.8134111  Test weighted F1: 0.8218387  Test macro F1 0.7549267 \n",
      "================ the 1 th CV Experiment ================ \n",
      "Leave one Out Experiment : The 2 Part as the test\n",
      "[-] Target sampling weights:  [0.00014928 0.00018305 0.00110011 0.00139082 0.00051151 0.00062189]\n",
      "Train data number :  17353\n",
      "The number of classes is :  6\n",
      "The input_length  is :  100\n",
      "The channel_in is :  3\n",
      "Validation data number :  1929\n",
      "Test data number :  12988\n",
      "================ Build the model ================ \n",
      "Build the deepconvlstm_attn model!\n",
      "Epoch: 1 cost time: 5.839672327041626\n",
      "VALI: Epoch: 1, Steps: 68 | Train Loss: 1.4250411  Vali Loss: 0.9926111 Vali Accuracy: 0.6620010  Vali weighted F1: 0.5468911  Vali macro F1 0.2678441 \n",
      "Validation loss decreased (inf --> 0.992611).  Saving model ...\n",
      "Epoch: 2 cost time: 5.85603141784668\n",
      "VALI: Epoch: 2, Steps: 68 | Train Loss: 0.7851028  Vali Loss: 0.6606988 Vali Accuracy: 0.7662001  Vali weighted F1: 0.7171137  Vali macro F1 0.5377132 \n",
      "new best score!!!!\n",
      "Validation loss decreased (0.992611 --> 0.660699).  Saving model ...\n",
      "new best score!!!!\n",
      "Epoch: 3 cost time: 5.737773656845093\n",
      "VALI: Epoch: 3, Steps: 68 | Train Loss: 0.5599369  Vali Loss: 0.5249437 Vali Accuracy: 0.8170036  Vali weighted F1: 0.7787732  Vali macro F1 0.7101295 \n",
      "new best score!!!!\n",
      "Validation loss decreased (0.660699 --> 0.524944).  Saving model ...\n",
      "new best score!!!!\n",
      "Epoch: 4 cost time: 5.774988889694214\n",
      "VALI: Epoch: 4, Steps: 68 | Train Loss: 0.4802434  Vali Loss: 0.4621151 Vali Accuracy: 0.8330741  Vali weighted F1: 0.8126422  Vali macro F1 0.7564767 \n",
      "new best score!!!!\n",
      "Validation loss decreased (0.524944 --> 0.462115).  Saving model ...\n",
      "new best score!!!!\n",
      "Epoch: 5 cost time: 5.76971960067749\n",
      "VALI: Epoch: 5, Steps: 68 | Train Loss: 0.4288562  Vali Loss: 0.4372858 Vali Accuracy: 0.8429238  Vali weighted F1: 0.8220919  Vali macro F1 0.7635019 \n",
      "new best score!!!!\n",
      "Validation loss decreased (0.462115 --> 0.437286).  Saving model ...\n",
      "new best score!!!!\n",
      "Epoch: 6 cost time: 5.765081882476807\n",
      "VALI: Epoch: 6, Steps: 68 | Train Loss: 0.4078776  Vali Loss: 0.3873761 Vali Accuracy: 0.8610679  Vali weighted F1: 0.8468845  Vali macro F1 0.8045360 \n",
      "new best score!!!!\n",
      "Validation loss decreased (0.437286 --> 0.387376).  Saving model ...\n",
      "new best score!!!!\n",
      "Epoch: 7 cost time: 5.771845817565918\n",
      "VALI: Epoch: 7, Steps: 68 | Train Loss: 0.3798867  Vali Loss: 0.3586075 Vali Accuracy: 0.8703992  Vali weighted F1: 0.8612730  Vali macro F1 0.8270798 \n",
      "new best score!!!!\n",
      "Validation loss decreased (0.387376 --> 0.358607).  Saving model ...\n",
      "new best score!!!!\n",
      "Epoch: 8 cost time: 5.802133798599243\n",
      "VALI: Epoch: 8, Steps: 68 | Train Loss: 0.3571381  Vali Loss: 0.3138545 Vali Accuracy: 0.8854329  Vali weighted F1: 0.8794164  Vali macro F1 0.8476997 \n",
      "new best score!!!!\n",
      "Validation loss decreased (0.358607 --> 0.313854).  Saving model ...\n",
      "new best score!!!!\n",
      "Epoch: 9 cost time: 5.7591712474823\n",
      "VALI: Epoch: 9, Steps: 68 | Train Loss: 0.3192920  Vali Loss: 0.2872354 Vali Accuracy: 0.8911353  Vali weighted F1: 0.8850728  Vali macro F1 0.8515890 \n",
      "new best score!!!!\n",
      "Validation loss decreased (0.313854 --> 0.287235).  Saving model ...\n",
      "new best score!!!!\n",
      "Epoch: 10 cost time: 5.7632763385772705\n",
      "VALI: Epoch: 10, Steps: 68 | Train Loss: 0.2949933  Vali Loss: 0.2683866 Vali Accuracy: 0.9035770  Vali weighted F1: 0.9020082  Vali macro F1 0.8683766 \n",
      "new best score!!!!\n",
      "Validation loss decreased (0.287235 --> 0.268387).  Saving model ...\n",
      "new best score!!!!\n",
      "Epoch: 11 cost time: 5.795987129211426\n",
      "VALI: Epoch: 11, Steps: 68 | Train Loss: 0.2624594  Vali Loss: 0.2288962 Vali Accuracy: 0.9206843  Vali weighted F1: 0.9191408  Vali macro F1 0.8929192 \n",
      "new best score!!!!\n",
      "Validation loss decreased (0.268387 --> 0.228896).  Saving model ...\n",
      "new best score!!!!\n",
      "Epoch: 12 cost time: 5.8472678661346436\n",
      "VALI: Epoch: 12, Steps: 68 | Train Loss: 0.2553889  Vali Loss: 0.2267279 Vali Accuracy: 0.9186107  Vali weighted F1: 0.9157058  Vali macro F1 0.8893712 \n",
      "new best score!!!!\n",
      "Validation loss decreased (0.228896 --> 0.226728).  Saving model ...\n",
      "new best score!!!!\n",
      "Epoch: 13 cost time: 5.8121771812438965\n",
      "VALI: Epoch: 13, Steps: 68 | Train Loss: 0.2412892  Vali Loss: 0.2173928 Vali Accuracy: 0.9170555  Vali weighted F1: 0.9147140  Vali macro F1 0.8868336 \n",
      "new best score!!!!\n",
      "Validation loss decreased (0.226728 --> 0.217393).  Saving model ...\n",
      "new best score!!!!\n",
      "Epoch: 14 cost time: 5.731185436248779\n",
      "VALI: Epoch: 14, Steps: 68 | Train Loss: 0.2248240  Vali Loss: 0.2220491 Vali Accuracy: 0.9248315  Vali weighted F1: 0.9232887  Vali macro F1 0.8968765 \n",
      "EarlyStopping counter: 1 out of 15\n",
      "Learning rate adjusting counter: 1 out of 7\n",
      "Epoch: 15 cost time: 5.762083053588867\n",
      "VALI: Epoch: 15, Steps: 68 | Train Loss: 0.2165205  Vali Loss: 0.1887568 Vali Accuracy: 0.9289787  Vali weighted F1: 0.9268956  Vali macro F1 0.8994162 \n",
      "new best score!!!!\n",
      "Validation loss decreased (0.217393 --> 0.188757).  Saving model ...\n",
      "new best score!!!!\n",
      "Epoch: 16 cost time: 5.7352821826934814\n",
      "VALI: Epoch: 16, Steps: 68 | Train Loss: 0.2082673  Vali Loss: 0.1854713 Vali Accuracy: 0.9336444  Vali weighted F1: 0.9330225  Vali macro F1 0.9103196 \n",
      "new best score!!!!\n",
      "Validation loss decreased (0.188757 --> 0.185471).  Saving model ...\n",
      "new best score!!!!\n",
      "Epoch: 17 cost time: 5.737722396850586\n",
      "VALI: Epoch: 17, Steps: 68 | Train Loss: 0.2034187  Vali Loss: 0.1932439 Vali Accuracy: 0.9315708  Vali weighted F1: 0.9297375  Vali macro F1 0.9071344 \n",
      "EarlyStopping counter: 1 out of 15\n",
      "Learning rate adjusting counter: 1 out of 7\n",
      "Epoch: 18 cost time: 5.783502817153931\n",
      "VALI: Epoch: 18, Steps: 68 | Train Loss: 0.1924037  Vali Loss: 0.1941347 Vali Accuracy: 0.9326076  Vali weighted F1: 0.9299560  Vali macro F1 0.9114725 \n",
      "EarlyStopping counter: 2 out of 15\n",
      "Learning rate adjusting counter: 2 out of 7\n",
      "Epoch: 19 cost time: 5.731696128845215\n",
      "VALI: Epoch: 19, Steps: 68 | Train Loss: 0.1960064  Vali Loss: 0.1686753 Vali Accuracy: 0.9429756  Vali weighted F1: 0.9422733  Vali macro F1 0.9196969 \n",
      "new best score!!!!\n",
      "Validation loss decreased (0.185471 --> 0.168675).  Saving model ...\n",
      "new best score!!!!\n",
      "Epoch: 20 cost time: 5.773480653762817\n",
      "VALI: Epoch: 20, Steps: 68 | Train Loss: 0.1809287  Vali Loss: 0.1859059 Vali Accuracy: 0.9341628  Vali weighted F1: 0.9327087  Vali macro F1 0.9087131 \n",
      "EarlyStopping counter: 1 out of 15\n",
      "Learning rate adjusting counter: 1 out of 7\n",
      "Epoch: 21 cost time: 5.742307901382446\n",
      "VALI: Epoch: 21, Steps: 68 | Train Loss: 0.1726806  Vali Loss: 0.1624707 Vali Accuracy: 0.9445308  Vali weighted F1: 0.9444788  Vali macro F1 0.9237377 \n",
      "new best score!!!!\n",
      "Validation loss decreased (0.168675 --> 0.162471).  Saving model ...\n",
      "new best score!!!!\n",
      "Epoch: 22 cost time: 5.76605486869812\n",
      "VALI: Epoch: 22, Steps: 68 | Train Loss: 0.1824400  Vali Loss: 0.1622335 Vali Accuracy: 0.9440124  Vali weighted F1: 0.9424624  Vali macro F1 0.9225335 \n",
      "new best score!!!!\n",
      "Validation loss decreased (0.162471 --> 0.162233).  Saving model ...\n",
      "new best score!!!!\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 23 cost time: 5.786476373672485\n",
      "VALI: Epoch: 23, Steps: 68 | Train Loss: 0.1670579  Vali Loss: 0.1494859 Vali Accuracy: 0.9481597  Vali weighted F1: 0.9477896  Vali macro F1 0.9273446 \n",
      "new best score!!!!\n",
      "Validation loss decreased (0.162233 --> 0.149486).  Saving model ...\n",
      "new best score!!!!\n",
      "Epoch: 24 cost time: 5.7921411991119385\n",
      "VALI: Epoch: 24, Steps: 68 | Train Loss: 0.1600990  Vali Loss: 0.1790569 Vali Accuracy: 0.9419388  Vali weighted F1: 0.9402772  Vali macro F1 0.9218290 \n",
      "EarlyStopping counter: 1 out of 15\n",
      "Learning rate adjusting counter: 1 out of 7\n",
      "Epoch: 25 cost time: 5.778265953063965\n",
      "VALI: Epoch: 25, Steps: 68 | Train Loss: 0.1569615  Vali Loss: 0.1700916 Vali Accuracy: 0.9429756  Vali weighted F1: 0.9426354  Vali macro F1 0.9215134 \n",
      "EarlyStopping counter: 2 out of 15\n",
      "Learning rate adjusting counter: 2 out of 7\n",
      "Epoch: 26 cost time: 5.814982891082764\n",
      "VALI: Epoch: 26, Steps: 68 | Train Loss: 0.1563817  Vali Loss: 0.1492313 Vali Accuracy: 0.9533437  Vali weighted F1: 0.9529800  Vali macro F1 0.9410141 \n",
      "new best score!!!!\n",
      "Validation loss decreased (0.149486 --> 0.149231).  Saving model ...\n",
      "new best score!!!!\n",
      "Epoch: 27 cost time: 5.775187015533447\n",
      "VALI: Epoch: 27, Steps: 68 | Train Loss: 0.1528237  Vali Loss: 0.1387115 Vali Accuracy: 0.9543805  Vali weighted F1: 0.9538816  Vali macro F1 0.9439847 \n",
      "new best score!!!!\n",
      "Validation loss decreased (0.149231 --> 0.138711).  Saving model ...\n",
      "new best score!!!!\n",
      "Epoch: 28 cost time: 5.721928358078003\n",
      "VALI: Epoch: 28, Steps: 68 | Train Loss: 0.1448212  Vali Loss: 0.1731192 Vali Accuracy: 0.9398652  Vali weighted F1: 0.9381293  Vali macro F1 0.9245669 \n",
      "EarlyStopping counter: 1 out of 15\n",
      "Learning rate adjusting counter: 1 out of 7\n",
      "Epoch: 29 cost time: 5.7104432582855225\n",
      "VALI: Epoch: 29, Steps: 68 | Train Loss: 0.1433636  Vali Loss: 0.1495283 Vali Accuracy: 0.9497149  Vali weighted F1: 0.9490622  Vali macro F1 0.9339717 \n",
      "EarlyStopping counter: 2 out of 15\n",
      "Learning rate adjusting counter: 2 out of 7\n",
      "Epoch: 30 cost time: 5.844827651977539\n",
      "VALI: Epoch: 30, Steps: 68 | Train Loss: 0.1402603  Vali Loss: 0.1650453 Vali Accuracy: 0.9414204  Vali weighted F1: 0.9388583  Vali macro F1 0.9270001 \n",
      "EarlyStopping counter: 3 out of 15\n",
      "Learning rate adjusting counter: 3 out of 7\n",
      "Epoch: 31 cost time: 5.772003650665283\n",
      "VALI: Epoch: 31, Steps: 68 | Train Loss: 0.1345869  Vali Loss: 0.1365122 Vali Accuracy: 0.9585277  Vali weighted F1: 0.9580301  Vali macro F1 0.9479156 \n",
      "new best score!!!!\n",
      "Validation loss decreased (0.138711 --> 0.136512).  Saving model ...\n",
      "new best score!!!!\n",
      "Epoch: 32 cost time: 5.774514675140381\n",
      "VALI: Epoch: 32, Steps: 68 | Train Loss: 0.1304040  Vali Loss: 0.1213009 Vali Accuracy: 0.9595645  Vali weighted F1: 0.9592610  Vali macro F1 0.9472535 \n",
      "new best score!!!!\n",
      "Validation loss decreased (0.136512 --> 0.121301).  Saving model ...\n",
      "new best score!!!!\n",
      "Epoch: 33 cost time: 5.7814836502075195\n",
      "VALI: Epoch: 33, Steps: 68 | Train Loss: 0.1326356  Vali Loss: 0.1647420 Vali Accuracy: 0.9476413  Vali weighted F1: 0.9469592  Vali macro F1 0.9340904 \n",
      "EarlyStopping counter: 1 out of 15\n",
      "Learning rate adjusting counter: 1 out of 7\n",
      "Epoch: 34 cost time: 5.8999857902526855\n",
      "VALI: Epoch: 34, Steps: 68 | Train Loss: 0.1229920  Vali Loss: 0.1470251 Vali Accuracy: 0.9574909  Vali weighted F1: 0.9570220  Vali macro F1 0.9482401 \n",
      "EarlyStopping counter: 2 out of 15\n",
      "Learning rate adjusting counter: 2 out of 7\n",
      "Epoch: 35 cost time: 5.752365827560425\n",
      "VALI: Epoch: 35, Steps: 68 | Train Loss: 0.1241922  Vali Loss: 0.1830240 Vali Accuracy: 0.9440124  Vali weighted F1: 0.9428413  Vali macro F1 0.9315917 \n",
      "EarlyStopping counter: 3 out of 15\n",
      "Learning rate adjusting counter: 3 out of 7\n",
      "Epoch: 36 cost time: 5.770720720291138\n",
      "VALI: Epoch: 36, Steps: 68 | Train Loss: 0.1258746  Vali Loss: 0.1368887 Vali Accuracy: 0.9554173  Vali weighted F1: 0.9547825  Vali macro F1 0.9455459 \n",
      "EarlyStopping counter: 4 out of 15\n",
      "Learning rate adjusting counter: 4 out of 7\n",
      "Epoch: 37 cost time: 5.855467081069946\n",
      "VALI: Epoch: 37, Steps: 68 | Train Loss: 0.1172468  Vali Loss: 0.1311255 Vali Accuracy: 0.9606013  Vali weighted F1: 0.9603917  Vali macro F1 0.9528648 \n",
      "EarlyStopping counter: 5 out of 15\n",
      "Learning rate adjusting counter: 5 out of 7\n",
      "Epoch: 38 cost time: 5.7851927280426025\n",
      "VALI: Epoch: 38, Steps: 68 | Train Loss: 0.1225507  Vali Loss: 0.1129260 Vali Accuracy: 0.9637118  Vali weighted F1: 0.9635709  Vali macro F1 0.9543910 \n",
      "new best score!!!!\n",
      "Validation loss decreased (0.121301 --> 0.112926).  Saving model ...\n",
      "new best score!!!!\n",
      "Epoch: 39 cost time: 5.7765185832977295\n",
      "VALI: Epoch: 39, Steps: 68 | Train Loss: 0.1101746  Vali Loss: 0.1122389 Vali Accuracy: 0.9590461  Vali weighted F1: 0.9585601  Vali macro F1 0.9505437 \n",
      "new best score!!!!\n",
      "Validation loss decreased (0.112926 --> 0.112239).  Saving model ...\n",
      "new best score!!!!\n",
      "Epoch: 40 cost time: 5.851734399795532\n",
      "VALI: Epoch: 40, Steps: 68 | Train Loss: 0.1118658  Vali Loss: 0.1146025 Vali Accuracy: 0.9642302  Vali weighted F1: 0.9639457  Vali macro F1 0.9562802 \n",
      "EarlyStopping counter: 1 out of 15\n",
      "Learning rate adjusting counter: 1 out of 7\n",
      "Epoch: 41 cost time: 5.796012878417969\n",
      "VALI: Epoch: 41, Steps: 68 | Train Loss: 0.1098664  Vali Loss: 0.1213860 Vali Accuracy: 0.9621566  Vali weighted F1: 0.9615438  Vali macro F1 0.9530108 \n",
      "EarlyStopping counter: 2 out of 15\n",
      "Learning rate adjusting counter: 2 out of 7\n",
      "Epoch: 42 cost time: 5.765495777130127\n",
      "VALI: Epoch: 42, Steps: 68 | Train Loss: 0.1047034  Vali Loss: 0.1106180 Vali Accuracy: 0.9631934  Vali weighted F1: 0.9628799  Vali macro F1 0.9532171 \n",
      "new best score!!!!\n",
      "Validation loss decreased (0.112239 --> 0.110618).  Saving model ...\n",
      "new best score!!!!\n",
      "Epoch: 43 cost time: 5.746095418930054\n",
      "VALI: Epoch: 43, Steps: 68 | Train Loss: 0.1077616  Vali Loss: 0.1313850 Vali Accuracy: 0.9564541  Vali weighted F1: 0.9562065  Vali macro F1 0.9463563 \n",
      "EarlyStopping counter: 1 out of 15\n",
      "Learning rate adjusting counter: 1 out of 7\n",
      "Epoch: 44 cost time: 5.881338357925415\n",
      "VALI: Epoch: 44, Steps: 68 | Train Loss: 0.1025393  Vali Loss: 0.1062314 Vali Accuracy: 0.9626750  Vali weighted F1: 0.9622180  Vali macro F1 0.9534424 \n",
      "new best score!!!!\n",
      "Validation loss decreased (0.110618 --> 0.106231).  Saving model ...\n",
      "new best score!!!!\n",
      "Epoch: 45 cost time: 5.772031784057617\n",
      "VALI: Epoch: 45, Steps: 68 | Train Loss: 0.0976836  Vali Loss: 0.1222871 Vali Accuracy: 0.9600829  Vali weighted F1: 0.9598682  Vali macro F1 0.9523374 \n",
      "EarlyStopping counter: 1 out of 15\n",
      "Learning rate adjusting counter: 1 out of 7\n",
      "Epoch: 46 cost time: 5.714264392852783\n",
      "VALI: Epoch: 46, Steps: 68 | Train Loss: 0.1064285  Vali Loss: 0.1019033 Vali Accuracy: 0.9647486  Vali weighted F1: 0.9644600  Vali macro F1 0.9564995 \n",
      "new best score!!!!\n",
      "Validation loss decreased (0.106231 --> 0.101903).  Saving model ...\n",
      "new best score!!!!\n",
      "Epoch: 47 cost time: 5.780524969100952\n",
      "VALI: Epoch: 47, Steps: 68 | Train Loss: 0.1036241  Vali Loss: 0.1006366 Vali Accuracy: 0.9637118  Vali weighted F1: 0.9633224  Vali macro F1 0.9514368 \n",
      "new best score!!!!\n",
      "Validation loss decreased (0.101903 --> 0.100637).  Saving model ...\n",
      "new best score!!!!\n",
      "Epoch: 48 cost time: 5.809110403060913\n",
      "VALI: Epoch: 48, Steps: 68 | Train Loss: 0.0928812  Vali Loss: 0.1176872 Vali Accuracy: 0.9626750  Vali weighted F1: 0.9621073  Vali macro F1 0.9532083 \n",
      "EarlyStopping counter: 1 out of 15\n",
      "Learning rate adjusting counter: 1 out of 7\n",
      "Epoch: 49 cost time: 5.852490663528442\n",
      "VALI: Epoch: 49, Steps: 68 | Train Loss: 0.0881384  Vali Loss: 0.0996496 Vali Accuracy: 0.9683774  Vali weighted F1: 0.9683655  Vali macro F1 0.9612159 \n",
      "new best score!!!!\n",
      "Validation loss decreased (0.100637 --> 0.099650).  Saving model ...\n",
      "new best score!!!!\n",
      "Epoch: 50 cost time: 5.819643974304199\n",
      "VALI: Epoch: 50, Steps: 68 | Train Loss: 0.1002857  Vali Loss: 0.1200604 Vali Accuracy: 0.9626750  Vali weighted F1: 0.9624120  Vali macro F1 0.9541011 \n",
      "EarlyStopping counter: 1 out of 15\n",
      "Learning rate adjusting counter: 1 out of 7\n",
      "Epoch: 51 cost time: 5.8466198444366455\n",
      "VALI: Epoch: 51, Steps: 68 | Train Loss: 0.0875668  Vali Loss: 0.1040389 Vali Accuracy: 0.9668222  Vali weighted F1: 0.9663406  Vali macro F1 0.9592411 \n",
      "EarlyStopping counter: 2 out of 15\n",
      "Learning rate adjusting counter: 2 out of 7\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 52 cost time: 5.801909446716309\n",
      "VALI: Epoch: 52, Steps: 68 | Train Loss: 0.0873968  Vali Loss: 0.1368416 Vali Accuracy: 0.9631934  Vali weighted F1: 0.9628480  Vali macro F1 0.9562949 \n",
      "EarlyStopping counter: 3 out of 15\n",
      "Learning rate adjusting counter: 3 out of 7\n",
      "Epoch: 53 cost time: 5.915728330612183\n",
      "VALI: Epoch: 53, Steps: 68 | Train Loss: 0.0820439  Vali Loss: 0.1133018 Vali Accuracy: 0.9631934  Vali weighted F1: 0.9626191  Vali macro F1 0.9530277 \n",
      "EarlyStopping counter: 4 out of 15\n",
      "Learning rate adjusting counter: 4 out of 7\n",
      "Epoch: 54 cost time: 5.828162908554077\n",
      "VALI: Epoch: 54, Steps: 68 | Train Loss: 0.0838684  Vali Loss: 0.0979018 Vali Accuracy: 0.9699326  Vali weighted F1: 0.9699399  Vali macro F1 0.9615914 \n",
      "new best score!!!!\n",
      "Validation loss decreased (0.099650 --> 0.097902).  Saving model ...\n",
      "new best score!!!!\n",
      "Epoch: 55 cost time: 5.783450603485107\n",
      "VALI: Epoch: 55, Steps: 68 | Train Loss: 0.0866414  Vali Loss: 0.0854583 Vali Accuracy: 0.9663038  Vali weighted F1: 0.9661961  Vali macro F1 0.9577121 \n",
      "new best score!!!!\n",
      "Validation loss decreased (0.097902 --> 0.085458).  Saving model ...\n",
      "new best score!!!!\n",
      "Epoch: 56 cost time: 5.740899324417114\n",
      "VALI: Epoch: 56, Steps: 68 | Train Loss: 0.0809105  Vali Loss: 0.1030783 Vali Accuracy: 0.9694142  Vali weighted F1: 0.9689881  Vali macro F1 0.9621059 \n",
      "EarlyStopping counter: 1 out of 15\n",
      "Learning rate adjusting counter: 1 out of 7\n",
      "Epoch: 57 cost time: 5.773525953292847\n",
      "VALI: Epoch: 57, Steps: 68 | Train Loss: 0.0835310  Vali Loss: 0.1029607 Vali Accuracy: 0.9673406  Vali weighted F1: 0.9669028  Vali macro F1 0.9573951 \n",
      "EarlyStopping counter: 2 out of 15\n",
      "Learning rate adjusting counter: 2 out of 7\n",
      "Epoch: 58 cost time: 5.696155548095703\n",
      "VALI: Epoch: 58, Steps: 68 | Train Loss: 0.0781274  Vali Loss: 0.0779235 Vali Accuracy: 0.9725246  Vali weighted F1: 0.9724000  Vali macro F1 0.9663871 \n",
      "new best score!!!!\n",
      "Validation loss decreased (0.085458 --> 0.077923).  Saving model ...\n",
      "new best score!!!!\n",
      "Epoch: 59 cost time: 5.7423036098480225\n",
      "VALI: Epoch: 59, Steps: 68 | Train Loss: 0.0792452  Vali Loss: 0.1143011 Vali Accuracy: 0.9631934  Vali weighted F1: 0.9626544  Vali macro F1 0.9545655 \n",
      "EarlyStopping counter: 1 out of 15\n",
      "Learning rate adjusting counter: 1 out of 7\n",
      "Epoch: 60 cost time: 5.743314027786255\n",
      "VALI: Epoch: 60, Steps: 68 | Train Loss: 0.0786544  Vali Loss: 0.0941649 Vali Accuracy: 0.9730430  Vali weighted F1: 0.9727119  Vali macro F1 0.9653389 \n",
      "EarlyStopping counter: 2 out of 15\n",
      "Learning rate adjusting counter: 2 out of 7\n",
      "Epoch: 61 cost time: 5.752823352813721\n",
      "VALI: Epoch: 61, Steps: 68 | Train Loss: 0.0758921  Vali Loss: 0.0803023 Vali Accuracy: 0.9714878  Vali weighted F1: 0.9713099  Vali macro F1 0.9651964 \n",
      "EarlyStopping counter: 3 out of 15\n",
      "Learning rate adjusting counter: 3 out of 7\n",
      "Epoch: 62 cost time: 5.733363628387451\n",
      "VALI: Epoch: 62, Steps: 68 | Train Loss: 0.0759608  Vali Loss: 0.0832148 Vali Accuracy: 0.9709694  Vali weighted F1: 0.9707430  Vali macro F1 0.9628698 \n",
      "EarlyStopping counter: 4 out of 15\n",
      "Learning rate adjusting counter: 4 out of 7\n",
      "Epoch: 63 cost time: 5.749946594238281\n",
      "VALI: Epoch: 63, Steps: 68 | Train Loss: 0.0734841  Vali Loss: 0.0871810 Vali Accuracy: 0.9714878  Vali weighted F1: 0.9714421  Vali macro F1 0.9637197 \n",
      "EarlyStopping counter: 5 out of 15\n",
      "Learning rate adjusting counter: 5 out of 7\n",
      "Epoch: 64 cost time: 5.770601034164429\n",
      "VALI: Epoch: 64, Steps: 68 | Train Loss: 0.0717876  Vali Loss: 0.0755588 Vali Accuracy: 0.9766719  Vali weighted F1: 0.9763907  Vali macro F1 0.9714049 \n",
      "new best score!!!!\n",
      "Validation loss decreased (0.077923 --> 0.075559).  Saving model ...\n",
      "new best score!!!!\n",
      "Epoch: 65 cost time: 5.7868146896362305\n",
      "VALI: Epoch: 65, Steps: 68 | Train Loss: 0.0769103  Vali Loss: 0.1063247 Vali Accuracy: 0.9631934  Vali weighted F1: 0.9630746  Vali macro F1 0.9532673 \n",
      "EarlyStopping counter: 1 out of 15\n",
      "Learning rate adjusting counter: 1 out of 7\n",
      "Epoch: 66 cost time: 5.690340280532837\n",
      "VALI: Epoch: 66, Steps: 68 | Train Loss: 0.0682074  Vali Loss: 0.1061664 Vali Accuracy: 0.9678590  Vali weighted F1: 0.9674566  Vali macro F1 0.9571865 \n",
      "EarlyStopping counter: 2 out of 15\n",
      "Learning rate adjusting counter: 2 out of 7\n",
      "Epoch: 67 cost time: 5.844947576522827\n",
      "VALI: Epoch: 67, Steps: 68 | Train Loss: 0.0677149  Vali Loss: 0.0867534 Vali Accuracy: 0.9699326  Vali weighted F1: 0.9699631  Vali macro F1 0.9623391 \n",
      "EarlyStopping counter: 3 out of 15\n",
      "Learning rate adjusting counter: 3 out of 7\n",
      "Epoch: 68 cost time: 5.833822011947632\n",
      "VALI: Epoch: 68, Steps: 68 | Train Loss: 0.0651062  Vali Loss: 0.0749846 Vali Accuracy: 0.9756350  Vali weighted F1: 0.9754907  Vali macro F1 0.9684303 \n",
      "new best score!!!!\n",
      "Validation loss decreased (0.075559 --> 0.074985).  Saving model ...\n",
      "new best score!!!!\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-6-21de09e58c74>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mexp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtrain\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32mE:\\TECO_Works\\Conference\\ISWC2022\\I2S0W2C2_CFC\\experiment.py\u001b[0m in \u001b[0;36mtrain\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    295\u001b[0m                     \u001b[0mepoch_time\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtime\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtime\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    296\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 297\u001b[1;33m                     \u001b[1;32mfor\u001b[0m \u001b[0mi\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0mbatch_x1\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mbatch_x2\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mbatch_y\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32min\u001b[0m \u001b[0menumerate\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtrain_loader\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    298\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    299\u001b[0m                         \u001b[1;31m#if \"cross\" in self.args.model_type:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mD:\\anaconda\\lib\\site-packages\\torch\\utils\\data\\dataloader.py\u001b[0m in \u001b[0;36m__next__\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    519\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_sampler_iter\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    520\u001b[0m                 \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_reset\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 521\u001b[1;33m             \u001b[0mdata\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_next_data\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    522\u001b[0m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_num_yielded\u001b[0m \u001b[1;33m+=\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    523\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_dataset_kind\u001b[0m \u001b[1;33m==\u001b[0m \u001b[0m_DatasetKind\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mIterable\u001b[0m \u001b[1;32mand\u001b[0m\u001b[0;31m \u001b[0m\u001b[0;31m\\\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mD:\\anaconda\\lib\\site-packages\\torch\\utils\\data\\dataloader.py\u001b[0m in \u001b[0;36m_next_data\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    559\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m_next_data\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    560\u001b[0m         \u001b[0mindex\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_next_index\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m  \u001b[1;31m# may raise StopIteration\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 561\u001b[1;33m         \u001b[0mdata\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_dataset_fetcher\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfetch\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mindex\u001b[0m\u001b[1;33m)\u001b[0m  \u001b[1;31m# may raise StopIteration\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    562\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_pin_memory\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    563\u001b[0m             \u001b[0mdata\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0m_utils\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpin_memory\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpin_memory\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mD:\\anaconda\\lib\\site-packages\\torch\\utils\\data\\_utils\\fetch.py\u001b[0m in \u001b[0;36mfetch\u001b[1;34m(self, possibly_batched_index)\u001b[0m\n\u001b[0;32m     42\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mfetch\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mpossibly_batched_index\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     43\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mauto_collation\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 44\u001b[1;33m             \u001b[0mdata\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdataset\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0midx\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0midx\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mpossibly_batched_index\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     45\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     46\u001b[0m             \u001b[0mdata\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdataset\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mpossibly_batched_index\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mD:\\anaconda\\lib\\site-packages\\torch\\utils\\data\\_utils\\fetch.py\u001b[0m in \u001b[0;36m<listcomp>\u001b[1;34m(.0)\u001b[0m\n\u001b[0;32m     42\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mfetch\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mpossibly_batched_index\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     43\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mauto_collation\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 44\u001b[1;33m             \u001b[0mdata\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdataset\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0midx\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0midx\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mpossibly_batched_index\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     45\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     46\u001b[0m             \u001b[0mdata\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdataset\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mpossibly_batched_index\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mE:\\TECO_Works\\Conference\\ISWC2022\\I2S0W2C2_CFC\\dataloaders\\__init__.py\u001b[0m in \u001b[0;36m__getitem__\u001b[1;34m(self, index)\u001b[0m\n\u001b[0;32m    164\u001b[0m                 \u001b[0msample_x\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0marray\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdata_x\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0miloc\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mstart_index\u001b[0m\u001b[1;33m:\u001b[0m\u001b[0mend_index\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m-\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mapply\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;32mlambda\u001b[0m \u001b[0mx\u001b[0m\u001b[1;33m:\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0mx\u001b[0m \u001b[1;33m-\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmean\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m/\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmax\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m-\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmin\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    165\u001b[0m             \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 166\u001b[1;33m                 \u001b[0msample_x\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdata_x\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0miloc\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mstart_index\u001b[0m\u001b[1;33m:\u001b[0m\u001b[0mend_index\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m-\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    167\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    168\u001b[0m             \u001b[0msample_y\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mclass_transform\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdata_y\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0miloc\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mstart_index\u001b[0m\u001b[1;33m:\u001b[0m\u001b[0mend_index\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmode\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mloc\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mD:\\anaconda\\lib\\site-packages\\pandas\\core\\indexing.py\u001b[0m in \u001b[0;36m__getitem__\u001b[1;34m(self, key)\u001b[0m\n\u001b[0;32m    887\u001b[0m                     \u001b[1;31m# AttributeError for IntervalTree get_value\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    888\u001b[0m                     \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mobj\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_get_value\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0mkey\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtakeable\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_takeable\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 889\u001b[1;33m             \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_getitem_tuple\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    890\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    891\u001b[0m             \u001b[1;31m# we by definition only have the 0th axis\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mD:\\anaconda\\lib\\site-packages\\pandas\\core\\indexing.py\u001b[0m in \u001b[0;36m_getitem_tuple\u001b[1;34m(self, tup)\u001b[0m\n\u001b[0;32m   1452\u001b[0m             \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_getitem_lowerdim\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtup\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1453\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1454\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_getitem_tuple_same_dim\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtup\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1455\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1456\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m_get_list_axis\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mkey\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mint\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mD:\\anaconda\\lib\\site-packages\\pandas\\core\\indexing.py\u001b[0m in \u001b[0;36m_getitem_tuple_same_dim\u001b[1;34m(self, tup)\u001b[0m\n\u001b[0;32m    773\u001b[0m                 \u001b[1;32mcontinue\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    774\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 775\u001b[1;33m             \u001b[0mretval\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mgetattr\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mretval\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mname\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_getitem_axis\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mi\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    776\u001b[0m             \u001b[1;31m# We should never have retval.ndim < self.ndim, as that should\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    777\u001b[0m             \u001b[1;31m#  be handled by the _getitem_lowerdim call above.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mD:\\anaconda\\lib\\site-packages\\pandas\\core\\indexing.py\u001b[0m in \u001b[0;36m_getitem_axis\u001b[1;34m(self, key, axis)\u001b[0m\n\u001b[0;32m   1479\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m_getitem_axis\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mkey\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mint\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1480\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mslice\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1481\u001b[1;33m             \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_get_slice_axis\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0maxis\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1482\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1483\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlist\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mD:\\anaconda\\lib\\site-packages\\pandas\\core\\indexing.py\u001b[0m in \u001b[0;36m_get_slice_axis\u001b[1;34m(self, slice_obj, axis)\u001b[0m\n\u001b[0;32m   1512\u001b[0m         \u001b[0mlabels\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mobj\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_get_axis\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0maxis\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1513\u001b[0m         \u001b[0mlabels\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_validate_positional_slice\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mslice_obj\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1514\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mobj\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_slice\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mslice_obj\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0maxis\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1515\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1516\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m_convert_to_indexer\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mkey\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mint\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mis_setter\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mbool\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;32mFalse\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mD:\\anaconda\\lib\\site-packages\\pandas\\core\\generic.py\u001b[0m in \u001b[0;36m_slice\u001b[1;34m(self, slobj, axis)\u001b[0m\n\u001b[0;32m   3809\u001b[0m         \u001b[1;32massert\u001b[0m \u001b[0misinstance\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mslobj\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mslice\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtype\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mslobj\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   3810\u001b[0m         \u001b[0maxis\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_get_block_manager_axis\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0maxis\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 3811\u001b[1;33m         \u001b[0mresult\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_constructor\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_mgr\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget_slice\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mslobj\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0maxis\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   3812\u001b[0m         \u001b[0mresult\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mresult\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m__finalize__\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   3813\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mD:\\anaconda\\lib\\site-packages\\pandas\\core\\internals\\managers.py\u001b[0m in \u001b[0;36mget_slice\u001b[1;34m(self, slobj, axis)\u001b[0m\n\u001b[0;32m    777\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    778\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0maxis\u001b[0m \u001b[1;33m==\u001b[0m \u001b[1;36m0\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 779\u001b[1;33m             \u001b[0mnew_blocks\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_slice_take_blocks_ax0\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mslobj\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    780\u001b[0m         \u001b[1;32melif\u001b[0m \u001b[0maxis\u001b[0m \u001b[1;33m==\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    781\u001b[0m             \u001b[0mslicer\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0mslice\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;32mNone\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mslobj\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mD:\\anaconda\\lib\\site-packages\\pandas\\core\\internals\\managers.py\u001b[0m in \u001b[0;36m_slice_take_blocks_ax0\u001b[1;34m(self, slice_or_indexer, fill_value, only_slice)\u001b[0m\n\u001b[0;32m   1383\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1384\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0msl_type\u001b[0m \u001b[1;32min\u001b[0m \u001b[1;33m(\u001b[0m\u001b[1;34m\"slice\"\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m\"mask\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1385\u001b[1;33m             \u001b[0mblknos\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mblknos\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mslobj\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1386\u001b[0m             \u001b[0mblklocs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mblklocs\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mslobj\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1387\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mD:\\anaconda\\lib\\site-packages\\pandas\\core\\internals\\managers.py\u001b[0m in \u001b[0;36mblknos\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    167\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_blknos\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    168\u001b[0m             \u001b[1;31m# Note: these can be altered by other BlockManager methods.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 169\u001b[1;33m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_rebuild_blknos_and_blklocs\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    170\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    171\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_blknos\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mD:\\anaconda\\lib\\site-packages\\pandas\\core\\internals\\managers.py\u001b[0m in \u001b[0;36m_rebuild_blknos_and_blklocs\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    242\u001b[0m             \u001b[0mrl\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mblk\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmgr_locs\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    243\u001b[0m             \u001b[0mnew_blknos\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mrl\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mindexer\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mblkno\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 244\u001b[1;33m             \u001b[0mnew_blklocs\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mrl\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mindexer\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0marange\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mrl\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    245\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    246\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0mnew_blknos\u001b[0m \u001b[1;33m==\u001b[0m \u001b[1;33m-\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0many\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAWcAAAD4CAYAAAAw/yevAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjMuNCwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy8QVMy6AAAACXBIWXMAAAsTAAALEwEAmpwYAABIqUlEQVR4nO3dd1zV1f/A8df7wkVc4GaXVjbMHLly5M49cI/UhmW/tF22l5lppZmWI7UUTVDciDhRww2aI/dOGW5xD7ic3x/3SiDIvcgFLvd7nj4+D+89n3HeHzi8OZx7Pp+PKKXQNE3THIshvwPQNE3TMtLJWdM0zQHp5KxpmuaAdHLWNE1zQDo5a5qmOSDX3K4g6dzRAjUdpLDvs/kdguaAKnh653cI2XbuxqX8DiHbLl49LDk9RnZyjrHMQzmuL7fonrOmaZoDyvWes6ZpWp5KMeV3BHahk7Omac7FlJzfEdiFTs6apjkVpVLyOwS70MlZ0zTnkqKTs6ZpmuPRPWdN0zQHpD8Q1DRNc0C656xpmuZ4lJ6toWma5oD0B4KapmkOSA9raJqmOSD9gaCmaZoDcpKec57d+OjWrdv0fOVtOr8wkI7Pv8avU2Zk2ObK1WsM+vCr1G0WLFmR43pv377N+18Mp3X3l+n16jvEJZwGIP7Uabq//CZdXhhEx+dfY/aCJTmuKytvv/UqO3esZsf2SP6cMY5ChQrlan051bJFY/bsjmL/3vV8OHhQfodjk7yI2a2QG3OXBxG2JoSIdaG89eFrGbZ5ZVBfwtYEE7YmmCVRs9l/KhrPEh45q9fNyM+Th7MqeiFzlwXhF+ADwBOVHyU0YioR60JZvHYWbQKfy7DvL+OHc/DYFjZGR2R67PrP1uHfuO1EbQwjamMYgz9+I0exmuN14/egMWzbGcnKNXMJeMAPgMpPPcHyyDlsjFnK+s3hdOrSJsd1ZWBKtn1xYHmWnN3cjPwxdgTzg8YzN2gcG7ZsY+fufem2CZm3mIfLP8D8oPFM/fV7fvxlMklJSTYdPy7hNC++8WGG8vnhK/AoXoyloX/Qt0cgP43/A4CypUvx58RRzAsaR8jkn/n9z1DOnD2f8xPNhK+vN28Mepk6z7ShWvVmuLi40KN7x1ypyx4MBgNjxwyjXfs+PFW1CT16BPLEExXzO6ws5VXMt2/dpl/n/6NDk150aNKbhk3rUa1G5XTbTBk3gw5NetOhSW9Gffsr0Rv/5lLiZZuO7xfgw58Lf8tQ3vX5QC4nXqZ57UCmTpzJ4C/fAuDG9ZsMfuNL2jzbnf493uCzbz+guEexdPuGzJxP18CXs6x308YYGtbrQMN6HfhxxK82xQoQ8IAfi5fOzFDe94VuXEq8RI2qzZgwbipfDzX/bN64cYPXB3xAvVqt6Rr4Mt99/zkensVtrs8mKSm2L1kQEXcRiRaRnSKyR0SGWMq/FpE4EdlhWdqk2ecTETksIgdEpGWa8hoi8o9l3VgRsXqr0jxLziJCkSKFAUhOTiY5OZm74xMRrl2/gVKK6zdu4ulRHBcXFwAWL19Nz1fepssLgxjyw1hMJtvGlVav20THNs0BaNH4WbZs24FSCqPRiJubGwC3k5JIyeWnkLu6ulK4sDsuLi4UKVyYhIRTuVpfTtSuVZ0jR45z7NgJkpKSCA1dRIf2La3vmI/yMubr124A4Gp0xdXoSlZNp13nVoTPX576vkPX1paedzBDR36KwWDbj2Dz1o2YPzscgGWLI6n7bG0Ajh89wb9HTwJw5vQ5zp+9QKkyJdPtu3FDDBcvJtp6eul079GRVWvnEbUxjNFjh9ocb+u2zQmZuQCARQuW0ahxXQCOHD7O0SP/AnDq1BnOnT1PmTKl7iu2e1HKZPNixS2gqVKqKlANaCUiz1jWjVZKVbMsEQAiUgnoCTwJtALGi4iLZfsJwACgomVpZa1yq19pEXlcRD6yZPsxltdPWNsvMyaTiS4vDKJhu17UrVWdKk8+nm597y7tOXr8JE06Pk+nfq/z8Tv/h8Fg4MjxEyyL/IsZlp6uwWAgfMUam+o8c/Y83uXKAODq6kKxokVIvGTuxSScPkunfq/TvFM/+j/fjXJlS9/PaVkVH3+Kn0ZP5NiRaGJPbOfS5cusXBWVK3XZg6+fNydj41Pfx8Yl4Ovr2Debz8uYDQYDYWuC2bxvJRvWbmbn37sz3c69sDvPNq3L8vBIAB6uWJ62gS3o2bY/HZr0xmRKoUPX1jbV6eVdllNx5iE5k8nE1ctXKVmqRLptqlR/Ejc3IyeOxWb7nGrVrs66TYuZM/93Hrf8xfHoYw/TqUtbWjXvQcN6HTCZUujWo4NNx/P19SIuNiE13suXrlKqdPpfGk/XqILRzcixoyeyHW+WVIrtS1aHMbtqeWu0LFn14joCs5RSt5RSx4DDQG0R8QE8lFKblFIKmA4EWjuNLD8QFJGPgF7ALCDaUuwPhIjILKXUiHvsNwDzbwnGj/qWV/r1AsDFxYV5QeO4fOUqb38ylENHj1PxofKp+22I3sbjFR/ij19GcDIugVff+ZQaVZ9ky9Yd7N1/mJ793wbg1q1blCpZAoC3PvmGuPjTJCUnkXD6LF1eMI819unekU5tW6Ay6dbc6bH7eJVlwfQJnDl7nrc++YbnmjSw9vW6LyVKeNKhfUseefQZEhMvM3vWb/Tu3Zng4Pm5Ul9OZfYXV2ZfR0eSlzGnpKTQoUlvinsUY3zQKCo+/jCH9h/JsF3Tls/yd/TO1CGNug1r82TVJ5i/cjoAhdwLcf7cBQDGTRtJwIO+GI1GfPy9CVsTDEDQpBDmhSy2en5lvcrw4/hv+OiNr7J93rt27KFKpUZcu3ad51o04s+QCdSs1pxGjetRtfqTrI4yt1N3d3fOWob+ZoSM58EH/TG6ueHv70PUxjAAJo4PIvjPeWAlXi+vskycPJKBr31o/+9TNuY5p81VFpOUUpPSrHcBtgGPAOOUUltEpDXwhoj0A7YC7yulLgJ+wOY0x4q1lCVZXt9dniVrszX6A08qpdIN/IrIT8AeINPkbDm5SZD5I2M8ihej1tNVWL95a7rkvGDJSl7p0x0R4QF/X/x8vDn2byxKKTq0bs67r7+Uoa6xw78EzGPOnw0bxbRff0i33qtcGU6dOYd3ubIkJ5u4eu06nh7px7jKlS3NIxUe5O+dmfeAcqpZs2c5dvwE5yw/iAsWLqXuMzUdNjnHxSYQ4O+b+t7fz4cEywepjio/Yr5y+SpbNmylYdN6mSbntoEt0w1piAgLZocz6tuMY7qDXvwAMI85f//L1/QJTP9B46mEM3j7eXEq4QwuLi4U8yhG4kXzY6iKFSvK5OAxjB4+gR3bst+Gr1y5mvp65Yq/GDl6iLmXKzBr5gK++Xpkhn369hoImMecx//2A+1bP59ufXzcKfz8fYiPP4WLiwsensW4eCERgOLFizF73hSGDR3N1pgd2Y7XqmzM1kibq+6x3gRUE5ESwAIRqYx5iGIo5l70UGAU8DKQ2TiyyqI8S9aGNVIA30zKfSzrbHbhYiKXLY3g5q1bbI7ZToUHA9If1Kssm7ftAODchYscPxGLv683z9Ssxsq16zlvGTe7dPkK8ads+8Fr0uAZFkWsAmDF2nXUqVEVEeHUmbPcvHUr9Xjb/9lL+Qf8s3NKNjt5Io46dZ6mcGF3AJo2acD+/YdypS57iNm6g0ceqUD58gEYjUa6d+/I4vCcz5zJTXkVc6nSJVI/cCvkXoh6jepw9NDxDNsVK16M2vWeZtWytallm6KiadW+WeqYsGcJD3z9bRt6iVz2F517tAOgVftmbF4fA4DR6Mq4oJEsDA1nWdiq+zqncpZhPzAPNRgMBi6cv0jU2k10CGxFmbLmMeESJT0JCMgsHWS0LCKSXs93AqBjp1ZE/bXZEq+RGSHjmRW8gEULlt5XvFaZkmxfbKSUSgTWAq2UUqeVUiZlvnH0ZKC2ZbNYIG1S8wfiLeX+mZRnyVrP+R0gUkQOASctZQ9g7uJna77N2fMX+ezbkZhSUlApipZNn6Vx/TqpU9h6dGrL/73Ym8+GjaJT39dRSvHuwJcpWcKTkiU8efPVfgx45zNSVApGV1c+e28gvt5eVuvt3K4lnwz9kdbdX8bTozg/DvkYgKPHT/Ljr5MREZRSvNirM48+XCE7p2Sz6JjtzJ+/hJjo5SQnJ7Njxx4mT8n4CbejMJlMvP3O50QsCcbFYGBa0Gz27j2Y32FlKa9iLutVhh9+HYLB4ILBICxdtIo1K9fR64UuAIQEzQOgRdsmrF+7mRvXb6bue/jgMUYPH8+0OeMQMZCcnMyQj0YQH2v9w+E5MxcxcvxQVkUvJPHiJd4d8CkArTs+R626T1OylCede7YH4KM3v2bf7v/OfcrU0dR/tg6lS5dk94H1jBg2BqPR/KM/9fcQOnZqzUuv9MaUnMyNG7fo/6J5+PDA/sMMG/oT8xdNw2AwkJSUzOD3vubkSat5hRlBoUycMoptOyO5eDGR/i++A0Cnzm2oV78WpUqVoHefzgAMfO0jdv+zL4ujZZOdLt8WkbJAklIqUUQKA82B70XERymVYNmsE3Dnz5UwINgysuCL+YO/aKWUSUSuWD5M3AL0A36xWr+18R4RMWD+zeCHuXseC8QoGz7qBP30bc056Kdv5w17PH375qYQm3OOe91e96xPRKoAQYAL5lGGUKXUNyIyA/PsDQUcB167k6xF5DPMQxzJwDtKqaWW8prANKAwsBR4U1lJvlavELR03Tdb207TNM0h2KnnrJTaBVTPpLxvFvsMA4ZlUr4VqJxxj3vTl29rmuZc9F3pNE3THI/Kxgd9jkwnZ03TnIuT3PhIJ2dN05yLHtbQNE1zQLrnrGma5oB0z1nTNM0B6Z6zpmmaA0p27Jvo20onZ03TnIvuOWuapjkgPeasaZrmgHTPWdM0zQHpnrNtfB+27TE8juLSV83yO4Rs8xwSmd8hOL3ryTetb6Q5Bt1z1jRNc0B6toamaZoDcvDnXdpKJ2dN05yLHnPWNE1zQDo5a5qmOSD9gaCmaZoDMtn0eFOHp5OzpmnOxUmGNQz5HYCmaZpdpaTYvmRBRNxFJFpEdorIHhEZYikvJSIrReSQ5f+Safb5REQOi8gBEWmZpryGiPxjWTdWRKw+ZVwnZ03TnItKsX3J2i2gqVKqKlANaCUizwAfA5FKqYpApOU9IlIJ6Ak8CbQCxouIi+VYE4ABQEXL0spa5To5a5rmVFSKsnnJ8jhmVy1vjZZFAR2BIEt5EBBoed0RmKWUuqWUOgYcBmqLiA/goZTapJRSwPQ0+9yTTs6apjmXbAxriMgAEdmaZhmQ9lAi4iIiO4AzwEql1BbASymVAGD5v5xlcz/gZJrdYy1lfpbXd5dnSX8gqGmac8nGbA2l1CRgUhbrTUA1ESkBLBCRylkcLrNxZJVFeZZ0ctY0zbnkwmwNpVSiiKzFPFZ8WkR8lFIJliGLM5bNYoGANLv5A/GWcv9MyrOkhzU0TXMu9putUdbSY0ZECgPNgf1AGPCCZbMXgEWW12FATxEpJCIVMH/wF20Z+rgiIs9YZmn0S7PPPeVZcvb182bB4ulsiI5g3eZwBvxfv0y3++77z4jevoK1G8KoUrVSjut1czMyeepoorevYFlkKAEPmId6Kj/1OBErZ7FuczhrN4QR2Dn9rU2leCncn/+Ywq+NoPCA73Ct1SLjwQsVplD3d3F/5VvzNlWezXG8uLhSqNMgCr/+I+4vfoV4ljHH41Ea95eH4P7KUHNdTzfJeV1ZaNmiMXt2R7F/73o+HDwoV+uyl7yI2dfPmzlhU1m7OYzVGxfR/7U+mW5Xt34tVkTNY/XGRcwNn5bjet3cjEz4fSTrty1l8coQ/AN8AXiy8uOELZ/J6o2LWLl+Ph06ZZwE8Mv44Rw8toWN0RH3PH79Z+sQtTGMjTFLCV8WbId43fg9aAzbdkaycs3cND93T7A8cg4bY5ayfnM4nbq0yXFdGShl+5I1H2CNiOwCYjCPOYcDI4DnROQQ8JzlPUqpPUAosBdYBgyyDIsAvA5Mwfwh4RFgqbXKReXyHZzKej6mALy8yuLlXZZdO/dStFhRIv+aR7/egzh44Ejqts2fa8grr/WlZ9dXqVGzKsO+/4xWzbrbVE/AA378Mn44ge3SJ/2XXulNpScfY/C7XxHYpQ1t2z3Hqy+9y0MPlwelOHr0X7y8yxH51zzq1W7DrtfMvxCkmCdSrAQpp/4FN3cKv/wNN+f+jDr3318jxnrtoVBhktaEQpHiFPm/77n+85uQYn3MSzzLUKj9q9z8c3i6ctcazTCUC+D20mm4VKqD62M1ubVgHBhcQARMyWAsROEB33EzaCjqaqLd7+dsMBjYt2cdrdr0IjY2gc2bIujTdyD79h2yaz32lNsxexUtAUA5rzKU8yrL7l37KFqsCMvWzOHlPm9xKE079vAozqLlM3m+22vExyZQukwpzp+7YFM9/gG+jB4/jG7tX0pX/kL/njzx5KN8/N43dOjcmtZtm/F6/w946OEHUUpx7OgJvLzLsnTNHBrXac/ly1e4nnQLgHr1a3H16nUmTv6RerUzJkMPz+Isj5xDt8CXiI1NoEzZUpw7a1u8AQ/4Mf63H2jf+vl05f1ffZ4nKz/Ge29/SeeubWnbvgX9X3ibhx8pj1KKo0f+xdu7HGvWL6ROjZZcvnQFgItXD1ud/2vN9Z9etTmpFXlvco7ryy151nM+ffosu3buBeDa1WscPHAUH1+vdNu0atuM2SELAdi2dSeenh54eZUFoGv3DixfPYc16xYy8uchGAy2hd66TVNmBy8AYPHC5TzbqC4AR48c5+jRf82xnTrD2bMXKFO6VOp+6uolc2IGuH2TlPPxSPGS6Q+OQgoVBkCMhVA3rqX+qeRSuR7uL32F+ytDcWv9ojmx2sCl4tMk71oPgGlfDC7lLX89pJjMiRnA1QiSe9+62rWqc+TIcY4dO0FSUhKhoYvo0L6l9R3zUV7FfOb0OXbv2gfAtavXOXTwKN4+5dJt06lbW5aGryI+NgEgXWLu3L0d4atmsSJqHt+P/srmdtyidVPmhJj/El6yaAUNGj0DwNEj/3Ls6AkATp86y/lzFyhdJn073bghhosXE+957G7dOxAetpxYS7xpE3P3Hh1ZtXYeURvDGD12qO0/d22bEzLT/HO3aMEyGjU2/9wdOXyco0fMP1enTp3h3NnzlClT6p7HuS8pyvbFgd33T7iIvGR9q8wFPODHU1WeYNvWnenKfXy8iI87lfo+Pv4U3r5eVHz0IQI7t6Zti140eTYQkymFrt3b21SXt48XcXHmRmcymbh8+QqlSqVvvNWffgo3NyPHjp3I9BjiWQaD14OkxB1JV560dRWG0j4UfnsshQd8x+2VfwIKKe2La6U63Az6lptTvgClcK1cz6Z4DcVLoi6fN79RKahb16FwMXMcxUtR+JVvKfLmaJI2haOuJtp0zOzy9fPmZOx/fyHExiXg6+udK3XZS37E7B/gS+UqT7B926505Q89XB7PEh7MWTyVpWtC6dqjAwCPPPoQHTq1JrBVH1o07ILJlELnbu1sqsvbt1zqz8addlyyVIl021R7+imMRleOHzuZyRHu7eFHylOihCeLl85kzbqF9OgVCMCjjz1Mpy5tadW8Bw3rdcBkSqGb5Vys8fX1Ii42zc/dpauUKp3+5+7pGlUwuhlTf7nYjclk++LAcjJbYwgwNbMVlrmCAwCKuZfD3a1E6rqiRYswdcZYPv/kO65euXb3fhmOpZSiYaO6VK1WmZVr5gLgXtidc2fNCWzan7/y4IP+GN2M+Pv7sGbdQgAmTZxOyMz59zzmHV5eZRk/6Ufe+L+PyHSIx1iIQl3e5PbKmXA7/aOKXB56ipTTJ7g9cwRSshzuvT/ixonPcKlQCYN3edxf/tp8Xq5uqGuXASjU9S2kRFnE4Ip4lsb9laEAJEevIHnXuswn3dyJ+8oFbkz5HClWgkLd3iZ5fwxYjmtP1r5mjiivYy5StAiTp//MV5+MyNCOXVxdqFK1Et0D++PuXojFK4L5e+tOGjR6hqeqViJi9WwA3N0LpbbjKTPG8MCD/hiNRvz8fVgRNc9cPnEGocELkcwaRprzK+dVhrETh/POwE+zfd6urq5UrVaZwHZ9cS/szorIOWyN2UGjxvWoWv1JVkfNt8TrzllLvDNCxlt+7tzw9/chamMYABPHBxH857xM/1K8++du4uSRDHztQ7t/n5ST3Fsjy+RsGQjPdBXgdY916eYO3hlzBnMjmDpjLHNDF7Nk8coM+8XHn8LX77/ejq+vN6cTziAizA5ZwLdDfsqwz4t93gDuPeacEH8KPz8fEuJP4+LigodH8dQ/8YoVL0rwnN8Y/u3PGXrxABhcKNTlLZJ3b8J0YGuG1a5VnyVpY7j5nC+eQSWexVDGFxCSd60nae2cDPvcmjsWuPeYc8rli4hHadSViyAGpFARuHE13TbqaiIpZ+NwCXgM0/6YjHHnUFxsAgH+vqnv/f18SEg4bfd67CkvY3Z1dWVy0M8smLOEpeGrMqxPiD/NhfMXuXH9Bjeu32Dzxq1UqvwYAsyZtYgR3/ycYZ9X+r5tjvseY84J8afx9fO+qx1fAsztePrsCfwwbCx/b73Xj+y9xced4vz5i1y/foPr12+wcUMMlZ96AgRmzVzAN1+PzLBP314DgXuPOcfHncLP34f4+FPmeD2LcfFCIgDFixdj9rwpDBs6mq0xO7Idr1UOPlxhK2vDGl6Yp320z2Q5n93Kfv51GAcPHGXiuGmZrl8esTr1T6oaNaty+fIVTp8+S9Rfm2jfsWXq2FSJkp6pn1ZbsyxiNT16dwKgfWBL1kdtBsBoNBI0cxyhIYsIW7gs033d2vZHnY8nOTrz9erSeVzKP2l+U9QDKe1NysUzmI7vwfWJWlCkuHmde1HEo7RN8ZoO/Y1rlQYAuDxRC9Nx8zi9FC9pHmsGcC+Ci/+jpJxPsOmY2RWzdQePPFKB8uUDMBqNdO/ekcXhK3KlLnvJy5hH/fINhw8eZdL4oEzXL49YTZ26NXBxccG9sDvVa1bh0MGjrI/aQrsOLSh9px2X8MQvwMemOlcsW0O3Xh0BaNuxBRuitgDmdvz7jLHMnRVG+KL7O9+IJauoW68mLi4uFC7sTs1aVTl44DBRazfRIbAVZcr+93MXYPPPXSS9njf/3HXs1Iqov/77uZsRMp5ZwQtYtMDqhIX7Y797a+Qra8Ma4UAxpdSOu1dYJmTbrM4zNejRK5A9uw+kDj0M++Yn/Czf7KA/ZrFyxV80b9GI6B0ruXH9Bm8N+hSAgweOMPzbn5mz4A/EYCA5OYmP3v+G2JNW53Ezc8Zcxk/6kejtK7h48RIDXn4XgI6dWlO3Xk1KlSxBT0vyfnPgx6n7GfwfxVilASmnT6QOPSStmYN4mpNs8t9rSFq/iELtX8X11WGAcHt1KNy4irpxldtr5+He+0MEQaWYuL1s+n9jyVlI3hFFoY6vUfj1H1E3r3JrwXgApIwv7s16pV5ulLQlAnU2Nstj3S+TycTb73xOxJJgXAwGpgXNZu/eg7lSl73kVcy1nnmarj07snfPgdShhxFDf8bP35xkZ0wN5fDBo6yJXM+q9QtIUSmETJ/HgX2HAfhh2FhC5k9GDEJyUjKfDf6WuJPWf8nOmjGPsRNHsH7bUhIvXmJg/w8AaN+pJXXq1aBkqRJ07x0IwLsDP2PP7v2p+06ZOpr6z9ahdOmS7D6wnhHDxmA0mn/0p/4ewsEDR4hcGcX6LUtQKSlMnxbKvr3mWS7Dhv7E/EXTMBgMJCUlM/i9rzlpw8/djKBQJk4ZxbadkVy8mEj/F98BoFPnNtSrX4tSpUrQu09nAAa+9hG7/9ln9Zg2c5Kec55NpSsojn9YJ79DyDZ7T6XTMrozla4guTOVriCxx1S6a1/2tDnnFP1mlsNOpdOXb2ua5lwcfLjCVjo5a5rmXJxkWEMnZ03TnMr/xFQ6TdO0Akf3nDVN0xyQTs6apmkOyMEvy7aVTs6apjkVa88GLCh0ctY0zbno5KxpmuaA9GwNTdM0B6R7zpqmaQ5IJ2dN0zTHo0x6WMMmF++6F7GjK4g3ESruVji/Q8i2K7dv5HcI2XL6WmJ+h5BtRYyF8juE/GGnnrOIBADTAW8gBZiklBojIl8DrwJnLZt+qpSKsOzzCdAfMAFvKaWWW8prANOAwkAE8Layctc53XPWNM2p2HEqXTLwvlLqbxEpDmwTkTtPCRmtlEr3FAIRqQT0BJ4EfIFVIvKo5QncEzA/HWoz5uTcCitP4M6zB7xqmqblCTs94FUplaCU+tvy+gqwD/DLYpeOwCyl1C2l1DHgMFBbRHwAD6XUJktveToQaO00dHLWNM25pNi+iMgAEdmaZhmQ2SFFpDxQHdhiKXpDRHaJyB8icufJtX5A2qfrxlrK/Cyv7y7Pkk7OmqY5FZWcYvui1CSlVM00y6S7jycixYB5wDtKqcuYhygeBqoBCcCoO5tmFk4W5VnSY86apjkXO07WEBEj5sQ8Uyk1H0ApdTrN+smYH+cH5h5xQJrd/YF4S7l/JuVZ0j1nTdOcikpRNi9ZEREBfgf2KaV+SlOe9qm8nYDdltdhQE8RKSQiFYCKQLRSKgG4IiLPWI7ZD1hk7Tx0z1nTNOdiv55zfaAv8I+I7LCUfQr0EpFqmIcmjgOvASil9ohIKLAX80yPQZaZGgCv899UuqVYmakBOjlrmuZk7DWVTim1nszHiyOy2GcYMCyT8q1A5ezUr5OzpmnOxTkuENTJWdM056KS8zsC+9DJWdM0p6J0z1nTNM0B6eSsaZrmeHTPWdM0zQE5S3IukBehtGzRmD27o9i/dz0fDh6U3+HYJC9i/mX8cA4e28LG6HvO9KH+s3WI2hjGxpilhC8LznGdbm5u/B40hm07I1m5Zi4BD5hvGVD5qSdYHjmHjTFLWb85nE5d2uS4LmsKWrvw9/dl1Yo5/LNrLTt3rObNN/rnSj3jJnzPkePRbI7JfGpt9x4d2bglgo1bIlgZOYfKTz2e4zrd3NyYGjSWHbtWs3rtfB6wtIunqjzBqtVz2RKzjI1bIujcpW2O67qbMonNiyMrcMnZYDAwdsww2rXvw1NVm9CjRyBPPFExv8PKUl7FHDJzPl0DX77neg/P4owcPYTe3V+jXq3WvNj3DZuPHfCAH4uXzsxQ3veFblxKvESNqs2YMG4qXw/9EIAbN27w+oAPqFerNV0DX+a77z/Hw7N49k/KRgWxXSQnJzP4wyE8VaUx9Ru05/XXX8yVmGf+OZfOgS/dc/3x4ydp07In9eq04Yfvf2XsL9/ZfOwHHvBjydKMv+T7vdCdxMTLVKvSlHG//sGQoR8BcOP6TV579QPq1GpF544vMuKHL/C0c7tQKbYvjsxqchaRx0WkmeXmH2nLW+VeWPdWu1Z1jhw5zrFjJ0hKSiI0dBEd2rfMj1Bsllcxb9wQw8WLifdc3617B8LDlhMbmwDAubMXUtd179GRVWvnEbUxjNFjh2Iw2PZ7u3Xb5oTMXADAogXLaNS4LgBHDh/n6JF/ATh16gznzp6nTJlS93NaNimI7eLUqTNs32G+8vfq1Wvs338IP19vu9ezcUMMFy8k3nN99Ja/SUy8DEBM9HZ8/f6LoUfPjqz5awHrN4Xz89hvbW4Xbds1J2TmPAAWLlhK48b1ADh8+BhHjhwHzOd/9ux5ypQpfR9ndW8qRWxeHFmWX2kReQvzNeBvArtFpGOa1bb/erUjXz9vTsb+d8+Q2LgEfHOhQduTo8T88CPlKVHCk8VLZ7Jm3UJ69AoE4NHHHqZTl7a0at6DhvU6YDKl0K1HB5uO6evrRZwl2ZtMJi5fukqp0iXTbfN0jSoY3YwcO3rCrueTLg4H+Rrfrwcf9Kda1cpsid6er3H0faE7K1f8BZjbRecu7XiuWTca1G1HiimFHj07WjmCmY+vV2onwGQycfnylQztokaNKrgZjRw9+q9dz8FZes7WPhB8FaihlLpquZ/pXBEpr5QaQ+aXNQLme6Rivus/4uKJwVDUXvFivm9Ielae9pLvHCVmV1dXqlarTGC7vrgXdmdF5By2xuygUeN6VK3+JKuj5gPg7u7O2bPnAZgRMp4HH/TH6OaGv78PURvDAJg4PojgP+eBlXPz8irLxMkjGfjah7l6zo7yNb4fRYsWIXT2ZN774CuuXMm/x7o92/AZ+vXrTsvnugPQuHE9qlWvzNp1CwEonKZdzAyZwIPlA3AzGvEP8GX9JvON2SaMn8bMGXORzNJD2nbhXZZJU37i/wZ8YPfvk1KO3SO2lbXk7KKUugqglDouIo0xJ+gHySI5W+6JOgnA1c3Prl/5uNgEAvx9U9/7+/mQkHA6iz3yn6PEHB93ivPnL3L9+g2uX7/Bxg0xVH7qCRCYNXMB33w9MsM+fXsNBMxjzuN/+4H2rZ/PcEw/fx/i40/h4uKCh2ex1D+hixcvxux5Uxg2dDRbY3bk6rk5ytc4u1xdXZkzezIhIQtYuNDqvXByzZOVH+fXccPp0ullLli+fyJC8Mz5DPnqxwzbP9/rdcA85jzhtx9p27p3uvXx8afwT9suPIqnHrd48WLMmfc7Q78ZRUwutAtH7xHbytoA0inL3ZcAsCTqdkAZ4KlcjOueYrbu4JFHKlC+fABGo5Hu3TuyOHxFfoRiM0eJOWLJKurWq4mLiwuFC7tTs1ZVDh44TNTaTXQIbEWZsuYx4RIlPQkI8LVyNLNlEZH0er4TAB07tSLqr80AGI1GZoSMZ1bwAhYtyP2k4yhf4+yaPGkU+/Yf5ucxGe7xnmf8/X2ZGTyeV195n8OHj6WWr127kcDA1pQpax4TLpmNdhGxJJJez3cBILBTa/76axNgbhczZ01kVvACFuZSu0gxic2LI7PWc+6H+dZ3qZRSyUA/Efkt16LKgslk4u13PidiSTAuBgPTgmazd+/B/AjFZnkV85Spo6n/bB1Kly7J7gPrGTFsDEaj+Vs89fcQDh44QuTKKNZvWYJKSWH6tFD27T0EwLChPzF/0TQMBgNJSckMfu9rTp60ej9wZgSFMnHKKLbtjOTixUT6v/gOAJ06t6Fe/VqUKlWC3n06AzDwtY/Y/c8+u583FMx2Ub9eLfr26cquf/ayNcb8i+SLL0awdNlqu9bzx7QxNLC0i30HN/Ddt/+1iz9+D+ajT96kZKmS/PTzNwAkJ5to/GxHDuw/zNBvRrEwLMjSLpL44N2vbGoX04NmM2nKT+zYtZqLFy/x0gtvAdC5Sxvqp7YLc/J+/bXB/LPLfu3C0T/os5Xk9ricvYc1tIyKuxXO7xCy7crtG/kdgtMrYiyU3yFk2+VrR3OcWY9Xe87mnFN+x0qHzeT6CkFN05xKAfkc2CqdnDVNcyrOMqyhk7OmaU7lf2UqnaZpWoFicvBZGLbSyVnTNKfiLD3nAnfjI03TtKzY694aIhIgImtEZJ+I7BGRty3lpURkpYgcsvxfMs0+n4jIYRE5ICIt05TXEJF/LOvGSmaXtN5FJ2dN05yKUrYvViQD7yulngCeAQaJSCXgYyBSKVURiLS8x7KuJ/Ak0AoYLyIulmNNwHxLi4qWxeqN43Ry1jTNqdir56yUSlBK/W15fQXYB/gBHYEgy2ZBQKDldUdgllLqllLqGHAYqC0iPoCHUmqTMl9YMj3NPvekx5w1TXMqphTb+5xpb9JmMclyb6C7tysPVAe2AF5KqQQwJ3ARKWfZzA/YnGa3WEtZkuX13eVZ0slZ0zSnkp2LUNLepO1eLPeynwe8o5S6nMVwcWYrVBblWdLJWdM0p5Jix9kaImLEnJhnKqXmW4pPi4iPpdfsA5yxlMcCAWl29wfiLeX+mZRnSY85a5rmVJQSm5esWGZU/A7sU0r9lGZVGPCC5fULmB9Icqe8p4gUEpEKmD/4i7YMgVwRkWcsx+yXZp970j1nTdOcih3vrVEf6Av8IyI7LGWfAiOAUBHpD5wAupnrVXtEJBTYi3mmxyCllMmy3+vANKAwsNSyZEnflU7LF97FSlrfyIGcunoxv0P4n5B8Oy7HYxJb/QNtzjk1Yxc67BUruuesaZpTyc5sDUemk7OmaU7FWf5U18lZ0zSnYs/ZGvlJJ2dN05yKs9z4SCdnTdOcipM8fFsnZ03TnIvK9IK8gkcnZ03TnEqyHtbQNE1zPLrnrGma5oD0mLOmaZoD0j1nTdM0B6R7zpqmaQ7IpHvOmqZpjsfK06cKjAJ5h5CWLRqzZ3cU+/eu58PBg/I7HJsUtJjzKl4fP29CF/3Bms1hRG5cSP/X+mTYpnjxYkwN/pUVUfOI3LiQ7r0Dc1yvm5uR8b+PZP3WCBavDMY/wBeASpUfY9HyP4ncuJCV6+bTvpPV53DeN39/X1atmMM/u9ayc8dq3nyjf67VZS8FoR2nIDYvjqzA3TLUYDCwb886WrXpRWxsAps3RdCn70D27Ttkz2rsqqDFnBfx3rllaDmvMpTzKsvuXfsoWqwIS1eH0r/vWxw6cDR12zfefRUPj2J8N2Q0pUqXJCo6nOqPNyIpKdlqPf4BvoweN4xuHV5KV97v5R488eRjfPL+N3To3JpWbZsxsP8HVHj4QVCKY0dP4OVdlojVoTR5pgMH40/Y7dzv8PYuh493Obbv2E2xYkWJ3rKMLl1f/p9uF/a4ZehC794255zAU8EOm6Gt9pxFpLaI1LK8riQi74lIm9wPLXO1a1XnyJHjHDt2gqSkJEJDF9Ghfcv8CscmBS3mvIz3zOlz7N61D4BrV69z6OBRvH280m2jlKJosaIAFC1ahMSLl0hONt/DvHO3doSvDGH5X3MZ8dOXGAy2/THYok1T5swyP4xiyaIVNGhYB4BjR/7l2FFzIj596iznz12gdJncuff0qVNn2L5jNwBXr15j//5D+Pl650pd9lBQ2nFKNhZHlmVLFpGvgLHABBEZDvwKFAM+FpHP8iC+DHz9vDkZ+9/jt2LjEvB14AYNBS/m/IrXP8CXylWeYPu2XenKp00JpuKjD7Ft7xpWrV/Al5+MQCnFI48+RPtOrQhs3ZeWjbpiMqXQqVs7m+ry9ilHQtwpAEwmE5cvX6VkqRLptqn2dGWMbkaOHztpl/PLyoMP+lOtamW2RG/P9bruV0FpxykiNi+OzNoHgl2BakAh4BTgb3n67I+YHxE+LLOd0j5uXFw8MRiK2i3gzJ58m9tDMzlV0GLOj3iLFC3MpKDRfP3p91y9ci3dusZN67Nn9366d3yZ8hUCCJ4/mRYNt9GgYR2eqlqJJZGzAHB3L8T5cxcAmDJ9DAEP+mF0M+Ln58Pyv+YC8PtvfxIavNDqOZbzKsOYCcN5d9BnuX7uRYsWIXT2ZN774CuuXLmaq3XlREFpxybrmxQI1pJzsuUZWNdF5IhS6jKAUuqGiNzzr4K0jxu395hzXGwCAf6+qe/9/XxISDhtzyrsrqDFnNfxurq6MinoZxbMXcLS8FUZ1nfv3YlxP08B4Pixk5z8N45HKlZARJg7K4wRQ3/OsM8r/d42x36PMeeE+NP4+HmTEH8aFxcXPDyKkXjxEgDFihclaNZ4fvjuF/7euivDse3J1dWVObMnExKygIULrT5WLl8VlHb8vzJb47aIFLG8rnGnUEQ8yachm5itO3jkkQqULx+A0Wike/eOLA5fkR+h2KygxZzX8Y4c+w2HDx5l8vjpma6Pi02gQaNnAChTtjQPP1Kef4/Hsj5qM207PEfpMqUAKFHCAz9/H5vqXLl0Dd16dgSgbccWbFi3BQCj0ZUp08cwd3YYSxbl/vdo8qRR7Nt/mJ/HTMr1unKqoLRje87WEJE/ROSMiOxOU/a1iMSJyA7L0ibNuk9E5LCIHBCRlmnKa4jIP5Z1YyWzP0PuYq3n3FApdQtAKZU2GRv579HgecpkMvH2O58TsSQYF4OBaUGz2bv3YH6EYrOCFnNexlurTnW69uzAvj0HU4cevh86Bl9Lkv1zWihjRk7kp3HDWLV+Pojw3ZDRXLyQyMULifzw3S8Ez5uEwWAgKSmJzz8cRlxsgtV6Z/05nzETh7N+awSJFy8x8JXBALQPbEWdejUoWaoE3XsFAvDuoM84tXmz3c+9fr1a9O3TlV3/7GVrjDnJffHFCJYuW233uuyhoLRjOw+0TMP8WdvdPYfRSqmRaQtEpBLQE3gS8AVWicijltGHCZiHejcDEUArrDyBu8BNpdOcg376tpYZe0ylm+7Xx+ac0y/uT6v1iUh5IFwpVdny/mvgaibJ+RMApdRwy/vlwNfAcWCNUupxS3kvoLFS6rWs6i2QF6FomqbdS3am0onIABHZmmYZYGM1b4jILsuwx52ehh+QdmpPrKXMz/L67vIs6eSsaZpTMYnti1JqklKqZprFlsH/CcDDmGeyJQCjLOWZ9cJVFuVZ0vfW0DTNqeT2TAWlVOoUFRGZDIRb3sYCAWk29QfiLeX+mZRnSfecNU1zKrl9haCIpJ0S1Am4M5MjDOgpIoVEpAJQEYhWSiUAV0TkGcssjX7AImv16J6zpmlOxZ6PEBSREKAxUEZEYoGvgMYiUg3z0MRx4DUApdQeEQkF9gLJwCDLTA2A1zHP/CiMeZaG1UntOjlrmuZU7DmsoZTqlUnx71lsP4xMrpxWSm0FKmenbp2cNU1zKv8rl29rmqYVKM5y+bZOzpqmORVHvxWorXRy1jTNqejkrGma5oCc5X4ROjlrmuZU9JizpmmaA9KzNWxkcPBHwdztQQ8v6xs5mGOXTuV3CNlW0O7y9oBHufwOIdvirp7L7xDyRYqTDGzonrOmaU5FfyCoaZrmgJyj36yTs6ZpTkb3nDVN0xxQsjhH31knZ03TnIpzpGadnDVNczJ6WEPTNM0B6al0mqZpDsg5UrNOzpqmORk9rKFpmuaATE7Sd9bJWdM0p6J7zpqmaQ5IOUnP2ZDfAWiaptlTSjYWa0TkDxE5IyK705SVEpGVInLI8n/JNOs+EZHDInJARFqmKa8hIv9Y1o0VsX5HuAKRnAsVKsSG9eFsjVnBju2RfPnF+wBUrVKJdVFhxEQvZ9PGJdSsWc1udboVcmPu8iDC1oQQsS6Utz58LcM2rwzqS9iaYMLWBLMkajb7T0XjWcIjZ/W6Gfl58nBWRS9k7rIg/AJ8AHii8qOERkwlYl0oi9fOok3gczmqx5qWLRqzZ3cU+/eu58PBg3K1LnvJi5jdCrmxYMUMlqydzbL1c3nno/+757ZVqlfi0OmttG7fPOf1uhkZO2UEq6MXMX/59HTtYu7SIJatn0vEX7NpG9gix3VlxmAwsGXzUhbMn5paNvD1F/ln11q2/72K74Z9miv13o8UlM2LDaYBre4q+xiIVEpVBCIt7xGRSkBP4EnLPuNFxMWyzwRgAFDRstx9zAwKxLDGrVu3aNGyO9euXcfV1ZW1axawbPkavvrqfb4dNprly9fQqlVThn/3Gc+16GaXOm/fuk2/zv/H9Ws3cHV1ZVb470RFbmDHttRfoEwZN4Mp42YA0LTFs7z4f89zKfGyTcf3C/Dh+1++pk9g+qTf9flALidepnntQNoGtmDwl2/xzqufcOP6TQa/8SX/Hj1JOa8yLIicybrVm7hy+apdzjctg8HA2DHDaNWmF7GxCWzeFMHi8BXs23fI7nXZS17FfPvWbZ7vNCC1XYQu+YO1qzawY9s/GeL58Mu3Wbd6U7aO7xfgw4+/fkPvjq+mK+/+fCCXE6/QtHZH2nVqyUdfvc1br3zMzRs3+WDQFxw/eoJy3mUJi5xJ1OqNdm8Xb77Rn/0HDuNRvBgAjRrVpX37FtSo2YLbt29Ttmxpu9aXE/Yc1FBKRYlI+buKOwKNLa+DgLXAR5byWUqpW8AxETkM1BaR44CHUmoTgIhMBwKBpVnVXSB6zgDXrl0HwGh0xWh0RSmFUiq1sXh6FCch4bRd67x+7QYArkZXXI2uqCy+6+06tyJ8/vLU9x26trb0vIMZOvJTDAbbvtTNWzdi/uxwAJYtjqTus7UBOH70BP8ePQnAmdPnOH/2AqXKlLzncXKidq3qHDlynGPHTpCUlERo6CI6tG9pfcd8lJcxZ2wXGRvGC6/2ZPniSM6du5CuvGO3NixYMYPwNbP4dtRn2WgXjZk3azEAS8NWUc/SLo4dOcHxoycAOHPqLOfPXqR0mVL3fW6Z8fPzpnXrpkydGpJaNuDVvvw4cjy3b98G4OzZ83atMyeSUTYvIjJARLamWQbYUIWXUioBwPL/nZt9+wEn02wXaynzs7y+uzxL2U7Olqyf5wwGAzHRy4mL3Ulk5DpiYrbzwQdfM3z45xw5HM2IEV/w+RfD7V5n2JpgNu9byYa1m9n59+5Mt3Mv7M6zTeuyPDwSgIcrlqdtYAt6tu1Phya9MZlS6NC1tU11enmX5VSc+ZeMyWTi6uWrlCxVIt02Vao/iZubkRPHYjM5Qs75+nlzMjY+9X1sXAK+vt65Upe95GXMBoOB8DWziNkXmWm78PIuS4u2TZk5bW668ocrVqBdYAu6tXmJdk16kmJKoWPXNjbV6eVTjoQ480MVTCYTV+7RLoxurvx77GQmR7h/I3/8mk8+/Y6UlP9GaStWfIj69WuzLiqMlSvnUKNGVbvWmRMqO/+UmqSUqplmmZSDqjMbR1ZZlGcpy2ENEQnLpPImIlICQCnV4R77DcA8voKLSwkMLkWtxWFVSkoKtWq3xNPTgzmhU3iy0mP0f+V5Bg8ewoKFEXTt0o7ffhtJ69a9clxX2jo7NOlNcY9ijA8aRcXHH+bQ/iMZtmva8ln+jt6ZOqRRt2Ftnqz6BPNXmn+PFXIvxHlLD2rctJEEPOiL0WjEx9+bsDXBAARNCmFeyGIy+5wgbc+srFcZfhz/DR+98VWmPTZ7sBaDI8rLmFNSUmjXpCfFPYoxcfpPPPr4wxxM0y6+GDaY74eMSZfMAOo1rE3lqpVYuPJPANwL/9cuJgSNIuABP4xuRnz9vAlfMwuAaZOCmRsSZlO7+GnCt3ww6Eu7nneb1s04e/Y827f/Q8OGz6SWu7q6UrKEJ8827EDNmtUInjmexx6vb7d6cyIPptKdFhEfpVSCiPgAZyzlsUBAmu38gXhLuX8m5VmyNubsD+wFpvDfb4CawKisdrL89pkE4FbI364/IZcuXSYqahMtWjamb5+uvPfelwDMnRfOxIk/2rOqVFcuX2XLhq00bFov0+TcNrBluiENEWHB7HBGfftrhm0HvfgBcO8x51MJZ/D28+JUwhlcXFwo5lGMxIuXAChWrCiTg8cweviEdGPf9hYXm0CAv2/qe38/H7sPGdlbfsSc2i6a1UuXnJ+qVomxk0cAULJUCRo3b0BycjIiwvxZi/nx218yHOv1F8wfct9rzPlU/Gl8/LxT20Xxu9rF7yFjGfXduAxj3zlVt15N2rZ9jpatmuBeqBAeHsWZOnUMcXEJLFxkHjLdunUHKSmKMmVKZRjGyQ95MJUuDHgBGGH5f1Ga8mAR+QnwxfzBX7RSyiQiV0TkGWAL0A/I2AjuYm1YoyawDfgMuKSUWgvcUEr9pZT6K/vndH/KlCmFp6d5FoS7uztNmzbgwIHDJCScpmHDugA0aVKfw4eP2a3OUqVLUNzDPJ5dyL0Q9RrV4eih4xm2K1a8GLXrPc2qZWtTyzZFRdOqfbPUMWHPEh74+tv2J3bksr/o3KMdAK3aN2Pz+hjAPNY+LmgkC0PDWRa2KgdnZl3M1h088kgFypcPwGg00r17RxaHr8jVOnMqr2IuVbpkunZRv2HGdtGoRjsaPt2Whk+3ZeniVXz14XBWLl3LxqhoWndoTul07cLHpnojl/1Fl57tAWjdoTmb1v3XLiZOH8WC2eEszYV28cUX3/PwI7V57LF69O03iLVrN/DSS28TFracxo3NPeWKj1TA6GZ0iMQMdp9KFwJsAh4TkVgR6Y85KT8nIoeA5yzvUUrtAUIxd2iXAYOUUneeN/s65k7uYeAIVj4MBCs9Z6VUCjBaROZY/j9tbZ/c4OPtxe+/j8bFxQWDQZg7N5yIiEgSEy/z06ghuLq6cvPmLV4f+JHd6izrVYYffh2CwWCuc+miVaxZuY5eL3QBICRoHgAt2jZh/drN3Lh+M3XfwwePMXr4eKbNGYeIgeTkZIZ8NIL4WOsPYp0zcxEjxw9lVfRCEi9e4t0B5ilKrTs+R626T1OylCedLT+kH735Nft2H7TbOd9hMpl4+53PiVgSjIvBwLSg2ezda/967CmvYi7nVYYff/0GFxcDYjAQsWglq1eso/eLXQEIvmucOa3DB48y6rtxBM2ZgMEgJCUn89WHI4iPTbBa7+yZC/lp/Lesjl7EpcTLvPXqxwC0CWxBrbpPU6JkCbr0NI8yDn7zy1xpF2lNC5rNpEkj+XvbKm7fvs0rr7ybq/Vlh8mOwzpKqXuNkza7x/bDgGGZlG8FKmenbsnO+JSItAXqK6VsntRo72GN3Kafvq1lRj99O2/cunnS6sUZ1vR+sJPNOSf43wU5ri+3ZKsXrJRaAizJpVg0TdNyzFku3y4QF6FomqbZSt/4SNM0zQHpJ6FomqY5ID2soWma5oDsOVsjP+nkrGmaU9HDGpqmaQ5IfyCoaZrmgPSYs6ZpmgPSwxqapmkOyNHvoGgrnZw1TXMqJt1z1jRNczx6WEPTNM0B6WENGxmkwDymENB3eNMyF3/VcZ6RZ6sGZZ7I7xDyhe45a5qmOSA9lU7TNM0B6cu3NU3THJAe1tA0TXNAzpKcC9andZqmaVYopWxerBGR4yLyj4jsEJGtlrJSIrJSRA5Z/i+ZZvtPROSwiBwQkZY5OQ+dnDVNcyopKJsXGzVRSlVTStW0vP8YiFRKVQQiLe8RkUpAT+BJoBUwXkRc7vc8dHLWNM2pqGz8u08dgSDL6yAgME35LKXULaXUMeAwUPt+K9HJWdM0p2JSKTYvIjJARLamWQbcdTgFrBCRbWnWeSmlEgAs/995NLsfcDLNvrGWsvuiPxDUNM2pZOcKQaXUJGBSFpvUV0rFi0g5YKWI7M9iW8msCpuDuYvuOWua5lTsOeaslIq3/H8GWIB5mOK0iPgAWP4/Y9k8FghIs7s/EH+/56GTs6ZpTsVeY84iUlREit95DbQAdgNhwAuWzV4AFllehwE9RaSQiFQAKgLR93seelhD0zSnkmK/KwS9gAUiAuZcGayUWiYiMUCoiPQHTgDdAJRSe0QkFNgLJAODlFKm+61cJ2dN05yKve6toZQ6ClTNpPw80Owe+wwDhtmjfp2cNU1zKiblHI94LTBjzp6eHgQHT2TnztXs2BFJnTpPM2PGOLZsWcqWLUs5cGADW7Ysze8wM/Xoow+zNWZF6nLh3H7eevOV/A4rSy1bNGbP7ij2713Ph4MH5Xc4NikIMWfWjr/77lN27lxNTMxyZs+ehKenh93rLepRlK9++4Kpa3/njzVTqPR0xtuJVq1bhd+WT+D3yEn8NHdkjus0uhn5fPynTF8/lV8Xj8XL3wuAhys9xC+Lfub3yElMXjmRxu0b5biutFKUsnlxZJLbN6Z2d3/ALhVMmfITGzZEM3XqLIxGI0WKFObSpcup60eM+JzLl6/w3XdjclRPcsp9DxHZxGAwcOL4Nuo1aMeJE3G5Wtf9MhgM7NuzjlZtehEbm8DmTRH06TuQffsO5Xdo95TbMbsa7vtCr3Qya8e1alVlzZqNmEwmvv32EwA+/3x4juuqX+bx1NcfjR7MP9H/EBGyDFejK4UKF+La5Wup64t6FOWXhT/zcZ9PORN/lhKlS5B4PtGmerz8vfhw9Ae8321wuvIO/drz0BMV+PmTsTTp0Jj6rerx7cDv8K/gh0IRdyye0l6lmBAxjpeavMK1y9eIjF2R2XS0bKlYtobNOefQ2W05ri+3ZKvnLCINROQ9EWmRWwFlpnjxYjRoUJupU2cBkJSUlC4xA3Tt2o7ZsxdltrtDada0AUeP/uuwiRmgdq3qHDlynGPHTpCUlERo6CI6tM/RbQJyXUGI+V7teNWqdZhM5k5BdPTf+Pt727XeIsWK8FSdp4gIWQZAclJyusQM0CywKeuWbuBM/FmAdIm5eedmjAsfy2/LJ/DuiLcxGGxLG/Va1GXFnJUA/LUkiqcbVAcg9lgcccfMM8zOn75A4vlESpT2zNE5puUsPecsv8oiEp3m9avAr0Bx4CsR+TiXY0tVocIDnD17gcmTR7F5cwQTJnxPkSKFU9c3aFCb06fPceTI8bwK6b51796RWbMX5ncYWfL18+Zk7H/TM2PjEvD1tW/CsLeCELO1dgzwwgs9WL58rV3r9XnAm0sXEvnwpw+YuGw87//4Lu6F3dNt4/+QH8U9izFqzo9MiBjHc12aA/DAIwE0bt+ItwLf5bWWr2MypdCsU1Ob6i3jXYYzCeZkn2JK4drla3iUTD9k81i1x3A1Gok/nmCHMzXLg8u384S1X4HGNK8HAM8ppYZgnu/3/L12SntJpMl0NcdBurq6Ur16ZSZNmsEzz7Th2rUbDB48MHV99+4dCQ11/F6z0WikfbsWzJ0Xnt+hZMkydSgdR38uW0GI2Vo7/uijN0hOTiYkZIFd63VxdaFi5YqEzQjn/1oN5Ob1m/Qc1CPjNlUq8lm/L/jo+U/o887z+Ffwo3qD6lR8qiLjl/zKb8sn8HSDavg86APAkClf8dvyCQyf/i2PVXmU35ZP4LflE2jZ3fyHdSbfEkjzPSlVrhSfjPmQH98fadfvlUmZbF4cmbXZGgbL7fAMmMenzwIopa6JSPK9dkp7SaQ9xpzj4hKIi0sgJmYHAAsWRPDBB68D4OLiQseOrahXr21Oq8l1rVo1Yfv2fzhz5lx+h5KluNgEAvx9U9/7+/mQkHA6HyOyriDEnFU77tOnK61bN6N16152r/dswjnOJpxl/3bzlcdRS9ZlSM5nE85x6cJlbt64yc0bN/lnyz88VOkhRIQVc1fy+4g/Mhz3q1eGAPcecz6bcI5yPmU5l3AOg4uBoh5FuZx4BTAPtXwXNJQ/fpjGvr+zuiI6+xztl/L9stZz9gS2AVuBUiLiDSAixcj8OvJccfr0WWJjE6hY8SEAmjSpn/pBT9OmDTh48AhxcY7/YNaePQIdfkgDIGbrDh55pALlywdgNBrp3r0ji8NX5HdYWSoIMd+rHT/3XCPef/91unbtz40bN+1e78WzFzkbfxb/h/wBqN6gOv8eOpFum43LN/JU7coYXAwUci/E49Ue58Thk2xfv52GbZ+lROkSABQvUZxyfuXuriJTm1ZuokW35wBo1LYh2zfsAMDV6MqQKV+xYu4qopass89JppELtwzNF1n2nJVS5e+xKgXoZPdosvDuu18ybdpY3NyMHDt2ggEDPgCge/cOzJ4dlpeh3JfChd1p3qwhrw/8KL9DscpkMvH2O58TsSQYF4OBaUGz2bv3YH6HlaWCEnNm7XjDhsUUKuTGkiUzAYiO3s6bb35q13p/+WIcn/7yMUY3VxL+PcUP74+kXR/zX5vhfy7hxOGTxKzdypSVv5GSoogIWcrxA8cBmPrDNL4PHo7BICQnmRj7+S+ciTuTRW1mEbOW8cmYj5i+fipXEq/w7cDvAGjcvhFV6jyFR0mP1CGQH979kSN7j9rlXJ2l51xgptLlldyeSqcVTPaaSpeX0k6lKyjsMZXOp0Qlm3NOQuJeh51Kp68Q1DTNqTj6LAxb6eSsaZpTcZbLt3Vy1jTNqTjLmLNOzpqmORVHv/LPVjo5a5rmVHTPWdM0zQE5+vxlW+nkrGmaU9E9Z03TNAekZ2tomqY5IP2BoKZpmgNylmGNAvOYKk3TNFvY837OItJKRA6IyOG8vIc96J6zpmlOxl49ZxFxAcYBzwGxQIyIhCml9tqlAit0ctY0zanYccy5NnBYKXUUQERmAR0B50jON2+eyLW7PonIAMuN/QuEghYvFLyYC1q8oGO2t+TbcTbnHBEZgPkpT3dMSnNefsDJNOtigTo5j9A2BX3MeYD1TRxKQYsXCl7MBS1e0DHnG6XUJKVUzTRL2l84mT5oK69iK+jJWdM0LbfEAgFp3vsD8ffY1u50ctY0TctcDFBRRCqIiBvQE8izxy4V9A8EHXLMKwsFLV4oeDEXtHhBx+yQlFLJIvIGsBxwAf5QSu3Jq/pz/TFVmqZpWvbpYQ1N0zQHpJOzpmmaAyqQyTk/L6m8HyLyh4icEZHd+R2LLUQkQETWiMg+EdkjIm/nd0zWiIi7iESLyE5LzEPyOyZbiIiLiGwXkfD8jsUWInJcRP4RkR0isjW/43FmBW7M2XJJ5UHSXFIJ9MqrSyrvh4g0BK4C05VSlfM7HmtExAfwUUr9LSLFgW1AoIN/jQUoqpS6KiJGYD3wtlJqcz6HliUReQ+oCXgopdrldzzWiMhxoKZS6lx+x+LsCmLPOfWSSqXUbeDOJZUOSykVBVzI7zhspZRKUEr9bXl9BdiH+Woph6XMrlreGi2LQ/c8RMQfaAtMye9YNMdTEJNzZpdUOnTiKMhEpDxQHdiSz6FYZRki2AGcAVYqpRw95p+BD4GCdHd4BawQkW2WS5+1XFIQk3O+XlL5v0REigHzgHeUUpfzOx5rlFImpVQ1zFdy1RYRhx1CEpF2wBml1Lb8jiWb6iulngZaA4MsQ3ZaLiiIyTlfL6n8X2EZt50HzFRKzc/veLJDKZUIrAVa5W8kWaoPdLCM4c4CmorIn/kbknVKqXjL/2eABZiHGbVcUBCTc75eUvm/wPLh2u/APqXUT/kdjy1EpKyIlLC8Lgw0B/bna1BZUEp9opTyV0qVx9yGVyul+uRzWFkSkaKWD4gRkaJAC6BAzEAqiApcclZKJQN3LqncB4Tm5SWV90NEQoBNwGMiEisi/fM7JivqA30x9+Z2WJY2+R2UFT7AGhHZhfkX+EqlVIGYnlaAeAHrRWQnEA0sUUoty+eYnFaBm0qnaZr2v6DA9Zw1TdP+F+jkrGma5oB0ctY0TXNAOjlrmqY5IJ2cNU3THJBOzpqmaQ5IJ2dN0zQH9P8f12/a8jH3IAAAAABJRU5ErkJggg==\n",
      "text/plain": [
       "<Figure size 432x288 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "exp.train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "26d97ad8",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "89d6c81d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "86ba8aac",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e2bb5ad4",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9d066180",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7a596b7a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4e7fb08e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "04508e6c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "339ae571",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = data_dict[args.data_name](args)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "779e3397",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cfb6776a",
   "metadata": {},
   "outputs": [],
   "source": [
    "start_index = dataset.train_slidingwindows[0][1]\n",
    "end_index   = dataset.train_slidingwindows[0][2]\n",
    "sample_x_1    = dataset.data_x.iloc[start_index:end_index, 1:-1].values\n",
    "\n",
    "start_index = dataset.train_slidingwindows[100][1]\n",
    "end_index   = dataset.train_slidingwindows[100][2]\n",
    "sample_x_2    = dataset.data_x.iloc[start_index:end_index, 1:-1].values\n",
    "\n",
    "temp_1 = np.expand_dims(sample_x_1,0)\n",
    "temp_2 = np.expand_dims(sample_x_2,0)\n",
    "combined_x = np.concatenate([temp_1,temp_2],axis=0)\n",
    "combined_x = np.expand_dims(combined_x,1)\n",
    "combined_x = torch.tensor(combined_x).double().to(exp.device)\n",
    "print(combined_x.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2af5063a",
   "metadata": {},
   "outputs": [],
   "source": [
    "out = exp.model(combined_x)\n",
    "out = out.cpu().detach().numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fc57c0e2",
   "metadata": {},
   "outputs": [],
   "source": [
    "out.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6f69036a",
   "metadata": {},
   "outputs": [],
   "source": [
    "weight = exp.model.wave_conv.wavelet_conv.weight.cpu().detach().numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d44c070a",
   "metadata": {},
   "outputs": [],
   "source": [
    "for n,p in exp.model.named_parameters():\n",
    "    print(n)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5f19ba6e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "index1 = 0\n",
    "index2 = 0\n",
    "\n",
    "plt.figure()\n",
    "plt.plot(out[0,0,:,index2])\n",
    "plt.plot(out[0,1,:,index2])\n",
    "plt.plot(out[0,2,:,index2])\n",
    "plt.plot(out[0,3,:,index2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a3ae8916",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ffe11eb7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 如果我们设置为 \n",
    "# args.wavelet_filtering_learnable      = True\n",
    "# exp = Exp(args)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5d15a68f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6beec6d1",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "90f99481",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d8700989",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7b222186",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5ae27337",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4506b3e7",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ca5dc27e",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
