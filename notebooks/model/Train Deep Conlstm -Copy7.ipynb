{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "894e2c21",
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "import sys\n",
    "sys.path.append(\"../../\")\n",
    "\n",
    "from experiment import Exp\n",
    "\n",
    "from dataloaders import data_set,data_dict\n",
    "import torch\n",
    "import yaml\n",
    "import os"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bcc56bc7",
   "metadata": {},
   "source": [
    "# 参数设置"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dcc5bcbc",
   "metadata": {},
   "source": [
    "# 训练参数 \n",
    "除了路径 其他不要变"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "86004ce0",
   "metadata": {},
   "outputs": [],
   "source": [
    "class dotdict(dict):\n",
    "    \"\"\"dot.notation access to dictionary attributes\"\"\"\n",
    "    __getattr__ = dict.get\n",
    "    __setattr__ = dict.__setitem__\n",
    "    __delattr__ = dict.__delitem__\n",
    "\n",
    "args = dotdict()   \n",
    "# TODO change the path as relative path\n",
    "args.to_save_path     = \"../../../ISWC2022LearnableFilter/Run_logs\"              \n",
    "args.freq_save_path   = \"../../../ISWC2022LearnableFilter/Freq_data\"\n",
    "args.window_save_path = \"../../../ISWC2022LearnableFilter/Sliding_window\"\n",
    "args.root_path        = \"../../../datasets\"\n",
    "\n",
    "\n",
    "args.drop_transition  = False\n",
    "args.datanorm_type    = \"standardization\" # None ,\"standardization\", \"minmax\"\n",
    "\n",
    "\n",
    "args.batch_size       = 128                                                     \n",
    "args.shuffle          = True\n",
    "args.drop_last        = False\n",
    "args.train_vali_quote = 0.90                                           \n",
    "\n",
    "\n",
    "# training setting \n",
    "args.train_epochs            = 150\n",
    "\n",
    "args.learning_rate           = 0.001  \n",
    "args.learning_rate_patience  = 5\n",
    "args.learning_rate_factor    = 0.1\n",
    "\n",
    "\n",
    "args.early_stop_patience     = 15\n",
    "\n",
    "args.use_gpu                 = True if torch.cuda.is_available() else False\n",
    "args.gpu                     = 2\n",
    "args.use_multi_gpu           = False\n",
    "\n",
    "args.optimizer               = \"Adam\"\n",
    "args.criterion               = \"CrossEntropy\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c282cbcb",
   "metadata": {},
   "source": [
    "## 数据参数\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "c6cd147b",
   "metadata": {},
   "outputs": [],
   "source": [
    "args.seed                             = 2\n",
    "\n",
    "\n",
    "args.data_name                        =  \"rw\"\n",
    "\n",
    "args.wavelet_filtering                = True\n",
    "args.wavelet_filtering_regularization = True\n",
    "args.wavelet_filtering_finetuning     = True\n",
    "args.wavelet_filtering_finetuning_percent = 0.3\n",
    "\n",
    "args.regulatization_tradeoff          = 0.0001\n",
    "args.number_wavelet_filtering         = 10\n",
    "\n",
    "\n",
    "args.difference       = False \n",
    "args.filtering        =  False\n",
    "args.magnitude        =  False\n",
    "args.weighted_sampler = False\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "args.pos_select       = None\n",
    "args.sensor_select    = None\n",
    "\n",
    "\n",
    "args.representation_type = \"time\"\n",
    "args.exp_mode            = \"LOCV\"\n",
    "\n",
    "config_file = open('../../configs/data.yaml', mode='r')\n",
    "data_config = yaml.load(config_file, Loader=yaml.FullLoader)\n",
    "config = data_config[args.data_name]\n",
    "\n",
    "args.root_path       = os.path.join(args.root_path,config[\"filename\"])\n",
    "args.sampling_freq   = config[\"sampling_freq\"]\n",
    "args.num_classes     =  config[\"num_classes\"]\n",
    "window_seconds       = config[\"window_seconds\"]\n",
    "args.windowsize      =   int(window_seconds * args.sampling_freq) \n",
    "args.input_length    =  args.windowsize\n",
    "# input information\n",
    "args.c_in            = config[\"num_channels\"]\n",
    "\n",
    "if args.wavelet_filtering :\n",
    "    \n",
    "    if args.windowsize%2==1:\n",
    "        N_ds = int(torch.log2(torch.tensor(args.windowsize-1)).floor()) - 2\n",
    "    else:\n",
    "        N_ds = int(torch.log2(torch.tensor(args.windowsize)).floor()) - 2\n",
    "\n",
    "    args.f_in            =  args.number_wavelet_filtering*N_ds+1\n",
    "else:\n",
    "    args.f_in            =  1\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4d435a4c",
   "metadata": {},
   "source": [
    "## 模型参数"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "de2f4d16",
   "metadata": {},
   "outputs": [],
   "source": [
    "args.filter_scaling_factor = 0.25\n",
    "args.model_type            = \"deepconvlstm\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cada66dd",
   "metadata": {},
   "source": [
    "# 实验"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "2e3f2fad",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Use GPU: cuda:2\n",
      "Wavelet Filtering Regularization\n",
      "Build the DeepConvLSTM model!\n",
      "Done!\n",
      "Parameter : 1720571\n",
      "Set the seed as :  2\n"
     ]
    }
   ],
   "source": [
    "exp = Exp(args)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "09a011fc",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " ----------------------- load all the data -------------------\n",
      "-----------------------Sliding file are generated -----------------------\n",
      "-----------------------Sliding file are generated -----------------------\n",
      "================ LOCV Mode ====================\n",
      "================ 15 CV ======================\n",
      "================ the 0 th CV Experiment ================ \n",
      "Leave one Out Experiment : The 1 Part as the test\n",
      "[-] Target sampling weights:  [0.00024184 0.00020602 0.00112613 0.00015901 0.00014329 0.00015964\n",
      " 0.00016075 0.00015637]\n",
      "Train data number :  42025\n",
      "The number of classes is :  8\n",
      "The input_length  is :  128\n",
      "The channel_in is :  21\n",
      "Validation data number :  4670\n",
      "Test data number :  17903\n",
      "================Skip the 0 CV Experiment================\n",
      "================Skip the 0 CV Experiment Fine Tuning================\n",
      "================ the 1 th CV Experiment ================ \n",
      "Leave one Out Experiment : The 2 Part as the test\n",
      "[-] Target sampling weights:  [0.00024231 0.00018997 0.00113636 0.0001579  0.00013998 0.00015873\n",
      " 0.00016021 0.00015667]\n",
      "Train data number :  42673\n",
      "The number of classes is :  8\n",
      "The input_length  is :  128\n",
      "The channel_in is :  21\n",
      "Validation data number :  4742\n",
      "Test data number :  14069\n",
      "================ Build the model ================ \n",
      "Wavelet Filtering Regularization\n",
      "Build the DeepConvLSTM model!\n",
      "Epoch: 1 cost time: 124.26556754112244\n",
      "VALI: Epoch: 1, Steps: 334 | Train Loss: 0.3216463  Vali Loss: 0.2277440 Vali Accuracy: 0.9247153  Vali weighted F1: 0.9248460  Vali macro F1 0.9232937 \n",
      "Validation loss decreased (inf --> 0.227744).  Saving model ...\n",
      "Epoch: 2 cost time: 119.82327699661255\n",
      "VALI: Epoch: 2, Steps: 334 | Train Loss: 0.1502886  Vali Loss: 0.1310131 Vali Accuracy: 0.9563475  Vali weighted F1: 0.9564074  Vali macro F1 0.9566202 \n",
      "new best score!!!!\n",
      "Validation loss decreased (0.227744 --> 0.131013).  Saving model ...\n",
      "new best score!!!!\n",
      "Epoch: 3 cost time: 119.70105648040771\n",
      "VALI: Epoch: 3, Steps: 334 | Train Loss: 0.1173237  Vali Loss: 0.1148142 Vali Accuracy: 0.9652046  Vali weighted F1: 0.9652119  Vali macro F1 0.9645469 \n",
      "new best score!!!!\n",
      "Validation loss decreased (0.131013 --> 0.114814).  Saving model ...\n",
      "new best score!!!!\n",
      "Epoch: 4 cost time: 119.61753630638123\n",
      "VALI: Epoch: 4, Steps: 334 | Train Loss: 0.0952212  Vali Loss: 0.1004772 Vali Accuracy: 0.9704766  Vali weighted F1: 0.9704477  Vali macro F1 0.9704910 \n",
      "new best score!!!!\n",
      "Validation loss decreased (0.114814 --> 0.100477).  Saving model ...\n",
      "new best score!!!!\n",
      "Epoch: 5 cost time: 119.48270511627197\n",
      "VALI: Epoch: 5, Steps: 334 | Train Loss: 0.0785900  Vali Loss: 0.1007447 Vali Accuracy: 0.9698439  Vali weighted F1: 0.9698241  Vali macro F1 0.9701290 \n",
      "EarlyStopping counter: 1 out of 15\n",
      "Learning rate adjusting counter: 1 out of 5\n",
      "Epoch: 6 cost time: 119.41040968894958\n",
      "VALI: Epoch: 6, Steps: 334 | Train Loss: 0.0706110  Vali Loss: 0.0757424 Vali Accuracy: 0.9751160  Vali weighted F1: 0.9751452  Vali macro F1 0.9757425 \n",
      "new best score!!!!\n",
      "Validation loss decreased (0.100477 --> 0.075742).  Saving model ...\n",
      "new best score!!!!\n",
      "Epoch: 7 cost time: 119.456303358078\n",
      "VALI: Epoch: 7, Steps: 334 | Train Loss: 0.0627108  Vali Loss: 0.0769509 Vali Accuracy: 0.9751160  Vali weighted F1: 0.9750965  Vali macro F1 0.9738525 \n",
      "EarlyStopping counter: 1 out of 15\n",
      "Learning rate adjusting counter: 1 out of 5\n",
      "Epoch: 8 cost time: 119.4353358745575\n",
      "VALI: Epoch: 8, Steps: 334 | Train Loss: 0.0557761  Vali Loss: 0.0686796 Vali Accuracy: 0.9791227  Vali weighted F1: 0.9791176  Vali macro F1 0.9775646 \n",
      "new best score!!!!\n",
      "Validation loss decreased (0.075742 --> 0.068680).  Saving model ...\n",
      "new best score!!!!\n",
      "Epoch: 9 cost time: 119.22768831253052\n",
      "VALI: Epoch: 9, Steps: 334 | Train Loss: 0.0519750  Vali Loss: 0.0643036 Vali Accuracy: 0.9789119  Vali weighted F1: 0.9788963  Vali macro F1 0.9776898 \n",
      "new best score!!!!\n",
      "Validation loss decreased (0.068680 --> 0.064304).  Saving model ...\n",
      "new best score!!!!\n",
      "Epoch: 10 cost time: 119.2194664478302\n",
      "VALI: Epoch: 10, Steps: 334 | Train Loss: 0.0461807  Vali Loss: 0.0650116 Vali Accuracy: 0.9789119  Vali weighted F1: 0.9788551  Vali macro F1 0.9774410 \n",
      "EarlyStopping counter: 1 out of 15\n",
      "Learning rate adjusting counter: 1 out of 5\n",
      "Epoch: 11 cost time: 119.17522597312927\n",
      "VALI: Epoch: 11, Steps: 334 | Train Loss: 0.0401826  Vali Loss: 0.0533677 Vali Accuracy: 0.9833404  Vali weighted F1: 0.9833282  Vali macro F1 0.9829950 \n",
      "new best score!!!!\n",
      "Validation loss decreased (0.064304 --> 0.053368).  Saving model ...\n",
      "new best score!!!!\n",
      "Epoch: 12 cost time: 119.20673274993896\n",
      "VALI: Epoch: 12, Steps: 334 | Train Loss: 0.0360484  Vali Loss: 0.0597249 Vali Accuracy: 0.9829186  Vali weighted F1: 0.9829100  Vali macro F1 0.9807293 \n",
      "EarlyStopping counter: 1 out of 15\n",
      "Learning rate adjusting counter: 1 out of 5\n",
      "Epoch: 13 cost time: 119.21949815750122\n",
      "VALI: Epoch: 13, Steps: 334 | Train Loss: 0.0352866  Vali Loss: 0.0624484 Vali Accuracy: 0.9818642  Vali weighted F1: 0.9818767  Vali macro F1 0.9807376 \n",
      "EarlyStopping counter: 2 out of 15\n",
      "Learning rate adjusting counter: 2 out of 5\n",
      "Epoch: 14 cost time: 119.11881470680237\n",
      "VALI: Epoch: 14, Steps: 334 | Train Loss: 0.0378364  Vali Loss: 0.0799955 Vali Accuracy: 0.9751160  Vali weighted F1: 0.9751281  Vali macro F1 0.9737968 \n",
      "EarlyStopping counter: 3 out of 15\n",
      "Learning rate adjusting counter: 3 out of 5\n",
      "Epoch: 15 cost time: 119.19270086288452\n",
      "VALI: Epoch: 15, Steps: 334 | Train Loss: 0.0368418  Vali Loss: 0.0576530 Vali Accuracy: 0.9810207  Vali weighted F1: 0.9810082  Vali macro F1 0.9778955 \n",
      "EarlyStopping counter: 4 out of 15\n",
      "Learning rate adjusting counter: 4 out of 5\n",
      "Epoch: 16 cost time: 119.15065026283264\n",
      "VALI: Epoch: 16, Steps: 334 | Train Loss: 0.0302231  Vali Loss: 0.0553966 Vali Accuracy: 0.9856601  Vali weighted F1: 0.9856600  Vali macro F1 0.9838805 \n",
      "EarlyStopping counter: 5 out of 15\n",
      "Learning rate adjusting counter: 5 out of 5\n",
      "Updating learning rate to 0.0001\n",
      "Epoch: 17 cost time: 119.08479714393616\n",
      "VALI: Epoch: 17, Steps: 334 | Train Loss: 0.0207069  Vali Loss: 0.0453525 Vali Accuracy: 0.9877689  Vali weighted F1: 0.9877578  Vali macro F1 0.9863757 \n",
      "new best score!!!!\n",
      "Validation loss decreased (0.053368 --> 0.045352).  Saving model ...\n",
      "new best score!!!!\n",
      "Epoch: 18 cost time: 119.09753060340881\n",
      "VALI: Epoch: 18, Steps: 334 | Train Loss: 0.0165718  Vali Loss: 0.0437907 Vali Accuracy: 0.9871362  Vali weighted F1: 0.9871296  Vali macro F1 0.9863486 \n",
      "new best score!!!!\n",
      "Validation loss decreased (0.045352 --> 0.043791).  Saving model ...\n",
      "new best score!!!!\n",
      "Epoch: 19 cost time: 119.10538625717163\n",
      "VALI: Epoch: 19, Steps: 334 | Train Loss: 0.0146100  Vali Loss: 0.0403606 Vali Accuracy: 0.9873471  Vali weighted F1: 0.9873356  Vali macro F1 0.9867143 \n",
      "new best score!!!!\n",
      "Validation loss decreased (0.043791 --> 0.040361).  Saving model ...\n",
      "new best score!!!!\n",
      "Epoch: 20 cost time: 119.13192963600159\n",
      "VALI: Epoch: 20, Steps: 334 | Train Loss: 0.0123636  Vali Loss: 0.0383100 Vali Accuracy: 0.9879798  Vali weighted F1: 0.9879721  Vali macro F1 0.9865630 \n",
      "new best score!!!!\n",
      "Validation loss decreased (0.040361 --> 0.038310).  Saving model ...\n",
      "new best score!!!!\n",
      "Epoch: 21 cost time: 119.00324749946594\n",
      "VALI: Epoch: 21, Steps: 334 | Train Loss: 0.0119710  Vali Loss: 0.0365670 Vali Accuracy: 0.9888233  Vali weighted F1: 0.9888166  Vali macro F1 0.9878610 \n",
      "new best score!!!!\n",
      "Validation loss decreased (0.038310 --> 0.036567).  Saving model ...\n",
      "new best score!!!!\n",
      "Epoch: 22 cost time: 119.0969352722168\n",
      "VALI: Epoch: 22, Steps: 334 | Train Loss: 0.0113915  Vali Loss: 0.0377423 Vali Accuracy: 0.9892450  Vali weighted F1: 0.9892345  Vali macro F1 0.9877946 \n",
      "EarlyStopping counter: 1 out of 15\n",
      "Learning rate adjusting counter: 1 out of 5\n",
      "Epoch: 23 cost time: 119.01442861557007\n",
      "VALI: Epoch: 23, Steps: 334 | Train Loss: 0.0100306  Vali Loss: 0.0349601 Vali Accuracy: 0.9884015  Vali weighted F1: 0.9883947  Vali macro F1 0.9874675 \n",
      "new best score!!!!\n",
      "Validation loss decreased (0.036567 --> 0.034960).  Saving model ...\n",
      "new best score!!!!\n",
      "Epoch: 24 cost time: 118.97560453414917\n",
      "VALI: Epoch: 24, Steps: 334 | Train Loss: 0.0095537  Vali Loss: 0.0364033 Vali Accuracy: 0.9888233  Vali weighted F1: 0.9888115  Vali macro F1 0.9878091 \n",
      "EarlyStopping counter: 1 out of 15\n",
      "Learning rate adjusting counter: 1 out of 5\n",
      "Epoch: 25 cost time: 118.9718770980835\n",
      "VALI: Epoch: 25, Steps: 334 | Train Loss: 0.0094402  Vali Loss: 0.0362182 Vali Accuracy: 0.9894559  Vali weighted F1: 0.9894476  Vali macro F1 0.9884797 \n",
      "EarlyStopping counter: 2 out of 15\n",
      "Learning rate adjusting counter: 2 out of 5\n",
      "Epoch: 26 cost time: 119.11149382591248\n",
      "VALI: Epoch: 26, Steps: 334 | Train Loss: 0.0087825  Vali Loss: 0.0325263 Vali Accuracy: 0.9894559  Vali weighted F1: 0.9894511  Vali macro F1 0.9884261 \n",
      "new best score!!!!\n",
      "Validation loss decreased (0.034960 --> 0.032526).  Saving model ...\n",
      "new best score!!!!\n",
      "Epoch: 27 cost time: 119.06227660179138\n",
      "VALI: Epoch: 27, Steps: 334 | Train Loss: 0.0084804  Vali Loss: 0.0337927 Vali Accuracy: 0.9894559  Vali weighted F1: 0.9894465  Vali macro F1 0.9884855 \n",
      "EarlyStopping counter: 1 out of 15\n",
      "Learning rate adjusting counter: 1 out of 5\n",
      "Epoch: 28 cost time: 119.0575475692749\n",
      "VALI: Epoch: 28, Steps: 334 | Train Loss: 0.0074545  Vali Loss: 0.0316835 Vali Accuracy: 0.9896668  Vali weighted F1: 0.9896634  Vali macro F1 0.9887040 \n",
      "new best score!!!!\n",
      "Validation loss decreased (0.032526 --> 0.031684).  Saving model ...\n",
      "new best score!!!!\n",
      "Epoch: 29 cost time: 119.10637712478638\n",
      "VALI: Epoch: 29, Steps: 334 | Train Loss: 0.0077610  Vali Loss: 0.0341938 Vali Accuracy: 0.9890342  Vali weighted F1: 0.9890298  Vali macro F1 0.9882339 \n",
      "EarlyStopping counter: 1 out of 15\n",
      "Learning rate adjusting counter: 1 out of 5\n",
      "Epoch: 30 cost time: 120.06202554702759\n",
      "VALI: Epoch: 30, Steps: 334 | Train Loss: 0.0070627  Vali Loss: 0.0326517 Vali Accuracy: 0.9905103  Vali weighted F1: 0.9905053  Vali macro F1 0.9890018 \n",
      "EarlyStopping counter: 2 out of 15\n",
      "Learning rate adjusting counter: 2 out of 5\n",
      "Epoch: 31 cost time: 120.47938418388367\n",
      "VALI: Epoch: 31, Steps: 334 | Train Loss: 0.0073037  Vali Loss: 0.0301740 Vali Accuracy: 0.9902995  Vali weighted F1: 0.9902960  Vali macro F1 0.9882899 \n",
      "new best score!!!!\n",
      "Validation loss decreased (0.031684 --> 0.030174).  Saving model ...\n",
      "new best score!!!!\n",
      "Epoch: 32 cost time: 120.49062991142273\n",
      "VALI: Epoch: 32, Steps: 334 | Train Loss: 0.0065160  Vali Loss: 0.0299075 Vali Accuracy: 0.9915647  Vali weighted F1: 0.9915617  Vali macro F1 0.9898515 \n",
      "new best score!!!!\n",
      "Validation loss decreased (0.030174 --> 0.029907).  Saving model ...\n",
      "new best score!!!!\n",
      "Epoch: 33 cost time: 120.9674015045166\n",
      "VALI: Epoch: 33, Steps: 334 | Train Loss: 0.0066832  Vali Loss: 0.0286531 Vali Accuracy: 0.9907212  Vali weighted F1: 0.9907172  Vali macro F1 0.9891431 \n",
      "new best score!!!!\n",
      "Validation loss decreased (0.029907 --> 0.028653).  Saving model ...\n",
      "new best score!!!!\n",
      "Epoch: 34 cost time: 120.49200010299683\n",
      "VALI: Epoch: 34, Steps: 334 | Train Loss: 0.0063796  Vali Loss: 0.0293341 Vali Accuracy: 0.9909321  Vali weighted F1: 0.9909260  Vali macro F1 0.9892890 \n",
      "EarlyStopping counter: 1 out of 15\n",
      "Learning rate adjusting counter: 1 out of 5\n",
      "Epoch: 35 cost time: 120.4036123752594\n",
      "VALI: Epoch: 35, Steps: 334 | Train Loss: 0.0055743  Vali Loss: 0.0305478 Vali Accuracy: 0.9911430  Vali weighted F1: 0.9911337  Vali macro F1 0.9900631 \n",
      "EarlyStopping counter: 2 out of 15\n",
      "Learning rate adjusting counter: 2 out of 5\n",
      "Epoch: 36 cost time: 120.43127274513245\n",
      "VALI: Epoch: 36, Steps: 334 | Train Loss: 0.0057523  Vali Loss: 0.0295142 Vali Accuracy: 0.9911430  Vali weighted F1: 0.9911346  Vali macro F1 0.9900364 \n",
      "EarlyStopping counter: 3 out of 15\n",
      "Learning rate adjusting counter: 3 out of 5\n",
      "Epoch: 37 cost time: 120.50828099250793\n",
      "VALI: Epoch: 37, Steps: 334 | Train Loss: 0.0058826  Vali Loss: 0.0292475 Vali Accuracy: 0.9913539  Vali weighted F1: 0.9913452  Vali macro F1 0.9896452 \n",
      "EarlyStopping counter: 4 out of 15\n",
      "Learning rate adjusting counter: 4 out of 5\n",
      "Epoch: 38 cost time: 120.47183132171631\n",
      "VALI: Epoch: 38, Steps: 334 | Train Loss: 0.0056556  Vali Loss: 0.0292743 Vali Accuracy: 0.9907212  Vali weighted F1: 0.9907144  Vali macro F1 0.9891097 \n",
      "EarlyStopping counter: 5 out of 15\n",
      "Learning rate adjusting counter: 5 out of 5\n",
      "Updating learning rate to 1e-05\n",
      "Epoch: 39 cost time: 120.42736911773682\n",
      "VALI: Epoch: 39, Steps: 334 | Train Loss: 0.0051078  Vali Loss: 0.0287580 Vali Accuracy: 0.9915647  Vali weighted F1: 0.9915565  Vali macro F1 0.9898920 \n",
      "EarlyStopping counter: 6 out of 15\n",
      "Learning rate adjusting counter: 1 out of 5\n",
      "Epoch: 40 cost time: 120.36933445930481\n",
      "VALI: Epoch: 40, Steps: 334 | Train Loss: 0.0050116  Vali Loss: 0.0287327 Vali Accuracy: 0.9917756  Vali weighted F1: 0.9917670  Vali macro F1 0.9905845 \n",
      "EarlyStopping counter: 7 out of 15\n",
      "Learning rate adjusting counter: 2 out of 5\n",
      "Epoch: 41 cost time: 120.23750615119934\n",
      "VALI: Epoch: 41, Steps: 334 | Train Loss: 0.0050305  Vali Loss: 0.0287051 Vali Accuracy: 0.9917756  Vali weighted F1: 0.9917661  Vali macro F1 0.9905180 \n",
      "EarlyStopping counter: 8 out of 15\n",
      "Learning rate adjusting counter: 3 out of 5\n",
      "Epoch: 42 cost time: 120.45509886741638\n",
      "VALI: Epoch: 42, Steps: 334 | Train Loss: 0.0048927  Vali Loss: 0.0286328 Vali Accuracy: 0.9917756  Vali weighted F1: 0.9917664  Vali macro F1 0.9905437 \n",
      "new best score!!!!\n",
      "Validation loss decreased (0.028653 --> 0.028633).  Saving model ...\n",
      "new best score!!!!\n",
      "Epoch: 43 cost time: 121.18888783454895\n",
      "VALI: Epoch: 43, Steps: 334 | Train Loss: 0.0047786  Vali Loss: 0.0282927 Vali Accuracy: 0.9917756  Vali weighted F1: 0.9917664  Vali macro F1 0.9905437 \n",
      "new best score!!!!\n",
      "Validation loss decreased (0.028633 --> 0.028293).  Saving model ...\n",
      "new best score!!!!\n",
      "Epoch: 44 cost time: 121.43124198913574\n",
      "VALI: Epoch: 44, Steps: 334 | Train Loss: 0.0047841  Vali Loss: 0.0285280 Vali Accuracy: 0.9915647  Vali weighted F1: 0.9915546  Vali macro F1 0.9902743 \n",
      "EarlyStopping counter: 1 out of 15\n",
      "Learning rate adjusting counter: 1 out of 5\n",
      "Epoch: 45 cost time: 121.49594640731812\n",
      "VALI: Epoch: 45, Steps: 334 | Train Loss: 0.0048851  Vali Loss: 0.0282399 Vali Accuracy: 0.9913539  Vali weighted F1: 0.9913438  Vali macro F1 0.9900976 \n",
      "new best score!!!!\n",
      "Validation loss decreased (0.028293 --> 0.028240).  Saving model ...\n",
      "new best score!!!!\n",
      "Epoch: 46 cost time: 121.50338649749756\n",
      "VALI: Epoch: 46, Steps: 334 | Train Loss: 0.0048053  Vali Loss: 0.0283314 Vali Accuracy: 0.9915647  Vali weighted F1: 0.9915556  Vali macro F1 0.9903407 \n",
      "EarlyStopping counter: 1 out of 15\n",
      "Learning rate adjusting counter: 1 out of 5\n",
      "Epoch: 47 cost time: 121.42056918144226\n",
      "VALI: Epoch: 47, Steps: 334 | Train Loss: 0.0045831  Vali Loss: 0.0281872 Vali Accuracy: 0.9915647  Vali weighted F1: 0.9915556  Vali macro F1 0.9903407 \n",
      "new best score!!!!\n",
      "Validation loss decreased (0.028240 --> 0.028187).  Saving model ...\n",
      "new best score!!!!\n",
      "Epoch: 48 cost time: 121.22820711135864\n",
      "VALI: Epoch: 48, Steps: 334 | Train Loss: 0.0046409  Vali Loss: 0.0283424 Vali Accuracy: 0.9915647  Vali weighted F1: 0.9915556  Vali macro F1 0.9903407 \n",
      "EarlyStopping counter: 1 out of 15\n",
      "Learning rate adjusting counter: 1 out of 5\n",
      "Epoch: 49 cost time: 121.45780515670776\n",
      "VALI: Epoch: 49, Steps: 334 | Train Loss: 0.0046288  Vali Loss: 0.0284819 Vali Accuracy: 0.9917756  Vali weighted F1: 0.9917664  Vali macro F1 0.9905173 \n",
      "EarlyStopping counter: 2 out of 15\n",
      "Learning rate adjusting counter: 2 out of 5\n",
      "Epoch: 50 cost time: 121.59006690979004\n",
      "VALI: Epoch: 50, Steps: 334 | Train Loss: 0.0047338  Vali Loss: 0.0284801 Vali Accuracy: 0.9917756  Vali weighted F1: 0.9917683  Vali macro F1 0.9905272 \n",
      "EarlyStopping counter: 3 out of 15\n",
      "Learning rate adjusting counter: 3 out of 5\n",
      "Epoch: 51 cost time: 121.49064636230469\n",
      "VALI: Epoch: 51, Steps: 334 | Train Loss: 0.0046246  Vali Loss: 0.0278813 Vali Accuracy: 0.9919865  Vali weighted F1: 0.9919783  Vali macro F1 0.9907220 \n",
      "new best score!!!!\n",
      "Validation loss decreased (0.028187 --> 0.027881).  Saving model ...\n",
      "new best score!!!!\n",
      "Epoch: 52 cost time: 121.54862689971924\n",
      "VALI: Epoch: 52, Steps: 334 | Train Loss: 0.0045315  Vali Loss: 0.0276541 Vali Accuracy: 0.9919865  Vali weighted F1: 0.9919766  Vali macro F1 0.9907218 \n",
      "new best score!!!!\n",
      "Validation loss decreased (0.027881 --> 0.027654).  Saving model ...\n",
      "new best score!!!!\n",
      "Epoch: 53 cost time: 121.53876399993896\n",
      "VALI: Epoch: 53, Steps: 334 | Train Loss: 0.0045371  Vali Loss: 0.0277151 Vali Accuracy: 0.9919865  Vali weighted F1: 0.9919771  Vali macro F1 0.9907122 \n",
      "EarlyStopping counter: 1 out of 15\n",
      "Learning rate adjusting counter: 1 out of 5\n",
      "Epoch: 54 cost time: 121.51233768463135\n",
      "VALI: Epoch: 54, Steps: 334 | Train Loss: 0.0045545  Vali Loss: 0.0272520 Vali Accuracy: 0.9921974  Vali weighted F1: 0.9921890  Vali macro F1 0.9909170 \n",
      "new best score!!!!\n",
      "Validation loss decreased (0.027654 --> 0.027252).  Saving model ...\n",
      "new best score!!!!\n",
      "Epoch: 55 cost time: 121.49111366271973\n",
      "VALI: Epoch: 55, Steps: 334 | Train Loss: 0.0045268  Vali Loss: 0.0274438 Vali Accuracy: 0.9924083  Vali weighted F1: 0.9924003  Vali macro F1 0.9911312 \n",
      "EarlyStopping counter: 1 out of 15\n",
      "Learning rate adjusting counter: 1 out of 5\n",
      "Epoch: 56 cost time: 121.43231701850891\n",
      "VALI: Epoch: 56, Steps: 334 | Train Loss: 0.0046087  Vali Loss: 0.0277846 Vali Accuracy: 0.9921974  Vali weighted F1: 0.9921885  Vali macro F1 0.9909265 \n",
      "EarlyStopping counter: 2 out of 15\n",
      "Learning rate adjusting counter: 2 out of 5\n",
      "Epoch: 57 cost time: 124.72401428222656\n",
      "VALI: Epoch: 57, Steps: 334 | Train Loss: 0.0045118  Vali Loss: 0.0275247 Vali Accuracy: 0.9919865  Vali weighted F1: 0.9919797  Vali macro F1 0.9907986 \n",
      "EarlyStopping counter: 3 out of 15\n",
      "Learning rate adjusting counter: 3 out of 5\n",
      "Epoch: 58 cost time: 120.776784658432\n",
      "VALI: Epoch: 58, Steps: 334 | Train Loss: 0.0043386  Vali Loss: 0.0277539 Vali Accuracy: 0.9917756  Vali weighted F1: 0.9917689  Vali macro F1 0.9905640 \n",
      "EarlyStopping counter: 4 out of 15\n",
      "Learning rate adjusting counter: 4 out of 5\n",
      "Epoch: 59 cost time: 120.38399934768677\n",
      "VALI: Epoch: 59, Steps: 334 | Train Loss: 0.0043616  Vali Loss: 0.0273675 Vali Accuracy: 0.9919865  Vali weighted F1: 0.9919782  Vali macro F1 0.9907573 \n",
      "EarlyStopping counter: 5 out of 15\n",
      "Learning rate adjusting counter: 5 out of 5\n",
      "Updating learning rate to 1.0000000000000002e-06\n",
      "Epoch: 60 cost time: 120.39811730384827\n",
      "VALI: Epoch: 60, Steps: 334 | Train Loss: 0.0044837  Vali Loss: 0.0273488 Vali Accuracy: 0.9919865  Vali weighted F1: 0.9919782  Vali macro F1 0.9907573 \n",
      "EarlyStopping counter: 6 out of 15\n",
      "Learning rate adjusting counter: 1 out of 5\n",
      "Epoch: 61 cost time: 120.35465598106384\n",
      "VALI: Epoch: 61, Steps: 334 | Train Loss: 0.0043553  Vali Loss: 0.0273483 Vali Accuracy: 0.9919865  Vali weighted F1: 0.9919782  Vali macro F1 0.9907573 \n",
      "EarlyStopping counter: 7 out of 15\n",
      "Learning rate adjusting counter: 2 out of 5\n",
      "Epoch: 62 cost time: 121.4498770236969\n",
      "VALI: Epoch: 62, Steps: 334 | Train Loss: 0.0044506  Vali Loss: 0.0273262 Vali Accuracy: 0.9919865  Vali weighted F1: 0.9919782  Vali macro F1 0.9907573 \n",
      "EarlyStopping counter: 8 out of 15\n",
      "Learning rate adjusting counter: 3 out of 5\n",
      "Epoch: 63 cost time: 119.51645374298096\n",
      "VALI: Epoch: 63, Steps: 334 | Train Loss: 0.0042217  Vali Loss: 0.0273361 Vali Accuracy: 0.9919865  Vali weighted F1: 0.9919782  Vali macro F1 0.9907573 \n",
      "EarlyStopping counter: 9 out of 15\n",
      "Learning rate adjusting counter: 4 out of 5\n",
      "Epoch: 64 cost time: 119.54664134979248\n",
      "VALI: Epoch: 64, Steps: 334 | Train Loss: 0.0043038  Vali Loss: 0.0273087 Vali Accuracy: 0.9919865  Vali weighted F1: 0.9919782  Vali macro F1 0.9907573 \n",
      "EarlyStopping counter: 10 out of 15\n",
      "Learning rate adjusting counter: 5 out of 5\n",
      "Updating learning rate to 1.0000000000000002e-07\n",
      "Epoch: 65 cost time: 119.54639625549316\n",
      "VALI: Epoch: 65, Steps: 334 | Train Loss: 0.0042502  Vali Loss: 0.0273034 Vali Accuracy: 0.9919865  Vali weighted F1: 0.9919782  Vali macro F1 0.9907573 \n",
      "EarlyStopping counter: 11 out of 15\n",
      "Learning rate adjusting counter: 1 out of 5\n",
      "Epoch: 66 cost time: 119.41479659080505\n",
      "VALI: Epoch: 66, Steps: 334 | Train Loss: 0.0044785  Vali Loss: 0.0273036 Vali Accuracy: 0.9919865  Vali weighted F1: 0.9919782  Vali macro F1 0.9907573 \n",
      "EarlyStopping counter: 12 out of 15\n",
      "Learning rate adjusting counter: 2 out of 5\n",
      "Epoch: 67 cost time: 119.44276452064514\n",
      "VALI: Epoch: 67, Steps: 334 | Train Loss: 0.0045318  Vali Loss: 0.0273008 Vali Accuracy: 0.9919865  Vali weighted F1: 0.9919782  Vali macro F1 0.9907573 \n",
      "EarlyStopping counter: 13 out of 15\n",
      "Learning rate adjusting counter: 3 out of 5\n",
      "Epoch: 68 cost time: 119.38246536254883\n",
      "VALI: Epoch: 68, Steps: 334 | Train Loss: 0.0043996  Vali Loss: 0.0273049 Vali Accuracy: 0.9919865  Vali weighted F1: 0.9919782  Vali macro F1 0.9907573 \n",
      "EarlyStopping counter: 14 out of 15\n",
      "Learning rate adjusting counter: 4 out of 5\n",
      "Epoch: 69 cost time: 119.4432966709137\n",
      "VALI: Epoch: 69, Steps: 334 | Train Loss: 0.0042734  Vali Loss: 0.0273002 Vali Accuracy: 0.9919865  Vali weighted F1: 0.9919782  Vali macro F1 0.9907573 \n",
      "EarlyStopping counter: 15 out of 15\n",
      "Early stopping\n",
      "Loading the best validation model!\n",
      "Final Test Performance : Test Accuracy: 0.9448433  Test weighted F1: 0.9603864  Test macro F1 0.8457174 \n",
      "Wavelet Filtering Regularization\n",
      "Build the DeepConvLSTM model!\n",
      "Wavelet Filtering Regularization\n",
      "Build the DeepConvLSTM model!\n",
      "------------Fine Tuning  :  36   will be pruned   -----------------------------------------\n",
      "old model Parameter : 1720571\n",
      "pruned model Parameter : 1709015\n",
      "----------------------------------------------------------------------------------------\n",
      "Fine Tuning Epoch: 1 cost time: 129.21508121490479\n",
      "Fine Tuning VALI: Epoch: 1, Steps: 334 | Train Loss: 0.0018441  Vali Loss: 0.0299372 Vali Accuracy: 0.9911430  Vali weighted F1: 0.9911370  Vali macro F1 0.9899552 \n",
      "Validation loss decreased (inf --> 0.029937).  Saving model ...\n",
      "Fine Tuning Epoch: 2 cost time: 129.67296504974365\n",
      "Fine Tuning VALI: Epoch: 2, Steps: 334 | Train Loss: 0.0017440  Vali Loss: 0.0305917 Vali Accuracy: 0.9902995  Vali weighted F1: 0.9902876  Vali macro F1 0.9890666 \n",
      "EarlyStopping counter: 1 out of 5\n",
      "Learning rate adjusting counter: 2 out of 5\n",
      "Fine Tuning Epoch: 3 cost time: 129.5555226802826\n",
      "Fine Tuning VALI: Epoch: 3, Steps: 334 | Train Loss: 0.0020446  Vali Loss: 0.0271122 Vali Accuracy: 0.9921974  Vali weighted F1: 0.9921925  Vali macro F1 0.9909865 \n",
      "new best score!!!!\n",
      "Validation loss decreased (0.029937 --> 0.027112).  Saving model ...\n",
      "new best score!!!!\n",
      "Fine Tuning Epoch: 4 cost time: 128.95998859405518\n",
      "Fine Tuning VALI: Epoch: 4, Steps: 334 | Train Loss: 0.0015517  Vali Loss: 0.0298705 Vali Accuracy: 0.9913539  Vali weighted F1: 0.9913468  Vali macro F1 0.9902546 \n",
      "EarlyStopping counter: 1 out of 5\n",
      "Learning rate adjusting counter: 1 out of 5\n",
      "Fine Tuning Epoch: 5 cost time: 129.43318796157837\n",
      "Fine Tuning VALI: Epoch: 5, Steps: 334 | Train Loss: 0.0014924  Vali Loss: 0.0282325 Vali Accuracy: 0.9909321  Vali weighted F1: 0.9909246  Vali macro F1 0.9897572 \n",
      "EarlyStopping counter: 2 out of 5\n",
      "Learning rate adjusting counter: 2 out of 5\n",
      "Fine Tuning Epoch: 6 cost time: 130.2436408996582\n",
      "Fine Tuning VALI: Epoch: 6, Steps: 334 | Train Loss: 0.0012926  Vali Loss: 0.0267348 Vali Accuracy: 0.9917756  Vali weighted F1: 0.9917714  Vali macro F1 0.9904800 \n",
      "new best score!!!!\n",
      "Validation loss decreased (0.027112 --> 0.026735).  Saving model ...\n",
      "new best score!!!!\n",
      "Fine Tuning Epoch: 7 cost time: 130.60167050361633\n",
      "Fine Tuning VALI: Epoch: 7, Steps: 334 | Train Loss: 0.0010339  Vali Loss: 0.0240129 Vali Accuracy: 0.9924083  Vali weighted F1: 0.9923976  Vali macro F1 0.9910377 \n",
      "new best score!!!!\n",
      "Validation loss decreased (0.026735 --> 0.024013).  Saving model ...\n",
      "new best score!!!!\n",
      "Fine Tuning Epoch: 8 cost time: 130.40992665290833\n",
      "Fine Tuning VALI: Epoch: 8, Steps: 334 | Train Loss: 0.0010053  Vali Loss: 0.0251447 Vali Accuracy: 0.9926191  Vali weighted F1: 0.9926130  Vali macro F1 0.9913775 \n",
      "EarlyStopping counter: 1 out of 5\n",
      "Learning rate adjusting counter: 1 out of 5\n",
      "Fine Tuning Epoch: 9 cost time: 129.79121780395508\n",
      "Fine Tuning VALI: Epoch: 9, Steps: 334 | Train Loss: 0.0010564  Vali Loss: 0.0256245 Vali Accuracy: 0.9924083  Vali weighted F1: 0.9924016  Vali macro F1 0.9916695 \n",
      "EarlyStopping counter: 2 out of 5\n",
      "Learning rate adjusting counter: 2 out of 5\n",
      "Fine Tuning Epoch: 10 cost time: 130.27902054786682\n",
      "Fine Tuning VALI: Epoch: 10, Steps: 334 | Train Loss: 0.0015302  Vali Loss: 0.0267223 Vali Accuracy: 0.9915647  Vali weighted F1: 0.9915569  Vali macro F1 0.9902825 \n",
      "EarlyStopping counter: 3 out of 5\n",
      "Learning rate adjusting counter: 3 out of 5\n",
      "Fine Tuning Epoch: 11 cost time: 130.20323610305786\n",
      "Fine Tuning VALI: Epoch: 11, Steps: 334 | Train Loss: 0.0009776  Vali Loss: 0.0277540 Vali Accuracy: 0.9909321  Vali weighted F1: 0.9909262  Vali macro F1 0.9891383 \n",
      "EarlyStopping counter: 4 out of 5\n",
      "Learning rate adjusting counter: 4 out of 5\n",
      "Fine Tuning Epoch: 12 cost time: 129.99986100196838\n",
      "Fine Tuning VALI: Epoch: 12, Steps: 334 | Train Loss: 0.0009213  Vali Loss: 0.0248184 Vali Accuracy: 0.9926191  Vali weighted F1: 0.9926132  Vali macro F1 0.9911331 \n",
      "EarlyStopping counter: 5 out of 5\n",
      "Early stopping\n",
      "Loading the best finetuned validation model!\n",
      "Fine Tuning Final Test Performance : Test Accuracy: 0.9516668  Test weighted F1: 0.9648026  Test macro F1 0.8489382 \n",
      "================ the 2 th CV Experiment ================ \n",
      "Leave one Out Experiment : The 3 Part as the test\n",
      "[-] Target sampling weights:  [0.00024085 0.00020721 0.00114155 0.00015901 0.00014704 0.00015654\n",
      " 0.00016142 0.00015838]\n",
      "Train data number :  41841\n",
      "The number of classes is :  8\n",
      "The input_length  is :  128\n",
      "The channel_in is :  21\n",
      "Validation data number :  4649\n",
      "Test data number :  18998\n",
      "================ Build the model ================ \n",
      "Wavelet Filtering Regularization\n",
      "Build the DeepConvLSTM model!\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Input \u001b[0;32mIn [6]\u001b[0m, in \u001b[0;36m<cell line: 1>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[43mexp\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtrain\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/pfs/data5/home/kit/tm/px3192/I2S0W2C2_CFC/notebooks/model/../../experiment.py:219\u001b[0m, in \u001b[0;36mExp.train\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    216\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmodel\u001b[38;5;241m.\u001b[39mtrain()\n\u001b[1;32m    217\u001b[0m epoch_time \u001b[38;5;241m=\u001b[39m time\u001b[38;5;241m.\u001b[39mtime()\n\u001b[0;32m--> 219\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m i, (batch_x1,batch_x2,batch_y) \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28menumerate\u001b[39m(train_loader):\n\u001b[1;32m    221\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcross\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39margs\u001b[38;5;241m.\u001b[39mmodel_type:\n\u001b[1;32m    222\u001b[0m         batch_x1 \u001b[38;5;241m=\u001b[39m batch_x1\u001b[38;5;241m.\u001b[39mdouble()\u001b[38;5;241m.\u001b[39mto(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdevice)\n",
      "File \u001b[0;32m~/miniconda3/envs/SDIL/lib/python3.8/site-packages/torch/utils/data/dataloader.py:521\u001b[0m, in \u001b[0;36m_BaseDataLoaderIter.__next__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    519\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_sampler_iter \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m    520\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_reset()\n\u001b[0;32m--> 521\u001b[0m data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_next_data\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    522\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_num_yielded \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m\n\u001b[1;32m    523\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_dataset_kind \u001b[38;5;241m==\u001b[39m _DatasetKind\u001b[38;5;241m.\u001b[39mIterable \u001b[38;5;129;01mand\u001b[39;00m \\\n\u001b[1;32m    524\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_IterableDataset_len_called \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m \\\n\u001b[1;32m    525\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_num_yielded \u001b[38;5;241m>\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_IterableDataset_len_called:\n",
      "File \u001b[0;32m~/miniconda3/envs/SDIL/lib/python3.8/site-packages/torch/utils/data/dataloader.py:561\u001b[0m, in \u001b[0;36m_SingleProcessDataLoaderIter._next_data\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    559\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_next_data\u001b[39m(\u001b[38;5;28mself\u001b[39m):\n\u001b[1;32m    560\u001b[0m     index \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_next_index()  \u001b[38;5;66;03m# may raise StopIteration\u001b[39;00m\n\u001b[0;32m--> 561\u001b[0m     data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_dataset_fetcher\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfetch\u001b[49m\u001b[43m(\u001b[49m\u001b[43mindex\u001b[49m\u001b[43m)\u001b[49m  \u001b[38;5;66;03m# may raise StopIteration\u001b[39;00m\n\u001b[1;32m    562\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_pin_memory:\n\u001b[1;32m    563\u001b[0m         data \u001b[38;5;241m=\u001b[39m _utils\u001b[38;5;241m.\u001b[39mpin_memory\u001b[38;5;241m.\u001b[39mpin_memory(data)\n",
      "File \u001b[0;32m~/miniconda3/envs/SDIL/lib/python3.8/site-packages/torch/utils/data/_utils/fetch.py:47\u001b[0m, in \u001b[0;36m_MapDatasetFetcher.fetch\u001b[0;34m(self, possibly_batched_index)\u001b[0m\n\u001b[1;32m     45\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m     46\u001b[0m     data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdataset[possibly_batched_index]\n\u001b[0;32m---> 47\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcollate_fn\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdata\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/miniconda3/envs/SDIL/lib/python3.8/site-packages/torch/utils/data/_utils/collate.py:84\u001b[0m, in \u001b[0;36mdefault_collate\u001b[0;34m(batch)\u001b[0m\n\u001b[1;32m     82\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mRuntimeError\u001b[39;00m(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124meach element in list of batch should be of equal size\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[1;32m     83\u001b[0m     transposed \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mzip\u001b[39m(\u001b[38;5;241m*\u001b[39mbatch)\n\u001b[0;32m---> 84\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m [default_collate(samples) \u001b[38;5;28;01mfor\u001b[39;00m samples \u001b[38;5;129;01min\u001b[39;00m transposed]\n\u001b[1;32m     86\u001b[0m \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mTypeError\u001b[39;00m(default_collate_err_msg_format\u001b[38;5;241m.\u001b[39mformat(elem_type))\n",
      "File \u001b[0;32m~/miniconda3/envs/SDIL/lib/python3.8/site-packages/torch/utils/data/_utils/collate.py:84\u001b[0m, in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m     82\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mRuntimeError\u001b[39;00m(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124meach element in list of batch should be of equal size\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[1;32m     83\u001b[0m     transposed \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mzip\u001b[39m(\u001b[38;5;241m*\u001b[39mbatch)\n\u001b[0;32m---> 84\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m [\u001b[43mdefault_collate\u001b[49m\u001b[43m(\u001b[49m\u001b[43msamples\u001b[49m\u001b[43m)\u001b[49m \u001b[38;5;28;01mfor\u001b[39;00m samples \u001b[38;5;129;01min\u001b[39;00m transposed]\n\u001b[1;32m     86\u001b[0m \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mTypeError\u001b[39;00m(default_collate_err_msg_format\u001b[38;5;241m.\u001b[39mformat(elem_type))\n",
      "File \u001b[0;32m~/miniconda3/envs/SDIL/lib/python3.8/site-packages/torch/utils/data/_utils/collate.py:64\u001b[0m, in \u001b[0;36mdefault_collate\u001b[0;34m(batch)\u001b[0m\n\u001b[1;32m     61\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m np_str_obj_array_pattern\u001b[38;5;241m.\u001b[39msearch(elem\u001b[38;5;241m.\u001b[39mdtype\u001b[38;5;241m.\u001b[39mstr) \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m     62\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mTypeError\u001b[39;00m(default_collate_err_msg_format\u001b[38;5;241m.\u001b[39mformat(elem\u001b[38;5;241m.\u001b[39mdtype))\n\u001b[0;32m---> 64\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mdefault_collate\u001b[49m\u001b[43m(\u001b[49m\u001b[43m[\u001b[49m\u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mas_tensor\u001b[49m\u001b[43m(\u001b[49m\u001b[43mb\u001b[49m\u001b[43m)\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mfor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mb\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mbatch\u001b[49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     65\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m elem\u001b[38;5;241m.\u001b[39mshape \u001b[38;5;241m==\u001b[39m ():  \u001b[38;5;66;03m# scalars\u001b[39;00m\n\u001b[1;32m     66\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m torch\u001b[38;5;241m.\u001b[39mas_tensor(batch)\n",
      "File \u001b[0;32m~/miniconda3/envs/SDIL/lib/python3.8/site-packages/torch/utils/data/_utils/collate.py:56\u001b[0m, in \u001b[0;36mdefault_collate\u001b[0;34m(batch)\u001b[0m\n\u001b[1;32m     54\u001b[0m         storage \u001b[38;5;241m=\u001b[39m elem\u001b[38;5;241m.\u001b[39mstorage()\u001b[38;5;241m.\u001b[39m_new_shared(numel)\n\u001b[1;32m     55\u001b[0m         out \u001b[38;5;241m=\u001b[39m elem\u001b[38;5;241m.\u001b[39mnew(storage)\n\u001b[0;32m---> 56\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mstack\u001b[49m\u001b[43m(\u001b[49m\u001b[43mbatch\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mout\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mout\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     57\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m elem_type\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__module__\u001b[39m \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mnumpy\u001b[39m\u001b[38;5;124m'\u001b[39m \u001b[38;5;129;01mand\u001b[39;00m elem_type\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__name__\u001b[39m \u001b[38;5;241m!=\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mstr_\u001b[39m\u001b[38;5;124m'\u001b[39m \\\n\u001b[1;32m     58\u001b[0m         \u001b[38;5;129;01mand\u001b[39;00m elem_type\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__name__\u001b[39m \u001b[38;5;241m!=\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mstring_\u001b[39m\u001b[38;5;124m'\u001b[39m:\n\u001b[1;32m     59\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m elem_type\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__name__\u001b[39m \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mndarray\u001b[39m\u001b[38;5;124m'\u001b[39m \u001b[38;5;129;01mor\u001b[39;00m elem_type\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__name__\u001b[39m \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mmemmap\u001b[39m\u001b[38;5;124m'\u001b[39m:\n\u001b[1;32m     60\u001b[0m         \u001b[38;5;66;03m# array of string classes and object\u001b[39;00m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAWcAAAD4CAYAAAAw/yevAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjUuMSwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy/YYfK9AAAACXBIWXMAAAsTAAALEwEAmpwYAABBYUlEQVR4nO3dd3gUVffA8e/ZJKQACWDAVCkCEVHpRUGKQABpVrCAYkOxoWD9WbDLq6KCrw0EBVSaSu8CCqhAAoQWenkhhV4TIGVzf3/sEkNLNm13XM/neebJ7p1yz8zOnty908QYg1JKKWuxeToApZRSF9LkrJRSFqTJWSmlLEiTs1JKWZAmZ6WUsiDf0q4g/f37LXE6SIXBv3o6BCyxIZTl2EQ8HQIAgX7+ng6B42k7ir0xsg7tdPmr5hdawxob/yJKPTkrpZRb5dg9HUGJ0OSslPIuJsfTEZQI7XNWSnmXnBzXh3yISLSILBaRRBHZKCIDnOVviEiyiCQ4h5vzzPOyiGwXkS0i0jFPeSdn2XYRecmV1dCWs1LKq5iSazlnA4OMMatFpDywSkQWOMd9Yoz5KO/EInI1cBdQF4gAfhWR2s7RnwMdgCQgTkSmG2MS86tck7NSyrvYs0tkMcaYVCDV+fqkiGwCIvOZpQcwwRiTAewSke1AU+e47caYnQAiMsE5bb7JWbs1lFLeJcfu+uAiEakGNABWOIueFJF1IjJaRCo6yyKBvXlmS3KWXao8X5qclVLexeS4PIhIPxGJzzP0O39xIlIO+Bl4xhhzAvgSuBKoj6NlPbQ0VkO7NZRS3qWAA315GWNGACMuNV5E/HAk5h+MMb8459mfZ/xIYKbzbTIQnWf2KGcZ+ZRfkraclVJexZgcl4f8iIgAo4BNxpiP85SH55nsVmCD8/V04C4R8ReR6kAtYCUQB9QSkeoiUgbHQcPpBa1HaSXn0cAB/g76XAFB+N/2NIEPvUPA/YOR0AK7Xwrm44t/j8cJfOwDAu5/HQkJBcAWXoOAB98iPm4+q+IX0KNHpwIXNXLEUJKT1rJmzcLcsttv70pCwiIyzuylUcPrih9vIXWMbcPGDUvYnLiMF55/wu31A/j7+/PXHzNZFb+AtQmLGPz6II/EYYVt4ak4oqLCmT9vEmsTFpGwZiFPPvkQAPWuu5qlS6YTt3Ief/05i8aN65d6LI893pe/Vs5hedwc+j/eF4Bvxwxn6Z8zWPrnDNZt/J2lf84o9TguUEKn0gEtgD7ATeedNveBiKwXkXVAW+BZAGPMRmASjgN9c4EnjDF2Y0w28CQwD9gETHJOmy8ppZvttwLSgLHp799f9/yRfm17QVYGWcumIpXC8e/YhzPjP3BpwRISin+Xhznz45Bzyn0b3oStcjSZ88bgU6cZvrUbkTHtC/AtA/ZsKrw+n7CwKqyKX8AVVRtit1/6YEDLls1IT0tn9LfDaNCgHQBXXVWTnBzDF58P4cUX32bV6nWubw2nom5pm83Gpo1L6XTz3SQlpbL8r9n07vM4mzZtK+ISi65s2SDS00/h6+vLkt+m8OzAwaxYudpt9VtlW5RkHIW5fDssrAphYVVISNhAuXJlWbF8Dnfc8RAfDX2D4cO/Yd68xXTqdBODBvanQ+ydhYqjMJdv17m6NqO/G8ZNrW8lMzOLX6Z+y7MDXmPnzv/lTvPOey9z4sRJPhjyX5eXWxKXb2ds/t3lr5r/Va0te/l2abWclwBHLllpaAT23Y6zSMyRVCSkMgQFA+BT9wYC7h9MwINvUaZTX3Bxx/Wp1ZDsDcsAsG+Ow6fa1Y4R2Zm5VwwFBPjjyj+jZctWcOTosXPKNm/eztatO1yKpaQ1bdKAHTt2s2vXHrKyspg0aRrdu3UseMZSkJ5+CgA/P198/fxc2p4lySrbwlNx7Nt3gIQExw/StLR0Nm/eRkRkGMYYgsuXAyAkuDypqfvzW0yxxcRcyaq4BE6fPoPdbmfZspV0637u+t96Wxd+mjzzEksoRYU4IGhlBR4QFJGrcJyTd7bvIRmYbozZVNRKcw7sxTemMZlJW7GF10BCLsMWXAkTWBbfOk05M+4dyLFTpuN9+Na9gewNfxS4TFv5ipgTzv8HJgeTcRoCy8HpNGwRNUhIWETVK6Lo+8DT+baarSgiMoy9SSm575OSU2napIFHYrHZbKxcMZeaV1bjy6++Y2XcGrfWb5VtYYU4qlaNol69a1i5cg3PPfcGM2f8wJAhr2Gz2Wjdpkep1p2YuJXXXh9ExUoVOHP6DLGxrVmz5u9ezBtaNOHggUPs3LG7VOO4qEIcELSyfJOziLwI3A1MwNGxDY4jjeNFZIIxZsgl5utXu3btJ2fOnHnl3JVbebBp7XPGZ/01kzIdehPw4FuYg0nk7P8f5OTgU60utrBqBPQd7FiObxlM+gkA/G97GqkQivj4IsGXEfDgWwBkxy0ge/3SfFcyJ2Un9evfxFVX1WT0qE+ZO3cxGRkZ+W8ZdVE5OTk0bhJLSEgwP08eRd26MWzcuMXTYf3rlC0bxMQJI3juuTc4eTKNfv3u4/nn32TK1NnccXtXvv76Izp3vrvU6t+6ZQeffvI1U6eNIf3UKdav33ROo+eOO7vx02QP9DeD5VvEriqo5fwQUNcYk5W3UEQ+BjYCF03OztNT5gMzI5rWvqDPmcwzZM76JvdtYP+PyDl2AFt0bbLX/0HW75MvmCXjl+GOui/R55xz8igSXAlz8iiIDfEPhNNp50yzefN20tJOcU3dmCL1GXtKSvI+oqMict9HRYaTkrLPgxHB8eMn+O33PxwHxdyYnK2yLTwZh6+vLxMnjmD8hClMnTYHgD6972DgwNcB+OnnmXz11YelHse4sZMZN9bxXX198KDc9ffx8aFb9460blm6rfdL8pKWc0F9zjk4rhE/X7hzXNH4B4HNBwDfeq2x790KmWew707E96rGEFTeMV1AWST4MpcWad+2Bt9rWgLgc1UT7P9z9LpISCiIYzWvuCKSmJgr2f2/vZdcjhXFxSdQs2Z1qlWLxs/Pj549ezBj5ny3xxEaWomQEMexgYCAANq3a8WWLe7th7fKtvBkHCO+/ojNm7czbNjI3LLU1P20anU9AG3btmD79l2lHkdoZcd3MyoqnG49OjJ5kuPssDZtW7B16w6PNSBMTpbLg5UV1HJ+BlgoItv4+/LDK4CaOE4NuZTxQBsgNPCJT8haOgV8HMk4e81ibKHh+HftB8aQcyiZjNmjADCHU8hc8jMBdz2PiA1jt5M5fyzmxOECVyR77RL8u/Uj8LEPMKfTHWdqAD7RtfFr3pX4zs+Rk5PDU0//H4cPH813WePGfU7rVtcTGlqJXTvjeeutjzhy9BiffvIOlStXYtq0saxdu5EuXe8tMK6SYLfbGfDMq8ye9SM+NhvfjZlIYuJWt9SdV3j45Ywe9Sk+PjZsNhs//TSDWbPd+xADq2wLT8Vxww1N6N37Dtav30TcynkAvPb6f3is/wt8PPRNfH19OXMmg/6Pv1jqsYz74XMqVapAVlY2zw18g+PHTwJw+x1d+dlTXRrgNS3nAk+lExEbjpt35D0gGGeMcemomj4J5W+W2BDKcvRJKH8riVPpzqya6vJXLaDRLdbY+BdR4NkaxnEZzXI3xKKUUsWnT0JRSikL+pecraGUUv8sXtLnrMlZKeVdSuhm+56myVkp5V205ayUUtbj4olklqfJWSnlXbTlrJRSFqRnayillAVpy9k1IRa4Mk8pK8tx8z2xLyU984ynQygZeraGUkpZkHZrKKWUBWm3hlJKWZAmZ6WUsiDt1lBKKQvSA4JKKWVB2q2hlFIWpN0aSillQV7Sci7oAa8e1TG2DRs3LGFz4jJeeP6Jf3UcVojBKnFYIQarxGGFGKwUB+BIzq4OFmbZ5Gyz2Rg+7F26duvNtfXa0qvXLdSpU+tfGYcVYrBKHFaIwSpxWCEGK8WRyxjXBwuzbHJu2qQBO3bsZteuPWRlZTFp0jS6d+v4r4zDCjFYJQ4rxGCVOKwQg5XiyJWd7fpgYZZNzhGRYexNSsl9n5ScSkRE2L8yDivEYJU4rBCDVeKwQgxWiiOXyXF9sLAiJ2cReSCfcf1EJF5E4nNy0otahVJKFZ72OfPmpUYYY0YYYxobYxrbbGWLtPCU5H1ER0Xkvo+KDCclZV+RllUcVojDCjFYJQ4rxGCVOKwQg5XiyPVv6HMWkXWXGNYDl5dmYHHxCdSsWZ1q1aLx8/OjZ88ezJg5vzSrtGwcVojBKnFYIQarxGGFGKwURy4vaTkXdJ7z5UBH4Oh55QL8WSoROdntdgY88yqzZ/2Ij83Gd2Mmkpi4tTSrtGwcVojBKnFYIQarxGGFGKwURy6LJ11XicmnaS8io4BvjTHLLjLuR2PMPQVV4Fsm0tq/HZRSlpGdmSzFXcapEc+6nHOC+n1S7PpKS77dGsaYhy6WmJ3jCkzMSinldiXUrSEi0SKyWEQSRWSjiAxwllcSkQUiss35t6KzXERkuIhsd3b/NsyzrPud028TkftdWQ3LnkqnlFJFUnKn0mUDg4wxVwPNgSdE5GrgJWChMaYWsND5HqAzUMs59AO+BEcyBwYDzYCmwOCzCT0/mpyVUt4lx7g+5MMYk2qMWe18fRLYBEQCPYAxzsnGALc4X/cAxhqH5UAFEQnHcdxugTHmiDHmKLAA6FTQauiNj5RS3qUQBwRFpB+OVu5ZI4wxIy4yXTWgAbACuNwYk+octY+/z1yLBPbmmS3JWXap8nxpclZKeRe73eVJnYn4gmScl4iUA34GnjHGnBD5+xiiMcaISKmc9KDdGkop71KC5zmLiB+OxPyDMeYXZ/F+Z3cFzr8HnOXJQHSe2aOcZZcqz5cmZ6WUdymhPmdxNJFHAZuMMR/nGTUdOHvGxf3AtDzl9znP2mgOHHd2f8wDYkWkovNAYKyzLF/araGU8i4ld0OjFkAfYL2IJDjL/g8YAkwSkYeA/wE9neNmAzcD24FTwAMAxpgjIvI2EOec7i1jzJGCKtfkrJTyLgW0iF3lvMbjUheptLvI9Aa46JMGjDGjgdGFqV+Tsxs1qVzb0yEAEHfQg5fWKlXKjJdcvq3JWSnlXQpxtoaVaXJWSnmXEurW8DRNzkop76LdGkopZUHaclZKKQuy+LMBXaXJWSnlXbTlrJRS1mOy9WwNpZSyHi9pOVv63hodY9uwccMSNicu44XnL3rhjaXj8Pf3568/ZrIqfgFrExbx8KC+F0wTFnk5n00cyrgF3/D55E+oHB5a7HiDK5Rn2PgPmbRsHMPGf0j5kHIAxN7annELvmHN6l9Z+vs0rrvu6kIv2wqfiRVisEocVojBSnEAJXmzfY+ybHK22WwMH/YuXbv15tp6benV6xbq1Kn1j4ojIyOD9rE9adS4A40ax9K8TVPqNqxzzjRPvf4Yc36aT58ODzP607H0f/kRl2NrcH09Xv3kxQvK+zxxD/HLVtOzZR/il62mzxOOJ4ql7k3l8TueoUHD9rz73qd89cV/XK4LrPGZWCEGq8RhhRisFEeuErrxkadZNjk3bdKAHTt2s2vXHrKyspg0aRrdu3X8x8WRnn4KAD8/X3z9fDj/ebrValUj/o/VAKz6Yw2tYlvkjrv3sV6MmvUl4xZ8c9FW96Xc2PEGZk923PRq9uR5tOrkWOb6+I2cPJ4GwPIVq4mMDHd5mWCNz8QKMVglDivEYKU4zjI5xuXBygpMziJylYi0c95wOm95gY9ZKY6IyDD2JqXkvk9KTiUiIqw0qyyVOGw2G/Fx80lNXsfKJatIXLPpnPHbE3fQpnMrAFp3vpGy5csSXDGYpq0aE1U9ioe69Oe+2Ee46rra1G92nUt1VgqtxOEDjpteHT5whEqhlS6Y5sEH7mLuvMUurwdY4zOxQgxWicMKMVgpjlzZdtcHC8v3gKCIPI3jLkubgFEiMsAYc/bepe8Bcy8xX+6jX8QnBJutbMlF/A+Tk5ND4yaxhIQEM3/aj9SIqcbOLbtzx3/29pcMeudpuvTsyJrl6ziQepAcu51mrRvTrHVjxswfCUBQUCDR1aNIWLGOb2Z8gZ+/H0FBgQRXKJ87zRfvjmDF73EXxGDOa663aX0DDzxwN63b3Fp6K66Up1i8Reyqgs7WeARoZIxJcz5D6ycRqWaMGcalb6V3zqNffMtEFmlLpSTvIzoqIvd9VGQ4KSn7irKoYimpOI4fP8HqPxJo3qbpOcn50P7DvPzIYAACgwJo26UVaSfSQYSx//2Rqd/PuGBZD3d7HHD0OXfp2Yl3nj237/jIoSNcVsXRer6sSiWOHj6aO+7KOjV486vX6Nq9D0eOHKUwrPCZWCEGq8RhhRisFEcuL0nOBXVr2IwxaQDGmN1AG6CziHxMPsm5JMTFJ1CzZnWqVYvGz8+Pnj17MGPm/NKsssTjCA2tREhIMAABAQE0adWI/+3Yc840IRWDOftMsvueupeZE+YAsOK3OLr26kxgUAAAlcNCqXhZBZfqXTb/T26+09Hnd/OdHVk6708ALo+owpCRb9H3gQFs27bTpWXlZYXPxAoxWCUOK8RgpTjOMsa4PFhZQS3n/SJS3xiTAOBsQXfFcdPoa0szMLvdzoBnXmX2rB/xsdn4bsxEEhPdfx/i4sQRHn45o0d9io+PDZvNxl+z/+KPX5fzyHMPsGntFpYt+JOGN9Sn/8uPYIwhYfk6PnplGAArl8RTrVZVRk7/HIBTp07z5lPvcfTwsQLrHfv5eN79ajDd7r6ZfUn7efWxNwF48Nn7CK4YzGefvQdAdnY2za+/2S3boqRYIQarxGGFGKwURy4vaTlLfv89RCQKyDbGXPAbRURaGGP+KKiConZreCO92b5S+cvOTC72L/ITD3VwOecEj1pQqj0AxZFvy9kYk5TPuAITs1JKuZvJtvbFJa7Sy7eVUt7FO3KzJmellHex+sUlrtLkrJTyLpqclVLKgrRbQymlrEe7NZRSyoJMtiZnpZSyHu3WUEop67H4PfRdpsnZjaxyZd7plKWeDoHAiBs9HYLyVpqclVLKerTlrJRSFmSyPR1BydDkrJTyKtpyVkopC9LkrJRSVmQsexfQQrHs07eVUqooTI7rQ0FEZLSIHBCRDXnK3hCRZBFJcA435xn3sohsF5EtItIxT3knZ9l2EXnJlfXQ5KyU8iomR1weXPAd0Oki5Z8YY+o7h9kAInI1cBdQ1znPFyLiIyI+wOdAZ+Bq4G7ntPnSbg2llFfJsZdct4YxZonz4dau6AFMMMZkALtEZDvQ1DluuzFmJ4CITHBOm5jfwizdcu4Y24aNG5awOXEZLzz/xL86juLE4OMjRIQFEB0ZRHRkIOMmTb3odCtXr+P2+5+gx72P0veJ54sdc2ZmJoNee5/OPR/k7keeITl1PwDrE7cQFRGYO5QN8nF5mbVrX0l83Pzc4cihzTz91MPFjrUo/un7hTfGAYXr1hCRfiISn2fo52I1T4rIOme3R0VnWSSwN880Sc6yS5Xny7LJ2WazMXzYu3Tt1ptr67WlV69bqFOn1r8yjpKI4dCRTPYmnyIp5TQTfpnJjl3/O2f8iZNpvDP0v/z3P4OZ9sPXDH3nFZeXnZy6n75PvnBB+S8z5xNcvhxzJo2mT69b+PiL0QDUrFGVpJTTJKWcJnX/GSqH+rtc19atO2jcJJbGTWJp2qwTp06dZuq0OS7PX1K8Zb/wpjjOKky3hjFmhDGmcZ5hhAtVfAlcCdQHUoGhpbEelk3OTZs0YMeO3ezatYesrCwmTZpG924dC57RC+Mobgx2uyEz03H0wxioUTWa/QcPnzPN7AW/0b51C8LDqgBwWcUKueNmzFvEXQ8P4Pb7n+DND4Zjt9tdqnfR0r/ocXN7AGLb3MiKVQkYYwgMCMidRgSKeg+xdje1ZOfO/7FnT3IRl1B03rBfeFscZxnj+lC05Zv9xhi7MSYHGMnfXRfJQHSeSaOcZZcqz1eByVlEmopIE+frq0VkYN6jk6UlIjKMvUkpue+TklOJiAgr7WotGUdJxuDrK2zatoPr6sacU757TxInTqbR98kX6PngU0yb8ysAO3bvYe7C3xn31VB+HvM5NpuNmfMXu1TXgYOHCasS6qzXh3Jlgzh2/AQA/v42oiMDiY4M4tChjCKtS8+ePZgwcWqR5i0ub9svvCGOs0r4gOAFRCQ8z9tbgbNnckwH7hIRfxGpDtQCVgJxQC0RqS4iZXAcNJxeUD35HhAUkcE4jjD6isgCoBmwGHhJRBoYY969xHz9gH4A4hOCzVa2oDiUG4hAWJUAXnz6UcqVPfczsdtzSNy8jW+GDyEjI4N7Hx1IvbpXsSI+gcTN27nroQEAZGRkUMnZqn765bdITtlPVnYWqfsPcvv9jr7G3j17cGuX2HxjycjIYW/yafz8hCqVAzh1+nShWjJ+fn506xrLK6++7/pM6l+hJA8Iish4oA0QKiJJwGCgjYjUx/GjbzfwKIAxZqOITMJxoC8beMIYY3cu50lgHuADjDbGbCyo7oLO1rgDR7+KP7APiDLGnBCRj4AVwEWTs7PfZgSAb5nIIv14SEneR3RURO77qMhwUlL2FWVRxWKFOEoqhrAqAZxMy6ZDmxYXjLu8SighIeUJCgwgKDCARvWvYcv2XRhj6N65Pc/2f+CCeYa//zrg6HN+5d2hfPffD84ZX6XyZew7cIiwKpXJzraTln6KCiHB50yTlWUwOYYyfjYyMl2/tKtTp7asWbOeAwcOuTxPSfKm/cJb4jirqC3iiy7LmLsvUjwqn+nf5SJ50Xm63ezC1F1Qt0a2s2/lFLDDGHPCWdFpSvnGfHHxCdSsWZ1q1aLx8/OjZ88ezJg5vzSrtGwcJRFDlVB/MrNyOH4i66Lj297YnDXrNpKdbef0mTOs37iFGtWiad64Pgt+W8bho8cAOH7iJCn79rtUZ9uWzZk229E9Mv+3pTRrVA8RISnPF9fXV/Dzs5GVXbjd6a5et3isSwO8Z7/wpjjOMkZcHqysoJZzpogEOZNzo7OFIhJCKSdnu93OgGdeZfasH/Gx2fhuzEQSE91/P2QrxFHcGAL8bZQv70dGpp2oiEBuv/8JBjx6P6n7DwLQ69YuXFntClo0a8xt9/fHJjZu79aRWjWqAfDUI/fR75lXyDE5+Pn68srAx4kIu7zAem/r2pGX3/6Qzj0fJCS4PB++6bgwavW6jURHBuZ2Yxw8nEFOIfamoKBA2rdrRf/HX3R9phLmDfuFt8VxlrfcW0NMPh19IuLvPKH6/PJQINwYs76gCoraraFKj95sX1lVdmZysZuzW+t0cjnn1N4017LN53xbzhdLzM7yQ4BnOvuUUiofVu+ucJVevq2U8iolebaGJ2lyVkp5lZI8W8OTNDkrpbxKjnZrKKWU9Wifs1JKWVBR75lhNZqclVJeRbs1lFLKgnL0gKBSSlmPtpzVP5YVrs5bF13f0yEAcN3eBE+HoEqYHhBUSikL0pazUkpZkJecrKHJWSnlXew5ln36XqFoclZKeRUvuWOoJmellHcxaJ+zUkpZTo6XdDprclZKeZUcbTkrpZT1aLeGUkpZkN1LkrOlzznpGNuGjRuWsDlxGS88/4RHYoiKiuDX+ZNZt3YxaxMW8dSTD3kkDitsi+LGMXLEUFKS1pKwZmG+0wVcW4s6W6ZTvlOL4oQKgC2kHFeMeYcrF47gijHvYAsuB0C59s2pMeu/xMfNZ/lfs2lxQ5OiLd9mI27lPKZNGVPsWIvCG/aLkpZTiMHKLJucbTYbw4e9S9duvbm2Xlt69bqFOnVquT2O7Oxsnn/hTa6r15YWLbvRv39ft8dhlW1R3DjGjp1El673FlQJl7/4AGnLVhcqtqBm1xLxwbMXlIc+difpf65lR7t+pP+5ltDH7gQg/c8EdnZ5ksZNYnmk3yC+/vqjQtV31tNPPczmzduKNG9xect+UdI0OZeypk0asGPHbnbt2kNWVhaTJk2je7eObo9j374DrEnYAEBaWjqbN28jMiLMrTFYZVsUN46ly1Zw5OixfKepdF83Tsz9A/vh4+eUX/bIbVSf8gk1Zv2XygMKSPB5lG/fnOO//ArA8V9+pXyH5gCYU2dypykbFER+T6G/lMjIcG7u3I7Ro8cXet6S4C37RUkziMuDlRU6OYvI2NII5HwRkWHsTUrJfZ+UnEqEm5Pi+apWjaJ+vWtYsXKNW+u1yrYo7Th8L7+M8rHXc/SH2eeUl23ZgDLVItl167Ps7PoUAdfUJKhJXdeWGVqB7INHAcg+eBTf0Aq548rHXs+G9b8zfdoYHnlkUKHj/Xjom7z08jvk5HimDfZv2S8KK0dcH6ws3wOCIjL9/CKgrYhUADDGdL/EfP2AfgDiE4LNVrb4kXpY2bJBTJo4koHPDebkyTRPh+OVwl7tx4EPvr3gURblbmxI2ZYNqDHjMwBsZQMoUy2SU3Ebqf7zx0gZP2xlA/AJKZ87zf4PviV96UW6RvIs+uT8v7hu1Jfc2LIZb77xPB073+VyrF1ubs+BA4dYvWY9rVtdX/iVVaXm33IqXRSQCHyDY7cWoDEwNL+ZjDEjgBEAvmUii3RKeEryPqKjIv4OJDKclJR9RVlUsfn6+jJ54kjGj5/C1Klz3F6/VbZFaccRcG1NIoe9CIBvxWDKtWkMdjsAh76axLHxcy+YZ9ftAwFHn3OF29uT8sIn54zPPnQM38oVHa3myhXJPnzsgmUsXbaC6tWv4LLLKnL48FGXYr3hhsZ06xpL5043ERDgT3BwecZ8N5z7+z5dmFUuln/LflFYdo/VXLIK6tZoDKwCXgGOG2N+A04bY343xvxemoHFxSdQs2Z1qlWLxs/Pj549ezBj5vzSrPKSRo4YyqbN2/l02AiP1G+VbVHacWxv8xDbWz/I9tYPcmLuH6S+/gUnFywnbelqKt4RiwQFAI7uD5/LQlxa5smFKwi5rT0AIbe15+SvywHwqxqeO02D+tfg71/G5cQM8MqrQ6hWozE1azfn3t6Ps3jxH25NzPDv2S8KK0fE5cHK8m05G2NygE9EZLLz7/6C5ikpdrudAc+8yuxZP+Jjs/HdmIkkJm51R9XnaHFDE/r0voN16xOJj3PscK+9NoQ5cxe5LQarbIvixvH9uM9p3ep6QkMrwbIxHBz2A+LrA8DR8Zf+RZK+bA3Ha0ZT/SfHD7ac9NMkD/rogoOGF3P4q8lEffYSFXp2ICv5IElPvQ9AcMcWhNx6E/Gn0zhz+gz33Nvf5fWwCm/ZL0qal1y9jRTmKLWIdAFaGGP+z9V5itqtobybPglFXUx2ZnKxm7MTw+91Oef0Sv3Bss3nQrWCjTGzgFmlFItSShWb1c/CcJVevq2U8ip6+bZSSllQSZ7nLCKjReSAiGzIU1ZJRBaIyDbn34rOchGR4SKyXUTWiUjDPPPc75x+m4jc78p6aHJWSnmVEr58+zug03llLwELjTG1gIXO9wCdgVrOoR/wJTiSOTAYaAY0BQafTej50eSslPIqphBDgcsyZglw5LziHsDZO12NAW7JUz7WOCwHKohIONARWGCMOWKMOQos4MKEfwFNzkopr1KYbg0R6Sci8XmGfi5UcbkxJtX5eh9wufN1JLA3z3RJzrJLledLDwgqpbxKYe50kvdq5qIwxhgRKZXThbXlrJTyKnZxfSii/c7uCpx/DzjLk4HoPNNFOcsuVZ4vbTkrj7DKxR+nk37zdAgERrXxdAhexQ33CJwO3A8Mcf6dlqf8SRGZgOPg33FjTKqIzAPey3MQMBZ4uaBKNDkrpbxKSSZnERkPtAFCRSQJx1kXQ4BJIvIQ8D+gp3Py2cDNwHbgFPAAgDHmiIi8DcQ5p3vLGHP+QcYLaHJWSnmVkuwANsbcfYlR7S4yrQEu+owuY8xoYHRh6tbkrJTyKnr5tlJKWZDVnw3oKk3OSimv4i0329fkrJTyKtqtoZRSFqTdGkopZUHe8nQPTc5KKa+S4yXp2dKXb3eMbcPGDUvYnLiMF56/6OmDpW7kiKGkJK0lYc1Cj9R/lhW2BcCApx9hbcIiEtYs5Ptxn+Pv7+/W+qOiIvh1/mTWrV3M2oRFPPXkQ4Wa38dHiAgLIDoyiOjIQMZNnnbR6VauWcftDzxFjz6P0/fJly46TWFkZmYxaPB/6HzXI9zdbyDJqfsBWJ+4haiIwNyhbJBPoZar++eF7IUYrMyyydlmszF82Lt07daba+u1pVevW6hTp5bb4xg7dhJdut7r9nrzssq2iIgI48knHqRZ85up36AdPj4+9OrZw60xZGdn8/wLb3Jdvba0aNmN/v37FnpbHDqSyd7kUySlnGbCL7PYsWvPOeNPnEzjnaFf8t8hrzFt3BcMfdv15Jycup++T104/S+z5hNcvixzJoykT88efPzVdwDUrFGVpJTTJKWcJnX/GSqHFu6fne6fFyrh+zl7jGWTc9MmDdixYze7du0hKyuLSZOm0b1bR7fHsXTZCo4cPeb2evOyyrYA8PX1JTAwAB8fH4ICA0lN3efW+vftO8CaBMdDKdLS0tm8eRuREWEuz2+3GzIzHV9LY6BGtWj2Hzp8zjSzf/2d9q1vIPzyKgBcVrFC7rgZ8xZzV79nuf2Bp3jzw/9it7vW/lq0dDk9OjkuKott05IVq9ZijCEwICB3GpHC95fq/nmhknwSiicVKjmLSEsRGSgisaUV0FkRkWHsTUrJfZ+UnEpEIb6E3sQq2yIlZR8ff/IVu3asJGnPGo6fOMGCX5e4PY6zqlaNon69a1ixck2R5vf1FTZt3cl1V8ecU757bzInTqbR96mX6PnQAKbNdXQZ7Ni9l7mLljDuiw/5+dvPsNlszFzwm0t1HTh0mLAqlZ31+lCubBDHjp8AwN/fRnRkINGRQRw6lFGkdfEkq+yfZ+VgXB6sLN8DgiKy0hjT1Pn6ERzXjU/B8ZiVhsaYIZeYrx+Ox7QgPiHYbGVLNmrlERUqhNC9W0dq1m7OsWMnmDjha+655zZ+/PEXt8dStmwQkyaOZOBzgzl5Mq3Q84tAWJUAXnz6EcqVDTpnnN1uJ3HLdr759F0yMjK4t/9z1Lv6KlasSiBxyw7ueuRZADIyMqlUMQSAp//vHZJT95OVlU3qgYPc/sBTAPS+ozu3dumQbywZGTnsTT6Nn59QpXIAp06fxlg7b1iat2y6gs7W8Mvzuh/QwRhzUEQ+ApbjuDvTBfLewNq3TGSRtlVK8j6ioyJy30dFhpOS4t6f0FZhlW3Rrt2N7Nq9h0OHHDfUmjJ1Dtc3b+z25Ozr68vkiSMZP34KU6fOKdIywqoEcDItmw6tb7hg3OWVQwkJDiYoMICgwAAa1buGLTt2YQx073QTzz7W94J5hr/3KuDoc37lvU/47rNzvxpVQi9j34GDhFUJJTvbTlr6KSqEBJ8zTVaWweQYyvjZyMi0eo/o36yyf571z9ly+SuoW8MmIhVF5DJAjDEHAYwx6UB2aQYWF59AzZrVqVYtGj8/P3r27MGMmfNLs0rLssq22LsnmWbNGhIY6OgnvaltSzZv3ub2OEaOGMqmzdv5dFjRHmBRJdSfzKwcjp/Iuuj4ti2bs2bdRrKz7Zw+c4b1iVuoUTWK5o3qseD3Pzjs7OM9fuIkKfsOXHQZFy6zWW73yPzfltGs4XWICEl5kpivr+DnZyMr+5+VXqyyf55lx7g8WFlBLecQYBUggBGRcOfNo8s5y0qN3W5nwDOvMnvWj/jYbHw3ZiKJiVtLs8qL+n7c57RudT2hoZXYvTOeN9/6iG+/m+DWGKyyLVbGreGXX2YRt3Ie2dnZJCRsZOQ3P7g1hhY3NKFP7ztYtz6R+DhHAnjttSHMmbvIpfkD/G2UL+9HRqadqIhAbn/gKQb0u4/U/QcB6HXLzVxZLZoWzRpxW98nsdmE27t2pFaNagA89XAf+g18jZwcg5+vD68M7E9EWJUC672tSywvvzOUznc9QkhwOT5840UAVq9LJDoyMLcb4+DhDHIKkZt1/7zQP+tf26WJKULnlogE4XjI4a6Cpi1qt4ZS7qBPQrGW7MzkYjf6Bla7y+Wc8/HuCZY9Z6NIVwgaY04BBSZmpZRyN29pDerl20opr+It3RqanJVSXsXqB/pcpclZKeVVrH5xias0OSulvIp3pGZNzkopL6MtZ6WUsiA9IKiUUhZktOX8z9Kkcm1Ph0DcQc9dNZWXv69fwROVsix7qV797zIrXABycmQfT4cAQPlHxnk6hBKhZ2sopZQFabeGUkpZUI6X3G9Vk7NSyqt4R2rW5KyU8jJ6Kp1SSlmQnq2hlFIWlK3JWSmlrEdbzkopZUHecipdQc8QVEqpfxRjjMtDQURkt4isF5EEEYl3llUSkQUiss35t6KzXERkuIhsF5F1ItKwOOth6eTcMbYNGzcsYXPiMl54/olCzevv789ff8xkVfwC1iYs4uFBfS+Y5vKIKvx38seMmTeCcQu+4fqbmhU75vDoML6Z8QWTl33P21++jq+f48fJXf3uZN3axaxetYD5cydyxRWRhVpucbZFcYWEBPP9D1+wes1CVq3+laZNG/Luuy+zes1CVqyYw/gJXxNy3pOkS1JUVDjz501ibcIiEtYs5MknHwLgumvrsOT3aaxe9StTfvmW8uXLlVoM5xs5YigpSWtJWLOw0PP6+AgRYQFERwYRHRnIDyu3XzDNrkMnuW/MbzT5zzTGLC+Zh+hmZtt5YcpKun05n97f/UbysXQA1qccoec3i4iKCCQqIpCyQT6FWu7537XBrw8qkXiLKgfj8uCitsaY+saYxs73LwELjTG1gIXO9wCdgVrOoR/wZXHWw7LJ2WazMXzYu3Tt1ptr67WlV69bqFOnlsvzZ2Rk0D62J40ad6BR41iat2lK3YZ1zpmm74A+LJzxG/d37Mdrj7/N8+894/Lyb+7ZkYcG3n9B+ROvPMqEkZO5s2VvTh4/Sbe7bwZg64ZtNGvemYaNOvDzL7MY8v6rLtdV3G1RXB9+OJgFC36nYYN2NG/WmS1btrNo0TKaNI6lWbPObN+2i+eee7zU6s/OtvPCi29Rr/5NtLyxO/0fu586V9Xiq68+5JVX36dho/ZMnTaXQQMfK7UYzjd27CS6dL23yPMfOpLJ3uRTJKWcZuLqnew4eOKc8SGBZXihQz3ua1az0MtOPpbOQ98vvaB8ytr/ERzgx4z+sfRuUpNhizcCULNyMD8+2IaklNOk7j9D5VD/QtV3/netY2wbmjUtVqOxWNzw9O0ewBjn6zHALXnKxxqH5UAFEQkvaiWWTc5NmzRgx47d7Nq1h6ysLCZNmkb3bh0LtYz09FMA+Pn54uvnw4W/YgxlywUBUC64LIf2HwIcyfDJVx9l1KwvGbfgG27p3c3lOhu1aMDiWb8DMHvyPFp1bAnA6j8TOH36DAArVq4iKtL1z6wktkVRBQeXp0XLpoz5biIAWVlZHD9+goULl2K32wHHU7kjI8NKLYZ9+w6QkLABgLS0dDZv3kZEZBi1atVg6dLlACxcuIRbb7251GI439JlKzhy9FiR5rXbDZmZjp5RY6DGZeU5kHbmnGkqlfXnmoiK+Nou/IrO2rCHe7/9jZ7fLOLt2Wuw57iWZH7bmkq3a68AoH2dCFbuPogxhkA/39x6RIp2Ece53zU/l7oMSksJt5wNMF9EVolIP2fZ5caYVOfrfcDlzteRwN488yY5y4ok3+QsIs1EJNj5OlBE3hSRGSLyHxEJKWqlroiIDGNvUkru+6TkVCIiCpcAbDYb8XHzSU1ex8olq0hcs+mc8d8M/Y5Ot3VgWvwkho4dwtBXPwOg2903k3YynYe69OfBLv3pfk8XwqMLrjukYjBpx9Ow2x1fvAOpB6kcFnrBdA/0vZu58xa7vB4lsS2Kqlq1aA4dOszXX3/En3/N4vMvhhAUFHjONPfddyfz5//mlniqVo2iXr1rWLlyDYmJW+ne3fFP6vbbuxIVFeGWGEqSr6+wef9xro2o6NL0Ow+dYF5iMt/d14pJD9+EzSbM3ri34BmBAydPExbsaIz42myU8/fj2OlMANYnHyE6MpDoyCAOHcoo9Hrk/a4tXLiElXFrCr2MklKYPmcR6Sci8XmGfuctrqUxpiGOLosnRKTVeXUZSumixILO1hgN1HO+HgacAv4DtAO+BW672EzOFewHID4h2GxlSyTYwsrJyaFxk1hCQoKZP+1HasRUY+eW3bnjO9zSjlmT5zL+68lc0+hqBg9/mXtvepCmrRtTs04N2nZpDUC58mWJrh5FetopPps4FIDgCuXx8/OjVSdHy/itp9/j0P7DBcZ0zz230bhRPdq2u73kV7gU+Pj6UL/+NQwa9AbxcQl8+OFgBj3Xn7ff+hiA5194guxsOxMmTC31WMqWDWLihBE899wbnDyZRr9HB/Hxx2/xfy8PYObMBWRmZpV6DCVJBMKqBPB8+2sp5+/anQJX7j7Ipn3HuPfb3wDIyLZTKcjRDfHsT8tJPnaKbHsOqSdO0fObRQDc0+RKbqlXNd/lXhtZib3Jp/HzE6pUDuDU6dMX+aV5aXm/az9PHkXdujFs3LjF9QWUoMKcrWGMGQGMyGd8svPvARGZAjQF9otIuDEm1dltccA5eTIQnWf2KGdZkRSUnG3GmLP3dmzs/A8CsExEEi41U94V9i0TWaT/KinJ+4jO0xKKigwnJWVfURbF8eMnWP1HAs3bND0nOXe762ae7f0CABtWJVLGvwwVKoUgCB+/+hkrfo+7YFn3xz4COPqcw6PCGPXxmHPGlwsph4+PDbs9hyrhlTm471DuuHY33cjLLz3NTe1uJzMz0+X4S3JbFFZK8j6Sk/cRH5cAwJQpsxn0XH8Aeve+g86d29Hl5ntKPQ5fX18mThzB+AlTmDptDgBbtuygSxdHv2+tWtXp3LldqcdRksKqBHAyLZt2V7n+y9cY6HbtFTzdtu4F4z65ozng6HN+feZqRvW+8ZzxVcoHsu/EKS4PDiQ7J4e0jCwqBJY5Z5qsLIPJMZTxs5GRWfiT0o4fP8Fvv//hOIDtoeRcUuc5i0hZHDnwpPN1LPAWMB24Hxji/DvNOct04EkRmQA0A47n6f4otIL6nDeIyAPO12tFpLEz6NpAqTZT4uITqFmzOtWqRePn50fPnj2YMXO+y/OHhlbKPYMgICCAJq0a8b8de86ZZn/yfhq3dPy/qVrzCsr4l+Ho4WOs+D2OW+/rjo+v46h1dI0oAgIDXKp39Z9rclvcN9/ZkaXz/wCgdt2afPH5EG697QEOHiy4hZ1XcbdFcezff5CkpBRq1aoBQJu2Ldi8aRsdOrTmmWcfpeedD+f2pZemEV9/xObN2xk2bGRuWeXKlwEgIrz80gBGjPzn3I+4Sqg/mVk5HD9RuK9R02qVWbA5mSPpjq6H46czSTl+yqV5W9cKZ8Z6x3fg100pNKlaGREh+Vg62TmOROzrK/j52cjKdj0xn/9da9+uFVu27CjMapWoEuxzvhxHQ3QtsBKYZYyZiyMpdxCRbUB753uA2cBOYDswEijWUXLJr+Pe2a88DLgROAQ0xNHhvRd42hiztqAKitpyBujc6SaGDn0TH5uN78ZM5P0hw12e99pr6zB61Kf4+Niw2Wz8NfsvRn86lkeee4BNa7ewbMGfVKtVlZc/fI7AsoEYY/j8na9ZuSQeEeHRFx+iZfvrQYRjR47x4oOvkX4yPXf5l2o5R1wRzttfvEZwhWC2btzGG0+9R1ZmFsMnfMQVta8gdZ/jF9DevcncetsDuKo42+J8hb3Z/nXXXc3nXwyhjJ8fu3bv5bFHn2PJ0un4+5fhyJFjAKxcuYYBT7/i8jILc7P9G25owm+Lp7B+/SZynEnktdf/Q82a1en/mOOMmalT5/DKq++7vlJORb295PfjPqd1q+sJDa3E/v2HePOtj/j2uwkuzRvgbyMyIoiMTDsYuDa6Ek+1uZp9J04DcGfD6hxKO8M93y4mPSMbESGojA+/9GtPOX8/5iUmMerPrRhj8PWx8XLHelwXWSl3+ZdqOWdk23llejxb9h8nOKAM/7mlCVEVyzJz/R5G/7WVTcnHADhyLJNTp+wub4vzv2s//TSDd9791OX588rOTJYizZhH26gOLn+oi5MWFLu+0pJvcs6dyHFQsDqObpAkY8x+VysoTnIuSfoklL/pk1D+ZoV7/+qTUP5WEsm5TVR7lz/U35J+tWxydunybWPMCaDAVrJSSnmaFf7hlgS9t4ZSyqt4R2rW5KyU8jJ6s32llLIgTc5KKWVBduMdNw3V5KyU8ip6s32llLIgT950qSRpclZKeRXtc1ZKKQvSlrOLfC5yP1pPSDy+p+CJ/iUysv9Zd2/zdla4Mg8gfc1YT4dQIuxe8hRBbTkrpbyKXiGolFIWpGdrKKWUBWnLWSmlLEhbzkopZUHaclZKKQvSy7eVUsqCtFtDKaUsyHhJy9kaV4g4+fv7s2zpDOJWzmPN6l957bWB54z/eOibHD602S2xPPZ4X/5aOYflcXPo/3hfAN5+5yXiVs/nj+Wz+H78l4SElHdLLIDjacYblrA5cRkvPP+E2+rNa+SIoaQkrSVhzUKP1A+OfeSvP2ayKn4BaxMWMfj1QR6LxdOfSVRUBL/On8y6tYtZm7CIp558qFDz+/gIEWEBREcGER0ZyPczF11y2g3bdtPgjieZ/+fq4obN8ZPp9HtjOF2fGEy/N4ZzIs3xgNrFK9cSExOzLiYmJiEmJiY+JiamZVGWX4IPePUoSyXnjIwMOnbqRZOmHWnStBOxHdrQtGkDABo2vI4KFUPcEkedq2tzf99e3NT6Vlo070qnzjdRo0ZVFi9aRvMmnWnRvAs7tu1i4KD+bonHZrMxfNi7dO3Wm2vrtaVXr1uoU6eWW+rOa+zYSXTpeq/b680rIyOD9rE9adS4A40ax9Ixtg3NmjZ0exxW+Eyys7N5/oU3ua5eW1q07Eb//n0LHcOhI5nsTT5FUsppJs5Zwo69qRdMY7fn8Mm4qVxfv06hlh23YSuvfnbhVYejpsyj2XUxzPz8TZpdF8OoX+YB0OzaGIB6W7ZsqQ88CHxTqAqdjDEuD1ZmqeQMkJ7u+C/q5+eLn58vxhhsNhvvv/8K//d/77klhpiYK1kVl8Dp02ew2+0sW7aSbt07smjRMux2x1OJ4+ISiIgMc0s8TZs0YMeO3ezatYesrCwmTZpG924d3VJ3XkuXreDI0WNur/d8efcRXz8/j3zJrPCZ7Nt3gDUJGwBIS0tn8+ZtREa4vk/a7YbMTEcXgDFQPSqMA4ePXTDdj7N/o8P1Dah03i/Fb6cu4O7nh3D7s+/w+YSZLte7eOU6urdpDkD3Ns1ZtNLxeNKgwAC2bNly9sMsSxGfOPWvaDmLyNMiEu2uYMDRIlm5Yi5JexNYuHApcXEJPN6/L7NmLmDfvgNuiSExcSvX39CEipUqEBgYQGxsayKjws+ZpnefO1gw/3e3xBMRGcbepJTc90nJqUQU4kvobWw2G/Fx80lNXsfChUtYGbfG7TFY7TOpWjWK+vWuYcXKom0LX19h8669XFu72jnl+w8fY9GKBHp2vPGc8j8TEtmTeoAfP3iRyUP/j0079hC/cZtLdR05dpLKlRy/gkMrBnPk2MnccTExMbfGxMRsBmbhaD0Xmj0nx+XBygo6IPg28JKI7ADGA5ONMQcLWqiI9AP6Afj4VsDHp5zLAeXk5NC0WSdCQoKZNGkkLVs247bbu9ChQ0+Xl1FcW7fs4NNPvmbqtDGknzrF+vWbclvMAM89/zjZdjuTJk5zW0zqbzk5OTRuEktISDA/Tx5F3boxbNy4xdNheUzZskFMmjiSgc8N5uTJtELPLwJhVQJ44cE7KBcUeM64D0ZP5pk+t2I77wZmfyZs4q+ETfQc9D4Ap85ksCf1AI3r1uKeFz8gKyubU2cyOJ6Wzp0DHb94n+lzCy0aXH1e3QLy9/stW7ZMAabExMS0wpF/2hd2ff4tZ2vsBBrh2EC9gDdFZBWORP2LMebkxWYyxowARgD4B0QXaUsdP36C33//k9atr+fKGtVITFwKQFBQIIkbl3J13RsLWELxjBs7mXFjJwPw+uBBpKTsA+Cee2+nY6e2dO/ap1TrzysleR/RURG576Miw3Pj+Tc7fvwEv/3+h+PAnJuTs1U+E19fXyZPHMn48VOYOnVOkZYRViWAk2nZtG/e4IJxG3fs4cWPRwFw9GQ6S1dtwNfHBgYeuq0jd3a88Hv4439eABx9ztMWL+edp+47Z3ylCuU5eOQ4lSuFcPDI8Qu6SwC2bNmyJCYmpkZMTEzoli1bDhVmfazel+yqgvqcjTEmxxgz3xjzEBABfAF0wpG4S1RoaCVCQoIBCAgIoF27VqxZvZ6q1RoRE3MDMTE3cOrU6VJPzAChlS8DICoqnG49OjJ50nTatW/FgGcf4a5ej3L69JlSj+GsuPgEatasTrVq0fj5+dGzZw9mzJzvtvqt5Px9pH27VmzZssPtcVjlMxk5YiibNm/n02EjijR/lVB/MrNyOH7i4reRnfvV28z9+h3mfv0OHa5vwCv97uKmZvW5oUEdpiz6i1PO78H+w8c4fOyibbULtGlyHdN/Ww7A9N+W07bpdQDsST1ATEyMAMTExDQE/IHDhV0nb+lzLqjlLHnfGGOygOnAdBEJKulgwsKqMOqbT/Dx8cFms/HTzzOYPcczp22N++FzKlWqQFZWNs8NfIPjx0/y0dA3KONfhqnTxwAQH5fAswNeK/VY7HY7A555ldmzfsTHZuO7MRNJTNxa6vWe7/txn9O61fWEhlZi98543nzrI779boJbYwgPv5zRoz7Fx8fm2Ed+msGs2b+6NQawxmfS4oYm9Ol9B+vWJxIf5/jH8NprQ5gz99KnxOUV4G+jfHk/MjLtREUEcufA93j63u6kHjoCQM+OrS457w31r2Zn0j56v/wRAEEB/rz/TF8uo+DTSx+6LZbnPhrFlIV/El65Eh8NehiAX/9KANgQExOTBZwGeuU5QOgyb2k5S34rIiK1jTHF2uOK2q1R0gJ8y3g6BNIz3dfaVqqwrHCzff+67aTgqfJXsVxNl3PO0bTtxa6vtOTbci5uYlZKKXezeneFq/TybaWUV/GWbg1Nzkopr6K3DFVKKQv6t5znrJRS/yjaclZKKQvK0VuGKqWU9ZTkXelEpJOIbBGR7SLykhvCz6UtZ6WUVympszVExAf4HOgAJAFxIjLdGJNYIhUUQFvOSimvYgoxFKApsN0Ys9MYkwlMAHqUStAXUeot54wze4t9BY6I9HPeTMljrBCDVeKwQgxWicMKMVglDivEAJCdmexyzsl7B02nEXnWIRLYm2dcEtCs+BG65p/Scu5X8CSlzgoxgDXisEIMYI04rBADWCMOK8RQKMaYEcaYxnkGj/9zOeufkpyVUsrdkoG8DxuJcpa5hSZnpZS6uDiglohUF5EywF047srpFv+UszWs8FPDCjGANeKwQgxgjTisEANYIw4rxFBijDHZIvIkMA/wAUYbYza6q/58bxmqlFLKM7RbQymlLEiTs1JKWZClk7MnL53ME8NoETkgIhs8Ub8zhmgRWSwiiSKyUUQGeCiOABFZKSJrnXG86Yk4nLH4iMgaEZnpwRh2i8h6EUkQkXgPxVBBRH4Skc0isklErvdADDHObXB2OCEiz7g7Dm9j2T5n56WTW8lz6SRwt7suncwTRysgDRhrjLnGnXXniSEcCDfGrBaR8sAq4BYPbAsByhpj0kTED1gGDDDGLHdnHM5YBgKNgWBjTFd31++MYTfQ2BhTqKdDl3AMY4ClxphvnGcUBBljjnkwHh8cp5s1M8b8z1NxeAMrt5w9eunkWcaYJcARd9d7XgypxpjVztcngU04rl5ydxzGGJPmfOvnHNz+311EooAuwDfurttKRCQEaAWMAjDGZHoyMTu1A3ZoYi4+Kyfni1066faEZDUiUg1oAKzwUP0+IpIAHAAWGGM8EcenwAuAp+8NaYD5IrLKeRmwu1UHDgLfOrt4vhGRsh6II6+7gPEejsErWDk5q/OISDngZ+AZY8wJT8RgjLEbY+rjuFqqqYi4tatHRLoCB4wxq9xZ7yW0NMY0BDoDTzi7wNzJF2gIfGmMaQCkAx45NgPg7FbpDkz2VAzexMrJ2aOXTlqNs4/3Z+AHY8wvno7H+fN5MdDJzVW3ALo7+3snADeJyPdujgEAY0yy8+8BYAqOrjh3SgKS8vx6+QlHsvaUzsBqY8x+D8bgNaycnD166aSVOA/EjQI2GWM+9mAclUWkgvN1II6DtZvdGYMx5mVjTJQxphqOfWKRMaa3O2MAEJGyzoOzOLsSYgG3ntFjjNkH7BWRGGdRO8CtB4nPczfapVFiLHv5tqcvnTxLRMYDbYBQEUkCBhtjRrk5jBZAH2C9s78X4P+MMbPdHEc4MMZ5RN4GTDLGeOxUNg+7HJji+L+JL/CjMWauB+J4CvjB2YDZCTzggRjO/oPqADzqifq9kWVPpVNKqX8zK3drKKXUv5YmZ6WUsiBNzkopZUGanJVSyoI0OSullAVpclZKKQvS5KyUUhb0/0Xh6KGRC0DFAAAAAElFTkSuQmCC\n",
      "text/plain": [
       "<Figure size 432x288 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "exp.train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6280dba8",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "db8bc4bd",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "SDIL",
   "language": "python",
   "name": "sdil"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.13"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": true
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
