{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "894e2c21",
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "import sys\n",
    "sys.path.append(\"../../\")\n",
    "\n",
    "from experiment import Exp\n",
    "\n",
    "from dataloaders import data_set,data_dict\n",
    "import torch\n",
    "import yaml\n",
    "import os"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bcc56bc7",
   "metadata": {},
   "source": [
    "# 参数设置"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dcc5bcbc",
   "metadata": {
    "tags": []
   },
   "source": [
    "# 训练参数 \n",
    "除了路径 其他不要变"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "86004ce0",
   "metadata": {},
   "outputs": [],
   "source": [
    "class dotdict(dict):\n",
    "    \"\"\"dot.notation access to dictionary attributes\"\"\"\n",
    "    __getattr__ = dict.get\n",
    "    __setattr__ = dict.__setitem__\n",
    "    __delattr__ = dict.__delitem__\n",
    "\n",
    "args = dotdict()   \n",
    "# TODO change the path as relative path\n",
    "args.to_save_path     = \"../../../ISWC2022LearnableFilter/Run_logs\"              \n",
    "args.freq_save_path   = \"../../../ISWC2022LearnableFilter/Freq_data\"\n",
    "args.window_save_path = \"../../../ISWC2022LearnableFilter/Sliding_window\"\n",
    "args.root_path        = \"../../../datasets\"\n",
    "\n",
    "\n",
    "args.drop_transition  = False\n",
    "args.datanorm_type    = \"standardization\" # None ,\"standardization\", \"minmax\"\n",
    "\n",
    "\n",
    "args.batch_size       = 256                                                    \n",
    "args.shuffle          = True\n",
    "args.drop_last        = False\n",
    "args.train_vali_quote = 0.90                                           \n",
    "\n",
    "\n",
    "# training setting \n",
    "args.train_epochs            = 150\n",
    "\n",
    "args.learning_rate           = 0.001  \n",
    "args.learning_rate_patience  = 5\n",
    "args.learning_rate_factor    = 0.1\n",
    "\n",
    "\n",
    "args.early_stop_patience     = 15\n",
    "\n",
    "args.use_gpu                 = True if torch.cuda.is_available() else False\n",
    "args.gpu                     = 0\n",
    "args.use_multi_gpu           = False\n",
    "\n",
    "args.optimizer               = \"Adam\"\n",
    "args.criterion               = \"CrossEntropy\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c282cbcb",
   "metadata": {},
   "source": [
    "## 数据参数\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "c6cd147b",
   "metadata": {},
   "outputs": [],
   "source": [
    "args.data_name                        =  \"dg\"\n",
    "\n",
    "args.wavelet_filtering                = False\n",
    "args.wavelet_filtering_regularization = False\n",
    "args.wavelet_filtering_finetuning     = False\n",
    "\n",
    "\n",
    "args.difference       = False \n",
    "args.filtering        = False\n",
    "args.magnitude        = False\n",
    "args.weighted_sampler = False\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "args.pos_select       = None\n",
    "args.sensor_select    = None\n",
    "\n",
    "\n",
    "args.representation_type = \"time\"\n",
    "args.exp_mode            = \"LOCV\"\n",
    "if args.data_name      ==  \"skodar\":\n",
    "    args.exp_mode            = \"SOCV\"\n",
    "\n",
    "config_file = open('../../configs/data.yaml', mode='r')\n",
    "data_config = yaml.load(config_file, Loader=yaml.FullLoader)\n",
    "config = data_config[args.data_name]\n",
    "\n",
    "args.root_path       = os.path.join(args.root_path,config[\"filename\"])\n",
    "args.sampling_freq   = config[\"sampling_freq\"]\n",
    "args.num_classes     =  config[\"num_classes\"]\n",
    "window_seconds       = config[\"window_seconds\"]\n",
    "args.windowsize      =   int(window_seconds * args.sampling_freq) \n",
    "args.input_length    =  args.windowsize\n",
    "# input information\n",
    "args.c_in            = config[\"num_channels\"]\n",
    "\n",
    "if args.wavelet_filtering :\n",
    "    \n",
    "    if args.windowsize%2==1:\n",
    "        N_ds = int(torch.log2(torch.tensor(args.windowsize-1)).floor()) - 2\n",
    "    else:\n",
    "        N_ds = int(torch.log2(torch.tensor(args.windowsize)).floor()) - 2\n",
    "\n",
    "    args.f_in            =  args.number_wavelet_filtering*N_ds+1\n",
    "else:\n",
    "    args.f_in            =  1"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4d435a4c",
   "metadata": {},
   "source": [
    "## 模型参数"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "de2f4d16",
   "metadata": {},
   "outputs": [],
   "source": [
    "args.filter_scaling_factor = 0.25\n",
    "args.model_type            = \"deepconvlstm\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cada66dd",
   "metadata": {},
   "source": [
    "# 实验"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2e3f2fad",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Use GPU: cuda:0\n",
      "Build the DeepConvLSTM model!\n",
      "Done!\n",
      "Parameter : 26834\n",
      "Set the seed as :  1\n",
      " ----------------------- load all the data -------------------\n",
      "-----------------------Sliding file are generated -----------------------\n",
      "-----------------------Sliding file are generated -----------------------\n",
      "================ LOCV Mode ====================\n",
      "================ 10 CV ======================\n",
      "================ the 0 th CV Experiment ================ \n",
      "Leave one Out Experiment : The 1 Part as the test\n",
      "[-] Target sampling weights:  [3.88198758e-05 3.44234079e-04]\n",
      "Train data number :  28665\n",
      "The number of classes is :  2\n",
      "The input_length  is :  64\n",
      "The channel_in is :  9\n",
      "Validation data number :  3185\n",
      "Test data number :  20267\n",
      "================Skip the 0 CV Experiment================\n",
      "================ the 1 th CV Experiment ================ \n",
      "Leave one Out Experiment : The 2 Part as the test\n",
      "[-] Target sampling weights:  [3.73566439e-05 3.61141206e-04]\n",
      "Train data number :  29538\n",
      "The number of classes is :  2\n",
      "The input_length  is :  64\n",
      "The channel_in is :  9\n",
      "Validation data number :  3282\n",
      "Test data number :  15093\n",
      "================Skip the 1 CV Experiment================\n",
      "================ the 2 th CV Experiment ================ \n",
      "Leave one Out Experiment : The 3 Part as the test\n",
      "[-] Target sampling weights:  [3.86100386e-05 3.89559797e-04]\n",
      "Train data number :  28467\n",
      "The number of classes is :  2\n",
      "The input_length  is :  64\n",
      "The channel_in is :  9\n",
      "Validation data number :  3163\n",
      "Test data number :  21440\n",
      "================Skip the 2 CV Experiment================\n",
      "================ the 3 th CV Experiment ================ \n",
      "Leave one Out Experiment : The 4 Part as the test\n",
      "[-] Target sampling weights:  [3.95600918e-05 3.24569945e-04]\n",
      "Train data number :  28359\n",
      "The number of classes is :  2\n",
      "The input_length  is :  64\n",
      "The channel_in is :  9\n",
      "Validation data number :  3151\n",
      "Test data number :  22080\n",
      "================Skip the 3 CV Experiment================\n",
      "================ the 4 th CV Experiment ================ \n",
      "Leave one Out Experiment : The 5 Part as the test\n",
      "[-] Target sampling weights:  [3.83420881e-05 4.46030330e-04]\n",
      "Train data number :  28323\n",
      "The number of classes is :  2\n",
      "The input_length  is :  64\n",
      "The channel_in is :  9\n",
      "Validation data number :  3147\n",
      "Test data number :  22294\n",
      "================Skip the 4 CV Experiment================\n",
      "================ the 5 th CV Experiment ================ \n",
      "Leave one Out Experiment : The 6 Part as the test\n",
      "[-] Target sampling weights:  [3.89741991e-05 3.51493849e-04]\n",
      "Train data number :  28503\n",
      "The number of classes is :  2\n",
      "The input_length  is :  64\n",
      "The channel_in is :  9\n",
      "Validation data number :  3167\n",
      "Test data number :  21227\n",
      "================Skip the 5 CV Experiment================\n",
      "================ the 6 th CV Experiment ================ \n",
      "Leave one Out Experiment : The 7 Part as the test\n",
      "[-] Target sampling weights:  [3.81271923e-05 3.37952011e-04]\n",
      "Train data number :  29187\n",
      "The number of classes is :  2\n",
      "The input_length  is :  64\n",
      "The channel_in is :  9\n",
      "Validation data number :  3243\n",
      "Test data number :  17173\n",
      "================Skip the 6 CV Experiment================\n",
      "================ the 7 th CV Experiment ================ \n",
      "Leave one Out Experiment : The 8 Part as the test\n",
      "[-] Target sampling weights:  [3.57347055e-05 3.68324125e-04]\n",
      "Train data number :  30699\n",
      "The number of classes is :  2\n",
      "The input_length  is :  64\n",
      "The channel_in is :  9\n",
      "Validation data number :  3411\n",
      "Test data number :  8214\n",
      "================Skip the 7 CV Experiment================\n",
      "================ the 8 th CV Experiment ================ \n",
      "Leave one Out Experiment : The 9 Part as the test\n",
      "[-] Target sampling weights:  [3.79650721e-05 3.82701875e-04]\n",
      "Train data number :  28953\n",
      "The number of classes is :  2\n",
      "The input_length  is :  64\n",
      "The channel_in is :  9\n",
      "Validation data number :  3217\n",
      "Test data number :  18560\n",
      "================ Build the model ================ \n",
      "Build the DeepConvLSTM model!\n",
      "Epoch: 1 cost time: 9.744635343551636\n",
      "VALI: Epoch: 1, Steps: 114 | Train Loss: 0.3338825  Vali Loss: 0.2755671 Vali Accuracy: 0.9073671  Vali weighted F1: 0.8633001  Vali macro F1 0.4757171 \n",
      "Validation loss decreased (inf --> 0.275567).  Saving model ...\n",
      "Epoch: 2 cost time: 8.062802076339722\n",
      "VALI: Epoch: 2, Steps: 114 | Train Loss: 0.2262816  Vali Loss: 0.2099276 Vali Accuracy: 0.9173143  Vali weighted F1: 0.8965734  Vali macro F1 0.6352185 \n",
      "new best score!!!!\n",
      "Validation loss decreased (0.275567 --> 0.209928).  Saving model ...\n",
      "new best score!!!!\n",
      "Epoch: 3 cost time: 7.931024074554443\n",
      "VALI: Epoch: 3, Steps: 114 | Train Loss: 0.1891605  Vali Loss: 0.1676806 Vali Accuracy: 0.9253963  Vali weighted F1: 0.9194885  Vali macro F1 0.7435298 \n",
      "new best score!!!!\n",
      "Validation loss decreased (0.209928 --> 0.167681).  Saving model ...\n",
      "new best score!!!!\n",
      "Epoch: 4 cost time: 7.992308616638184\n",
      "VALI: Epoch: 4, Steps: 114 | Train Loss: 0.1778583  Vali Loss: 0.1621961 Vali Accuracy: 0.9260180  Vali weighted F1: 0.9177992  Vali macro F1 0.7320968 \n",
      "new best score!!!!\n",
      "Validation loss decreased (0.167681 --> 0.162196).  Saving model ...\n",
      "new best score!!!!\n",
      "Epoch: 5 cost time: 7.95263934135437\n",
      "VALI: Epoch: 5, Steps: 114 | Train Loss: 0.1733345  Vali Loss: 0.1533007 Vali Accuracy: 0.9278831  Vali weighted F1: 0.9203886  Vali macro F1 0.7418145 \n",
      "new best score!!!!\n",
      "Validation loss decreased (0.162196 --> 0.153301).  Saving model ...\n",
      "new best score!!!!\n",
      "Epoch: 6 cost time: 7.944479703903198\n",
      "VALI: Epoch: 6, Steps: 114 | Train Loss: 0.1680254  Vali Loss: 0.1629804 Vali Accuracy: 0.9263289  Vali weighted F1: 0.9151739  Vali macro F1 0.7162807 \n",
      "EarlyStopping counter: 1 out of 15\n",
      "Learning rate adjusting counter: 1 out of 5\n",
      "Epoch: 7 cost time: 7.984461545944214\n",
      "VALI: Epoch: 7, Steps: 114 | Train Loss: 0.1634119  Vali Loss: 0.1488968 Vali Accuracy: 0.9325459  Vali weighted F1: 0.9268389  Vali macro F1 0.7660005 \n",
      "new best score!!!!\n",
      "Validation loss decreased (0.153301 --> 0.148897).  Saving model ...\n",
      "new best score!!!!\n",
      "Epoch: 8 cost time: 8.040149688720703\n",
      "VALI: Epoch: 8, Steps: 114 | Train Loss: 0.1593352  Vali Loss: 0.1466507 Vali Accuracy: 0.9347218  Vali weighted F1: 0.9311492  Vali macro F1 0.7848410 \n",
      "new best score!!!!\n",
      "Validation loss decreased (0.148897 --> 0.146651).  Saving model ...\n",
      "new best score!!!!\n",
      "Epoch: 9 cost time: 8.269539833068848\n",
      "VALI: Epoch: 9, Steps: 114 | Train Loss: 0.1546434  Vali Loss: 0.1453093 Vali Accuracy: 0.9356543  Vali weighted F1: 0.9365432  Vali macro F1 0.8139208 \n",
      "new best score!!!!\n",
      "Validation loss decreased (0.146651 --> 0.145309).  Saving model ...\n",
      "new best score!!!!\n",
      "Epoch: 10 cost time: 8.067872285842896\n",
      "VALI: Epoch: 10, Steps: 114 | Train Loss: 0.1543912  Vali Loss: 0.1406491 Vali Accuracy: 0.9362760  Vali weighted F1: 0.9344781  Vali macro F1 0.7998378 \n",
      "new best score!!!!\n",
      "Validation loss decreased (0.145309 --> 0.140649).  Saving model ...\n",
      "new best score!!!!\n",
      "Epoch: 11 cost time: 8.195529222488403\n",
      "VALI: Epoch: 11, Steps: 114 | Train Loss: 0.1503133  Vali Loss: 0.1441882 Vali Accuracy: 0.9387628  Vali weighted F1: 0.9391710  Vali macro F1 0.8202918 \n",
      "EarlyStopping counter: 1 out of 15\n",
      "Learning rate adjusting counter: 1 out of 5\n",
      "Epoch: 12 cost time: 8.280598163604736\n",
      "VALI: Epoch: 12, Steps: 114 | Train Loss: 0.1531017  Vali Loss: 0.1426061 Vali Accuracy: 0.9353435  Vali weighted F1: 0.9330084  Vali macro F1 0.7939131 \n",
      "EarlyStopping counter: 2 out of 15\n",
      "Learning rate adjusting counter: 2 out of 5\n",
      "Epoch: 13 cost time: 8.261020421981812\n",
      "VALI: Epoch: 13, Steps: 114 | Train Loss: 0.1496322  Vali Loss: 0.1424550 Vali Accuracy: 0.9378303  Vali weighted F1: 0.9364463  Vali macro F1 0.8068963 \n",
      "EarlyStopping counter: 3 out of 15\n",
      "Learning rate adjusting counter: 3 out of 5\n",
      "Epoch: 14 cost time: 8.176414489746094\n",
      "VALI: Epoch: 14, Steps: 114 | Train Loss: 0.1459214  Vali Loss: 0.1375587 Vali Accuracy: 0.9415605  Vali weighted F1: 0.9410200  Vali macro F1 0.8229727 \n",
      "new best score!!!!\n",
      "Validation loss decreased (0.140649 --> 0.137559).  Saving model ...\n",
      "new best score!!!!\n",
      "Epoch: 15 cost time: 8.261475801467896\n",
      "VALI: Epoch: 15, Steps: 114 | Train Loss: 0.1457960  Vali Loss: 0.1336627 Vali Accuracy: 0.9446689  Vali weighted F1: 0.9441572  Vali macro F1 0.8323891 \n",
      "new best score!!!!\n",
      "Validation loss decreased (0.137559 --> 0.133663).  Saving model ...\n",
      "new best score!!!!\n",
      "Epoch: 16 cost time: 8.218624830245972\n",
      "VALI: Epoch: 16, Steps: 114 | Train Loss: 0.1446982  Vali Loss: 0.1449042 Vali Accuracy: 0.9359652  Vali weighted F1: 0.9286956  Vali macro F1 0.7672253 \n",
      "EarlyStopping counter: 1 out of 15\n",
      "Learning rate adjusting counter: 1 out of 5\n",
      "Epoch: 17 cost time: 8.214157342910767\n",
      "VALI: Epoch: 17, Steps: 114 | Train Loss: 0.1430201  Vali Loss: 0.1354637 Vali Accuracy: 0.9406279  Vali weighted F1: 0.9376633  Vali macro F1 0.8059655 \n",
      "EarlyStopping counter: 2 out of 15\n",
      "Learning rate adjusting counter: 2 out of 5\n",
      "Epoch: 18 cost time: 7.991046905517578\n",
      "VALI: Epoch: 18, Steps: 114 | Train Loss: 0.1418145  Vali Loss: 0.1324655 Vali Accuracy: 0.9428039  Vali weighted F1: 0.9422749  Vali macro F1 0.8267393 \n",
      "new best score!!!!\n",
      "Validation loss decreased (0.133663 --> 0.132465).  Saving model ...\n",
      "new best score!!!!\n",
      "Epoch: 19 cost time: 8.131321430206299\n",
      "VALI: Epoch: 19, Steps: 114 | Train Loss: 0.1394764  Vali Loss: 0.1371638 Vali Accuracy: 0.9396954  Vali weighted F1: 0.9409030  Vali macro F1 0.8278559 \n",
      "EarlyStopping counter: 1 out of 15\n",
      "Learning rate adjusting counter: 1 out of 5\n",
      "Epoch: 20 cost time: 7.976255178451538\n",
      "VALI: Epoch: 20, Steps: 114 | Train Loss: 0.1382317  Vali Loss: 0.1366068 Vali Accuracy: 0.9390737  Vali weighted F1: 0.9398725  Vali macro F1 0.8235524 \n",
      "EarlyStopping counter: 2 out of 15\n",
      "Learning rate adjusting counter: 2 out of 5\n",
      "Epoch: 21 cost time: 7.9288928508758545\n",
      "VALI: Epoch: 21, Steps: 114 | Train Loss: 0.1369975  Vali Loss: 0.1300898 Vali Accuracy: 0.9412496  Vali weighted F1: 0.9410262  Vali macro F1 0.8239283 \n",
      "new best score!!!!\n",
      "Validation loss decreased (0.132465 --> 0.130090).  Saving model ...\n",
      "new best score!!!!\n",
      "Epoch: 22 cost time: 7.9222517013549805\n",
      "VALI: Epoch: 22, Steps: 114 | Train Loss: 0.1368736  Vali Loss: 0.1311678 Vali Accuracy: 0.9400062  Vali weighted F1: 0.9390182  Vali macro F1 0.8157035 \n",
      "EarlyStopping counter: 1 out of 15\n",
      "Learning rate adjusting counter: 1 out of 5\n",
      "Epoch: 23 cost time: 7.950673818588257\n",
      "VALI: Epoch: 23, Steps: 114 | Train Loss: 0.1348718  Vali Loss: 0.1290503 Vali Accuracy: 0.9446689  Vali weighted F1: 0.9414245  Vali macro F1 0.8163700 \n",
      "new best score!!!!\n",
      "Validation loss decreased (0.130090 --> 0.129050).  Saving model ...\n",
      "new best score!!!!\n",
      "Epoch: 24 cost time: 7.928677797317505\n",
      "VALI: Epoch: 24, Steps: 114 | Train Loss: 0.1379275  Vali Loss: 0.1344436 Vali Accuracy: 0.9393845  Vali weighted F1: 0.9389665  Vali macro F1 0.8172260 \n",
      "EarlyStopping counter: 1 out of 15\n",
      "Learning rate adjusting counter: 1 out of 5\n",
      "Epoch: 25 cost time: 7.92672061920166\n",
      "VALI: Epoch: 25, Steps: 114 | Train Loss: 0.1352690  Vali Loss: 0.1397577 Vali Accuracy: 0.9378303  Vali weighted F1: 0.9334311  Vali macro F1 0.7893039 \n",
      "EarlyStopping counter: 2 out of 15\n",
      "Learning rate adjusting counter: 2 out of 5\n",
      "Epoch: 26 cost time: 7.97524619102478\n",
      "VALI: Epoch: 26, Steps: 114 | Train Loss: 0.1335002  Vali Loss: 0.1332757 Vali Accuracy: 0.9403171  Vali weighted F1: 0.9408446  Vali macro F1 0.8256274 \n",
      "EarlyStopping counter: 3 out of 15\n",
      "Learning rate adjusting counter: 3 out of 5\n",
      "Epoch: 27 cost time: 7.9285290241241455\n",
      "VALI: Epoch: 27, Steps: 114 | Train Loss: 0.1302284  Vali Loss: 0.1331830 Vali Accuracy: 0.9365869  Vali weighted F1: 0.9391576  Vali macro F1 0.8268590 \n",
      "EarlyStopping counter: 4 out of 15\n",
      "Learning rate adjusting counter: 4 out of 5\n",
      "Epoch: 28 cost time: 7.913774490356445\n",
      "VALI: Epoch: 28, Steps: 114 | Train Loss: 0.1285904  Vali Loss: 0.1244322 Vali Accuracy: 0.9437364  Vali weighted F1: 0.9434358  Vali macro F1 0.8308664 \n",
      "new best score!!!!\n",
      "Validation loss decreased (0.129050 --> 0.124432).  Saving model ...\n",
      "new best score!!!!\n",
      "Epoch: 29 cost time: 7.923097372055054\n",
      "VALI: Epoch: 29, Steps: 114 | Train Loss: 0.1290216  Vali Loss: 0.1267051 Vali Accuracy: 0.9387628  Vali weighted F1: 0.9400307  Vali macro F1 0.8254436 \n",
      "EarlyStopping counter: 1 out of 15\n",
      "Learning rate adjusting counter: 1 out of 5\n",
      "Epoch: 30 cost time: 7.923364877700806\n",
      "VALI: Epoch: 30, Steps: 114 | Train Loss: 0.1293469  Vali Loss: 0.1234473 Vali Accuracy: 0.9456015  Vali weighted F1: 0.9440667  Vali macro F1 0.8291298 \n",
      "new best score!!!!\n",
      "Validation loss decreased (0.124432 --> 0.123447).  Saving model ...\n",
      "new best score!!!!\n",
      "Epoch: 31 cost time: 7.948365211486816\n",
      "VALI: Epoch: 31, Steps: 114 | Train Loss: 0.1283421  Vali Loss: 0.1264321 Vali Accuracy: 0.9400062  Vali weighted F1: 0.9406654  Vali macro F1 0.8254900 \n",
      "EarlyStopping counter: 1 out of 15\n",
      "Learning rate adjusting counter: 1 out of 5\n",
      "Epoch: 32 cost time: 8.067167282104492\n",
      "VALI: Epoch: 32, Steps: 114 | Train Loss: 0.1269115  Vali Loss: 0.1314211 Vali Accuracy: 0.9387628  Vali weighted F1: 0.9389004  Vali macro F1 0.8186784 \n",
      "EarlyStopping counter: 2 out of 15\n",
      "Learning rate adjusting counter: 2 out of 5\n",
      "Epoch: 33 cost time: 8.10029911994934\n",
      "VALI: Epoch: 33, Steps: 114 | Train Loss: 0.1254281  Vali Loss: 0.1415386 Vali Accuracy: 0.9341001  Vali weighted F1: 0.9374671  Vali macro F1 0.8243272 \n",
      "EarlyStopping counter: 3 out of 15\n",
      "Learning rate adjusting counter: 3 out of 5\n",
      "Epoch: 34 cost time: 8.194024324417114\n",
      "VALI: Epoch: 34, Steps: 114 | Train Loss: 0.1252064  Vali Loss: 0.1263872 Vali Accuracy: 0.9415605  Vali weighted F1: 0.9406456  Vali macro F1 0.8207591 \n",
      "EarlyStopping counter: 4 out of 15\n",
      "Learning rate adjusting counter: 4 out of 5\n",
      "Epoch: 35 cost time: 7.975449085235596\n",
      "VALI: Epoch: 35, Steps: 114 | Train Loss: 0.1251751  Vali Loss: 0.1303165 Vali Accuracy: 0.9384520  Vali weighted F1: 0.9407213  Vali macro F1 0.8305761 \n",
      "EarlyStopping counter: 5 out of 15\n",
      "Learning rate adjusting counter: 5 out of 5\n",
      "Updating learning rate to 0.0001\n",
      "Epoch: 36 cost time: 8.007002830505371\n",
      "VALI: Epoch: 36, Steps: 114 | Train Loss: 0.1180141  Vali Loss: 0.1238106 Vali Accuracy: 0.9431147  Vali weighted F1: 0.9434107  Vali macro F1 0.8325667 \n",
      "EarlyStopping counter: 6 out of 15\n",
      "Learning rate adjusting counter: 1 out of 5\n",
      "Epoch: 37 cost time: 8.047062397003174\n",
      "VALI: Epoch: 37, Steps: 114 | Train Loss: 0.1177810  Vali Loss: 0.1260496 Vali Accuracy: 0.9421822  Vali weighted F1: 0.9433400  Vali macro F1 0.8349547 \n",
      "EarlyStopping counter: 7 out of 15\n",
      "Learning rate adjusting counter: 2 out of 5\n",
      "Epoch: 38 cost time: 8.027739763259888\n",
      "VALI: Epoch: 38, Steps: 114 | Train Loss: 0.1172429  Vali Loss: 0.1236438 Vali Accuracy: 0.9412496  Vali weighted F1: 0.9418111  Vali macro F1 0.8286044 \n",
      "EarlyStopping counter: 8 out of 15\n",
      "Learning rate adjusting counter: 3 out of 5\n",
      "Epoch: 39 cost time: 8.146432638168335\n",
      "VALI: Epoch: 39, Steps: 114 | Train Loss: 0.1178438  Vali Loss: 0.1228751 Vali Accuracy: 0.9424930  Vali weighted F1: 0.9428763  Vali macro F1 0.8312385 \n",
      "new best score!!!!\n",
      "Validation loss decreased (0.123447 --> 0.122875).  Saving model ...\n",
      "new best score!!!!\n",
      "Epoch: 40 cost time: 8.036830425262451\n",
      "VALI: Epoch: 40, Steps: 114 | Train Loss: 0.1148824  Vali Loss: 0.1251437 Vali Accuracy: 0.9418713  Vali weighted F1: 0.9431531  Vali macro F1 0.8347759 \n",
      "EarlyStopping counter: 1 out of 15\n",
      "Learning rate adjusting counter: 1 out of 5\n",
      "Epoch: 41 cost time: 7.973858118057251\n",
      "VALI: Epoch: 41, Steps: 114 | Train Loss: 0.1159734  Vali Loss: 0.1238999 Vali Accuracy: 0.9424930  Vali weighted F1: 0.9432064  Vali macro F1 0.8332120 \n",
      "EarlyStopping counter: 2 out of 15\n",
      "Learning rate adjusting counter: 2 out of 5\n",
      "Epoch: 42 cost time: 8.04233717918396\n",
      "VALI: Epoch: 42, Steps: 114 | Train Loss: 0.1161735  Vali Loss: 0.1215279 Vali Accuracy: 0.9437364  Vali weighted F1: 0.9437787  Vali macro F1 0.8329042 \n",
      "new best score!!!!\n",
      "Validation loss decreased (0.122875 --> 0.121528).  Saving model ...\n",
      "new best score!!!!\n",
      "Epoch: 43 cost time: 8.14958643913269\n",
      "VALI: Epoch: 43, Steps: 114 | Train Loss: 0.1164439  Vali Loss: 0.1230184 Vali Accuracy: 0.9424930  Vali weighted F1: 0.9431248  Vali macro F1 0.8327236 \n",
      "EarlyStopping counter: 1 out of 15\n",
      "Learning rate adjusting counter: 1 out of 5\n",
      "Epoch: 44 cost time: 7.946147680282593\n",
      "VALI: Epoch: 44, Steps: 114 | Train Loss: 0.1155269  Vali Loss: 0.1253367 Vali Accuracy: 0.9409388  Vali weighted F1: 0.9421215  Vali macro F1 0.8314053 \n",
      "EarlyStopping counter: 2 out of 15\n",
      "Learning rate adjusting counter: 2 out of 5\n",
      "Epoch: 45 cost time: 7.979730844497681\n",
      "VALI: Epoch: 45, Steps: 114 | Train Loss: 0.1155389  Vali Loss: 0.1245464 Vali Accuracy: 0.9421822  Vali weighted F1: 0.9431019  Vali macro F1 0.8335242 \n",
      "EarlyStopping counter: 3 out of 15\n",
      "Learning rate adjusting counter: 3 out of 5\n",
      "Epoch: 46 cost time: 7.996508598327637\n",
      "VALI: Epoch: 46, Steps: 114 | Train Loss: 0.1156308  Vali Loss: 0.1276455 Vali Accuracy: 0.9406279  Vali weighted F1: 0.9423287  Vali macro F1 0.8336045 \n",
      "EarlyStopping counter: 4 out of 15\n",
      "Learning rate adjusting counter: 4 out of 5\n",
      "Epoch: 47 cost time: 7.987239837646484\n",
      "VALI: Epoch: 47, Steps: 114 | Train Loss: 0.1145534  Vali Loss: 0.1235155 Vali Accuracy: 0.9418713  Vali weighted F1: 0.9425100  Vali macro F1 0.8309152 \n",
      "EarlyStopping counter: 5 out of 15\n",
      "Learning rate adjusting counter: 5 out of 5\n",
      "Updating learning rate to 1e-05\n",
      "Epoch: 48 cost time: 7.960901498794556\n",
      "VALI: Epoch: 48, Steps: 114 | Train Loss: 0.1144752  Vali Loss: 0.1230604 Vali Accuracy: 0.9418713  Vali weighted F1: 0.9425100  Vali macro F1 0.8309152 \n",
      "EarlyStopping counter: 6 out of 15\n",
      "Learning rate adjusting counter: 1 out of 5\n",
      "Epoch: 49 cost time: 8.003503322601318\n",
      "VALI: Epoch: 49, Steps: 114 | Train Loss: 0.1149935  Vali Loss: 0.1233321 Vali Accuracy: 0.9418713  Vali weighted F1: 0.9425925  Vali macro F1 0.8314089 \n",
      "EarlyStopping counter: 7 out of 15\n",
      "Learning rate adjusting counter: 2 out of 5\n",
      "Epoch: 50 cost time: 7.951929092407227\n",
      "VALI: Epoch: 50, Steps: 114 | Train Loss: 0.1137887  Vali Loss: 0.1233164 Vali Accuracy: 0.9421822  Vali weighted F1: 0.9428585  Vali macro F1 0.8320653 \n",
      "EarlyStopping counter: 8 out of 15\n",
      "Learning rate adjusting counter: 3 out of 5\n",
      "Epoch: 51 cost time: 7.9615912437438965\n",
      "VALI: Epoch: 51, Steps: 114 | Train Loss: 0.1132240  Vali Loss: 0.1231801 Vali Accuracy: 0.9418713  Vali weighted F1: 0.9425925  Vali macro F1 0.8314089 \n",
      "EarlyStopping counter: 9 out of 15\n",
      "Learning rate adjusting counter: 4 out of 5\n",
      "Epoch: 52 cost time: 7.98259162902832\n",
      "VALI: Epoch: 52, Steps: 114 | Train Loss: 0.1140438  Vali Loss: 0.1231073 Vali Accuracy: 0.9421822  Vali weighted F1: 0.9428585  Vali macro F1 0.8320653 \n",
      "EarlyStopping counter: 10 out of 15\n",
      "Learning rate adjusting counter: 5 out of 5\n",
      "Updating learning rate to 1.0000000000000002e-06\n",
      "Epoch: 53 cost time: 7.939811706542969\n",
      "VALI: Epoch: 53, Steps: 114 | Train Loss: 0.1135955  Vali Loss: 0.1230612 Vali Accuracy: 0.9421822  Vali weighted F1: 0.9428585  Vali macro F1 0.8320653 \n",
      "EarlyStopping counter: 11 out of 15\n",
      "Learning rate adjusting counter: 1 out of 5\n",
      "Epoch: 54 cost time: 7.941126346588135\n",
      "VALI: Epoch: 54, Steps: 114 | Train Loss: 0.1129825  Vali Loss: 0.1230351 Vali Accuracy: 0.9421822  Vali weighted F1: 0.9428585  Vali macro F1 0.8320653 \n",
      "EarlyStopping counter: 12 out of 15\n",
      "Learning rate adjusting counter: 2 out of 5\n",
      "Epoch: 55 cost time: 7.962263345718384\n",
      "VALI: Epoch: 55, Steps: 114 | Train Loss: 0.1136142  Vali Loss: 0.1229526 Vali Accuracy: 0.9421822  Vali weighted F1: 0.9428585  Vali macro F1 0.8320653 \n",
      "EarlyStopping counter: 13 out of 15\n",
      "Learning rate adjusting counter: 3 out of 5\n",
      "Epoch: 56 cost time: 7.9766175746917725\n",
      "VALI: Epoch: 56, Steps: 114 | Train Loss: 0.1146437  Vali Loss: 0.1229407 Vali Accuracy: 0.9421822  Vali weighted F1: 0.9428585  Vali macro F1 0.8320653 \n",
      "EarlyStopping counter: 14 out of 15\n",
      "Learning rate adjusting counter: 4 out of 5\n",
      "Epoch: 57 cost time: 7.946353912353516\n",
      "VALI: Epoch: 57, Steps: 114 | Train Loss: 0.1145421  Vali Loss: 0.1228965 Vali Accuracy: 0.9421822  Vali weighted F1: 0.9428585  Vali macro F1 0.8320653 \n",
      "EarlyStopping counter: 15 out of 15\n",
      "Early stopping\n",
      "Loading the best validation model!\n",
      "Final Test Performance : Test Accuracy: 0.8592134  Test weighted F1: 0.8066557  Test macro F1 0.5471689 \n",
      "================ the 9 th CV Experiment ================ \n",
      "Leave one Out Experiment : The 10 Part as the test\n",
      "[-] Target sampling weights:  [4.00432467e-05 3.22788896e-04]\n",
      "Train data number :  28071\n",
      "The number of classes is :  2\n",
      "The input_length  is :  64\n",
      "The channel_in is :  9\n",
      "Validation data number :  3119\n",
      "Test data number :  23786\n",
      "================ Build the model ================ \n",
      "Build the DeepConvLSTM model!\n",
      "Epoch: 1 cost time: 7.758031845092773\n",
      "VALI: Epoch: 1, Steps: 110 | Train Loss: 0.3731636  Vali Loss: 0.3049811 Vali Accuracy: 0.8871433  Vali weighted F1: 0.8340896  Vali macro F1 0.4700985 \n",
      "Validation loss decreased (inf --> 0.304981).  Saving model ...\n",
      "Epoch: 2 cost time: 7.770761251449585\n",
      "VALI: Epoch: 2, Steps: 110 | Train Loss: 0.2590098  Vali Loss: 0.2286703 Vali Accuracy: 0.8986855  Vali weighted F1: 0.8798183  Vali macro F1 0.6564643 \n",
      "new best score!!!!\n",
      "Validation loss decreased (0.304981 --> 0.228670).  Saving model ...\n",
      "new best score!!!!\n",
      "Epoch: 3 cost time: 7.802082777023315\n",
      "VALI: Epoch: 3, Steps: 110 | Train Loss: 0.2236973  Vali Loss: 0.2164272 Vali Accuracy: 0.9009298  Vali weighted F1: 0.8936946  Vali macro F1 0.7172004 \n",
      "new best score!!!!\n",
      "Validation loss decreased (0.228670 --> 0.216427).  Saving model ...\n",
      "new best score!!!!\n"
     ]
    }
   ],
   "source": [
    "for seed in [1,2,3,4,5]:\n",
    "    args.seed = seed\n",
    "    exp = Exp(args)\n",
    "    exp.train()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "SDIL",
   "language": "python",
   "name": "sdil"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.13"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": true
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
