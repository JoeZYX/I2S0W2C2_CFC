{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "894e2c21",
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "import sys\n",
    "sys.path.append(\"../../\")\n",
    "\n",
    "from experiment import Exp\n",
    "\n",
    "from dataloaders import data_set,data_dict\n",
    "import torch\n",
    "import yaml\n",
    "import os"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bcc56bc7",
   "metadata": {},
   "source": [
    "# 参数设置"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dcc5bcbc",
   "metadata": {
    "tags": []
   },
   "source": [
    "# 训练参数 \n",
    "除了路径 其他不要变"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "86004ce0",
   "metadata": {},
   "outputs": [],
   "source": [
    "class dotdict(dict):\n",
    "    \"\"\"dot.notation access to dictionary attributes\"\"\"\n",
    "    __getattr__ = dict.get\n",
    "    __setattr__ = dict.__setitem__\n",
    "    __delattr__ = dict.__delitem__\n",
    "\n",
    "args = dotdict()   \n",
    "# TODO change the path as relative path\n",
    "args.to_save_path     = \"../../../Run_logs\"              \n",
    "args.freq_save_path   = \"../../../Freq_data\"\n",
    "args.window_save_path = \"../../../Sliding_window\"\n",
    "args.root_path        = \"../../../datasets\"\n",
    "\n",
    "\n",
    "args.drop_transition  = False\n",
    "args.datanorm_type    = \"standardization\" # None ,\"standardization\", \"minmax\"\n",
    "\n",
    "\n",
    "args.batch_size       = 256                                                    \n",
    "args.shuffle          = True\n",
    "args.drop_last        = False\n",
    "args.train_vali_quote = 0.90                                           \n",
    "\n",
    "\n",
    "# training setting \n",
    "args.train_epochs            = 150\n",
    "\n",
    "args.learning_rate           = 0.001  \n",
    "args.learning_rate_patience  = 5\n",
    "args.learning_rate_factor    = 0.1\n",
    "\n",
    "\n",
    "args.early_stop_patience     = 15\n",
    "\n",
    "args.use_gpu                 = True if torch.cuda.is_available() else False\n",
    "args.gpu                     = 3\n",
    "args.use_multi_gpu           = False\n",
    "\n",
    "args.optimizer               = \"Adam\"\n",
    "args.criterion               = \"CrossEntropy\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c282cbcb",
   "metadata": {},
   "source": [
    "## 数据参数\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "c6cd147b",
   "metadata": {},
   "outputs": [],
   "source": [
    "args.data_name                        =  \"uschad\"\n",
    "\n",
    "args.wavelet_filtering                = True\n",
    "args.wavelet_filtering_regularization = True\n",
    "args.wavelet_filtering_finetuning     = True\n",
    "args.wavelet_filtering_finetuning_percent = 1\n",
    "args.wavelet_filtering_learnable      = False\n",
    "args.wavelet_filtering_layernorm      = False\n",
    "\n",
    "args.regulatization_tradeoff          = 0\n",
    "args.number_wavelet_filtering         = 10\n",
    "\n",
    "args.difference       = False \n",
    "args.filtering        = False\n",
    "args.magnitude        = False\n",
    "args.weighted_sampler = False\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "args.pos_select       = None\n",
    "args.sensor_select    = None\n",
    "\n",
    "\n",
    "args.representation_type = \"time\"\n",
    "args.exp_mode            = \"LOCV\"\n",
    "if args.data_name      ==  \"skodar\":\n",
    "    args.exp_mode            = \"SOCV\"\n",
    "\n",
    "config_file = open('../../configs/data.yaml', mode='r')\n",
    "data_config = yaml.load(config_file, Loader=yaml.FullLoader)\n",
    "config = data_config[args.data_name]\n",
    "\n",
    "args.root_path       = os.path.join(args.root_path,config[\"filename\"])\n",
    "args.sampling_freq   = config[\"sampling_freq\"]\n",
    "args.num_classes     =  config[\"num_classes\"]\n",
    "window_seconds       = config[\"window_seconds\"]\n",
    "args.windowsize      =   int(window_seconds * args.sampling_freq) \n",
    "args.input_length    =  args.windowsize\n",
    "# input information\n",
    "args.c_in            = config[\"num_channels\"]\n",
    "\n",
    "if args.difference:\n",
    "    args.c_in = args.c_in*2\n",
    "\n",
    "if args.wavelet_filtering :\n",
    "    \n",
    "    if args.windowsize%2==1:\n",
    "        N_ds = int(torch.log2(torch.tensor(args.windowsize-1)).floor()) - 2\n",
    "    else:\n",
    "        N_ds = int(torch.log2(torch.tensor(args.windowsize)).floor()) - 2\n",
    "\n",
    "    args.f_in            =  args.number_wavelet_filtering*N_ds+1\n",
    "else:\n",
    "    args.f_in            =  1"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4d435a4c",
   "metadata": {},
   "source": [
    "## 模型参数"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "de2f4d16",
   "metadata": {},
   "outputs": [],
   "source": [
    "args.filter_scaling_factor = 1\n",
    "args.model_type            = \"deepconvlstm\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cada66dd",
   "metadata": {},
   "source": [
    "# 实验"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2e3f2fad",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Use GPU: cuda:3\n",
      "clone the  wavefiler weight\n",
      "Wavelet Filtering Regularization\n",
      "Build the DeepConvLSTM model!\n",
      "Done!\n",
      "Parameter : 339573\n",
      "Set the seed as :  1\n",
      " ----------------------- load all the data -------------------\n",
      "-----------------------Sliding file are generated -----------------------\n",
      "-----------------------Sliding file are generated -----------------------\n",
      "================ LOCV Mode ====================\n",
      "================ 7 CV ======================\n",
      "================ the 0 th CV Experiment ================ \n",
      "Leave one Out Experiment : The 1 Part as the test\n",
      "[-] Target sampling weights:  [0.00015738 0.00024728 0.00023403 0.00035575 0.00038835 0.00035436\n",
      " 0.00061275 0.0002426  0.00026076 0.00017167 0.00039573 0.00040486]\n",
      "Train data number :  43290\n",
      "The number of classes is :  12\n",
      "The input_length  is :  100\n",
      "The channel_in is :  6\n",
      "Validation data number :  4810\n",
      "Test data number :  35662\n",
      "================ Build the model ================ \n",
      "clone the  wavefiler weight\n",
      "Wavelet Filtering Regularization\n",
      "Build the DeepConvLSTM model!\n",
      "Epoch: 1 cost time: 19.95121431350708\n",
      "VALI: Epoch: 1, Steps: 170 | Train Loss: 0.8721886  Vali Loss: 0.4333695 Vali Accuracy: 0.8278586  Vali weighted F1: 0.8222760  Vali macro F1 0.8038361 \n",
      "Validation loss decreased (inf --> 0.433369).  Saving model ...\n",
      "Epoch: 2 cost time: 16.81880283355713\n",
      "VALI: Epoch: 2, Steps: 170 | Train Loss: 0.3430692  Vali Loss: 0.2886251 Vali Accuracy: 0.8794179  Vali weighted F1: 0.8746781  Vali macro F1 0.8552314 \n",
      "new best score!!!!\n",
      "Validation loss decreased (0.433369 --> 0.288625).  Saving model ...\n",
      "new best score!!!!\n",
      "Epoch: 3 cost time: 16.701024293899536\n",
      "VALI: Epoch: 3, Steps: 170 | Train Loss: 0.2817223  Vali Loss: 0.2613469 Vali Accuracy: 0.8866944  Vali weighted F1: 0.8768105  Vali macro F1 0.8546555 \n",
      "new best score!!!!\n",
      "Validation loss decreased (0.288625 --> 0.261347).  Saving model ...\n",
      "new best score!!!!\n",
      "Epoch: 4 cost time: 16.688585996627808\n",
      "VALI: Epoch: 4, Steps: 170 | Train Loss: 0.2411268  Vali Loss: 0.2217565 Vali Accuracy: 0.8970894  Vali weighted F1: 0.8971560  Vali macro F1 0.8798691 \n",
      "new best score!!!!\n",
      "Validation loss decreased (0.261347 --> 0.221757).  Saving model ...\n",
      "new best score!!!!\n",
      "Epoch: 5 cost time: 16.71437406539917\n",
      "VALI: Epoch: 5, Steps: 170 | Train Loss: 0.2245532  Vali Loss: 0.2318457 Vali Accuracy: 0.8966736  Vali weighted F1: 0.8781512  Vali macro F1 0.8530885 \n",
      "EarlyStopping counter: 1 out of 15\n",
      "Learning rate adjusting counter: 1 out of 5\n",
      "Epoch: 6 cost time: 16.701032638549805\n",
      "VALI: Epoch: 6, Steps: 170 | Train Loss: 0.2073835  Vali Loss: 0.2043025 Vali Accuracy: 0.9020790  Vali weighted F1: 0.8890183  Vali macro F1 0.8647504 \n",
      "new best score!!!!\n",
      "Validation loss decreased (0.221757 --> 0.204302).  Saving model ...\n",
      "new best score!!!!\n",
      "Epoch: 7 cost time: 16.812169313430786\n",
      "VALI: Epoch: 7, Steps: 170 | Train Loss: 0.1924057  Vali Loss: 0.1942691 Vali Accuracy: 0.9054054  Vali weighted F1: 0.9048638  Vali macro F1 0.8870225 \n",
      "new best score!!!!\n",
      "Validation loss decreased (0.204302 --> 0.194269).  Saving model ...\n",
      "new best score!!!!\n",
      "Epoch: 8 cost time: 16.717666149139404\n",
      "VALI: Epoch: 8, Steps: 170 | Train Loss: 0.1846227  Vali Loss: 0.2025642 Vali Accuracy: 0.9064449  Vali weighted F1: 0.9024067  Vali macro F1 0.8837918 \n",
      "EarlyStopping counter: 1 out of 15\n",
      "Learning rate adjusting counter: 1 out of 5\n",
      "Epoch: 9 cost time: 16.807445526123047\n",
      "VALI: Epoch: 9, Steps: 170 | Train Loss: 0.1795681  Vali Loss: 0.1832783 Vali Accuracy: 0.9074844  Vali weighted F1: 0.9044741  Vali macro F1 0.8858591 \n",
      "new best score!!!!\n",
      "Validation loss decreased (0.194269 --> 0.183278).  Saving model ...\n",
      "new best score!!!!\n",
      "Epoch: 10 cost time: 16.750895738601685\n",
      "VALI: Epoch: 10, Steps: 170 | Train Loss: 0.1724230  Vali Loss: 0.1866363 Vali Accuracy: 0.9122661  Vali weighted F1: 0.9117670  Vali macro F1 0.8942530 \n",
      "EarlyStopping counter: 1 out of 15\n",
      "Learning rate adjusting counter: 1 out of 5\n",
      "Epoch: 11 cost time: 16.70932960510254\n",
      "VALI: Epoch: 11, Steps: 170 | Train Loss: 0.1640707  Vali Loss: 0.1855957 Vali Accuracy: 0.9076923  Vali weighted F1: 0.9084082  Vali macro F1 0.8902711 \n",
      "EarlyStopping counter: 2 out of 15\n",
      "Learning rate adjusting counter: 2 out of 5\n",
      "Epoch: 12 cost time: 16.79719877243042\n",
      "VALI: Epoch: 12, Steps: 170 | Train Loss: 0.1621091  Vali Loss: 0.1858115 Vali Accuracy: 0.9120582  Vali weighted F1: 0.9103784  Vali macro F1 0.8927926 \n",
      "EarlyStopping counter: 3 out of 15\n",
      "Learning rate adjusting counter: 3 out of 5\n",
      "Epoch: 13 cost time: 16.72647452354431\n",
      "VALI: Epoch: 13, Steps: 170 | Train Loss: 0.1547917  Vali Loss: 0.1822806 Vali Accuracy: 0.9145530  Vali weighted F1: 0.9095792  Vali macro F1 0.8902821 \n",
      "new best score!!!!\n",
      "Validation loss decreased (0.183278 --> 0.182281).  Saving model ...\n",
      "new best score!!!!\n",
      "Epoch: 14 cost time: 16.81474471092224\n",
      "VALI: Epoch: 14, Steps: 170 | Train Loss: 0.1531773  Vali Loss: 0.1811402 Vali Accuracy: 0.9126819  Vali weighted F1: 0.9106968  Vali macro F1 0.8929428 \n",
      "new best score!!!!\n",
      "Validation loss decreased (0.182281 --> 0.181140).  Saving model ...\n",
      "new best score!!!!\n",
      "Epoch: 15 cost time: 16.711766958236694\n",
      "VALI: Epoch: 15, Steps: 170 | Train Loss: 0.1500686  Vali Loss: 0.1705607 Vali Accuracy: 0.9137214  Vali weighted F1: 0.9107568  Vali macro F1 0.8919891 \n",
      "new best score!!!!\n",
      "Validation loss decreased (0.181140 --> 0.170561).  Saving model ...\n",
      "new best score!!!!\n",
      "Epoch: 16 cost time: 16.773566246032715\n",
      "VALI: Epoch: 16, Steps: 170 | Train Loss: 0.1451084  Vali Loss: 0.1729960 Vali Accuracy: 0.9168399  Vali weighted F1: 0.9165040  Vali macro F1 0.8981165 \n",
      "EarlyStopping counter: 1 out of 15\n",
      "Learning rate adjusting counter: 1 out of 5\n",
      "Epoch: 17 cost time: 16.745140314102173\n",
      "VALI: Epoch: 17, Steps: 170 | Train Loss: 0.1438564  Vali Loss: 0.1840591 Vali Accuracy: 0.9108108  Vali weighted F1: 0.9094043  Vali macro F1 0.8913968 \n",
      "EarlyStopping counter: 2 out of 15\n",
      "Learning rate adjusting counter: 2 out of 5\n",
      "Epoch: 18 cost time: 16.681429147720337\n",
      "VALI: Epoch: 18, Steps: 170 | Train Loss: 0.1414141  Vali Loss: 0.1706959 Vali Accuracy: 0.9108108  Vali weighted F1: 0.9086710  Vali macro F1 0.8898124 \n",
      "EarlyStopping counter: 3 out of 15\n",
      "Learning rate adjusting counter: 3 out of 5\n",
      "Epoch: 19 cost time: 16.778639554977417\n",
      "VALI: Epoch: 19, Steps: 170 | Train Loss: 0.1411619  Vali Loss: 0.1795855 Vali Accuracy: 0.9072765  Vali weighted F1: 0.9079700  Vali macro F1 0.8891704 \n",
      "EarlyStopping counter: 4 out of 15\n",
      "Learning rate adjusting counter: 4 out of 5\n",
      "Epoch: 20 cost time: 16.68978524208069\n",
      "VALI: Epoch: 20, Steps: 170 | Train Loss: 0.1365225  Vali Loss: 0.1684420 Vali Accuracy: 0.9199584  Vali weighted F1: 0.9198889  Vali macro F1 0.9030630 \n",
      "new best score!!!!\n",
      "Validation loss decreased (0.170561 --> 0.168442).  Saving model ...\n",
      "new best score!!!!\n",
      "Epoch: 21 cost time: 16.751240491867065\n",
      "VALI: Epoch: 21, Steps: 170 | Train Loss: 0.1336931  Vali Loss: 0.1720146 Vali Accuracy: 0.9147609  Vali weighted F1: 0.9109915  Vali macro F1 0.8923829 \n",
      "EarlyStopping counter: 1 out of 15\n",
      "Learning rate adjusting counter: 1 out of 5\n",
      "Epoch: 22 cost time: 16.668810606002808\n",
      "VALI: Epoch: 22, Steps: 170 | Train Loss: 0.1321139  Vali Loss: 0.1764514 Vali Accuracy: 0.9141372  Vali weighted F1: 0.9127559  Vali macro F1 0.8945106 \n",
      "EarlyStopping counter: 2 out of 15\n",
      "Learning rate adjusting counter: 2 out of 5\n",
      "Epoch: 23 cost time: 16.724806547164917\n",
      "VALI: Epoch: 23, Steps: 170 | Train Loss: 0.1312674  Vali Loss: 0.1869828 Vali Accuracy: 0.9122661  Vali weighted F1: 0.9008620  Vali macro F1 0.8802441 \n",
      "EarlyStopping counter: 3 out of 15\n",
      "Learning rate adjusting counter: 3 out of 5\n",
      "Epoch: 24 cost time: 16.702038288116455\n",
      "VALI: Epoch: 24, Steps: 170 | Train Loss: 0.1271091  Vali Loss: 0.1782287 Vali Accuracy: 0.9153846  Vali weighted F1: 0.9111989  Vali macro F1 0.8915429 \n",
      "EarlyStopping counter: 4 out of 15\n",
      "Learning rate adjusting counter: 4 out of 5\n",
      "Epoch: 25 cost time: 16.678622007369995\n",
      "VALI: Epoch: 25, Steps: 170 | Train Loss: 0.1276199  Vali Loss: 0.1695147 Vali Accuracy: 0.9214137  Vali weighted F1: 0.9206918  Vali macro F1 0.9024876 \n",
      "EarlyStopping counter: 5 out of 15\n",
      "Learning rate adjusting counter: 5 out of 5\n",
      "Updating learning rate to 0.0001\n",
      "Epoch: 26 cost time: 16.778618097305298\n",
      "VALI: Epoch: 26, Steps: 170 | Train Loss: 0.1126885  Vali Loss: 0.1622089 Vali Accuracy: 0.9207900  Vali weighted F1: 0.9197819  Vali macro F1 0.9015596 \n",
      "new best score!!!!\n",
      "Validation loss decreased (0.168442 --> 0.162209).  Saving model ...\n",
      "new best score!!!!\n",
      "Epoch: 27 cost time: 16.676204681396484\n",
      "VALI: Epoch: 27, Steps: 170 | Train Loss: 0.1077938  Vali Loss: 0.1604940 Vali Accuracy: 0.9199584  Vali weighted F1: 0.9194686  Vali macro F1 0.9011028 \n",
      "new best score!!!!\n",
      "Validation loss decreased (0.162209 --> 0.160494).  Saving model ...\n",
      "new best score!!!!\n",
      "Epoch: 28 cost time: 16.767847776412964\n",
      "VALI: Epoch: 28, Steps: 170 | Train Loss: 0.1063735  Vali Loss: 0.1592698 Vali Accuracy: 0.9216216  Vali weighted F1: 0.9211286  Vali macro F1 0.9030608 \n",
      "new best score!!!!\n",
      "Validation loss decreased (0.160494 --> 0.159270).  Saving model ...\n",
      "new best score!!!!\n",
      "Epoch: 29 cost time: 16.686021089553833\n",
      "VALI: Epoch: 29, Steps: 170 | Train Loss: 0.1046337  Vali Loss: 0.1600002 Vali Accuracy: 0.9216216  Vali weighted F1: 0.9206770  Vali macro F1 0.9028356 \n",
      "EarlyStopping counter: 1 out of 15\n",
      "Learning rate adjusting counter: 1 out of 5\n",
      "Epoch: 30 cost time: 16.702677488327026\n",
      "VALI: Epoch: 30, Steps: 170 | Train Loss: 0.1045324  Vali Loss: 0.1589989 Vali Accuracy: 0.9232848  Vali weighted F1: 0.9220834  Vali macro F1 0.9045483 \n",
      "new best score!!!!\n",
      "Validation loss decreased (0.159270 --> 0.158999).  Saving model ...\n",
      "new best score!!!!\n",
      "Epoch: 31 cost time: 16.71393632888794\n",
      "VALI: Epoch: 31, Steps: 170 | Train Loss: 0.1042004  Vali Loss: 0.1586928 Vali Accuracy: 0.9220374  Vali weighted F1: 0.9210624  Vali macro F1 0.9036025 \n",
      "new best score!!!!\n",
      "Validation loss decreased (0.158999 --> 0.158693).  Saving model ...\n",
      "new best score!!!!\n",
      "Epoch: 32 cost time: 16.6866455078125\n",
      "VALI: Epoch: 32, Steps: 170 | Train Loss: 0.1036981  Vali Loss: 0.1581925 Vali Accuracy: 0.9222453  Vali weighted F1: 0.9221210  Vali macro F1 0.9041452 \n",
      "new best score!!!!\n",
      "Validation loss decreased (0.158693 --> 0.158192).  Saving model ...\n",
      "new best score!!!!\n",
      "Epoch: 33 cost time: 16.758044958114624\n",
      "VALI: Epoch: 33, Steps: 170 | Train Loss: 0.1026889  Vali Loss: 0.1576718 Vali Accuracy: 0.9220374  Vali weighted F1: 0.9211654  Vali macro F1 0.9030523 \n",
      "new best score!!!!\n",
      "Validation loss decreased (0.158192 --> 0.157672).  Saving model ...\n",
      "new best score!!!!\n",
      "Epoch: 34 cost time: 16.68452501296997\n",
      "VALI: Epoch: 34, Steps: 170 | Train Loss: 0.1013134  Vali Loss: 0.1591184 Vali Accuracy: 0.9232848  Vali weighted F1: 0.9221337  Vali macro F1 0.9046159 \n",
      "EarlyStopping counter: 1 out of 15\n",
      "Learning rate adjusting counter: 1 out of 5\n",
      "Epoch: 35 cost time: 16.738912105560303\n",
      "VALI: Epoch: 35, Steps: 170 | Train Loss: 0.1015410  Vali Loss: 0.1601026 Vali Accuracy: 0.9226611  Vali weighted F1: 0.9218947  Vali macro F1 0.9043019 \n",
      "EarlyStopping counter: 2 out of 15\n",
      "Learning rate adjusting counter: 2 out of 5\n",
      "Epoch: 36 cost time: 16.672657012939453\n",
      "VALI: Epoch: 36, Steps: 170 | Train Loss: 0.1013414  Vali Loss: 0.1609373 Vali Accuracy: 0.9201663  Vali weighted F1: 0.9198255  Vali macro F1 0.9017811 \n",
      "EarlyStopping counter: 3 out of 15\n",
      "Learning rate adjusting counter: 3 out of 5\n",
      "Epoch: 37 cost time: 16.679400205612183\n",
      "VALI: Epoch: 37, Steps: 170 | Train Loss: 0.0997446  Vali Loss: 0.1603808 Vali Accuracy: 0.9224532  Vali weighted F1: 0.9219572  Vali macro F1 0.9045538 \n",
      "EarlyStopping counter: 4 out of 15\n",
      "Learning rate adjusting counter: 4 out of 5\n",
      "Epoch: 38 cost time: 16.768572092056274\n",
      "VALI: Epoch: 38, Steps: 170 | Train Loss: 0.0991287  Vali Loss: 0.1605058 Vali Accuracy: 0.9216216  Vali weighted F1: 0.9213133  Vali macro F1 0.9038313 \n",
      "EarlyStopping counter: 5 out of 15\n",
      "Learning rate adjusting counter: 5 out of 5\n",
      "Updating learning rate to 1e-05\n",
      "Epoch: 39 cost time: 16.689335107803345\n",
      "VALI: Epoch: 39, Steps: 170 | Train Loss: 0.0978131  Vali Loss: 0.1591190 Vali Accuracy: 0.9239085  Vali weighted F1: 0.9232854  Vali macro F1 0.9059874 \n",
      "EarlyStopping counter: 6 out of 15\n",
      "Learning rate adjusting counter: 1 out of 5\n",
      "Epoch: 40 cost time: 16.76007056236267\n",
      "VALI: Epoch: 40, Steps: 170 | Train Loss: 0.0978725  Vali Loss: 0.1585236 Vali Accuracy: 0.9249480  Vali weighted F1: 0.9241932  Vali macro F1 0.9071865 \n",
      "EarlyStopping counter: 7 out of 15\n",
      "Learning rate adjusting counter: 2 out of 5\n",
      "Epoch: 41 cost time: 16.68339776992798\n",
      "VALI: Epoch: 41, Steps: 170 | Train Loss: 0.0982340  Vali Loss: 0.1587910 Vali Accuracy: 0.9245322  Vali weighted F1: 0.9237645  Vali macro F1 0.9067049 \n",
      "EarlyStopping counter: 8 out of 15\n",
      "Learning rate adjusting counter: 3 out of 5\n",
      "Epoch: 42 cost time: 16.69693899154663\n",
      "VALI: Epoch: 42, Steps: 170 | Train Loss: 0.0982144  Vali Loss: 0.1592450 Vali Accuracy: 0.9245322  Vali weighted F1: 0.9238433  Vali macro F1 0.9069036 \n",
      "EarlyStopping counter: 9 out of 15\n",
      "Learning rate adjusting counter: 4 out of 5\n",
      "Epoch: 43 cost time: 16.686044692993164\n",
      "VALI: Epoch: 43, Steps: 170 | Train Loss: 0.0977469  Vali Loss: 0.1591735 Vali Accuracy: 0.9245322  Vali weighted F1: 0.9238068  Vali macro F1 0.9067976 \n",
      "EarlyStopping counter: 10 out of 15\n",
      "Learning rate adjusting counter: 5 out of 5\n",
      "Updating learning rate to 1.0000000000000002e-06\n",
      "Epoch: 44 cost time: 16.69737458229065\n",
      "VALI: Epoch: 44, Steps: 170 | Train Loss: 0.0978774  Vali Loss: 0.1591645 Vali Accuracy: 0.9251559  Vali weighted F1: 0.9244249  Vali macro F1 0.9076194 \n",
      "EarlyStopping counter: 11 out of 15\n",
      "Learning rate adjusting counter: 1 out of 5\n",
      "Epoch: 45 cost time: 16.7668354511261\n",
      "VALI: Epoch: 45, Steps: 170 | Train Loss: 0.0975331  Vali Loss: 0.1591306 Vali Accuracy: 0.9247401  Vali weighted F1: 0.9240313  Vali macro F1 0.9070906 \n",
      "EarlyStopping counter: 12 out of 15\n",
      "Learning rate adjusting counter: 2 out of 5\n",
      "Epoch: 46 cost time: 16.66356587409973\n",
      "VALI: Epoch: 46, Steps: 170 | Train Loss: 0.0975726  Vali Loss: 0.1591142 Vali Accuracy: 0.9247401  Vali weighted F1: 0.9240313  Vali macro F1 0.9070906 \n",
      "EarlyStopping counter: 13 out of 15\n",
      "Learning rate adjusting counter: 3 out of 5\n",
      "Epoch: 47 cost time: 16.744717121124268\n",
      "VALI: Epoch: 47, Steps: 170 | Train Loss: 0.0977331  Vali Loss: 0.1591470 Vali Accuracy: 0.9247401  Vali weighted F1: 0.9240313  Vali macro F1 0.9070906 \n",
      "EarlyStopping counter: 14 out of 15\n",
      "Learning rate adjusting counter: 4 out of 5\n",
      "Epoch: 48 cost time: 16.672666311264038\n",
      "VALI: Epoch: 48, Steps: 170 | Train Loss: 0.0979260  Vali Loss: 0.1590979 Vali Accuracy: 0.9247401  Vali weighted F1: 0.9240313  Vali macro F1 0.9070906 \n",
      "EarlyStopping counter: 15 out of 15\n",
      "Early stopping\n",
      "Loading the best validation model!\n",
      "Final Test Performance : Test Accuracy: 0.7830744  Test weighted F1: 0.7791412  Test macro F1 0.7181585 \n",
      "clone the  wavefiler weight\n",
      "Wavelet Filtering Regularization\n",
      "Build the DeepConvLSTM model!\n",
      "Wavelet Filtering Regularization\n",
      "Build the DeepConvLSTM model!\n",
      "------------Fine Tuning  :  1   will be pruned   -----------------------------------------\n",
      "old model Parameter : 339573\n",
      "pruned model Parameter : 343252\n",
      "----------------------------------------------------------------------------------------\n",
      "Fine Tuning Epoch: 1 cost time: 16.720820903778076\n",
      "Fine Tuning VALI: Epoch: 1, Steps: 170 | Train Loss: 0.1028611  Vali Loss: 0.1624236 Vali Accuracy: 0.9228690  Vali weighted F1: 0.9214350  Vali macro F1 0.9046034 \n",
      "Validation loss decreased (inf --> 0.162424).  Saving model ...\n",
      "Fine Tuning Epoch: 2 cost time: 16.560084342956543\n",
      "Fine Tuning VALI: Epoch: 2, Steps: 170 | Train Loss: 0.1031171  Vali Loss: 0.1582707 Vali Accuracy: 0.9239085  Vali weighted F1: 0.9232412  Vali macro F1 0.9059785 \n",
      "new best score!!!!\n",
      "Validation loss decreased (0.162424 --> 0.158271).  Saving model ...\n",
      "new best score!!!!\n",
      "Fine Tuning Epoch: 3 cost time: 16.644049644470215\n",
      "Fine Tuning VALI: Epoch: 3, Steps: 170 | Train Loss: 0.1007862  Vali Loss: 0.1611453 Vali Accuracy: 0.9216216  Vali weighted F1: 0.9209264  Vali macro F1 0.9029840 \n",
      "EarlyStopping counter: 1 out of 15\n",
      "Learning rate adjusting counter: 1 out of 5\n",
      "Fine Tuning Epoch: 4 cost time: 16.54287886619568\n",
      "Fine Tuning VALI: Epoch: 4, Steps: 170 | Train Loss: 0.1005794  Vali Loss: 0.1592098 Vali Accuracy: 0.9226611  Vali weighted F1: 0.9222423  Vali macro F1 0.9047550 \n",
      "EarlyStopping counter: 2 out of 15\n",
      "Learning rate adjusting counter: 2 out of 5\n",
      "Fine Tuning Epoch: 5 cost time: 16.519600868225098\n",
      "Fine Tuning VALI: Epoch: 5, Steps: 170 | Train Loss: 0.0994239  Vali Loss: 0.1580161 Vali Accuracy: 0.9226611  Vali weighted F1: 0.9211759  Vali macro F1 0.9031654 \n",
      "new best score!!!!\n",
      "Validation loss decreased (0.158271 --> 0.158016).  Saving model ...\n",
      "new best score!!!!\n",
      "Fine Tuning Epoch: 6 cost time: 16.59519052505493\n",
      "Fine Tuning VALI: Epoch: 6, Steps: 170 | Train Loss: 0.0994038  Vali Loss: 0.1560850 Vali Accuracy: 0.9245322  Vali weighted F1: 0.9240558  Vali macro F1 0.9065623 \n",
      "new best score!!!!\n",
      "Validation loss decreased (0.158016 --> 0.156085).  Saving model ...\n",
      "new best score!!!!\n",
      "Fine Tuning Epoch: 7 cost time: 16.557169437408447\n",
      "Fine Tuning VALI: Epoch: 7, Steps: 170 | Train Loss: 0.0991476  Vali Loss: 0.1585656 Vali Accuracy: 0.9251559  Vali weighted F1: 0.9248577  Vali macro F1 0.9080123 \n",
      "EarlyStopping counter: 1 out of 15\n",
      "Learning rate adjusting counter: 1 out of 5\n",
      "Fine Tuning Epoch: 8 cost time: 16.6171977519989\n",
      "Fine Tuning VALI: Epoch: 8, Steps: 170 | Train Loss: 0.0988297  Vali Loss: 0.1566082 Vali Accuracy: 0.9224532  Vali weighted F1: 0.9211457  Vali macro F1 0.9031866 \n",
      "EarlyStopping counter: 2 out of 15\n",
      "Learning rate adjusting counter: 2 out of 5\n",
      "Fine Tuning Epoch: 9 cost time: 16.531033039093018\n",
      "Fine Tuning VALI: Epoch: 9, Steps: 170 | Train Loss: 0.0974792  Vali Loss: 0.1570752 Vali Accuracy: 0.9230769  Vali weighted F1: 0.9220497  Vali macro F1 0.9043318 \n",
      "EarlyStopping counter: 3 out of 15\n",
      "Learning rate adjusting counter: 3 out of 5\n",
      "Fine Tuning Epoch: 10 cost time: 16.607917547225952\n",
      "Fine Tuning VALI: Epoch: 10, Steps: 170 | Train Loss: 0.0978594  Vali Loss: 0.1580088 Vali Accuracy: 0.9234927  Vali weighted F1: 0.9230612  Vali macro F1 0.9058226 \n",
      "EarlyStopping counter: 4 out of 15\n",
      "Learning rate adjusting counter: 4 out of 5\n",
      "Fine Tuning Epoch: 11 cost time: 16.546295404434204\n",
      "Fine Tuning VALI: Epoch: 11, Steps: 170 | Train Loss: 0.0975481  Vali Loss: 0.1590946 Vali Accuracy: 0.9232848  Vali weighted F1: 0.9221114  Vali macro F1 0.9041617 \n",
      "EarlyStopping counter: 5 out of 15\n",
      "Learning rate adjusting counter: 5 out of 5\n",
      "Updating learning rate to 0.0001\n",
      "Fine Tuning Epoch: 12 cost time: 16.54756450653076\n",
      "Fine Tuning VALI: Epoch: 12, Steps: 170 | Train Loss: 0.0977905  Vali Loss: 0.1576014 Vali Accuracy: 0.9224532  Vali weighted F1: 0.9219651  Vali macro F1 0.9039202 \n",
      "EarlyStopping counter: 6 out of 15\n",
      "Learning rate adjusting counter: 1 out of 5\n",
      "Fine Tuning Epoch: 13 cost time: 16.62229013442993\n",
      "Fine Tuning VALI: Epoch: 13, Steps: 170 | Train Loss: 0.0968373  Vali Loss: 0.1597380 Vali Accuracy: 0.9257796  Vali weighted F1: 0.9249677  Vali macro F1 0.9078602 \n",
      "EarlyStopping counter: 7 out of 15\n",
      "Learning rate adjusting counter: 2 out of 5\n",
      "Fine Tuning Epoch: 14 cost time: 16.54529619216919\n",
      "Fine Tuning VALI: Epoch: 14, Steps: 170 | Train Loss: 0.0967425  Vali Loss: 0.1604436 Vali Accuracy: 0.9234927  Vali weighted F1: 0.9230772  Vali macro F1 0.9056856 \n",
      "EarlyStopping counter: 8 out of 15\n",
      "Learning rate adjusting counter: 3 out of 5\n",
      "Fine Tuning Epoch: 15 cost time: 16.620900630950928\n",
      "Fine Tuning VALI: Epoch: 15, Steps: 170 | Train Loss: 0.0966477  Vali Loss: 0.1597667 Vali Accuracy: 0.9234927  Vali weighted F1: 0.9227043  Vali macro F1 0.9058191 \n",
      "EarlyStopping counter: 9 out of 15\n",
      "Learning rate adjusting counter: 4 out of 5\n",
      "Fine Tuning Epoch: 16 cost time: 16.59087085723877\n",
      "Fine Tuning VALI: Epoch: 16, Steps: 170 | Train Loss: 0.0964619  Vali Loss: 0.1611090 Vali Accuracy: 0.9207900  Vali weighted F1: 0.9200872  Vali macro F1 0.9020008 \n",
      "EarlyStopping counter: 10 out of 15\n",
      "Learning rate adjusting counter: 5 out of 5\n",
      "Updating learning rate to 1e-05\n",
      "Fine Tuning Epoch: 17 cost time: 16.58246397972107\n",
      "Fine Tuning VALI: Epoch: 17, Steps: 170 | Train Loss: 0.0946021  Vali Loss: 0.1586369 Vali Accuracy: 0.9243243  Vali weighted F1: 0.9233984  Vali macro F1 0.9059460 \n",
      "EarlyStopping counter: 11 out of 15\n",
      "Learning rate adjusting counter: 1 out of 5\n",
      "Fine Tuning Epoch: 18 cost time: 16.57697319984436\n",
      "Fine Tuning VALI: Epoch: 18, Steps: 170 | Train Loss: 0.0939771  Vali Loss: 0.1582877 Vali Accuracy: 0.9247401  Vali weighted F1: 0.9240569  Vali macro F1 0.9068932 \n",
      "EarlyStopping counter: 12 out of 15\n",
      "Learning rate adjusting counter: 2 out of 5\n",
      "Fine Tuning Epoch: 19 cost time: 16.54088568687439\n",
      "Fine Tuning VALI: Epoch: 19, Steps: 170 | Train Loss: 0.0951272  Vali Loss: 0.1580964 Vali Accuracy: 0.9249480  Vali weighted F1: 0.9243077  Vali macro F1 0.9067652 \n",
      "EarlyStopping counter: 13 out of 15\n",
      "Learning rate adjusting counter: 3 out of 5\n",
      "Fine Tuning Epoch: 20 cost time: 16.61692523956299\n",
      "Fine Tuning VALI: Epoch: 20, Steps: 170 | Train Loss: 0.0938129  Vali Loss: 0.1579531 Vali Accuracy: 0.9234927  Vali weighted F1: 0.9227629  Vali macro F1 0.9050142 \n",
      "EarlyStopping counter: 14 out of 15\n",
      "Learning rate adjusting counter: 4 out of 5\n",
      "Fine Tuning Epoch: 21 cost time: 16.526269674301147\n",
      "Fine Tuning VALI: Epoch: 21, Steps: 170 | Train Loss: 0.0939288  Vali Loss: 0.1579737 Vali Accuracy: 0.9245322  Vali weighted F1: 0.9238583  Vali macro F1 0.9063940 \n",
      "EarlyStopping counter: 15 out of 15\n",
      "Early stopping\n",
      "Loading the best finetuned validation model!\n",
      "Fine Tuning Final Test Performance : Test Accuracy: 0.7877012  Test weighted F1: 0.7816858  Test macro F1 0.7194557 \n",
      "================ the 1 th CV Experiment ================ \n",
      "Leave one Out Experiment : The 2 Part as the test\n"
     ]
    }
   ],
   "source": [
    "for seed in [1,2,3,4,5]:\n",
    "    args.seed = seed\n",
    "    exp = Exp(args)\n",
    "    exp.train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "85dd817c-865b-4ef9-9cfb-b73b3da137af",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "iswc",
   "language": "python",
   "name": "iswc"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.13"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": true
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
