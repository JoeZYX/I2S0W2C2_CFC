{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "894e2c21",
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "import sys\n",
    "sys.path.append(\"../../\")\n",
    "\n",
    "from experiment import Exp\n",
    "\n",
    "from dataloaders import data_set,data_dict\n",
    "import torch\n",
    "import yaml\n",
    "import os"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bcc56bc7",
   "metadata": {},
   "source": [
    "# 参数设置"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dcc5bcbc",
   "metadata": {},
   "source": [
    "# 训练参数 \n",
    "除了路径 其他不要变"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "86004ce0",
   "metadata": {},
   "outputs": [],
   "source": [
    "class dotdict(dict):\n",
    "    \"\"\"dot.notation access to dictionary attributes\"\"\"\n",
    "    __getattr__ = dict.get\n",
    "    __setattr__ = dict.__setitem__\n",
    "    __delattr__ = dict.__delitem__\n",
    "\n",
    "args = dotdict()   \n",
    "# TODO change the path as relative path\n",
    "args.to_save_path     = \"/pfs/data5/home/kit/tm/px3192/ISWC2022LearnableFilter/Run_logs\"              \n",
    "args.freq_save_path   = \"/pfs/data5/home/kit/tm/px3192/ISWC2022LearnableFilter/Freq_data\"\n",
    "args.window_save_path = \"/pfs/data5/home/kit/tm/px3192/ISWC2022LearnableFilter/Sliding_window\"\n",
    "args.root_path        = \"/pfs/data5/home/kit/tm/px3192/datasets\"\n",
    "\n",
    "\n",
    "args.drop_transition  = False\n",
    "args.datanorm_type    = \"standardization\" # None ,\"standardization\", \"minmax\"\n",
    "\n",
    "\n",
    "args.batch_size       = 128                                                     \n",
    "args.shuffle          = True\n",
    "args.drop_last        = False\n",
    "args.train_vali_quote = 0.90                                           \n",
    "\n",
    "\n",
    "# training setting \n",
    "args.train_epochs            = 150\n",
    "\n",
    "args.learning_rate           = 0.001  \n",
    "args.learning_rate_patience  = 5\n",
    "args.learning_rate_factor    = 0.1\n",
    "\n",
    "\n",
    "args.early_stop_patience     = 15\n",
    "\n",
    "args.use_gpu                 = True if torch.cuda.is_available() else False\n",
    "args.gpu                     = 0\n",
    "args.use_multi_gpu           = False\n",
    "\n",
    "args.optimizer               = \"Adam\"\n",
    "args.criterion               = \"CrossEntropy\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c282cbcb",
   "metadata": {},
   "source": [
    "## 数据参数\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "c6cd147b",
   "metadata": {},
   "outputs": [],
   "source": [
    "args.seed                             = 1\n",
    "\n",
    "\n",
    "args.data_name                        =  \"hapt\"\n",
    "\n",
    "args.wavelet_filtering                = True\n",
    "args.wavelet_filtering_regularization = True\n",
    "args.wavelet_filtering_finetuning     = True\n",
    "args.wavelet_filtering_finetuning_percent = 0.3\n",
    "\n",
    "args.regulatization_tradeoff          = 0.0001\n",
    "args.number_wavelet_filtering         = 10\n",
    "\n",
    "\n",
    "args.difference       = False \n",
    "args.filtering        =  False\n",
    "args.magnitude        =  False\n",
    "args.weighted_sampler = False\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "args.pos_select       = None\n",
    "args.sensor_select    = None\n",
    "\n",
    "\n",
    "args.representation_type = \"time\"\n",
    "args.exp_mode            = \"LOCV\"\n",
    "\n",
    "config_file = open('../../configs/data.yaml', mode='r')\n",
    "data_config = yaml.load(config_file, Loader=yaml.FullLoader)\n",
    "config = data_config[args.data_name]\n",
    "\n",
    "args.root_path       = os.path.join(args.root_path,config[\"filename\"])\n",
    "args.sampling_freq   = config[\"sampling_freq\"]\n",
    "args.num_classes     =  config[\"num_classes\"]\n",
    "window_seconds       = config[\"window_seconds\"]\n",
    "args.windowsize      =   int(window_seconds * args.sampling_freq) \n",
    "args.input_length    =  args.windowsize\n",
    "# input information\n",
    "args.c_in            = config[\"num_channels\"]\n",
    "\n",
    "if args.wavelet_filtering :\n",
    "    \n",
    "    if args.windowsize%2==1:\n",
    "        N_ds = int(torch.log2(torch.tensor(args.windowsize-1)).floor()) - 2\n",
    "    else:\n",
    "        N_ds = int(torch.log2(torch.tensor(args.windowsize)).floor()) - 2\n",
    "\n",
    "    args.f_in            =  args.number_wavelet_filtering*N_ds+1\n",
    "else:\n",
    "    args.f_in            =  1\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4d435a4c",
   "metadata": {},
   "source": [
    "## 模型参数"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "de2f4d16",
   "metadata": {},
   "outputs": [],
   "source": [
    "args.filter_scaling_factor = 0.25\n",
    "args.model_type              = \"deepconvlstm\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cada66dd",
   "metadata": {},
   "source": [
    "# 实验"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "2e3f2fad",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Use GPU: cuda:0\n",
      "Wavelet Filtering Regularization\n",
      "Build the DeepConvLSTM model!\n",
      "Done!\n",
      "Parameter : 738559\n",
      "Set the seed as :  5\n"
     ]
    }
   ],
   "source": [
    "exp = Exp(args)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "09a011fc",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " ----------------------- load all the data -------------------\n",
      "-----------------------Sliding file are generated -----------------------\n",
      "-----------------------Sliding file are generated -----------------------\n",
      "================ LOCV Mode ====================\n",
      "================ 30 CV ======================\n",
      "================ the 0 th CV Experiment ================ \n",
      "Leave one Out Experiment : The 1 Part as the test\n",
      "[-] Target sampling weights:  [0.00065963 0.00069013 0.00072833 0.00060643 0.0005685  0.00057339\n",
      " 0.00763359 0.01020408 0.00617284 0.00719424 0.00574713 0.00689655]\n",
      "================ Build the model ================ \n",
      "Wavelet Filtering Regularization\n",
      "Build the DeepConvLSTM model!\n",
      "Train data number :  10339\n",
      "The number of classes is :  12\n",
      "The input_length  is :  128\n",
      "The channel_in is :  6\n",
      "Validation data number :  1149\n",
      "Test data number :  6632\n",
      "Epoch: 1 cost time: 12.94200086593628\n",
      "VALI: Epoch: 1, Steps: 81 | Train Loss: 0.9190039  Vali Loss: 0.3790627 Vali Accuracy: 0.8694517  Vali weighted F1: 0.8564985  Vali macro F1 0.5750926 \n",
      "Validation loss decreased (inf --> 0.379063).  Saving model ...\n",
      "Epoch: 2 cost time: 12.937283039093018\n",
      "VALI: Epoch: 2, Steps: 81 | Train Loss: 0.3179352  Vali Loss: 0.2750707 Vali Accuracy: 0.9042646  Vali weighted F1: 0.8973065  Vali macro F1 0.6592321 \n",
      "new best score!!!!\n",
      "Validation loss decreased (0.379063 --> 0.275071).  Saving model ...\n",
      "new best score!!!!\n",
      "Loading the best validation model!\n",
      "Final Test Performance : Test Accuracy: 0.9030458  Test weighted F1: 0.8969345  Test macro F1 0.7244152 \n",
      "Wavelet Filtering Regularization\n",
      "Build the DeepConvLSTM model!\n",
      "------------Fine Tuning  :  36   will be pruned   -----------------------------------------\n",
      "old model Parameter : 738559\n",
      "pruned model Parameter : 727003\n",
      "----------------------------------------------------------------------------------------\n",
      "Fine Tuning Epoch: 1 cost time: 13.042970418930054\n",
      "Fine Tuning VALI: Epoch: 1, Steps: 81 | Train Loss: 0.2512827  Vali Loss: 0.2489147 Vali Accuracy: 0.9129678  Vali weighted F1: 0.9110671  Vali macro F1 0.7138724 \n",
      "Validation loss decreased (inf --> 0.248915).  Saving model ...\n",
      "Fine Tuning Epoch: 2 cost time: 13.049669742584229\n",
      "Fine Tuning VALI: Epoch: 2, Steps: 81 | Train Loss: 0.2139420  Vali Loss: 0.2360362 Vali Accuracy: 0.9199304  Vali weighted F1: 0.9187133  Vali macro F1 0.7172988 \n",
      "new best score!!!!\n",
      "Validation loss decreased (0.248915 --> 0.236036).  Saving model ...\n",
      "new best score!!!!\n",
      "Loading the best finetuned validation model!\n",
      "Fine Tuning Final Test Performance : Test Accuracy: 0.9107358  Test weighted F1: 0.9089524  Test macro F1 0.7998771 \n",
      "================ the 1 th CV Experiment ================ \n",
      "Leave one Out Experiment : The 2 Part as the test\n",
      "[-] Target sampling weights:  [0.00064641 0.00068166 0.00073314 0.00060386 0.00056275 0.00057045\n",
      " 0.0075188  0.01010101 0.00636943 0.00740741 0.00584795 0.00746269]\n",
      "================ Build the model ================ \n",
      "Wavelet Filtering Regularization\n",
      "Build the DeepConvLSTM model!\n",
      "Train data number :  10393\n",
      "The number of classes is :  12\n",
      "The input_length  is :  128\n",
      "The channel_in is :  6\n",
      "Validation data number :  1155\n",
      "Test data number :  6311\n",
      "Epoch: 1 cost time: 12.413485050201416\n",
      "VALI: Epoch: 1, Steps: 82 | Train Loss: 0.8574423  Vali Loss: 0.3207566 Vali Accuracy: 0.8909091  Vali weighted F1: 0.8817801  Vali macro F1 0.6653347 \n",
      "Validation loss decreased (inf --> 0.320757).  Saving model ...\n",
      "Epoch: 2 cost time: 12.50567102432251\n",
      "VALI: Epoch: 2, Steps: 82 | Train Loss: 0.2725713  Vali Loss: 0.2271164 Vali Accuracy: 0.9116883  Vali weighted F1: 0.9104946  Vali macro F1 0.7538548 \n",
      "new best score!!!!\n",
      "Validation loss decreased (0.320757 --> 0.227116).  Saving model ...\n",
      "new best score!!!!\n",
      "Loading the best validation model!\n",
      "Final Test Performance : Test Accuracy: 0.8634131  Test weighted F1: 0.8619161  Test macro F1 0.7548682 \n",
      "Wavelet Filtering Regularization\n",
      "Build the DeepConvLSTM model!\n",
      "------------Fine Tuning  :  36   will be pruned   -----------------------------------------\n",
      "old model Parameter : 738559\n",
      "pruned model Parameter : 727003\n",
      "----------------------------------------------------------------------------------------\n",
      "Fine Tuning Epoch: 1 cost time: 12.525973320007324\n",
      "Fine Tuning VALI: Epoch: 1, Steps: 82 | Train Loss: 0.2198382  Vali Loss: 0.2135869 Vali Accuracy: 0.9160173  Vali weighted F1: 0.9144542  Vali macro F1 0.7579245 \n",
      "Validation loss decreased (inf --> 0.213587).  Saving model ...\n",
      "Fine Tuning Epoch: 2 cost time: 12.529738903045654\n",
      "Fine Tuning VALI: Epoch: 2, Steps: 82 | Train Loss: 0.1932225  Vali Loss: 0.1925327 Vali Accuracy: 0.9272727  Vali weighted F1: 0.9260568  Vali macro F1 0.7985690 \n",
      "new best score!!!!\n",
      "Validation loss decreased (0.213587 --> 0.192533).  Saving model ...\n",
      "new best score!!!!\n",
      "Loading the best finetuned validation model!\n",
      "Fine Tuning Final Test Performance : Test Accuracy: 0.8768816  Test weighted F1: 0.8768576  Test macro F1 0.7624310 \n",
      "================ the 2 th CV Experiment ================ \n",
      "Leave one Out Experiment : The 3 Part as the test\n",
      "[-] Target sampling weights:  [0.00064061 0.000668   0.00072411 0.0006105  0.0005618  0.00057241\n",
      " 0.00714286 0.00990099 0.00645161 0.0070922  0.00543478 0.00714286]\n",
      "================ Build the model ================ \n",
      "Wavelet Filtering Regularization\n",
      "Build the DeepConvLSTM model!\n",
      "Train data number :  10465\n",
      "The number of classes is :  12\n",
      "The input_length  is :  128\n",
      "The channel_in is :  6\n",
      "Validation data number :  1163\n",
      "Test data number :  5897\n",
      "Epoch: 1 cost time: 12.513147592544556\n",
      "VALI: Epoch: 1, Steps: 82 | Train Loss: 0.8843267  Vali Loss: 0.3579613 Vali Accuracy: 0.8761823  Vali weighted F1: 0.8624033  Vali macro F1 0.5946262 \n",
      "Validation loss decreased (inf --> 0.357961).  Saving model ...\n",
      "Epoch: 2 cost time: 12.497193336486816\n",
      "VALI: Epoch: 2, Steps: 82 | Train Loss: 0.2859549  Vali Loss: 0.2275900 Vali Accuracy: 0.9131556  Vali weighted F1: 0.9107764  Vali macro F1 0.7141071 \n",
      "new best score!!!!\n",
      "Validation loss decreased (0.357961 --> 0.227590).  Saving model ...\n",
      "new best score!!!!\n",
      "Loading the best validation model!\n",
      "Final Test Performance : Test Accuracy: 0.8026115  Test weighted F1: 0.8033582  Test macro F1 0.6236519 \n",
      "Wavelet Filtering Regularization\n",
      "Build the DeepConvLSTM model!\n",
      "------------Fine Tuning  :  36   will be pruned   -----------------------------------------\n",
      "old model Parameter : 738559\n",
      "pruned model Parameter : 727003\n",
      "----------------------------------------------------------------------------------------\n",
      "Fine Tuning Epoch: 1 cost time: 12.683915853500366\n",
      "Fine Tuning VALI: Epoch: 1, Steps: 82 | Train Loss: 0.2216533  Vali Loss: 0.2045199 Vali Accuracy: 0.9269132  Vali weighted F1: 0.9246324  Vali macro F1 0.7832164 \n",
      "Validation loss decreased (inf --> 0.204520).  Saving model ...\n",
      "Fine Tuning Epoch: 2 cost time: 12.69531774520874\n",
      "Fine Tuning VALI: Epoch: 2, Steps: 82 | Train Loss: 0.1890076  Vali Loss: 0.1914869 Vali Accuracy: 0.9260533  Vali weighted F1: 0.9241341  Vali macro F1 0.7614358 \n",
      "new best score!!!!\n",
      "Validation loss decreased (0.204520 --> 0.191487).  Saving model ...\n",
      "new best score!!!!\n",
      "Loading the best finetuned validation model!\n",
      "Fine Tuning Final Test Performance : Test Accuracy: 0.8322876  Test weighted F1: 0.8294157  Test macro F1 0.6746121 \n",
      "================ the 3 th CV Experiment ================ \n",
      "Leave one Out Experiment : The 4 Part as the test\n",
      "[-] Target sampling weights:  [0.00064267 0.00067751 0.00072464 0.0006192  0.00055525 0.00057143\n",
      " 0.00793651 0.0106383  0.00645161 0.00689655 0.00534759 0.00735294]\n",
      "================ Build the model ================ \n",
      "Wavelet Filtering Regularization\n",
      "Build the DeepConvLSTM model!\n",
      "Train data number :  10421\n",
      "The number of classes is :  12\n",
      "The input_length  is :  128\n",
      "The channel_in is :  6\n",
      "Validation data number :  1158\n",
      "Test data number :  6195\n",
      "Epoch: 1 cost time: 12.440237522125244\n",
      "VALI: Epoch: 1, Steps: 82 | Train Loss: 0.8423587  Vali Loss: 0.3926874 Vali Accuracy: 0.8601036  Vali weighted F1: 0.8455505  Vali macro F1 0.5856864 \n",
      "Validation loss decreased (inf --> 0.392687).  Saving model ...\n",
      "Epoch: 2 cost time: 12.484378099441528\n",
      "VALI: Epoch: 2, Steps: 82 | Train Loss: 0.2940665  Vali Loss: 0.2889503 Vali Accuracy: 0.8972366  Vali weighted F1: 0.8911729  Vali macro F1 0.6870724 \n",
      "new best score!!!!\n",
      "Validation loss decreased (0.392687 --> 0.288950).  Saving model ...\n",
      "new best score!!!!\n",
      "Loading the best validation model!\n",
      "Final Test Performance : Test Accuracy: 0.9037934  Test weighted F1: 0.9009837  Test macro F1 0.7498900 \n",
      "Wavelet Filtering Regularization\n",
      "Build the DeepConvLSTM model!\n",
      "------------Fine Tuning  :  36   will be pruned   -----------------------------------------\n",
      "old model Parameter : 738559\n",
      "pruned model Parameter : 727003\n",
      "----------------------------------------------------------------------------------------\n",
      "Fine Tuning Epoch: 1 cost time: 12.592661619186401\n",
      "Fine Tuning VALI: Epoch: 1, Steps: 82 | Train Loss: 0.2338582  Vali Loss: 0.2771262 Vali Accuracy: 0.9127807  Vali weighted F1: 0.9076260  Vali macro F1 0.7518410 \n",
      "Validation loss decreased (inf --> 0.277126).  Saving model ...\n",
      "Fine Tuning Epoch: 2 cost time: 12.589469909667969\n",
      "Fine Tuning VALI: Epoch: 2, Steps: 82 | Train Loss: 0.2027935  Vali Loss: 0.2455989 Vali Accuracy: 0.9214162  Vali weighted F1: 0.9180040  Vali macro F1 0.7984118 \n",
      "new best score!!!!\n",
      "Validation loss decreased (0.277126 --> 0.245599).  Saving model ...\n",
      "new best score!!!!\n",
      "Loading the best finetuned validation model!\n",
      "Fine Tuning Final Test Performance : Test Accuracy: 0.9050847  Test weighted F1: 0.9032013  Test macro F1 0.7746493 \n",
      "================ the 4 th CV Experiment ================ \n",
      "Leave one Out Experiment : The 5 Part as the test\n",
      "[-] Target sampling weights:  [0.00064558 0.00067889 0.00073584 0.00062228 0.00056243 0.00056883\n",
      " 0.00763359 0.0106383  0.00666667 0.00714286 0.00546448 0.00740741]\n",
      "================ Build the model ================ \n",
      "Wavelet Filtering Regularization\n",
      "Build the DeepConvLSTM model!\n",
      "Train data number :  10357\n",
      "The number of classes is :  12\n",
      "The input_length  is :  128\n",
      "The channel_in is :  6\n",
      "Validation data number :  1151\n",
      "Test data number :  6522\n",
      "Epoch: 1 cost time: 11.869166135787964\n",
      "VALI: Epoch: 1, Steps: 81 | Train Loss: 0.8054077  Vali Loss: 0.3601809 Vali Accuracy: 0.8670721  Vali weighted F1: 0.8578011  Vali macro F1 0.6293700 \n",
      "Validation loss decreased (inf --> 0.360181).  Saving model ...\n",
      "Epoch: 2 cost time: 11.856569290161133\n",
      "VALI: Epoch: 2, Steps: 81 | Train Loss: 0.3011047  Vali Loss: 0.2562779 Vali Accuracy: 0.9079062  Vali weighted F1: 0.9034706  Vali macro F1 0.7490168 \n",
      "new best score!!!!\n",
      "Validation loss decreased (0.360181 --> 0.256278).  Saving model ...\n",
      "new best score!!!!\n",
      "Loading the best validation model!\n",
      "Final Test Performance : Test Accuracy: 0.8679853  Test weighted F1: 0.8664217  Test macro F1 0.7137382 \n",
      "Wavelet Filtering Regularization\n",
      "Build the DeepConvLSTM model!\n",
      "------------Fine Tuning  :  36   will be pruned   -----------------------------------------\n",
      "old model Parameter : 738559\n",
      "pruned model Parameter : 727003\n",
      "----------------------------------------------------------------------------------------\n",
      "Fine Tuning Epoch: 1 cost time: 12.32808780670166\n",
      "Fine Tuning VALI: Epoch: 1, Steps: 81 | Train Loss: 0.3448095  Vali Loss: 0.2808922 Vali Accuracy: 0.9061685  Vali weighted F1: 0.9024005  Vali macro F1 0.7495602 \n",
      "Validation loss decreased (inf --> 0.280892).  Saving model ...\n",
      "Fine Tuning Epoch: 2 cost time: 12.323975563049316\n",
      "Fine Tuning VALI: Epoch: 2, Steps: 81 | Train Loss: 0.2382902  Vali Loss: 0.2522941 Vali Accuracy: 0.9070374  Vali weighted F1: 0.9045265  Vali macro F1 0.7452033 \n",
      "new best score!!!!\n",
      "Validation loss decreased (0.280892 --> 0.252294).  Saving model ...\n",
      "new best score!!!!\n",
      "Loading the best finetuned validation model!\n",
      "Fine Tuning Final Test Performance : Test Accuracy: 0.8710518  Test weighted F1: 0.8686193  Test macro F1 0.7291409 \n",
      "================ the 5 th CV Experiment ================ \n",
      "Leave one Out Experiment : The 6 Part as the test\n",
      "[-] Target sampling weights:  [0.00064725 0.0006854  0.00072569 0.00063091 0.0005872  0.00057937\n",
      " 0.00740741 0.01020408 0.00645161 0.00729927 0.00561798 0.00740741]\n",
      "================ Build the model ================ \n",
      "Wavelet Filtering Regularization\n",
      "Build the DeepConvLSTM model!\n",
      "Train data number :  10234\n",
      "The number of classes is :  12\n",
      "The input_length  is :  128\n",
      "The channel_in is :  6\n",
      "Validation data number :  1138\n",
      "Test data number :  7257\n",
      "Epoch: 1 cost time: 12.222733974456787\n",
      "VALI: Epoch: 1, Steps: 80 | Train Loss: 0.8346243  Vali Loss: 0.3052225 Vali Accuracy: 0.8857645  Vali weighted F1: 0.8778331  Vali macro F1 0.6585646 \n",
      "Validation loss decreased (inf --> 0.305222).  Saving model ...\n",
      "Epoch: 2 cost time: 12.241188049316406\n",
      "VALI: Epoch: 2, Steps: 80 | Train Loss: 0.2809139  Vali Loss: 0.2360787 Vali Accuracy: 0.9086116  Vali weighted F1: 0.9067373  Vali macro F1 0.7309581 \n",
      "new best score!!!!\n",
      "Validation loss decreased (0.305222 --> 0.236079).  Saving model ...\n",
      "new best score!!!!\n",
      "Loading the best validation model!\n",
      "Final Test Performance : Test Accuracy: 0.8755684  Test weighted F1: 0.8728603  Test macro F1 0.7559963 \n",
      "Wavelet Filtering Regularization\n",
      "Build the DeepConvLSTM model!\n",
      "------------Fine Tuning  :  36   will be pruned   -----------------------------------------\n",
      "old model Parameter : 738559\n",
      "pruned model Parameter : 727003\n",
      "----------------------------------------------------------------------------------------\n",
      "Fine Tuning Epoch: 1 cost time: 12.36653184890747\n",
      "Fine Tuning VALI: Epoch: 1, Steps: 80 | Train Loss: 0.2414910  Vali Loss: 0.2269109 Vali Accuracy: 0.9217926  Vali weighted F1: 0.9202167  Vali macro F1 0.7668875 \n",
      "Validation loss decreased (inf --> 0.226911).  Saving model ...\n",
      "Fine Tuning Epoch: 2 cost time: 12.344114065170288\n",
      "Fine Tuning VALI: Epoch: 2, Steps: 80 | Train Loss: 0.2019569  Vali Loss: 0.2099393 Vali Accuracy: 0.9261863  Vali weighted F1: 0.9243138  Vali macro F1 0.7598488 \n",
      "new best score!!!!\n",
      "Validation loss decreased (0.226911 --> 0.209939).  Saving model ...\n",
      "new best score!!!!\n",
      "Loading the best finetuned validation model!\n",
      "Fine Tuning Final Test Performance : Test Accuracy: 0.8779110  Test weighted F1: 0.8758084  Test macro F1 0.7668390 \n",
      "================ the 6 th CV Experiment ================ \n",
      "Leave one Out Experiment : The 7 Part as the test\n",
      "[-] Target sampling weights:  [0.00064267 0.00067204 0.00071531 0.00064392 0.00059207 0.00058858\n",
      " 0.00763359 0.01020408 0.00649351 0.00724638 0.00578035 0.00704225]\n",
      "================ Build the model ================ \n",
      "Wavelet Filtering Regularization\n",
      "Build the DeepConvLSTM model!\n",
      "Train data number :  10219\n",
      "The number of classes is :  12\n",
      "The input_length  is :  128\n",
      "The channel_in is :  6\n",
      "Validation data number :  1136\n",
      "Test data number :  7352\n",
      "Epoch: 1 cost time: 11.637417316436768\n",
      "VALI: Epoch: 1, Steps: 80 | Train Loss: 0.8868096  Vali Loss: 0.3650542 Vali Accuracy: 0.8705986  Vali weighted F1: 0.8601018  Vali macro F1 0.6356840 \n",
      "Validation loss decreased (inf --> 0.365054).  Saving model ...\n",
      "Epoch: 2 cost time: 11.645222425460815\n",
      "VALI: Epoch: 2, Steps: 80 | Train Loss: 0.3043251  Vali Loss: 0.2834137 Vali Accuracy: 0.8961268  Vali weighted F1: 0.8907370  Vali macro F1 0.7176170 \n",
      "new best score!!!!\n",
      "Validation loss decreased (0.365054 --> 0.283414).  Saving model ...\n",
      "new best score!!!!\n",
      "Loading the best validation model!\n",
      "Final Test Performance : Test Accuracy: 0.9175734  Test weighted F1: 0.9143165  Test macro F1 0.7532705 \n",
      "Wavelet Filtering Regularization\n",
      "Build the DeepConvLSTM model!\n",
      "------------Fine Tuning  :  36   will be pruned   -----------------------------------------\n",
      "old model Parameter : 738559\n",
      "pruned model Parameter : 727003\n",
      "----------------------------------------------------------------------------------------\n",
      "Fine Tuning Epoch: 1 cost time: 12.12908124923706\n",
      "Fine Tuning VALI: Epoch: 1, Steps: 80 | Train Loss: 0.2787593  Vali Loss: 0.2516649 Vali Accuracy: 0.9110915  Vali weighted F1: 0.9079460  Vali macro F1 0.7804305 \n",
      "Validation loss decreased (inf --> 0.251665).  Saving model ...\n",
      "Fine Tuning Epoch: 2 cost time: 12.132132291793823\n",
      "Fine Tuning VALI: Epoch: 2, Steps: 80 | Train Loss: 0.2162734  Vali Loss: 0.2220154 Vali Accuracy: 0.9137324  Vali weighted F1: 0.9103454  Vali macro F1 0.7758798 \n",
      "new best score!!!!\n",
      "Validation loss decreased (0.251665 --> 0.222015).  Saving model ...\n",
      "new best score!!!!\n",
      "Loading the best finetuned validation model!\n",
      "Fine Tuning Final Test Performance : Test Accuracy: 0.9272307  Test weighted F1: 0.9260038  Test macro F1 0.7653137 \n",
      "================ the 7 th CV Experiment ================ \n",
      "Leave one Out Experiment : The 8 Part as the test\n",
      "[-] Target sampling weights:  [0.00064809 0.00066845 0.00072202 0.00063816 0.00057078 0.00059102\n",
      " 0.00729927 0.00990099 0.00675676 0.00724638 0.00564972 0.00724638]\n",
      "================ Build the model ================ \n",
      "Wavelet Filtering Regularization\n",
      "Build the DeepConvLSTM model!\n",
      "Train data number :  10274\n",
      "The number of classes is :  12\n",
      "The input_length  is :  128\n",
      "The channel_in is :  6\n",
      "Validation data number :  1142\n",
      "Test data number :  7032\n",
      "Epoch: 1 cost time: 11.707938432693481\n",
      "VALI: Epoch: 1, Steps: 81 | Train Loss: 0.8776289  Vali Loss: 0.3792540 Vali Accuracy: 0.8607706  Vali weighted F1: 0.8523643  Vali macro F1 0.6130287 \n",
      "Validation loss decreased (inf --> 0.379254).  Saving model ...\n",
      "Epoch: 2 cost time: 11.712388515472412\n",
      "VALI: Epoch: 2, Steps: 81 | Train Loss: 0.2963310  Vali Loss: 0.2540981 Vali Accuracy: 0.9150613  Vali weighted F1: 0.9130812  Vali macro F1 0.7555297 \n",
      "new best score!!!!\n",
      "Validation loss decreased (0.379254 --> 0.254098).  Saving model ...\n",
      "new best score!!!!\n",
      "Loading the best validation model!\n",
      "Final Test Performance : Test Accuracy: 0.9172355  Test weighted F1: 0.9110654  Test macro F1 0.7150297 \n",
      "Wavelet Filtering Regularization\n",
      "Build the DeepConvLSTM model!\n",
      "------------Fine Tuning  :  36   will be pruned   -----------------------------------------\n",
      "old model Parameter : 738559\n",
      "pruned model Parameter : 727003\n",
      "----------------------------------------------------------------------------------------\n",
      "Fine Tuning Epoch: 1 cost time: 11.879345893859863\n",
      "Fine Tuning VALI: Epoch: 1, Steps: 81 | Train Loss: 0.2293034  Vali Loss: 0.2090048 Vali Accuracy: 0.9264448  Vali weighted F1: 0.9254330  Vali macro F1 0.8078365 \n",
      "Validation loss decreased (inf --> 0.209005).  Saving model ...\n",
      "Fine Tuning Epoch: 2 cost time: 11.830357313156128\n",
      "Fine Tuning VALI: Epoch: 2, Steps: 81 | Train Loss: 0.1980343  Vali Loss: 0.1925204 Vali Accuracy: 0.9246935  Vali weighted F1: 0.9236718  Vali macro F1 0.7963476 \n",
      "new best score!!!!\n",
      "Validation loss decreased (0.209005 --> 0.192520).  Saving model ...\n",
      "new best score!!!!\n",
      "Loading the best finetuned validation model!\n",
      "Fine Tuning Final Test Performance : Test Accuracy: 0.9350114  Test weighted F1: 0.9321892  Test macro F1 0.7922190 \n",
      "================ the 8 th CV Experiment ================ \n",
      "Leave one Out Experiment : The 9 Part as the test\n",
      "[-] Target sampling weights:  [0.00064809 0.00068399 0.00072833 0.0006398  0.00058548 0.00058445\n",
      " 0.00769231 0.01052632 0.00694444 0.00724638 0.00543478 0.00740741]\n",
      "================ Build the model ================ \n",
      "Wavelet Filtering Regularization\n",
      "Build the DeepConvLSTM model!\n",
      "Train data number :  10186\n",
      "The number of classes is :  12\n",
      "The input_length  is :  128\n",
      "The channel_in is :  6\n",
      "Validation data number :  1132\n",
      "Test data number :  7568\n",
      "Epoch: 1 cost time: 11.593433618545532\n",
      "VALI: Epoch: 1, Steps: 80 | Train Loss: 0.8969728  Vali Loss: 0.3721761 Vali Accuracy: 0.8666078  Vali weighted F1: 0.8600227  Vali macro F1 0.6786866 \n",
      "Validation loss decreased (inf --> 0.372176).  Saving model ...\n",
      "Epoch: 2 cost time: 11.56390643119812\n",
      "VALI: Epoch: 2, Steps: 80 | Train Loss: 0.2939986  Vali Loss: 0.2993652 Vali Accuracy: 0.8922261  Vali weighted F1: 0.8866519  Vali macro F1 0.7365351 \n",
      "new best score!!!!\n",
      "Validation loss decreased (0.372176 --> 0.299365).  Saving model ...\n",
      "new best score!!!!\n",
      "Loading the best validation model!\n",
      "Final Test Performance : Test Accuracy: 0.9014271  Test weighted F1: 0.9022326  Test macro F1 0.7110502 \n",
      "Wavelet Filtering Regularization\n",
      "Build the DeepConvLSTM model!\n",
      "------------Fine Tuning  :  36   will be pruned   -----------------------------------------\n",
      "old model Parameter : 738559\n",
      "pruned model Parameter : 727003\n",
      "----------------------------------------------------------------------------------------\n",
      "Fine Tuning Epoch: 1 cost time: 11.697164058685303\n",
      "Fine Tuning VALI: Epoch: 1, Steps: 80 | Train Loss: 0.2484925  Vali Loss: 0.2434072 Vali Accuracy: 0.9116608  Vali weighted F1: 0.9080353  Vali macro F1 0.7557561 \n",
      "Validation loss decreased (inf --> 0.243407).  Saving model ...\n",
      "Fine Tuning Epoch: 2 cost time: 11.70281720161438\n",
      "Fine Tuning VALI: Epoch: 2, Steps: 80 | Train Loss: 0.1996418  Vali Loss: 0.2285639 Vali Accuracy: 0.9125442  Vali weighted F1: 0.9097281  Vali macro F1 0.7547492 \n",
      "new best score!!!!\n",
      "Validation loss decreased (0.243407 --> 0.228564).  Saving model ...\n",
      "new best score!!!!\n",
      "Loading the best finetuned validation model!\n",
      "Fine Tuning Final Test Performance : Test Accuracy: 0.9151691  Test weighted F1: 0.9165512  Test macro F1 0.7524859 \n",
      "================ the 9 th CV Experiment ================ \n",
      "Leave one Out Experiment : The 10 Part as the test\n",
      "[-] Target sampling weights:  [0.0006398  0.00068353 0.00073584 0.00063052 0.00057637 0.00059032\n",
      " 0.00806452 0.01010101 0.00641026 0.00657895 0.00531915 0.00740741]\n",
      "================ Build the model ================ \n",
      "Wavelet Filtering Regularization\n",
      "Build the DeepConvLSTM model!\n",
      "Train data number :  10254\n",
      "The number of classes is :  12\n",
      "The input_length  is :  128\n",
      "The channel_in is :  6\n",
      "Validation data number :  1140\n",
      "Test data number :  7165\n",
      "Epoch: 1 cost time: 11.659008741378784\n",
      "VALI: Epoch: 1, Steps: 81 | Train Loss: 0.8735333  Vali Loss: 0.3217707 Vali Accuracy: 0.8938596  Vali weighted F1: 0.8889762  Vali macro F1 0.6621953 \n",
      "Validation loss decreased (inf --> 0.321771).  Saving model ...\n",
      "Epoch: 2 cost time: 11.707534551620483\n",
      "VALI: Epoch: 2, Steps: 81 | Train Loss: 0.2930247  Vali Loss: 0.2092280 Vali Accuracy: 0.9271930  Vali weighted F1: 0.9243930  Vali macro F1 0.7479514 \n",
      "new best score!!!!\n",
      "Validation loss decreased (0.321771 --> 0.209228).  Saving model ...\n",
      "new best score!!!!\n",
      "Loading the best validation model!\n",
      "Final Test Performance : Test Accuracy: 0.8997906  Test weighted F1: 0.8965460  Test macro F1 0.7513000 \n",
      "Wavelet Filtering Regularization\n",
      "Build the DeepConvLSTM model!\n",
      "------------Fine Tuning  :  36   will be pruned   -----------------------------------------\n",
      "old model Parameter : 738559\n",
      "pruned model Parameter : 727003\n",
      "----------------------------------------------------------------------------------------\n",
      "Fine Tuning Epoch: 1 cost time: 11.821091890335083\n",
      "Fine Tuning VALI: Epoch: 1, Steps: 81 | Train Loss: 0.2518859  Vali Loss: 0.1997735 Vali Accuracy: 0.9254386  Vali weighted F1: 0.9239873  Vali macro F1 0.7567658 \n",
      "Validation loss decreased (inf --> 0.199773).  Saving model ...\n",
      "Fine Tuning Epoch: 2 cost time: 11.79641056060791\n",
      "Fine Tuning VALI: Epoch: 2, Steps: 81 | Train Loss: 0.2109868  Vali Loss: 0.1736199 Vali Accuracy: 0.9403509  Vali weighted F1: 0.9398319  Vali macro F1 0.7871360 \n",
      "new best score!!!!\n",
      "Validation loss decreased (0.199773 --> 0.173620).  Saving model ...\n",
      "new best score!!!!\n",
      "Loading the best finetuned validation model!\n",
      "Fine Tuning Final Test Performance : Test Accuracy: 0.9098395  Test weighted F1: 0.9076848  Test macro F1 0.7799742 \n",
      "================ the 10 th CV Experiment ================ \n",
      "Leave one Out Experiment : The 11 Part as the test\n",
      "[-] Target sampling weights:  [0.00060132 0.00064103 0.00067981 0.0005767  0.00052687 0.0005339\n",
      " 0.0070922  0.00961538 0.00588235 0.00657895 0.00515464 0.00680272]\n",
      "================ Build the model ================ \n",
      "Wavelet Filtering Regularization\n",
      "Build the DeepConvLSTM model!\n",
      "Train data number :  11107\n",
      "The number of classes is :  12\n",
      "The input_length  is :  128\n",
      "The channel_in is :  6\n",
      "Validation data number :  1235\n",
      "Test data number :  2102\n",
      "Epoch: 1 cost time: 12.694651365280151\n",
      "VALI: Epoch: 1, Steps: 87 | Train Loss: 0.8028085  Vali Loss: 0.3183588 Vali Accuracy: 0.8874494  Vali weighted F1: 0.8828633  Vali macro F1 0.6918746 \n",
      "Validation loss decreased (inf --> 0.318359).  Saving model ...\n",
      "Epoch: 2 cost time: 12.648846864700317\n",
      "VALI: Epoch: 2, Steps: 87 | Train Loss: 0.2918801  Vali Loss: 0.2448617 Vali Accuracy: 0.9101215  Vali weighted F1: 0.9080082  Vali macro F1 0.7689723 \n",
      "new best score!!!!\n",
      "Validation loss decreased (0.318359 --> 0.244862).  Saving model ...\n",
      "new best score!!!!\n",
      "Loading the best validation model!\n",
      "Final Test Performance : Test Accuracy: 0.9638440  Test weighted F1: 0.9620588  Test macro F1 0.8292226 \n",
      "Wavelet Filtering Regularization\n",
      "Build the DeepConvLSTM model!\n",
      "------------Fine Tuning  :  36   will be pruned   -----------------------------------------\n",
      "old model Parameter : 738559\n",
      "pruned model Parameter : 727003\n",
      "----------------------------------------------------------------------------------------\n",
      "Fine Tuning Epoch: 1 cost time: 13.00106430053711\n",
      "Fine Tuning VALI: Epoch: 1, Steps: 87 | Train Loss: 0.2665059  Vali Loss: 0.2251929 Vali Accuracy: 0.9190283  Vali weighted F1: 0.9175592  Vali macro F1 0.7826333 \n",
      "Validation loss decreased (inf --> 0.225193).  Saving model ...\n",
      "Fine Tuning Epoch: 2 cost time: 13.106878280639648\n",
      "Fine Tuning VALI: Epoch: 2, Steps: 87 | Train Loss: 0.2227873  Vali Loss: 0.2115531 Vali Accuracy: 0.9246964  Vali weighted F1: 0.9240891  Vali macro F1 0.8181773 \n",
      "new best score!!!!\n",
      "Validation loss decreased (0.225193 --> 0.211553).  Saving model ...\n",
      "new best score!!!!\n",
      "Loading the best finetuned validation model!\n",
      "Fine Tuning Final Test Performance : Test Accuracy: 0.9628925  Test weighted F1: 0.9623410  Test macro F1 0.8206927 \n",
      "================ the 11 th CV Experiment ================ \n",
      "Leave one Out Experiment : The 12 Part as the test\n",
      "[-] Target sampling weights:  [0.00059952 0.00063492 0.00067069 0.00057438 0.00053619 0.00053533\n",
      " 0.00680272 0.00952381 0.00628931 0.00694444 0.00507614 0.00714286]\n",
      "================ Build the model ================ \n",
      "Wavelet Filtering Regularization\n",
      "Build the DeepConvLSTM model!\n",
      "Train data number :  11100\n",
      "The number of classes is :  12\n",
      "The input_length  is :  128\n",
      "The channel_in is :  6\n",
      "Validation data number :  1234\n",
      "Test data number :  2144\n",
      "Epoch: 1 cost time: 12.687888860702515\n",
      "VALI: Epoch: 1, Steps: 87 | Train Loss: 0.8093923  Vali Loss: 0.3368002 Vali Accuracy: 0.8735818  Vali weighted F1: 0.8674495  Vali macro F1 0.6945410 \n",
      "Validation loss decreased (inf --> 0.336800).  Saving model ...\n",
      "Epoch: 2 cost time: 12.690778970718384\n",
      "VALI: Epoch: 2, Steps: 87 | Train Loss: 0.2876796  Vali Loss: 0.2493159 Vali Accuracy: 0.9035656  Vali weighted F1: 0.8984320  Vali macro F1 0.7614960 \n",
      "new best score!!!!\n",
      "Validation loss decreased (0.336800 --> 0.249316).  Saving model ...\n",
      "new best score!!!!\n",
      "Loading the best validation model!\n",
      "Final Test Performance : Test Accuracy: 0.9486940  Test weighted F1: 0.9454417  Test macro F1 0.7710911 \n",
      "Wavelet Filtering Regularization\n",
      "Build the DeepConvLSTM model!\n",
      "------------Fine Tuning  :  36   will be pruned   -----------------------------------------\n",
      "old model Parameter : 738559\n",
      "pruned model Parameter : 727003\n",
      "----------------------------------------------------------------------------------------\n",
      "Fine Tuning Epoch: 1 cost time: 12.95903730392456\n",
      "Fine Tuning VALI: Epoch: 1, Steps: 87 | Train Loss: 0.2481177  Vali Loss: 0.2271058 Vali Accuracy: 0.9222042  Vali weighted F1: 0.9200760  Vali macro F1 0.8142866 \n",
      "Validation loss decreased (inf --> 0.227106).  Saving model ...\n",
      "Fine Tuning Epoch: 2 cost time: 12.856584787368774\n",
      "Fine Tuning VALI: Epoch: 2, Steps: 87 | Train Loss: 0.2121343  Vali Loss: 0.2173817 Vali Accuracy: 0.9197731  Vali weighted F1: 0.9164991  Vali macro F1 0.7808471 \n",
      "new best score!!!!\n",
      "Validation loss decreased (0.227106 --> 0.217382).  Saving model ...\n",
      "new best score!!!!\n",
      "Loading the best finetuned validation model!\n",
      "Fine Tuning Final Test Performance : Test Accuracy: 0.9491604  Test weighted F1: 0.9471710  Test macro F1 0.8127613 \n",
      "================ the 12 th CV Experiment ================ \n",
      "Leave one Out Experiment : The 13 Part as the test\n",
      "[-] Target sampling weights:  [0.00060496 0.00063251 0.00069204 0.0005787  0.00052687 0.0005339\n",
      " 0.00689655 0.00900901 0.00606061 0.00684932 0.00507614 0.00657895]\n",
      "================ Build the model ================ \n",
      "Wavelet Filtering Regularization\n",
      "Build the DeepConvLSTM model!\n",
      "Train data number :  11094\n",
      "The number of classes is :  12\n",
      "The input_length  is :  128\n",
      "The channel_in is :  6\n",
      "Validation data number :  1233\n",
      "Test data number :  2179\n",
      "Epoch: 1 cost time: 13.329219102859497\n",
      "VALI: Epoch: 1, Steps: 87 | Train Loss: 0.8233399  Vali Loss: 0.2990860 Vali Accuracy: 0.8969992  Vali weighted F1: 0.8921864  Vali macro F1 0.6991945 \n",
      "Validation loss decreased (inf --> 0.299086).  Saving model ...\n",
      "Epoch: 2 cost time: 13.35213828086853\n",
      "VALI: Epoch: 2, Steps: 87 | Train Loss: 0.2964415  Vali Loss: 0.2050012 Vali Accuracy: 0.9245742  Vali weighted F1: 0.9196092  Vali macro F1 0.7177135 \n",
      "new best score!!!!\n",
      "Validation loss decreased (0.299086 --> 0.205001).  Saving model ...\n",
      "new best score!!!!\n",
      "Loading the best validation model!\n",
      "Final Test Performance : Test Accuracy: 0.9206058  Test weighted F1: 0.9183497  Test macro F1 0.7401133 \n",
      "Wavelet Filtering Regularization\n",
      "Build the DeepConvLSTM model!\n",
      "------------Fine Tuning  :  36   will be pruned   -----------------------------------------\n",
      "old model Parameter : 738559\n",
      "pruned model Parameter : 727003\n",
      "----------------------------------------------------------------------------------------\n",
      "Fine Tuning Epoch: 1 cost time: 13.468364238739014\n",
      "Fine Tuning VALI: Epoch: 1, Steps: 87 | Train Loss: 0.2452816  Vali Loss: 0.1784153 Vali Accuracy: 0.9343066  Vali weighted F1: 0.9323493  Vali macro F1 0.7623962 \n",
      "Validation loss decreased (inf --> 0.178415).  Saving model ...\n",
      "Fine Tuning Epoch: 2 cost time: 13.464004039764404\n",
      "Fine Tuning VALI: Epoch: 2, Steps: 87 | Train Loss: 0.2103407  Vali Loss: 0.1632455 Vali Accuracy: 0.9351176  Vali weighted F1: 0.9328972  Vali macro F1 0.7635781 \n",
      "new best score!!!!\n",
      "Validation loss decreased (0.178415 --> 0.163245).  Saving model ...\n",
      "new best score!!!!\n",
      "Loading the best finetuned validation model!\n",
      "Fine Tuning Final Test Performance : Test Accuracy: 0.9412575  Test weighted F1: 0.9381909  Test macro F1 0.7954489 \n",
      "================ the 13 th CV Experiment ================ \n",
      "Leave one Out Experiment : The 14 Part as the test\n",
      "[-] Target sampling weights:  [0.00060314 0.00062854 0.00068213 0.00058514 0.0005291  0.00053191\n",
      " 0.00704225 0.00943396 0.0060241  0.00666667 0.00507614 0.0070922 ]\n",
      "================ Build the model ================ \n",
      "Wavelet Filtering Regularization\n",
      "Build the DeepConvLSTM model!\n",
      "Train data number :  11096\n",
      "The number of classes is :  12\n",
      "The input_length  is :  128\n",
      "The channel_in is :  6\n",
      "Validation data number :  1233\n",
      "Test data number :  2158\n",
      "Epoch: 1 cost time: 12.74943208694458\n",
      "VALI: Epoch: 1, Steps: 87 | Train Loss: 0.8117697  Vali Loss: 0.3071175 Vali Accuracy: 0.8856448  Vali weighted F1: 0.8786996  Vali macro F1 0.6529018 \n",
      "Validation loss decreased (inf --> 0.307117).  Saving model ...\n",
      "Epoch: 2 cost time: 12.710833072662354\n",
      "VALI: Epoch: 2, Steps: 87 | Train Loss: 0.2811095  Vali Loss: 0.2532759 Vali Accuracy: 0.9083536  Vali weighted F1: 0.9085540  Vali macro F1 0.7264596 \n",
      "new best score!!!!\n",
      "Validation loss decreased (0.307117 --> 0.253276).  Saving model ...\n",
      "new best score!!!!\n",
      "Loading the best validation model!\n",
      "Final Test Performance : Test Accuracy: 0.7075996  Test weighted F1: 0.6678529  Test macro F1 0.5615828 \n",
      "Wavelet Filtering Regularization\n",
      "Build the DeepConvLSTM model!\n",
      "------------Fine Tuning  :  36   will be pruned   -----------------------------------------\n",
      "old model Parameter : 738559\n",
      "pruned model Parameter : 727003\n",
      "----------------------------------------------------------------------------------------\n",
      "Fine Tuning Epoch: 1 cost time: 12.83890962600708\n",
      "Fine Tuning VALI: Epoch: 1, Steps: 87 | Train Loss: 0.2252441  Vali Loss: 0.2271430 Vali Accuracy: 0.9205191  Vali weighted F1: 0.9192078  Vali macro F1 0.7597208 \n",
      "Validation loss decreased (inf --> 0.227143).  Saving model ...\n",
      "Fine Tuning Epoch: 2 cost time: 12.882990837097168\n",
      "Fine Tuning VALI: Epoch: 2, Steps: 87 | Train Loss: 0.2019994  Vali Loss: 0.2174880 Vali Accuracy: 0.9245742  Vali weighted F1: 0.9244397  Vali macro F1 0.7893957 \n",
      "new best score!!!!\n",
      "Validation loss decreased (0.227143 --> 0.217488).  Saving model ...\n",
      "new best score!!!!\n",
      "Loading the best finetuned validation model!\n",
      "Fine Tuning Final Test Performance : Test Accuracy: 0.6635774  Test weighted F1: 0.6227002  Test macro F1 0.5349330 \n",
      "================ the 14 th CV Experiment ================ \n",
      "Leave one Out Experiment : The 15 Part as the test\n",
      "[-] Target sampling weights:  [0.0005988  0.00062422 0.00068776 0.00057904 0.00052411 0.00054466\n",
      " 0.00714286 0.00952381 0.00628931 0.00666667 0.0052356  0.00684932]\n",
      "================ Build the model ================ \n",
      "Wavelet Filtering Regularization\n",
      "Build the DeepConvLSTM model!\n",
      "Train data number :  11088\n",
      "The number of classes is :  12\n",
      "The input_length  is :  128\n",
      "The channel_in is :  6\n",
      "Validation data number :  1232\n",
      "Test data number :  2185\n",
      "Epoch: 1 cost time: 12.71161150932312\n",
      "VALI: Epoch: 1, Steps: 87 | Train Loss: 0.8340012  Vali Loss: 0.3041407 Vali Accuracy: 0.8952922  Vali weighted F1: 0.8855441  Vali macro F1 0.6720802 \n",
      "Validation loss decreased (inf --> 0.304141).  Saving model ...\n",
      "Epoch: 2 cost time: 12.703912019729614\n",
      "VALI: Epoch: 2, Steps: 87 | Train Loss: 0.2691767  Vali Loss: 0.2178831 Vali Accuracy: 0.9139610  Vali weighted F1: 0.9102092  Vali macro F1 0.7573634 \n",
      "new best score!!!!\n",
      "Validation loss decreased (0.304141 --> 0.217883).  Saving model ...\n",
      "new best score!!!!\n",
      "Loading the best validation model!\n",
      "Final Test Performance : Test Accuracy: 0.9533181  Test weighted F1: 0.9508347  Test macro F1 0.7522090 \n",
      "Wavelet Filtering Regularization\n",
      "Build the DeepConvLSTM model!\n",
      "------------Fine Tuning  :  36   will be pruned   -----------------------------------------\n",
      "old model Parameter : 738559\n",
      "pruned model Parameter : 727003\n",
      "----------------------------------------------------------------------------------------\n",
      "Fine Tuning Epoch: 1 cost time: 12.864948272705078\n",
      "Fine Tuning VALI: Epoch: 1, Steps: 87 | Train Loss: 0.2114142  Vali Loss: 0.1927766 Vali Accuracy: 0.9334416  Vali weighted F1: 0.9324791  Vali macro F1 0.7748277 \n",
      "Validation loss decreased (inf --> 0.192777).  Saving model ...\n",
      "Fine Tuning Epoch: 2 cost time: 12.810938835144043\n",
      "Fine Tuning VALI: Epoch: 2, Steps: 87 | Train Loss: 0.1785170  Vali Loss: 0.1733585 Vali Accuracy: 0.9391234  Vali weighted F1: 0.9376659  Vali macro F1 0.7914942 \n",
      "new best score!!!!\n",
      "Validation loss decreased (0.192777 --> 0.173359).  Saving model ...\n",
      "new best score!!!!\n",
      "Loading the best finetuned validation model!\n",
      "Fine Tuning Final Test Performance : Test Accuracy: 0.9519451  Test weighted F1: 0.9522228  Test macro F1 0.7985930 \n",
      "================ the 15 th CV Experiment ================ \n",
      "Leave one Out Experiment : The 16 Part as the test\n",
      "[-] Target sampling weights:  [0.00060168 0.00063211 0.00068776 0.00058173 0.00052854 0.00053879\n",
      " 0.00699301 0.00961538 0.00609756 0.00689655 0.005      0.00684932]\n",
      "================ Build the model ================ \n",
      "Wavelet Filtering Regularization\n",
      "Build the DeepConvLSTM model!\n",
      "Train data number :  11067\n",
      "The number of classes is :  12\n",
      "The input_length  is :  128\n",
      "The channel_in is :  6\n",
      "Validation data number :  1230\n",
      "Test data number :  2332\n",
      "Epoch: 1 cost time: 12.630470275878906\n",
      "VALI: Epoch: 1, Steps: 87 | Train Loss: 0.7714543  Vali Loss: 0.4080447 Vali Accuracy: 0.8390244  Vali weighted F1: 0.8341941  Vali macro F1 0.6207637 \n",
      "Validation loss decreased (inf --> 0.408045).  Saving model ...\n",
      "Epoch: 2 cost time: 12.671409845352173\n",
      "VALI: Epoch: 2, Steps: 87 | Train Loss: 0.2705826  Vali Loss: 0.2489767 Vali Accuracy: 0.9130081  Vali weighted F1: 0.9112205  Vali macro F1 0.7715495 \n",
      "new best score!!!!\n",
      "Validation loss decreased (0.408045 --> 0.248977).  Saving model ...\n",
      "new best score!!!!\n",
      "Loading the best validation model!\n",
      "Final Test Performance : Test Accuracy: 0.7748714  Test weighted F1: 0.7720442  Test macro F1 0.6835162 \n",
      "Wavelet Filtering Regularization\n",
      "Build the DeepConvLSTM model!\n",
      "------------Fine Tuning  :  36   will be pruned   -----------------------------------------\n",
      "old model Parameter : 738559\n",
      "pruned model Parameter : 727003\n",
      "----------------------------------------------------------------------------------------\n",
      "Fine Tuning Epoch: 1 cost time: 12.684103727340698\n",
      "Fine Tuning VALI: Epoch: 1, Steps: 87 | Train Loss: 0.2244118  Vali Loss: 0.2321551 Vali Accuracy: 0.9203252  Vali weighted F1: 0.9189968  Vali macro F1 0.8027797 \n",
      "Validation loss decreased (inf --> 0.232155).  Saving model ...\n",
      "Fine Tuning Epoch: 2 cost time: 12.712304592132568\n",
      "Fine Tuning VALI: Epoch: 2, Steps: 87 | Train Loss: 0.1961989  Vali Loss: 0.2183699 Vali Accuracy: 0.9195122  Vali weighted F1: 0.9186869  Vali macro F1 0.8021749 \n",
      "new best score!!!!\n",
      "Validation loss decreased (0.232155 --> 0.218370).  Saving model ...\n",
      "new best score!!!!\n",
      "Loading the best finetuned validation model!\n",
      "Fine Tuning Final Test Performance : Test Accuracy: 0.7727273  Test weighted F1: 0.7717604  Test macro F1 0.6812193 \n",
      "================ the 16 th CV Experiment ================ \n",
      "Leave one Out Experiment : The 17 Part as the test\n",
      "[-] Target sampling weights:  [0.00059952 0.00063291 0.00067705 0.00057737 0.00053821 0.00054585\n",
      " 0.00699301 0.00952381 0.00606061 0.00680272 0.00510204 0.0070922 ]\n",
      "================ Build the model ================ \n",
      "Wavelet Filtering Regularization\n",
      "Build the DeepConvLSTM model!\n",
      "Train data number :  11044\n",
      "The number of classes is :  12\n",
      "The input_length  is :  128\n",
      "The channel_in is :  6\n",
      "Validation data number :  1228\n",
      "Test data number :  2459\n",
      "Epoch: 1 cost time: 13.326303958892822\n",
      "VALI: Epoch: 1, Steps: 87 | Train Loss: 0.7944619  Vali Loss: 0.3264833 Vali Accuracy: 0.8859935  Vali weighted F1: 0.8811362  Vali macro F1 0.6862022 \n",
      "Validation loss decreased (inf --> 0.326483).  Saving model ...\n",
      "Epoch: 2 cost time: 13.266702890396118\n",
      "VALI: Epoch: 2, Steps: 87 | Train Loss: 0.2712385  Vali Loss: 0.2349523 Vali Accuracy: 0.9210098  Vali weighted F1: 0.9194587  Vali macro F1 0.7691086 \n",
      "new best score!!!!\n",
      "Validation loss decreased (0.326483 --> 0.234952).  Saving model ...\n",
      "new best score!!!!\n",
      "Loading the best validation model!\n",
      "Final Test Performance : Test Accuracy: 0.9182595  Test weighted F1: 0.9157049  Test macro F1 0.7562694 \n",
      "Wavelet Filtering Regularization\n",
      "Build the DeepConvLSTM model!\n",
      "------------Fine Tuning  :  36   will be pruned   -----------------------------------------\n",
      "old model Parameter : 738559\n",
      "pruned model Parameter : 727003\n",
      "----------------------------------------------------------------------------------------\n",
      "Fine Tuning Epoch: 1 cost time: 13.36991286277771\n",
      "Fine Tuning VALI: Epoch: 1, Steps: 87 | Train Loss: 0.2367937  Vali Loss: 0.2230667 Vali Accuracy: 0.9250814  Vali weighted F1: 0.9229582  Vali macro F1 0.7816173 \n",
      "Validation loss decreased (inf --> 0.223067).  Saving model ...\n",
      "Fine Tuning Epoch: 2 cost time: 13.445669889450073\n",
      "Fine Tuning VALI: Epoch: 2, Steps: 87 | Train Loss: 0.1904499  Vali Loss: 0.1977498 Vali Accuracy: 0.9315961  Vali weighted F1: 0.9297479  Vali macro F1 0.7878934 \n",
      "new best score!!!!\n",
      "Validation loss decreased (0.223067 --> 0.197750).  Saving model ...\n",
      "new best score!!!!\n",
      "Loading the best finetuned validation model!\n",
      "Fine Tuning Final Test Performance : Test Accuracy: 0.9251728  Test weighted F1: 0.9239826  Test macro F1 0.7915227 \n",
      "================ the 17 th CV Experiment ================ \n",
      "Leave one Out Experiment : The 18 Part as the test\n",
      "[-] Target sampling weights:  [0.00060753 0.00063452 0.00068399 0.00058038 0.00053305 0.00053619\n",
      " 0.00699301 0.01       0.00598802 0.00666667 0.0052356  0.00694444]\n",
      "================ Build the model ================ \n",
      "Wavelet Filtering Regularization\n",
      "Build the DeepConvLSTM model!\n",
      "Train data number :  11043\n",
      "The number of classes is :  12\n",
      "The input_length  is :  128\n",
      "The channel_in is :  6\n",
      "Validation data number :  1228\n",
      "Test data number :  2466\n",
      "Epoch: 1 cost time: 12.466011762619019\n",
      "VALI: Epoch: 1, Steps: 87 | Train Loss: 0.8068726  Vali Loss: 0.3471876 Vali Accuracy: 0.8705212  Vali weighted F1: 0.8572630  Vali macro F1 0.5805062 \n",
      "Validation loss decreased (inf --> 0.347188).  Saving model ...\n",
      "Epoch: 2 cost time: 12.453880071640015\n",
      "VALI: Epoch: 2, Steps: 87 | Train Loss: 0.2798998  Vali Loss: 0.2543296 Vali Accuracy: 0.9063518  Vali weighted F1: 0.9042665  Vali macro F1 0.7669228 \n",
      "new best score!!!!\n",
      "Validation loss decreased (0.347188 --> 0.254330).  Saving model ...\n",
      "new best score!!!!\n",
      "Loading the best validation model!\n",
      "Final Test Performance : Test Accuracy: 0.9164639  Test weighted F1: 0.9114489  Test macro F1 0.7598909 \n",
      "Wavelet Filtering Regularization\n",
      "Build the DeepConvLSTM model!\n",
      "------------Fine Tuning  :  36   will be pruned   -----------------------------------------\n",
      "old model Parameter : 738559\n",
      "pruned model Parameter : 727003\n",
      "----------------------------------------------------------------------------------------\n",
      "Fine Tuning Epoch: 1 cost time: 12.943143367767334\n",
      "Fine Tuning VALI: Epoch: 1, Steps: 87 | Train Loss: 0.2640877  Vali Loss: 0.2273429 Vali Accuracy: 0.9210098  Vali weighted F1: 0.9190779  Vali macro F1 0.7887662 \n",
      "Validation loss decreased (inf --> 0.227343).  Saving model ...\n"
     ]
    }
   ],
   "source": [
    "exp.train()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "SDIL",
   "language": "python",
   "name": "sdil"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.13"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": true
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
