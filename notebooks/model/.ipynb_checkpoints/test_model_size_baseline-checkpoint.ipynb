{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "894e2c21",
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "import sys\n",
    "sys.path.append(\"../../\")\n",
    "\n",
    "from experiment import Exp\n",
    "\n",
    "from dataloaders import data_set,data_dict\n",
    "import torch\n",
    "import yaml\n",
    "import os"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bcc56bc7",
   "metadata": {},
   "source": [
    "# 参数设置"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dcc5bcbc",
   "metadata": {
    "tags": []
   },
   "source": [
    "# 训练参数 \n",
    "除了路径 其他不要变"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "86004ce0",
   "metadata": {},
   "outputs": [],
   "source": [
    "class dotdict(dict):\n",
    "    \"\"\"dot.notation access to dictionary attributes\"\"\"\n",
    "    __getattr__ = dict.get\n",
    "    __setattr__ = dict.__setitem__\n",
    "    __delattr__ = dict.__delitem__\n",
    "\n",
    "args = dotdict()   \n",
    "# TODO change the path as relative path\n",
    "args.to_save_path     = \"../../../ISWC2022LearnableFilter/Run_logs\"              \n",
    "args.freq_save_path   = \"../../../ISWC2022LearnableFilter/Freq_data\"\n",
    "args.window_save_path = \"../../../ISWC2022LearnableFilter/Sliding_window\"\n",
    "args.root_path        = \"../../../datasets\"\n",
    "\n",
    "\n",
    "args.drop_transition  = False\n",
    "args.datanorm_type    = \"standardization\" # None ,\"standardization\", \"minmax\"\n",
    "\n",
    "\n",
    "args.batch_size       = 256                                                    \n",
    "args.shuffle          = True\n",
    "args.drop_last        = False\n",
    "args.train_vali_quote = 0.90                                           \n",
    "\n",
    "\n",
    "# training setting \n",
    "args.train_epochs            = 150\n",
    "\n",
    "args.learning_rate           = 0.001  \n",
    "args.learning_rate_patience  = 5\n",
    "args.learning_rate_factor    = 0.1\n",
    "\n",
    "\n",
    "args.early_stop_patience     = 15\n",
    "\n",
    "args.use_gpu                 = True if torch.cuda.is_available() else False\n",
    "args.gpu                     = 0\n",
    "args.use_multi_gpu           = False\n",
    "\n",
    "args.optimizer               = \"Adam\"\n",
    "args.criterion               = \"CrossEntropy\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c282cbcb",
   "metadata": {},
   "source": [
    "## 数据参数\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "c6cd147b",
   "metadata": {},
   "outputs": [],
   "source": [
    "args.data_name                        =  \"rw\"\n",
    "\n",
    "args.wavelet_filtering                = False\n",
    "args.wavelet_filtering_regularization = False\n",
    "args.wavelet_filtering_finetuning     = False\n",
    "\n",
    "\n",
    "args.difference       = False \n",
    "args.filtering        = False\n",
    "args.magnitude        = False\n",
    "args.weighted_sampler = False\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "args.pos_select       = None\n",
    "args.sensor_select    = None\n",
    "\n",
    "\n",
    "args.representation_type = \"time\"\n",
    "args.exp_mode            = \"LOCV\"\n",
    "if args.data_name      ==  \"skodar\":\n",
    "    args.exp_mode            = \"SOCV\"\n",
    "\n",
    "config_file = open('../../configs/data.yaml', mode='r')\n",
    "data_config = yaml.load(config_file, Loader=yaml.FullLoader)\n",
    "config = data_config[args.data_name]\n",
    "\n",
    "args.root_path       = os.path.join(args.root_path,config[\"filename\"])\n",
    "args.sampling_freq   = config[\"sampling_freq\"]\n",
    "args.num_classes     =  config[\"num_classes\"]\n",
    "window_seconds       = config[\"window_seconds\"]\n",
    "args.windowsize      =   int(window_seconds * args.sampling_freq) \n",
    "args.input_length    =  args.windowsize\n",
    "# input information\n",
    "args.c_in            = config[\"num_channels\"]\n",
    "\n",
    "if args.wavelet_filtering :\n",
    "    \n",
    "    if args.windowsize%2==1:\n",
    "        N_ds = int(torch.log2(torch.tensor(args.windowsize-1)).floor()) - 2\n",
    "    else:\n",
    "        N_ds = int(torch.log2(torch.tensor(args.windowsize)).floor()) - 2\n",
    "\n",
    "    args.f_in            =  args.number_wavelet_filtering*N_ds+1\n",
    "else:\n",
    "    args.f_in            =  1"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4d435a4c",
   "metadata": {},
   "source": [
    "## 模型参数"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "de2f4d16",
   "metadata": {},
   "outputs": [],
   "source": [
    "args.filter_scaling_factor = 0.25\n",
    "args.model_type            = \"deepconvlstm\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cada66dd",
   "metadata": {},
   "source": [
    "# 实验"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2e3f2fad",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Use GPU: cuda:0\n",
      "Build the DeepConvLSTM model!\n",
      "Done!\n",
      "Parameter : 51608\n",
      "Set the seed as :  1\n",
      " ----------------------- load all the data -------------------\n",
      "-----------------------Sliding file are generated -----------------------\n",
      "-----------------------Sliding file are generated -----------------------\n",
      "================ LOCV Mode ====================\n",
      "================ 15 CV ======================\n",
      "================ the 0 th CV Experiment ================ \n",
      "Leave one Out Experiment : The 1 Part as the test\n",
      "[-] Target sampling weights:  [0.00023935 0.00020614 0.00114025 0.00015751 0.00014501 0.00015934\n",
      " 0.00016038 0.00015716]\n",
      "Train data number :  42025\n",
      "The number of classes is :  8\n",
      "The input_length  is :  128\n",
      "The channel_in is :  21\n",
      "Validation data number :  4670\n",
      "Test data number :  17903\n",
      "================Skip the 0 CV Experiment================\n",
      "================ the 1 th CV Experiment ================ \n",
      "Leave one Out Experiment : The 2 Part as the test\n",
      "[-] Target sampling weights:  [0.00024073 0.00019051 0.00113122 0.00015868 0.00014059 0.0001578\n",
      " 0.00016046 0.0001562 ]\n",
      "Train data number :  42673\n",
      "The number of classes is :  8\n",
      "The input_length  is :  128\n",
      "The channel_in is :  21\n",
      "Validation data number :  4742\n",
      "Test data number :  14069\n",
      "================Skip the 1 CV Experiment================\n",
      "================ the 2 th CV Experiment ================ \n",
      "Leave one Out Experiment : The 3 Part as the test\n",
      "[-] Target sampling weights:  [0.00024301 0.00020777 0.00113636 0.00015751 0.00014678 0.00015913\n",
      " 0.00015995 0.00015785]\n",
      "Train data number :  41841\n",
      "The number of classes is :  8\n",
      "The input_length  is :  128\n",
      "The channel_in is :  21\n",
      "Validation data number :  4649\n",
      "Test data number :  18998\n",
      "================Skip the 2 CV Experiment================\n",
      "================ the 3 th CV Experiment ================ \n",
      "Leave one Out Experiment : The 4 Part as the test\n",
      "[-] Target sampling weights:  [0.00022904 0.00019885 0.00112994 0.0001581  0.00015142 0.00015954\n",
      " 0.00015972 0.00015659]\n",
      "Train data number :  42124\n",
      "The number of classes is :  8\n",
      "The input_length  is :  128\n",
      "The channel_in is :  21\n",
      "Validation data number :  4681\n",
      "Test data number :  17311\n",
      "================Skip the 3 CV Experiment================\n",
      "================ the 4 th CV Experiment ================ \n",
      "Leave one Out Experiment : The 5 Part as the test\n",
      "[-] Target sampling weights:  [0.00023923 0.00020855 0.00113379 0.00015848 0.00015242 0.00015893\n",
      " 0.00015967 0.00015868]\n",
      "Train data number :  41585\n",
      "The number of classes is :  8\n",
      "The input_length  is :  128\n",
      "The channel_in is :  21\n",
      "Validation data number :  4621\n",
      "Test data number :  20508\n",
      "================Skip the 4 CV Experiment================\n",
      "================ the 5 th CV Experiment ================ \n",
      "Leave one Out Experiment : The 6 Part as the test\n",
      "[-] Target sampling weights:  [0.00023946 0.00020589 0.0010582  0.00015758 0.00014535 0.00015936\n",
      " 0.00016054 0.00015718]\n",
      "Train data number :  42070\n",
      "The number of classes is :  8\n",
      "The input_length  is :  128\n",
      "The channel_in is :  21\n",
      "Validation data number :  4675\n",
      "Test data number :  17641\n",
      "================Skip the 5 CV Experiment================\n",
      "================ the 6 th CV Experiment ================ \n",
      "Leave one Out Experiment : The 7 Part as the test\n",
      "[-] Target sampling weights:  [0.00022862 0.00019631 0.00113122 0.00015765 0.00014656 0.00015985\n",
      " 0.00015987 0.00015738]\n",
      "Train data number :  42383\n",
      "The number of classes is :  8\n",
      "The input_length  is :  128\n",
      "The channel_in is :  21\n",
      "Validation data number :  4710\n",
      "Test data number :  15785\n",
      "================Skip the 6 CV Experiment================\n",
      "================ the 7 th CV Experiment ================ \n",
      "Leave one Out Experiment : The 8 Part as the test\n",
      "[-] Target sampling weights:  [0.00023663 0.0002265  0.00114025 0.00015843 0.00014397 0.00015954\n",
      " 0.00016108 0.00015731]\n",
      "Train data number :  41609\n",
      "The number of classes is :  8\n",
      "The input_length  is :  128\n",
      "The channel_in is :  21\n",
      "Validation data number :  4624\n",
      "Test data number :  20366\n",
      "================Skip the 7 CV Experiment================\n",
      "================ the 8 th CV Experiment ================ \n",
      "Leave one Out Experiment : The 9 Part as the test\n",
      "[-] Target sampling weights:  [0.00024033 0.00020644 0.00113636 0.00015733 0.00014797 0.00015929\n",
      " 0.00016041 0.00015694]\n",
      "Train data number :  41883\n",
      "The number of classes is :  8\n",
      "The input_length  is :  128\n",
      "The channel_in is :  21\n",
      "Validation data number :  4654\n",
      "Test data number :  18740\n",
      "================Skip the 8 CV Experiment================\n",
      "================ the 9 th CV Experiment ================ \n",
      "Leave one Out Experiment : The 10 Part as the test\n",
      "[-] Target sampling weights:  [0.00023607 0.00020425 0.0011534  0.00015775 0.0001451  0.00015926\n",
      " 0.00016088 0.00015718]\n",
      "Train data number :  42087\n",
      "The number of classes is :  8\n",
      "The input_length  is :  128\n",
      "The channel_in is :  21\n",
      "Validation data number :  4677\n",
      "Test data number :  17533\n",
      "================Skip the 9 CV Experiment================\n",
      "================ the 10 th CV Experiment ================ \n",
      "Leave one Out Experiment : The 11 Part as the test\n",
      "[-] Target sampling weights:  [0.00023946 0.00020877 0.00114811 0.0001582  0.00014484 0.00015853\n",
      " 0.00016093 0.00015716]\n",
      "Train data number :  41947\n",
      "The number of classes is :  8\n",
      "The input_length  is :  128\n",
      "The channel_in is :  21\n",
      "Validation data number :  4661\n",
      "Test data number :  18360\n",
      "================Skip the 10 CV Experiment================\n",
      "================ the 11 th CV Experiment ================ \n",
      "Leave one Out Experiment : The 12 Part as the test\n",
      "[-] Target sampling weights:  [0.00023866 0.00020708 0.00114548 0.00015721 0.00014499 0.00015883\n",
      " 0.00016026 0.00015706]\n",
      "Train data number :  42053\n",
      "The number of classes is :  8\n",
      "The input_length  is :  128\n",
      "The channel_in is :  21\n",
      "Validation data number :  4673\n",
      "Test data number :  17736\n",
      "================Skip the 11 CV Experiment================\n",
      "================ the 12 th CV Experiment ================ \n",
      "Leave one Out Experiment : The 13 Part as the test\n",
      "[-] Target sampling weights:  [0.00023821 0.00020803 0.00114155 0.00015768 0.00014486 0.00015939\n",
      " 0.00016116 0.00015721]\n",
      "Train data number :  41966\n",
      "The number of classes is :  8\n",
      "The input_length  is :  128\n",
      "The channel_in is :  21\n",
      "Validation data number :  4663\n",
      "Test data number :  18256\n",
      "================Skip the 12 CV Experiment================\n",
      "================ the 13 th CV Experiment ================ \n",
      "Leave one Out Experiment : The 14 Part as the test\n",
      "[-] Target sampling weights:  [0.00022645 0.00019474 0.00116414 0.0001583  0.00014497 0.00015823\n",
      " 0.00015987 0.0001581 ]\n",
      "Train data number :  42525\n",
      "The number of classes is :  8\n",
      "The input_length  is :  128\n",
      "The channel_in is :  21\n",
      "Validation data number :  4725\n",
      "Test data number :  14947\n",
      "================Skip the 13 CV Experiment================\n",
      "================ the 14 th CV Experiment ================ \n",
      "Leave one Out Experiment : The 15 Part as the test\n",
      "[-] Target sampling weights:  [0.00024044 0.00020717 0.00112994 0.00015873 0.00014582 0.00015901\n",
      " 0.00016038 0.00015716]\n",
      "Train data number :  41916\n",
      "The number of classes is :  8\n",
      "The input_length  is :  128\n",
      "The channel_in is :  21\n",
      "Validation data number :  4658\n",
      "Test data number :  18542\n",
      "================Skip the 14 CV Experiment================\n",
      "Use GPU: cuda:0\n",
      "Build the DeepConvLSTM model!\n",
      "Done!\n",
      "Parameter : 51608\n",
      "Set the seed as :  2\n",
      " ----------------------- load all the data -------------------\n",
      "-----------------------Sliding file are generated -----------------------\n",
      "-----------------------Sliding file are generated -----------------------\n",
      "================ LOCV Mode ====================\n",
      "================ 15 CV ======================\n",
      "================ the 0 th CV Experiment ================ \n",
      "Leave one Out Experiment : The 1 Part as the test\n",
      "[-] Target sampling weights:  [0.00024184 0.00020602 0.00112613 0.00015901 0.00014329 0.00015964\n",
      " 0.00016075 0.00015637]\n",
      "Train data number :  42025\n",
      "The number of classes is :  8\n",
      "The input_length  is :  128\n",
      "The channel_in is :  21\n",
      "Validation data number :  4670\n",
      "Test data number :  17903\n",
      "================Skip the 0 CV Experiment================\n",
      "================ the 1 th CV Experiment ================ \n",
      "Leave one Out Experiment : The 2 Part as the test\n",
      "[-] Target sampling weights:  [0.00024137 0.00019131 0.00113379 0.00015845 0.00013978 0.0001583\n",
      " 0.00015985 0.00015667]\n",
      "Train data number :  42673\n",
      "The number of classes is :  8\n",
      "The input_length  is :  128\n",
      "The channel_in is :  21\n",
      "Validation data number :  4742\n",
      "Test data number :  14069\n",
      "================Skip the 1 CV Experiment================\n",
      "================ the 2 th CV Experiment ================ \n",
      "Leave one Out Experiment : The 3 Part as the test\n",
      "[-] Target sampling weights:  [0.00024137 0.00020855 0.00114943 0.00015888 0.00014637 0.0001583\n",
      " 0.00016026 0.00015748]\n",
      "Train data number :  41841\n",
      "The number of classes is :  8\n",
      "The input_length  is :  128\n",
      "The channel_in is :  21\n",
      "Validation data number :  4649\n",
      "Test data number :  18998\n",
      "================Skip the 2 CV Experiment================\n",
      "================ the 3 th CV Experiment ================ \n",
      "Leave one Out Experiment : The 4 Part as the test\n",
      "[-] Target sampling weights:  [0.0002301  0.0001994  0.00113895 0.00015881 0.00015074 0.0001583\n",
      " 0.00016023 0.00015635]\n",
      "Train data number :  42124\n",
      "The number of classes is :  8\n",
      "The input_length  is :  128\n",
      "The channel_in is :  21\n",
      "Validation data number :  4681\n",
      "Test data number :  17311\n",
      "================Skip the 3 CV Experiment================\n",
      "================ the 4 th CV Experiment ================ \n",
      "Leave one Out Experiment : The 5 Part as the test\n",
      "[-] Target sampling weights:  [0.00023861 0.00020894 0.00113766 0.00015918 0.00015161 0.0001584\n",
      " 0.00016049 0.00015855]\n",
      "Train data number :  41585\n",
      "The number of classes is :  8\n",
      "The input_length  is :  128\n",
      "The channel_in is :  21\n",
      "Validation data number :  4621\n",
      "Test data number :  20508\n",
      "================Skip the 4 CV Experiment================\n",
      "================ the 5 th CV Experiment ================ \n",
      "Leave one Out Experiment : The 6 Part as the test\n",
      "[-] Target sampling weights:  [0.00023838 0.00020713 0.00104932 0.00015886 0.00014512 0.00015855\n",
      " 0.00016085 0.00015664]\n",
      "Train data number :  42070\n",
      "The number of classes is :  8\n",
      "The input_length  is :  128\n",
      "The channel_in is :  21\n",
      "Validation data number :  4675\n",
      "Test data number :  17641\n",
      "================Skip the 5 CV Experiment================\n",
      "================ the 6 th CV Experiment ================ \n",
      "Leave one Out Experiment : The 7 Part as the test\n",
      "[-] Target sampling weights:  [0.00022722 0.00019736 0.00114155 0.00015936 0.00014616 0.0001585\n",
      " 0.00016069 0.00015649]\n",
      "Train data number :  42383\n",
      "The number of classes is :  8\n",
      "The input_length  is :  128\n",
      "The channel_in is :  21\n",
      "Validation data number :  4710\n",
      "Test data number :  15785\n",
      "================Skip the 6 CV Experiment================\n",
      "================ the 7 th CV Experiment ================ \n",
      "Leave one Out Experiment : The 8 Part as the test\n",
      "[-] Target sampling weights:  [0.00023663 0.00022722 0.00113895 0.00015833 0.00014455 0.00015876\n",
      " 0.00016069 0.00015753]\n",
      "Train data number :  41609\n",
      "The number of classes is :  8\n",
      "The input_length  is :  128\n",
      "The channel_in is :  21\n",
      "Validation data number :  4624\n",
      "Test data number :  20366\n",
      "================Skip the 7 CV Experiment================\n",
      "================ the 8 th CV Experiment ================ \n",
      "Leave one Out Experiment : The 9 Part as the test\n",
      "[-] Target sampling weights:  [0.00023883 0.00020717 0.00114811 0.00015888 0.00014732 0.00015873\n",
      " 0.00016036 0.00015674]\n",
      "Train data number :  41883\n",
      "The number of classes is :  8\n",
      "The input_length  is :  128\n",
      "The channel_in is :  21\n",
      "Validation data number :  4654\n",
      "Test data number :  18740\n",
      "================Skip the 8 CV Experiment================\n",
      "================ the 9 th CV Experiment ================ \n",
      "Leave one Out Experiment : The 10 Part as the test\n",
      "[-] Target sampling weights:  [0.00023725 0.00020454 0.0011655  0.00015845 0.00014468 0.0001583\n",
      " 0.00016113 0.00015676]\n",
      "Train data number :  42087\n",
      "The number of classes is :  8\n",
      "The input_length  is :  128\n",
      "The channel_in is :  21\n",
      "Validation data number :  4677\n",
      "Test data number :  17533\n",
      "================Skip the 9 CV Experiment================\n",
      "================ the 10 th CV Experiment ================ \n",
      "Leave one Out Experiment : The 11 Part as the test\n",
      "[-] Target sampling weights:  [0.00024004 0.00020969 0.00113507 0.00015896 0.00014434 0.00015838\n",
      " 0.00016044 0.00015711]\n",
      "Train data number :  41947\n",
      "The number of classes is :  8\n",
      "The input_length  is :  128\n",
      "The channel_in is :  21\n",
      "Validation data number :  4661\n",
      "Test data number :  18360\n",
      "================Skip the 10 CV Experiment================\n",
      "================ the 11 th CV Experiment ================ \n",
      "Leave one Out Experiment : The 12 Part as the test\n",
      "[-] Target sampling weights:  [0.00023981 0.00020708 0.00115473 0.00015845 0.00014411 0.00015803\n",
      " 0.00016046 0.00015679]\n",
      "Train data number :  42053\n",
      "The number of classes is :  8\n",
      "The input_length  is :  128\n",
      "The channel_in is :  21\n",
      "Validation data number :  4673\n",
      "Test data number :  17736\n",
      "================Skip the 11 CV Experiment================\n",
      "================ the 12 th CV Experiment ================ \n",
      "Leave one Out Experiment : The 13 Part as the test\n",
      "[-] Target sampling weights:  [0.00023641 0.00020907 0.00114943 0.00015924 0.00014428 0.00015855\n",
      " 0.00016137 0.00015704]\n",
      "Train data number :  41966\n",
      "The number of classes is :  8\n",
      "The input_length  is :  128\n",
      "The channel_in is :  21\n",
      "Validation data number :  4663\n",
      "Test data number :  18256\n",
      "================Skip the 12 CV Experiment================\n",
      "================ the 13 th CV Experiment ================ \n",
      "Leave one Out Experiment : The 14 Part as the test\n",
      "[-] Target sampling weights:  [0.00022784 0.00019763 0.00112867 0.00015763 0.00014393 0.00015926\n",
      " 0.00016    0.00015701]\n",
      "Train data number :  42525\n",
      "The number of classes is :  8\n",
      "The input_length  is :  128\n",
      "The channel_in is :  21\n",
      "Validation data number :  4725\n",
      "Test data number :  14947\n",
      "================Skip the 13 CV Experiment================\n",
      "================ the 14 th CV Experiment ================ \n",
      "Leave one Out Experiment : The 15 Part as the test\n",
      "[-] Target sampling weights:  [0.00023992 0.00020899 0.00112994 0.00015924 0.00014482 0.00015931\n",
      " 0.00016013 0.00015696]\n",
      "Train data number :  41916\n",
      "The number of classes is :  8\n",
      "The input_length  is :  128\n",
      "The channel_in is :  21\n",
      "Validation data number :  4658\n",
      "Test data number :  18542\n",
      "================Skip the 14 CV Experiment================\n",
      "Use GPU: cuda:0\n",
      "Build the DeepConvLSTM model!\n",
      "Done!\n",
      "Parameter : 51608\n",
      "Set the seed as :  3\n",
      " ----------------------- load all the data -------------------\n",
      "-----------------------Sliding file are generated -----------------------\n",
      "-----------------------Sliding file are generated -----------------------\n",
      "================ LOCV Mode ====================\n",
      "================ 15 CV ======================\n",
      "================ the 0 th CV Experiment ================ \n",
      "Leave one Out Experiment : The 1 Part as the test\n",
      "[-] Target sampling weights:  [0.00024073 0.00020602 0.00110254 0.00015751 0.0001444  0.00015952\n",
      " 0.00016093 0.00015741]\n",
      "Train data number :  42025\n",
      "The number of classes is :  8\n",
      "The input_length  is :  128\n",
      "The channel_in is :  21\n",
      "Validation data number :  4670\n",
      "Test data number :  17903\n",
      "================ Build the model ================ \n",
      "Build the DeepConvLSTM model!\n",
      "Epoch: 1 cost time: 12.961116075515747\n",
      "VALI: Epoch: 1, Steps: 165 | Train Loss: 0.9358222  Vali Loss: 0.3217046 Vali Accuracy: 0.9128480  Vali weighted F1: 0.9128178  Vali macro F1 0.9029517 \n",
      "Validation loss decreased (inf --> 0.321705).  Saving model ...\n",
      "Epoch: 2 cost time: 12.804665088653564\n",
      "VALI: Epoch: 2, Steps: 165 | Train Loss: 0.2928070  Vali Loss: 0.2115553 Vali Accuracy: 0.9449679  Vali weighted F1: 0.9451181  Vali macro F1 0.9434349 \n",
      "new best score!!!!\n",
      "Validation loss decreased (0.321705 --> 0.211555).  Saving model ...\n",
      "new best score!!!!\n",
      "Epoch: 3 cost time: 12.851065397262573\n",
      "VALI: Epoch: 3, Steps: 165 | Train Loss: 0.2107096  Vali Loss: 0.1567620 Vali Accuracy: 0.9584582  Vali weighted F1: 0.9585468  Vali macro F1 0.9577001 \n",
      "new best score!!!!\n",
      "Validation loss decreased (0.211555 --> 0.156762).  Saving model ...\n",
      "new best score!!!!\n",
      "Epoch: 4 cost time: 12.956939935684204\n",
      "VALI: Epoch: 4, Steps: 165 | Train Loss: 0.1694488  Vali Loss: 0.1394562 Vali Accuracy: 0.9616702  Vali weighted F1: 0.9616055  Vali macro F1 0.9601017 \n",
      "new best score!!!!\n",
      "Validation loss decreased (0.156762 --> 0.139456).  Saving model ...\n",
      "new best score!!!!\n",
      "Epoch: 5 cost time: 12.833025217056274\n",
      "VALI: Epoch: 5, Steps: 165 | Train Loss: 0.1471159  Vali Loss: 0.1245924 Vali Accuracy: 0.9642398  Vali weighted F1: 0.9643110  Vali macro F1 0.9642564 \n",
      "new best score!!!!\n",
      "Validation loss decreased (0.139456 --> 0.124592).  Saving model ...\n",
      "new best score!!!!\n",
      "Epoch: 6 cost time: 12.755343198776245\n",
      "VALI: Epoch: 6, Steps: 165 | Train Loss: 0.1312807  Vali Loss: 0.1057650 Vali Accuracy: 0.9670236  Vali weighted F1: 0.9670066  Vali macro F1 0.9668475 \n",
      "new best score!!!!\n",
      "Validation loss decreased (0.124592 --> 0.105765).  Saving model ...\n",
      "new best score!!!!\n",
      "Epoch: 7 cost time: 12.937582969665527\n",
      "VALI: Epoch: 7, Steps: 165 | Train Loss: 0.1189811  Vali Loss: 0.0942464 Vali Accuracy: 0.9732334  Vali weighted F1: 0.9732224  Vali macro F1 0.9725755 \n",
      "new best score!!!!\n",
      "Validation loss decreased (0.105765 --> 0.094246).  Saving model ...\n",
      "new best score!!!!\n",
      "Epoch: 8 cost time: 12.70082974433899\n",
      "VALI: Epoch: 8, Steps: 165 | Train Loss: 0.1058587  Vali Loss: 0.0828815 Vali Accuracy: 0.9773019  Vali weighted F1: 0.9773070  Vali macro F1 0.9770054 \n",
      "new best score!!!!\n",
      "Validation loss decreased (0.094246 --> 0.082882).  Saving model ...\n",
      "new best score!!!!\n",
      "Epoch: 9 cost time: 12.789387941360474\n",
      "VALI: Epoch: 9, Steps: 165 | Train Loss: 0.0974529  Vali Loss: 0.0825226 Vali Accuracy: 0.9770878  Vali weighted F1: 0.9771012  Vali macro F1 0.9759773 \n",
      "new best score!!!!\n",
      "Validation loss decreased (0.082882 --> 0.082523).  Saving model ...\n",
      "new best score!!!!\n",
      "Epoch: 10 cost time: 12.851884603500366\n",
      "VALI: Epoch: 10, Steps: 165 | Train Loss: 0.0911723  Vali Loss: 0.0788863 Vali Accuracy: 0.9745182  Vali weighted F1: 0.9745371  Vali macro F1 0.9739094 \n",
      "new best score!!!!\n",
      "Validation loss decreased (0.082523 --> 0.078886).  Saving model ...\n",
      "new best score!!!!\n",
      "Epoch: 11 cost time: 12.783608198165894\n",
      "VALI: Epoch: 11, Steps: 165 | Train Loss: 0.0843241  Vali Loss: 0.0721375 Vali Accuracy: 0.9794433  Vali weighted F1: 0.9794477  Vali macro F1 0.9769732 \n",
      "new best score!!!!\n",
      "Validation loss decreased (0.078886 --> 0.072138).  Saving model ...\n",
      "new best score!!!!\n",
      "Epoch: 12 cost time: 12.72064471244812\n",
      "VALI: Epoch: 12, Steps: 165 | Train Loss: 0.0773110  Vali Loss: 0.0658337 Vali Accuracy: 0.9822270  Vali weighted F1: 0.9822317  Vali macro F1 0.9816537 \n",
      "new best score!!!!\n",
      "Validation loss decreased (0.072138 --> 0.065834).  Saving model ...\n",
      "new best score!!!!\n",
      "Epoch: 13 cost time: 12.710294723510742\n",
      "VALI: Epoch: 13, Steps: 165 | Train Loss: 0.0727820  Vali Loss: 0.0598247 Vali Accuracy: 0.9817987  Vali weighted F1: 0.9817987  Vali macro F1 0.9799357 \n",
      "new best score!!!!\n",
      "Validation loss decreased (0.065834 --> 0.059825).  Saving model ...\n",
      "new best score!!!!\n",
      "Epoch: 14 cost time: 12.848884105682373\n",
      "VALI: Epoch: 14, Steps: 165 | Train Loss: 0.0670224  Vali Loss: 0.0600168 Vali Accuracy: 0.9824411  Vali weighted F1: 0.9824545  Vali macro F1 0.9829863 \n",
      "EarlyStopping counter: 1 out of 15\n",
      "Learning rate adjusting counter: 1 out of 5\n",
      "Epoch: 15 cost time: 12.74397611618042\n",
      "VALI: Epoch: 15, Steps: 165 | Train Loss: 0.0639008  Vali Loss: 0.0619993 Vali Accuracy: 0.9828694  Vali weighted F1: 0.9828654  Vali macro F1 0.9834417 \n",
      "EarlyStopping counter: 2 out of 15\n",
      "Learning rate adjusting counter: 2 out of 5\n",
      "Epoch: 16 cost time: 12.743728876113892\n",
      "VALI: Epoch: 16, Steps: 165 | Train Loss: 0.0633879  Vali Loss: 0.0540459 Vali Accuracy: 0.9841542  Vali weighted F1: 0.9841469  Vali macro F1 0.9833499 \n",
      "new best score!!!!\n",
      "Validation loss decreased (0.059825 --> 0.054046).  Saving model ...\n",
      "new best score!!!!\n",
      "Epoch: 17 cost time: 12.93551778793335\n",
      "VALI: Epoch: 17, Steps: 165 | Train Loss: 0.0578676  Vali Loss: 0.0543983 Vali Accuracy: 0.9841542  Vali weighted F1: 0.9841427  Vali macro F1 0.9837157 \n",
      "EarlyStopping counter: 1 out of 15\n",
      "Learning rate adjusting counter: 1 out of 5\n",
      "Epoch: 18 cost time: 12.703262567520142\n",
      "VALI: Epoch: 18, Steps: 165 | Train Loss: 0.0552654  Vali Loss: 0.0578861 Vali Accuracy: 0.9839400  Vali weighted F1: 0.9839479  Vali macro F1 0.9848204 \n",
      "EarlyStopping counter: 2 out of 15\n",
      "Learning rate adjusting counter: 2 out of 5\n",
      "Epoch: 19 cost time: 12.747621059417725\n",
      "VALI: Epoch: 19, Steps: 165 | Train Loss: 0.0543061  Vali Loss: 0.0506521 Vali Accuracy: 0.9856531  Vali weighted F1: 0.9856486  Vali macro F1 0.9860948 \n",
      "new best score!!!!\n",
      "Validation loss decreased (0.054046 --> 0.050652).  Saving model ...\n",
      "new best score!!!!\n",
      "Epoch: 20 cost time: 12.946852684020996\n",
      "VALI: Epoch: 20, Steps: 165 | Train Loss: 0.0483988  Vali Loss: 0.0506169 Vali Accuracy: 0.9860814  Vali weighted F1: 0.9860664  Vali macro F1 0.9861964 \n",
      "new best score!!!!\n",
      "Validation loss decreased (0.050652 --> 0.050617).  Saving model ...\n",
      "new best score!!!!\n",
      "Epoch: 21 cost time: 12.71132755279541\n",
      "VALI: Epoch: 21, Steps: 165 | Train Loss: 0.0470308  Vali Loss: 0.0468205 Vali Accuracy: 0.9869379  Vali weighted F1: 0.9869351  Vali macro F1 0.9865465 \n",
      "new best score!!!!\n",
      "Validation loss decreased (0.050617 --> 0.046821).  Saving model ...\n",
      "new best score!!!!\n",
      "Epoch: 22 cost time: 12.705546617507935\n",
      "VALI: Epoch: 22, Steps: 165 | Train Loss: 0.0439744  Vali Loss: 0.0455661 Vali Accuracy: 0.9892934  Vali weighted F1: 0.9892885  Vali macro F1 0.9887245 \n",
      "new best score!!!!\n",
      "Validation loss decreased (0.046821 --> 0.045566).  Saving model ...\n",
      "new best score!!!!\n",
      "Epoch: 23 cost time: 12.81510615348816\n",
      "VALI: Epoch: 23, Steps: 165 | Train Loss: 0.0442631  Vali Loss: 0.0476486 Vali Accuracy: 0.9852248  Vali weighted F1: 0.9852348  Vali macro F1 0.9848499 \n",
      "EarlyStopping counter: 1 out of 15\n",
      "Learning rate adjusting counter: 1 out of 5\n",
      "Epoch: 24 cost time: 12.811962842941284\n",
      "VALI: Epoch: 24, Steps: 165 | Train Loss: 0.0418670  Vali Loss: 0.0458570 Vali Accuracy: 0.9873662  Vali weighted F1: 0.9873669  Vali macro F1 0.9868409 \n",
      "EarlyStopping counter: 2 out of 15\n",
      "Learning rate adjusting counter: 2 out of 5\n",
      "Epoch: 25 cost time: 12.727923393249512\n",
      "VALI: Epoch: 25, Steps: 165 | Train Loss: 0.0392799  Vali Loss: 0.0396807 Vali Accuracy: 0.9890792  Vali weighted F1: 0.9890732  Vali macro F1 0.9886969 \n",
      "new best score!!!!\n",
      "Validation loss decreased (0.045566 --> 0.039681).  Saving model ...\n",
      "new best score!!!!\n",
      "Epoch: 26 cost time: 12.770198106765747\n",
      "VALI: Epoch: 26, Steps: 165 | Train Loss: 0.0369516  Vali Loss: 0.0358582 Vali Accuracy: 0.9905782  Vali weighted F1: 0.9905712  Vali macro F1 0.9905215 \n",
      "new best score!!!!\n",
      "Validation loss decreased (0.039681 --> 0.035858).  Saving model ...\n",
      "new best score!!!!\n",
      "Epoch: 27 cost time: 12.878353595733643\n",
      "VALI: Epoch: 27, Steps: 165 | Train Loss: 0.0361597  Vali Loss: 0.0429844 Vali Accuracy: 0.9888651  Vali weighted F1: 0.9888703  Vali macro F1 0.9888541 \n",
      "EarlyStopping counter: 1 out of 15\n",
      "Learning rate adjusting counter: 1 out of 5\n",
      "Epoch: 28 cost time: 12.728507280349731\n",
      "VALI: Epoch: 28, Steps: 165 | Train Loss: 0.0334945  Vali Loss: 0.0360209 Vali Accuracy: 0.9897216  Vali weighted F1: 0.9897195  Vali macro F1 0.9892761 \n",
      "EarlyStopping counter: 2 out of 15\n",
      "Learning rate adjusting counter: 2 out of 5\n",
      "Epoch: 29 cost time: 12.763468503952026\n",
      "VALI: Epoch: 29, Steps: 165 | Train Loss: 0.0341894  Vali Loss: 0.0401068 Vali Accuracy: 0.9877944  Vali weighted F1: 0.9878186  Vali macro F1 0.9879377 \n",
      "EarlyStopping counter: 3 out of 15\n",
      "Learning rate adjusting counter: 3 out of 5\n",
      "Epoch: 30 cost time: 12.79687237739563\n",
      "VALI: Epoch: 30, Steps: 165 | Train Loss: 0.0322791  Vali Loss: 0.0382267 Vali Accuracy: 0.9901499  Vali weighted F1: 0.9901386  Vali macro F1 0.9899775 \n",
      "EarlyStopping counter: 4 out of 15\n",
      "Learning rate adjusting counter: 4 out of 5\n",
      "Epoch: 31 cost time: 12.801548480987549\n",
      "VALI: Epoch: 31, Steps: 165 | Train Loss: 0.0318084  Vali Loss: 0.0339830 Vali Accuracy: 0.9901499  Vali weighted F1: 0.9901444  Vali macro F1 0.9904557 \n",
      "new best score!!!!\n",
      "Validation loss decreased (0.035858 --> 0.033983).  Saving model ...\n",
      "new best score!!!!\n",
      "Epoch: 32 cost time: 12.641407251358032\n",
      "VALI: Epoch: 32, Steps: 165 | Train Loss: 0.0308345  Vali Loss: 0.0311230 Vali Accuracy: 0.9914347  Vali weighted F1: 0.9914328  Vali macro F1 0.9914389 \n",
      "new best score!!!!\n",
      "Validation loss decreased (0.033983 --> 0.031123).  Saving model ...\n",
      "new best score!!!!\n",
      "Epoch: 33 cost time: 12.857611656188965\n",
      "VALI: Epoch: 33, Steps: 165 | Train Loss: 0.0270799  Vali Loss: 0.0383560 Vali Accuracy: 0.9875803  Vali weighted F1: 0.9875892  Vali macro F1 0.9868350 \n",
      "EarlyStopping counter: 1 out of 15\n",
      "Learning rate adjusting counter: 1 out of 5\n",
      "Epoch: 34 cost time: 12.627675533294678\n",
      "VALI: Epoch: 34, Steps: 165 | Train Loss: 0.0274929  Vali Loss: 0.0350363 Vali Accuracy: 0.9899358  Vali weighted F1: 0.9899279  Vali macro F1 0.9892221 \n",
      "EarlyStopping counter: 2 out of 15\n",
      "Learning rate adjusting counter: 2 out of 5\n",
      "Epoch: 35 cost time: 12.636341333389282\n",
      "VALI: Epoch: 35, Steps: 165 | Train Loss: 0.0266286  Vali Loss: 0.0335608 Vali Accuracy: 0.9901499  Vali weighted F1: 0.9901454  Vali macro F1 0.9903406 \n",
      "EarlyStopping counter: 3 out of 15\n",
      "Learning rate adjusting counter: 3 out of 5\n",
      "Epoch: 36 cost time: 12.755947828292847\n",
      "VALI: Epoch: 36, Steps: 165 | Train Loss: 0.0257329  Vali Loss: 0.0289411 Vali Accuracy: 0.9925054  Vali weighted F1: 0.9925044  Vali macro F1 0.9925097 \n",
      "new best score!!!!\n",
      "Validation loss decreased (0.031123 --> 0.028941).  Saving model ...\n",
      "new best score!!!!\n",
      "Epoch: 37 cost time: 12.735986948013306\n",
      "VALI: Epoch: 37, Steps: 165 | Train Loss: 0.0233336  Vali Loss: 0.0357572 Vali Accuracy: 0.9910064  Vali weighted F1: 0.9910023  Vali macro F1 0.9901654 \n",
      "EarlyStopping counter: 1 out of 15\n",
      "Learning rate adjusting counter: 1 out of 5\n",
      "Epoch: 38 cost time: 12.645015716552734\n",
      "VALI: Epoch: 38, Steps: 165 | Train Loss: 0.0227373  Vali Loss: 0.0262867 Vali Accuracy: 0.9929336  Vali weighted F1: 0.9929296  Vali macro F1 0.9918828 \n",
      "new best score!!!!\n",
      "Validation loss decreased (0.028941 --> 0.026287).  Saving model ...\n",
      "new best score!!!!\n",
      "Epoch: 39 cost time: 12.663232326507568\n",
      "VALI: Epoch: 39, Steps: 165 | Train Loss: 0.0206724  Vali Loss: 0.0278140 Vali Accuracy: 0.9927195  Vali weighted F1: 0.9927164  Vali macro F1 0.9919574 \n",
      "EarlyStopping counter: 1 out of 15\n",
      "Learning rate adjusting counter: 1 out of 5\n",
      "Epoch: 40 cost time: 12.85692572593689\n",
      "VALI: Epoch: 40, Steps: 165 | Train Loss: 0.0208651  Vali Loss: 0.0314480 Vali Accuracy: 0.9916488  Vali weighted F1: 0.9916446  Vali macro F1 0.9910466 \n",
      "EarlyStopping counter: 2 out of 15\n",
      "Learning rate adjusting counter: 2 out of 5\n",
      "Epoch: 41 cost time: 12.70227336883545\n",
      "VALI: Epoch: 41, Steps: 165 | Train Loss: 0.0226676  Vali Loss: 0.0298042 Vali Accuracy: 0.9925054  Vali weighted F1: 0.9925023  Vali macro F1 0.9916698 \n",
      "EarlyStopping counter: 3 out of 15\n",
      "Learning rate adjusting counter: 3 out of 5\n",
      "Epoch: 42 cost time: 12.683595657348633\n",
      "VALI: Epoch: 42, Steps: 165 | Train Loss: 0.0204230  Vali Loss: 0.0270117 Vali Accuracy: 0.9925054  Vali weighted F1: 0.9925026  Vali macro F1 0.9918287 \n",
      "EarlyStopping counter: 4 out of 15\n",
      "Learning rate adjusting counter: 4 out of 5\n"
     ]
    }
   ],
   "source": [
    "for seed in [1,2,3,4,5]:\n",
    "    args.seed = seed\n",
    "    exp = Exp(args)\n",
    "    exp.train()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "SDIL",
   "language": "python",
   "name": "sdil"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.13"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": true
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
