{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "894e2c21",
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "import sys\n",
    "sys.path.append(\"../../\")\n",
    "\n",
    "from experiment import Exp\n",
    "\n",
    "from dataloaders import data_set,data_dict\n",
    "import torch\n",
    "import yaml\n",
    "import os"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bcc56bc7",
   "metadata": {},
   "source": [
    "# 参数设置"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dcc5bcbc",
   "metadata": {},
   "source": [
    "# 训练参数 \n",
    "除了路径 其他不要变"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "86004ce0",
   "metadata": {},
   "outputs": [],
   "source": [
    "class dotdict(dict):\n",
    "    \"\"\"dot.notation access to dictionary attributes\"\"\"\n",
    "    __getattr__ = dict.get\n",
    "    __setattr__ = dict.__setitem__\n",
    "    __delattr__ = dict.__delitem__\n",
    "\n",
    "args = dotdict()   \n",
    "# TODO change the path as relative path\n",
    "args.to_save_path     = \"../../../ISWC2022LearnableFilter/Run_logs\"              \n",
    "args.freq_save_path   = \"../../../ISWC2022LearnableFilter/Freq_data\"\n",
    "args.window_save_path = \"../../../ISWC2022LearnableFilter/Sliding_window\"\n",
    "args.root_path        = \"../../../datasets\"\n",
    "\n",
    "\n",
    "args.drop_transition  = False\n",
    "args.datanorm_type    = \"standardization\" # None ,\"standardization\", \"minmax\"\n",
    "\n",
    "\n",
    "args.batch_size       = 256                                                    \n",
    "args.shuffle          = True\n",
    "args.drop_last        = False\n",
    "args.train_vali_quote = 0.90                                           \n",
    "\n",
    "\n",
    "# training setting \n",
    "args.train_epochs            = 150\n",
    "\n",
    "args.learning_rate           = 0.001  \n",
    "args.learning_rate_patience  = 5\n",
    "args.learning_rate_factor    = 0.1\n",
    "\n",
    "\n",
    "args.early_stop_patience     = 15\n",
    "\n",
    "args.use_gpu                 = True if torch.cuda.is_available() else False\n",
    "args.gpu                     = 1\n",
    "args.use_multi_gpu           = False\n",
    "\n",
    "args.optimizer               = \"Adam\"\n",
    "args.criterion               = \"CrossEntropy\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c282cbcb",
   "metadata": {},
   "source": [
    "## 数据参数\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "c6cd147b",
   "metadata": {},
   "outputs": [],
   "source": [
    "args.seed                             = 2\n",
    "\n",
    "\n",
    "args.data_name                        =  \"oppo\"\n",
    "\n",
    "args.wavelet_filtering                = True\n",
    "args.wavelet_filtering_regularization = True\n",
    "args.wavelet_filtering_finetuning     = True\n",
    "args.wavelet_filtering_finetuning_percent = 0.3\n",
    "\n",
    "args.regulatization_tradeoff          = 0.0001\n",
    "args.number_wavelet_filtering         = 10\n",
    "\n",
    "\n",
    "args.difference       = False \n",
    "args.filtering        =  False\n",
    "args.magnitude        =  False\n",
    "args.weighted_sampler = False\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "args.pos_select       = None\n",
    "args.sensor_select    = None\n",
    "\n",
    "\n",
    "args.representation_type = \"time\"\n",
    "args.exp_mode            = \"LOCV\"\n",
    "\n",
    "config_file = open('../../configs/data.yaml', mode='r')\n",
    "data_config = yaml.load(config_file, Loader=yaml.FullLoader)\n",
    "config = data_config[args.data_name]\n",
    "\n",
    "args.root_path       = os.path.join(args.root_path,config[\"filename\"])\n",
    "args.sampling_freq   = config[\"sampling_freq\"]\n",
    "args.num_classes     =  config[\"num_classes\"]\n",
    "window_seconds       = config[\"window_seconds\"]\n",
    "args.windowsize      =   int(window_seconds * args.sampling_freq) \n",
    "args.input_length    =  args.windowsize\n",
    "# input information\n",
    "args.c_in            = config[\"num_channels\"]\n",
    "\n",
    "if args.wavelet_filtering :\n",
    "    \n",
    "    if args.windowsize%2==1:\n",
    "        N_ds = int(torch.log2(torch.tensor(args.windowsize-1)).floor()) - 2\n",
    "    else:\n",
    "        N_ds = int(torch.log2(torch.tensor(args.windowsize)).floor()) - 2\n",
    "\n",
    "    args.f_in            =  args.number_wavelet_filtering*N_ds+1\n",
    "else:\n",
    "    args.f_in            =  1\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4d435a4c",
   "metadata": {},
   "source": [
    "## 模型参数"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "de2f4d16",
   "metadata": {},
   "outputs": [],
   "source": [
    "args.filter_scaling_factor = 0.25\n",
    "args.model_type            = \"deepconvlstm\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cada66dd",
   "metadata": {},
   "source": [
    "# 实验"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "2e3f2fad",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Use GPU: cuda:1\n",
      "Wavelet Filtering Regularization\n",
      "Build the DeepConvLSTM model!\n",
      "Done!\n",
      "Parameter : 5383527\n",
      "Set the seed as :  2\n"
     ]
    }
   ],
   "source": [
    "exp = Exp(args)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "09a011fc",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " ----------------------- load all the data -------------------\n",
      "-----------------------Sliding file are generated -----------------------\n",
      "-----------------------Sliding file are generated -----------------------\n",
      "================ LOCV Mode ====================\n",
      "================ 4 CV ======================\n",
      "================ the 0 th CV Experiment ================ \n",
      "Leave one Out Experiment : The 1 Part as the test\n",
      "[-] Target sampling weights:  [3.63768643e-05 1.64744646e-03 1.64744646e-03 1.72117040e-03\n",
      " 1.67785235e-03 1.19617225e-03 1.35317997e-03 1.79856115e-03\n",
      " 2.08333333e-03 2.73224044e-03 3.28947368e-03 3.09597523e-03\n",
      " 3.58422939e-03 2.43902439e-03 2.46305419e-03 1.27713921e-03\n",
      " 4.54132607e-04 2.02020202e-03]\n",
      "Train data number :  38060\n",
      "The number of classes is :  18\n",
      "The input_length  is :  30\n",
      "The channel_in is :  77\n",
      "Validation data number :  4229\n",
      "Test data number :  78162\n",
      "================Skip the 0 CV Experiment================\n",
      "================Skip the 0 CV Experiment Fine Tuning================\n",
      "================ the 1 th CV Experiment ================ \n",
      "Leave one Out Experiment : The 2 Part as the test\n",
      "[-] Target sampling weights:  [3.57768953e-05 1.50150150e-03 1.47928994e-03 1.61550889e-03\n",
      " 1.62601626e-03 1.29198966e-03 1.43884892e-03 2.21238938e-03\n",
      " 2.30946882e-03 2.84090909e-03 2.86532951e-03 2.81690141e-03\n",
      " 3.03951368e-03 2.38663484e-03 2.36406619e-03 1.58478605e-03\n",
      " 4.13223140e-04 2.13219616e-03]\n",
      "Train data number :  38628\n",
      "The number of classes is :  18\n",
      "The input_length  is :  30\n",
      "The channel_in is :  77\n",
      "Validation data number :  4292\n",
      "Test data number :  75003\n",
      "================Skip the 1 CV Experiment================\n",
      "Wavelet Filtering Regularization\n",
      "Build the DeepConvLSTM model!\n",
      "Wavelet Filtering Regularization\n",
      "Build the DeepConvLSTM model!\n",
      "------------Fine Tuning  :  15   will be pruned   -----------------------------------------\n",
      "old model Parameter : 5383527\n",
      "pruned model Parameter : 5378712\n",
      "----------------------------------------------------------------------------------------\n",
      "Fine Tuning Epoch: 1 cost time: 55.1318473815918\n",
      "Fine Tuning VALI: Epoch: 1, Steps: 302 | Train Loss: 0.5857894  Vali Loss: 0.6089039 Vali Accuracy: 0.8103448  Vali weighted F1: 0.7803354  Vali macro F1 0.4173850 \n",
      "Validation loss decreased (inf --> 0.608904).  Saving model ...\n",
      "Fine Tuning Epoch: 2 cost time: 51.69499897956848\n",
      "Fine Tuning VALI: Epoch: 2, Steps: 302 | Train Loss: 0.5753104  Vali Loss: 0.5963906 Vali Accuracy: 0.8126747  Vali weighted F1: 0.7871963  Vali macro F1 0.4343601 \n",
      "new best score!!!!\n",
      "Validation loss decreased (0.608904 --> 0.596391).  Saving model ...\n",
      "new best score!!!!\n",
      "Fine Tuning Epoch: 3 cost time: 51.86830973625183\n",
      "Fine Tuning VALI: Epoch: 3, Steps: 302 | Train Loss: 0.5627836  Vali Loss: 0.5870646 Vali Accuracy: 0.8164026  Vali weighted F1: 0.7917023  Vali macro F1 0.4420355 \n",
      "new best score!!!!\n",
      "Validation loss decreased (0.596391 --> 0.587065).  Saving model ...\n",
      "new best score!!!!\n",
      "Fine Tuning Epoch: 4 cost time: 51.63894200325012\n",
      "Fine Tuning VALI: Epoch: 4, Steps: 302 | Train Loss: 0.5547404  Vali Loss: 0.5804161 Vali Accuracy: 0.8159366  Vali weighted F1: 0.7919569  Vali macro F1 0.4461960 \n",
      "new best score!!!!\n",
      "Validation loss decreased (0.587065 --> 0.580416).  Saving model ...\n",
      "new best score!!!!\n",
      "Fine Tuning Epoch: 5 cost time: 51.556655406951904\n",
      "Fine Tuning VALI: Epoch: 5, Steps: 302 | Train Loss: 0.5501987  Vali Loss: 0.5730040 Vali Accuracy: 0.8208295  Vali weighted F1: 0.7976663  Vali macro F1 0.4690136 \n",
      "new best score!!!!\n",
      "Validation loss decreased (0.580416 --> 0.573004).  Saving model ...\n",
      "new best score!!!!\n",
      "Fine Tuning Epoch: 6 cost time: 51.72434735298157\n",
      "Fine Tuning VALI: Epoch: 6, Steps: 302 | Train Loss: 0.5422195  Vali Loss: 0.5682441 Vali Accuracy: 0.8226934  Vali weighted F1: 0.8001802  Vali macro F1 0.4631786 \n",
      "new best score!!!!\n",
      "Validation loss decreased (0.573004 --> 0.568244).  Saving model ...\n",
      "new best score!!!!\n",
      "Fine Tuning Epoch: 7 cost time: 52.15031933784485\n",
      "Fine Tuning VALI: Epoch: 7, Steps: 302 | Train Loss: 0.5353249  Vali Loss: 0.5620469 Vali Accuracy: 0.8240913  Vali weighted F1: 0.8039060  Vali macro F1 0.4820956 \n",
      "new best score!!!!\n",
      "Validation loss decreased (0.568244 --> 0.562047).  Saving model ...\n",
      "new best score!!!!\n",
      "Fine Tuning Epoch: 8 cost time: 51.429957151412964\n",
      "Fine Tuning VALI: Epoch: 8, Steps: 302 | Train Loss: 0.5283816  Vali Loss: 0.5555592 Vali Accuracy: 0.8229264  Vali weighted F1: 0.8017655  Vali macro F1 0.4750382 \n",
      "new best score!!!!\n",
      "Validation loss decreased (0.562047 --> 0.555559).  Saving model ...\n",
      "new best score!!!!\n",
      "Fine Tuning Epoch: 9 cost time: 51.638651609420776\n",
      "Fine Tuning VALI: Epoch: 9, Steps: 302 | Train Loss: 0.5246071  Vali Loss: 0.5552530 Vali Accuracy: 0.8275862  Vali weighted F1: 0.8076762  Vali macro F1 0.4894001 \n",
      "new best score!!!!\n",
      "Validation loss decreased (0.555559 --> 0.555253).  Saving model ...\n",
      "new best score!!!!\n",
      "Fine Tuning Epoch: 10 cost time: 51.71147799491882\n",
      "Fine Tuning VALI: Epoch: 10, Steps: 302 | Train Loss: 0.5213387  Vali Loss: 0.5467224 Vali Accuracy: 0.8238583  Vali weighted F1: 0.8064650  Vali macro F1 0.4908897 \n",
      "new best score!!!!\n",
      "Validation loss decreased (0.555253 --> 0.546722).  Saving model ...\n",
      "new best score!!!!\n",
      "Fine Tuning Epoch: 11 cost time: 51.636561155319214\n",
      "Fine Tuning VALI: Epoch: 11, Steps: 302 | Train Loss: 0.5178236  Vali Loss: 0.5472463 Vali Accuracy: 0.8271202  Vali weighted F1: 0.8088830  Vali macro F1 0.4988077 \n",
      "EarlyStopping counter: 1 out of 5\n",
      "Learning rate adjusting counter: 1 out of 5\n",
      "Fine Tuning Epoch: 12 cost time: 51.54679489135742\n",
      "Fine Tuning VALI: Epoch: 12, Steps: 302 | Train Loss: 0.5144682  Vali Loss: 0.5440731 Vali Accuracy: 0.8294501  Vali weighted F1: 0.8102521  Vali macro F1 0.4987063 \n",
      "new best score!!!!\n",
      "Validation loss decreased (0.546722 --> 0.544073).  Saving model ...\n",
      "new best score!!!!\n",
      "Fine Tuning Epoch: 13 cost time: 51.70430326461792\n",
      "Fine Tuning VALI: Epoch: 13, Steps: 302 | Train Loss: 0.5112212  Vali Loss: 0.5409343 Vali Accuracy: 0.8303821  Vali weighted F1: 0.8155229  Vali macro F1 0.5220915 \n",
      "new best score!!!!\n",
      "Validation loss decreased (0.544073 --> 0.540934).  Saving model ...\n",
      "new best score!!!!\n",
      "Fine Tuning Epoch: 14 cost time: 51.59596490859985\n",
      "Fine Tuning VALI: Epoch: 14, Steps: 302 | Train Loss: 0.5063101  Vali Loss: 0.5366509 Vali Accuracy: 0.8345760  Vali weighted F1: 0.8200591  Vali macro F1 0.5260204 \n",
      "new best score!!!!\n",
      "Validation loss decreased (0.540934 --> 0.536651).  Saving model ...\n",
      "new best score!!!!\n",
      "Fine Tuning Epoch: 15 cost time: 51.62384033203125\n",
      "Fine Tuning VALI: Epoch: 15, Steps: 302 | Train Loss: 0.5050220  Vali Loss: 0.5344424 Vali Accuracy: 0.8299161  Vali weighted F1: 0.8147396  Vali macro F1 0.5128403 \n",
      "new best score!!!!\n",
      "Validation loss decreased (0.536651 --> 0.534442).  Saving model ...\n",
      "new best score!!!!\n",
      "Fine Tuning Epoch: 16 cost time: 51.74579906463623\n",
      "Fine Tuning VALI: Epoch: 16, Steps: 302 | Train Loss: 0.5018229  Vali Loss: 0.5329637 Vali Accuracy: 0.8338770  Vali weighted F1: 0.8182208  Vali macro F1 0.5245521 \n",
      "new best score!!!!\n",
      "Validation loss decreased (0.534442 --> 0.532964).  Saving model ...\n",
      "new best score!!!!\n",
      "Fine Tuning Epoch: 17 cost time: 51.70283102989197\n",
      "Fine Tuning VALI: Epoch: 17, Steps: 302 | Train Loss: 0.4963880  Vali Loss: 0.5330079 Vali Accuracy: 0.8355079  Vali weighted F1: 0.8219792  Vali macro F1 0.5291928 \n",
      "EarlyStopping counter: 1 out of 5\n",
      "Learning rate adjusting counter: 1 out of 5\n",
      "Fine Tuning Epoch: 18 cost time: 51.6283540725708\n",
      "Fine Tuning VALI: Epoch: 18, Steps: 302 | Train Loss: 0.4945916  Vali Loss: 0.5276636 Vali Accuracy: 0.8329450  Vali weighted F1: 0.8171591  Vali macro F1 0.5132392 \n",
      "new best score!!!!\n",
      "Validation loss decreased (0.532964 --> 0.527664).  Saving model ...\n",
      "new best score!!!!\n",
      "Fine Tuning Epoch: 19 cost time: 51.546152114868164\n",
      "Fine Tuning VALI: Epoch: 19, Steps: 302 | Train Loss: 0.4901880  Vali Loss: 0.5259845 Vali Accuracy: 0.8343430  Vali weighted F1: 0.8213628  Vali macro F1 0.5275175 \n",
      "new best score!!!!\n",
      "Validation loss decreased (0.527664 --> 0.525984).  Saving model ...\n",
      "new best score!!!!\n",
      "Fine Tuning Epoch: 20 cost time: 51.55630016326904\n",
      "Fine Tuning VALI: Epoch: 20, Steps: 302 | Train Loss: 0.4869864  Vali Loss: 0.5206506 Vali Accuracy: 0.8336440  Vali weighted F1: 0.8193467  Vali macro F1 0.5165798 \n",
      "new best score!!!!\n",
      "Validation loss decreased (0.525984 --> 0.520651).  Saving model ...\n",
      "new best score!!!!\n",
      "Fine Tuning Epoch: 21 cost time: 51.60201811790466\n",
      "Fine Tuning VALI: Epoch: 21, Steps: 302 | Train Loss: 0.4851671  Vali Loss: 0.5206087 Vali Accuracy: 0.8329450  Vali weighted F1: 0.8197683  Vali macro F1 0.5284838 \n",
      "new best score!!!!\n",
      "Validation loss decreased (0.520651 --> 0.520609).  Saving model ...\n",
      "new best score!!!!\n",
      "Fine Tuning Epoch: 22 cost time: 52.187328577041626\n",
      "Fine Tuning VALI: Epoch: 22, Steps: 302 | Train Loss: 0.4822821  Vali Loss: 0.5187370 Vali Accuracy: 0.8390028  Vali weighted F1: 0.8268399  Vali macro F1 0.5396153 \n",
      "new best score!!!!\n",
      "Validation loss decreased (0.520609 --> 0.518737).  Saving model ...\n",
      "new best score!!!!\n",
      "Fine Tuning Epoch: 23 cost time: 51.81894564628601\n",
      "Fine Tuning VALI: Epoch: 23, Steps: 302 | Train Loss: 0.4804273  Vali Loss: 0.5161129 Vali Accuracy: 0.8345760  Vali weighted F1: 0.8214336  Vali macro F1 0.5270198 \n",
      "new best score!!!!\n",
      "Validation loss decreased (0.518737 --> 0.516113).  Saving model ...\n",
      "new best score!!!!\n",
      "Fine Tuning Epoch: 24 cost time: 51.846396923065186\n",
      "Fine Tuning VALI: Epoch: 24, Steps: 302 | Train Loss: 0.4781646  Vali Loss: 0.5130252 Vali Accuracy: 0.8369059  Vali weighted F1: 0.8227249  Vali macro F1 0.5296216 \n",
      "new best score!!!!\n",
      "Validation loss decreased (0.516113 --> 0.513025).  Saving model ...\n",
      "new best score!!!!\n",
      "Fine Tuning Epoch: 25 cost time: 51.73226714134216\n",
      "Fine Tuning VALI: Epoch: 25, Steps: 302 | Train Loss: 0.4786185  Vali Loss: 0.5124891 Vali Accuracy: 0.8385368  Vali weighted F1: 0.8252754  Vali macro F1 0.5419903 \n",
      "new best score!!!!\n",
      "Validation loss decreased (0.513025 --> 0.512489).  Saving model ...\n",
      "new best score!!!!\n",
      "Fine Tuning Epoch: 26 cost time: 51.70510792732239\n",
      "Fine Tuning VALI: Epoch: 26, Steps: 302 | Train Loss: 0.4771355  Vali Loss: 0.5088965 Vali Accuracy: 0.8394688  Vali weighted F1: 0.8272253  Vali macro F1 0.5479669 \n",
      "new best score!!!!\n",
      "Validation loss decreased (0.512489 --> 0.508897).  Saving model ...\n",
      "new best score!!!!\n",
      "Fine Tuning Epoch: 27 cost time: 51.53088426589966\n",
      "Fine Tuning VALI: Epoch: 27, Steps: 302 | Train Loss: 0.4731874  Vali Loss: 0.5073228 Vali Accuracy: 0.8394688  Vali weighted F1: 0.8285453  Vali macro F1 0.5486642 \n",
      "new best score!!!!\n",
      "Validation loss decreased (0.508897 --> 0.507323).  Saving model ...\n",
      "new best score!!!!\n",
      "Fine Tuning Epoch: 28 cost time: 51.36881113052368\n",
      "Fine Tuning VALI: Epoch: 28, Steps: 302 | Train Loss: 0.4681634  Vali Loss: 0.5063888 Vali Accuracy: 0.8399348  Vali weighted F1: 0.8276562  Vali macro F1 0.5528745 \n",
      "new best score!!!!\n",
      "Validation loss decreased (0.507323 --> 0.506389).  Saving model ...\n",
      "new best score!!!!\n",
      "Fine Tuning Epoch: 29 cost time: 51.498446464538574\n",
      "Fine Tuning VALI: Epoch: 29, Steps: 302 | Train Loss: 0.4718614  Vali Loss: 0.5033421 Vali Accuracy: 0.8413327  Vali weighted F1: 0.8299833  Vali macro F1 0.5520374 \n",
      "new best score!!!!\n",
      "Validation loss decreased (0.506389 --> 0.503342).  Saving model ...\n",
      "new best score!!!!\n",
      "Fine Tuning Epoch: 30 cost time: 51.65248370170593\n",
      "Fine Tuning VALI: Epoch: 30, Steps: 302 | Train Loss: 0.4670681  Vali Loss: 0.5015496 Vali Accuracy: 0.8450606  Vali weighted F1: 0.8365810  Vali macro F1 0.5756130 \n",
      "new best score!!!!\n",
      "Validation loss decreased (0.503342 --> 0.501550).  Saving model ...\n",
      "new best score!!!!\n",
      "Fine Tuning Epoch: 31 cost time: 51.36943817138672\n",
      "Fine Tuning VALI: Epoch: 31, Steps: 302 | Train Loss: 0.4642136  Vali Loss: 0.5004983 Vali Accuracy: 0.8450606  Vali weighted F1: 0.8376755  Vali macro F1 0.5872822 \n",
      "new best score!!!!\n",
      "Validation loss decreased (0.501550 --> 0.500498).  Saving model ...\n",
      "new best score!!!!\n",
      "Fine Tuning Epoch: 32 cost time: 51.42941999435425\n",
      "Fine Tuning VALI: Epoch: 32, Steps: 302 | Train Loss: 0.4598396  Vali Loss: 0.4983529 Vali Accuracy: 0.8434296  Vali weighted F1: 0.8352002  Vali macro F1 0.5768481 \n",
      "new best score!!!!\n",
      "Validation loss decreased (0.500498 --> 0.498353).  Saving model ...\n",
      "new best score!!!!\n",
      "Fine Tuning Epoch: 33 cost time: 51.59211730957031\n",
      "Fine Tuning VALI: Epoch: 33, Steps: 302 | Train Loss: 0.4585169  Vali Loss: 0.4933602 Vali Accuracy: 0.8455266  Vali weighted F1: 0.8369378  Vali macro F1 0.5807189 \n",
      "new best score!!!!\n",
      "Validation loss decreased (0.498353 --> 0.493360).  Saving model ...\n",
      "new best score!!!!\n",
      "Fine Tuning Epoch: 34 cost time: 49.34395670890808\n",
      "Fine Tuning VALI: Epoch: 34, Steps: 302 | Train Loss: 0.4570312  Vali Loss: 0.4957460 Vali Accuracy: 0.8413327  Vali weighted F1: 0.8339393  Vali macro F1 0.5645852 \n",
      "EarlyStopping counter: 1 out of 5\n",
      "Learning rate adjusting counter: 1 out of 5\n",
      "Fine Tuning Epoch: 35 cost time: 49.16111421585083\n",
      "Fine Tuning VALI: Epoch: 35, Steps: 302 | Train Loss: 0.4573090  Vali Loss: 0.4920953 Vali Accuracy: 0.8457596  Vali weighted F1: 0.8375164  Vali macro F1 0.5782174 \n",
      "new best score!!!!\n",
      "Validation loss decreased (0.493360 --> 0.492095).  Saving model ...\n",
      "new best score!!!!\n",
      "Fine Tuning Epoch: 36 cost time: 49.298094749450684\n",
      "Fine Tuning VALI: Epoch: 36, Steps: 302 | Train Loss: 0.4546965  Vali Loss: 0.4898690 Vali Accuracy: 0.8462255  Vali weighted F1: 0.8384738  Vali macro F1 0.5784348 \n",
      "new best score!!!!\n",
      "Validation loss decreased (0.492095 --> 0.489869).  Saving model ...\n",
      "new best score!!!!\n",
      "Fine Tuning Epoch: 37 cost time: 49.28691864013672\n",
      "Fine Tuning VALI: Epoch: 37, Steps: 302 | Train Loss: 0.4509801  Vali Loss: 0.4853789 Vali Accuracy: 0.8473905  Vali weighted F1: 0.8374346  Vali macro F1 0.5737187 \n",
      "new best score!!!!\n",
      "Validation loss decreased (0.489869 --> 0.485379).  Saving model ...\n",
      "new best score!!!!\n",
      "Fine Tuning Epoch: 38 cost time: 49.5138943195343\n",
      "Fine Tuning VALI: Epoch: 38, Steps: 302 | Train Loss: 0.4501405  Vali Loss: 0.4885779 Vali Accuracy: 0.8508854  Vali weighted F1: 0.8428242  Vali macro F1 0.5851140 \n",
      "EarlyStopping counter: 1 out of 5\n",
      "Learning rate adjusting counter: 1 out of 5\n",
      "Fine Tuning Epoch: 39 cost time: 49.16794991493225\n",
      "Fine Tuning VALI: Epoch: 39, Steps: 302 | Train Loss: 0.4495603  Vali Loss: 0.4824936 Vali Accuracy: 0.8494874  Vali weighted F1: 0.8416948  Vali macro F1 0.5905572 \n",
      "new best score!!!!\n",
      "Validation loss decreased (0.485379 --> 0.482494).  Saving model ...\n",
      "new best score!!!!\n",
      "Fine Tuning Epoch: 40 cost time: 49.637911319732666\n",
      "Fine Tuning VALI: Epoch: 40, Steps: 302 | Train Loss: 0.4464669  Vali Loss: 0.4828608 Vali Accuracy: 0.8455266  Vali weighted F1: 0.8373541  Vali macro F1 0.5730557 \n",
      "EarlyStopping counter: 1 out of 5\n",
      "Learning rate adjusting counter: 1 out of 5\n",
      "Fine Tuning Epoch: 41 cost time: 49.55559301376343\n",
      "Fine Tuning VALI: Epoch: 41, Steps: 302 | Train Loss: 0.4446487  Vali Loss: 0.4801524 Vali Accuracy: 0.8518173  Vali weighted F1: 0.8447490  Vali macro F1 0.5883886 \n",
      "new best score!!!!\n",
      "Validation loss decreased (0.482494 --> 0.480152).  Saving model ...\n",
      "new best score!!!!\n",
      "Fine Tuning Epoch: 42 cost time: 49.228546142578125\n",
      "Fine Tuning VALI: Epoch: 42, Steps: 302 | Train Loss: 0.4448424  Vali Loss: 0.4765437 Vali Accuracy: 0.8506524  Vali weighted F1: 0.8425931  Vali macro F1 0.5861567 \n",
      "new best score!!!!\n",
      "Validation loss decreased (0.480152 --> 0.476544).  Saving model ...\n",
      "new best score!!!!\n",
      "Fine Tuning Epoch: 43 cost time: 49.58145236968994\n",
      "Fine Tuning VALI: Epoch: 43, Steps: 302 | Train Loss: 0.4442324  Vali Loss: 0.4788927 Vali Accuracy: 0.8483225  Vali weighted F1: 0.8420502  Vali macro F1 0.5852896 \n",
      "EarlyStopping counter: 1 out of 5\n",
      "Learning rate adjusting counter: 1 out of 5\n",
      "Fine Tuning Epoch: 44 cost time: 49.37608098983765\n",
      "Fine Tuning VALI: Epoch: 44, Steps: 302 | Train Loss: 0.4418137  Vali Loss: 0.4755608 Vali Accuracy: 0.8497204  Vali weighted F1: 0.8411263  Vali macro F1 0.5915332 \n",
      "new best score!!!!\n",
      "Validation loss decreased (0.476544 --> 0.475561).  Saving model ...\n",
      "new best score!!!!\n",
      "Fine Tuning Epoch: 45 cost time: 49.65772294998169\n",
      "Fine Tuning VALI: Epoch: 45, Steps: 302 | Train Loss: 0.4401734  Vali Loss: 0.4743817 Vali Accuracy: 0.8525163  Vali weighted F1: 0.8465181  Vali macro F1 0.5935023 \n",
      "new best score!!!!\n",
      "Validation loss decreased (0.475561 --> 0.474382).  Saving model ...\n",
      "new best score!!!!\n",
      "Fine Tuning Epoch: 46 cost time: 49.8500497341156\n",
      "Fine Tuning VALI: Epoch: 46, Steps: 302 | Train Loss: 0.4373949  Vali Loss: 0.4718332 Vali Accuracy: 0.8511184  Vali weighted F1: 0.8436542  Vali macro F1 0.5866925 \n",
      "new best score!!!!\n",
      "Validation loss decreased (0.474382 --> 0.471833).  Saving model ...\n",
      "new best score!!!!\n",
      "Fine Tuning Epoch: 47 cost time: 49.78590393066406\n",
      "Fine Tuning VALI: Epoch: 47, Steps: 302 | Train Loss: 0.4378692  Vali Loss: 0.4676169 Vali Accuracy: 0.8483225  Vali weighted F1: 0.8391254  Vali macro F1 0.5804801 \n",
      "new best score!!!!\n",
      "Validation loss decreased (0.471833 --> 0.467617).  Saving model ...\n",
      "new best score!!!!\n",
      "Fine Tuning Epoch: 48 cost time: 49.51736855506897\n",
      "Fine Tuning VALI: Epoch: 48, Steps: 302 | Train Loss: 0.4379921  Vali Loss: 0.4682528 Vali Accuracy: 0.8497204  Vali weighted F1: 0.8407795  Vali macro F1 0.5882263 \n",
      "EarlyStopping counter: 1 out of 5\n",
      "Learning rate adjusting counter: 1 out of 5\n",
      "Fine Tuning Epoch: 49 cost time: 49.29740762710571\n",
      "Fine Tuning VALI: Epoch: 49, Steps: 302 | Train Loss: 0.4337065  Vali Loss: 0.4644759 Vali Accuracy: 0.8513514  Vali weighted F1: 0.8428143  Vali macro F1 0.5859005 \n",
      "new best score!!!!\n",
      "Validation loss decreased (0.467617 --> 0.464476).  Saving model ...\n",
      "new best score!!!!\n",
      "Fine Tuning Epoch: 50 cost time: 49.48849010467529\n",
      "Fine Tuning VALI: Epoch: 50, Steps: 302 | Train Loss: 0.4315380  Vali Loss: 0.4597560 Vali Accuracy: 0.8550792  Vali weighted F1: 0.8455478  Vali macro F1 0.5944669 \n",
      "new best score!!!!\n",
      "Validation loss decreased (0.464476 --> 0.459756).  Saving model ...\n",
      "new best score!!!!\n",
      "Fine Tuning Epoch: 51 cost time: 49.07749700546265\n",
      "Fine Tuning VALI: Epoch: 51, Steps: 302 | Train Loss: 0.4313466  Vali Loss: 0.4620748 Vali Accuracy: 0.8525163  Vali weighted F1: 0.8438241  Vali macro F1 0.5966984 \n",
      "EarlyStopping counter: 1 out of 5\n",
      "Learning rate adjusting counter: 1 out of 5\n",
      "Fine Tuning Epoch: 52 cost time: 49.827152490615845\n",
      "Fine Tuning VALI: Epoch: 52, Steps: 302 | Train Loss: 0.4291686  Vali Loss: 0.4671043 Vali Accuracy: 0.8485555  Vali weighted F1: 0.8385543  Vali macro F1 0.5742405 \n",
      "EarlyStopping counter: 2 out of 5\n",
      "Learning rate adjusting counter: 2 out of 5\n",
      "Fine Tuning Epoch: 53 cost time: 49.11519980430603\n",
      "Fine Tuning VALI: Epoch: 53, Steps: 302 | Train Loss: 0.4299605  Vali Loss: 0.4595454 Vali Accuracy: 0.8557782  Vali weighted F1: 0.8469860  Vali macro F1 0.5991252 \n",
      "new best score!!!!\n",
      "Validation loss decreased (0.459756 --> 0.459545).  Saving model ...\n",
      "new best score!!!!\n",
      "Fine Tuning Epoch: 54 cost time: 49.66343426704407\n",
      "Fine Tuning VALI: Epoch: 54, Steps: 302 | Train Loss: 0.4272531  Vali Loss: 0.4573546 Vali Accuracy: 0.8555452  Vali weighted F1: 0.8465907  Vali macro F1 0.5908590 \n",
      "new best score!!!!\n",
      "Validation loss decreased (0.459545 --> 0.457355).  Saving model ...\n",
      "new best score!!!!\n",
      "Fine Tuning Epoch: 55 cost time: 49.11813282966614\n",
      "Fine Tuning VALI: Epoch: 55, Steps: 302 | Train Loss: 0.4257329  Vali Loss: 0.4562602 Vali Accuracy: 0.8527493  Vali weighted F1: 0.8441762  Vali macro F1 0.5843262 \n",
      "new best score!!!!\n",
      "Validation loss decreased (0.457355 --> 0.456260).  Saving model ...\n",
      "new best score!!!!\n",
      "Fine Tuning Epoch: 56 cost time: 49.37645649909973\n",
      "Fine Tuning VALI: Epoch: 56, Steps: 302 | Train Loss: 0.4239468  Vali Loss: 0.4608126 Vali Accuracy: 0.8574091  Vali weighted F1: 0.8492999  Vali macro F1 0.5995356 \n",
      "EarlyStopping counter: 1 out of 5\n",
      "Learning rate adjusting counter: 1 out of 5\n",
      "Fine Tuning Epoch: 57 cost time: 49.10245323181152\n",
      "Fine Tuning VALI: Epoch: 57, Steps: 302 | Train Loss: 0.4229947  Vali Loss: 0.4555014 Vali Accuracy: 0.8553122  Vali weighted F1: 0.8463096  Vali macro F1 0.5959555 \n",
      "new best score!!!!\n",
      "Validation loss decreased (0.456260 --> 0.455501).  Saving model ...\n",
      "new best score!!!!\n",
      "Fine Tuning Epoch: 58 cost time: 49.229761838912964\n",
      "Fine Tuning VALI: Epoch: 58, Steps: 302 | Train Loss: 0.4215644  Vali Loss: 0.4559456 Vali Accuracy: 0.8548462  Vali weighted F1: 0.8463944  Vali macro F1 0.5959063 \n",
      "EarlyStopping counter: 1 out of 5\n",
      "Learning rate adjusting counter: 1 out of 5\n",
      "Fine Tuning Epoch: 59 cost time: 48.88642334938049\n",
      "Fine Tuning VALI: Epoch: 59, Steps: 302 | Train Loss: 0.4214869  Vali Loss: 0.4540650 Vali Accuracy: 0.8562442  Vali weighted F1: 0.8482310  Vali macro F1 0.6067779 \n",
      "new best score!!!!\n",
      "Validation loss decreased (0.455501 --> 0.454065).  Saving model ...\n",
      "new best score!!!!\n",
      "Fine Tuning Epoch: 60 cost time: 49.211421251297\n",
      "Fine Tuning VALI: Epoch: 60, Steps: 302 | Train Loss: 0.4238032  Vali Loss: 0.4520069 Vali Accuracy: 0.8550792  Vali weighted F1: 0.8482854  Vali macro F1 0.6033054 \n",
      "new best score!!!!\n",
      "Validation loss decreased (0.454065 --> 0.452007).  Saving model ...\n",
      "new best score!!!!\n",
      "Fine Tuning Epoch: 61 cost time: 49.4715371131897\n",
      "Fine Tuning VALI: Epoch: 61, Steps: 302 | Train Loss: 0.4196919  Vali Loss: 0.4517345 Vali Accuracy: 0.8567102  Vali weighted F1: 0.8503375  Vali macro F1 0.6025503 \n",
      "new best score!!!!\n",
      "Validation loss decreased (0.452007 --> 0.451735).  Saving model ...\n",
      "new best score!!!!\n",
      "Fine Tuning Epoch: 62 cost time: 48.98353838920593\n",
      "Fine Tuning VALI: Epoch: 62, Steps: 302 | Train Loss: 0.4142512  Vali Loss: 0.4532547 Vali Accuracy: 0.8546132  Vali weighted F1: 0.8470789  Vali macro F1 0.6049012 \n",
      "EarlyStopping counter: 1 out of 5\n",
      "Learning rate adjusting counter: 1 out of 5\n",
      "Fine Tuning Epoch: 63 cost time: 49.56179928779602\n",
      "Fine Tuning VALI: Epoch: 63, Steps: 302 | Train Loss: 0.4163792  Vali Loss: 0.4555726 Vali Accuracy: 0.8548462  Vali weighted F1: 0.8471946  Vali macro F1 0.5941707 \n",
      "EarlyStopping counter: 2 out of 5\n",
      "Learning rate adjusting counter: 2 out of 5\n",
      "Fine Tuning Epoch: 64 cost time: 49.09171462059021\n",
      "Fine Tuning VALI: Epoch: 64, Steps: 302 | Train Loss: 0.4147468  Vali Loss: 0.4584260 Vali Accuracy: 0.8569432  Vali weighted F1: 0.8503556  Vali macro F1 0.6067369 \n",
      "EarlyStopping counter: 3 out of 5\n",
      "Learning rate adjusting counter: 3 out of 5\n",
      "Fine Tuning Epoch: 65 cost time: 49.503071546554565\n",
      "Fine Tuning VALI: Epoch: 65, Steps: 302 | Train Loss: 0.4144477  Vali Loss: 0.4534633 Vali Accuracy: 0.8567102  Vali weighted F1: 0.8508266  Vali macro F1 0.6118508 \n",
      "EarlyStopping counter: 4 out of 5\n",
      "Learning rate adjusting counter: 4 out of 5\n",
      "Fine Tuning Epoch: 66 cost time: 49.131741523742676\n",
      "Fine Tuning VALI: Epoch: 66, Steps: 302 | Train Loss: 0.4109374  Vali Loss: 0.4413435 Vali Accuracy: 0.8569432  Vali weighted F1: 0.8509009  Vali macro F1 0.6084849 \n",
      "new best score!!!!\n",
      "Validation loss decreased (0.451735 --> 0.441343).  Saving model ...\n",
      "new best score!!!!\n",
      "Fine Tuning Epoch: 67 cost time: 49.64434862136841\n",
      "Fine Tuning VALI: Epoch: 67, Steps: 302 | Train Loss: 0.4099645  Vali Loss: 0.4406171 Vali Accuracy: 0.8595061  Vali weighted F1: 0.8531637  Vali macro F1 0.6159761 \n",
      "new best score!!!!\n",
      "Validation loss decreased (0.441343 --> 0.440617).  Saving model ...\n",
      "new best score!!!!\n",
      "Fine Tuning Epoch: 68 cost time: 52.7663209438324\n",
      "Fine Tuning VALI: Epoch: 68, Steps: 302 | Train Loss: 0.4092170  Vali Loss: 0.4425775 Vali Accuracy: 0.8581081  Vali weighted F1: 0.8517852  Vali macro F1 0.6177567 \n",
      "EarlyStopping counter: 1 out of 5\n",
      "Learning rate adjusting counter: 1 out of 5\n",
      "Fine Tuning Epoch: 69 cost time: 51.69636344909668\n",
      "Fine Tuning VALI: Epoch: 69, Steps: 302 | Train Loss: 0.4089042  Vali Loss: 0.4397671 Vali Accuracy: 0.8583411  Vali weighted F1: 0.8525408  Vali macro F1 0.6229897 \n",
      "new best score!!!!\n",
      "Validation loss decreased (0.440617 --> 0.439767).  Saving model ...\n",
      "new best score!!!!\n",
      "Fine Tuning Epoch: 70 cost time: 52.15909242630005\n",
      "Fine Tuning VALI: Epoch: 70, Steps: 302 | Train Loss: 0.4065210  Vali Loss: 0.4388360 Vali Accuracy: 0.8590401  Vali weighted F1: 0.8535332  Vali macro F1 0.6205156 \n",
      "new best score!!!!\n",
      "Validation loss decreased (0.439767 --> 0.438836).  Saving model ...\n",
      "new best score!!!!\n",
      "Fine Tuning Epoch: 71 cost time: 51.53029227256775\n",
      "Fine Tuning VALI: Epoch: 71, Steps: 302 | Train Loss: 0.4058715  Vali Loss: 0.4390663 Vali Accuracy: 0.8590401  Vali weighted F1: 0.8531162  Vali macro F1 0.6236686 \n",
      "EarlyStopping counter: 1 out of 5\n",
      "Learning rate adjusting counter: 1 out of 5\n",
      "Fine Tuning Epoch: 72 cost time: 51.46012616157532\n",
      "Fine Tuning VALI: Epoch: 72, Steps: 302 | Train Loss: 0.4055850  Vali Loss: 0.4415347 Vali Accuracy: 0.8564772  Vali weighted F1: 0.8513715  Vali macro F1 0.6196341 \n",
      "EarlyStopping counter: 2 out of 5\n",
      "Learning rate adjusting counter: 2 out of 5\n",
      "Fine Tuning Epoch: 73 cost time: 51.33185052871704\n",
      "Fine Tuning VALI: Epoch: 73, Steps: 302 | Train Loss: 0.4057381  Vali Loss: 0.4400199 Vali Accuracy: 0.8606710  Vali weighted F1: 0.8550672  Vali macro F1 0.6239320 \n",
      "EarlyStopping counter: 3 out of 5\n",
      "Learning rate adjusting counter: 3 out of 5\n",
      "Fine Tuning Epoch: 74 cost time: 51.95280575752258\n",
      "Fine Tuning VALI: Epoch: 74, Steps: 302 | Train Loss: 0.4050085  Vali Loss: 0.4411059 Vali Accuracy: 0.8611370  Vali weighted F1: 0.8553854  Vali macro F1 0.6130202 \n",
      "EarlyStopping counter: 4 out of 5\n",
      "Learning rate adjusting counter: 4 out of 5\n",
      "Fine Tuning Epoch: 75 cost time: 52.07832622528076\n",
      "Fine Tuning VALI: Epoch: 75, Steps: 302 | Train Loss: 0.4052755  Vali Loss: 0.4378373 Vali Accuracy: 0.8588071  Vali weighted F1: 0.8526065  Vali macro F1 0.6175322 \n",
      "new best score!!!!\n",
      "Validation loss decreased (0.438836 --> 0.437837).  Saving model ...\n",
      "new best score!!!!\n",
      "Fine Tuning Epoch: 76 cost time: 51.5573410987854\n",
      "Fine Tuning VALI: Epoch: 76, Steps: 302 | Train Loss: 0.4023138  Vali Loss: 0.4357854 Vali Accuracy: 0.8595061  Vali weighted F1: 0.8540014  Vali macro F1 0.6226895 \n",
      "new best score!!!!\n",
      "Validation loss decreased (0.437837 --> 0.435785).  Saving model ...\n",
      "new best score!!!!\n",
      "Fine Tuning Epoch: 77 cost time: 51.75467777252197\n",
      "Fine Tuning VALI: Epoch: 77, Steps: 302 | Train Loss: 0.4020625  Vali Loss: 0.4338698 Vali Accuracy: 0.8602050  Vali weighted F1: 0.8554580  Vali macro F1 0.6350867 \n",
      "new best score!!!!\n",
      "Validation loss decreased (0.435785 --> 0.433870).  Saving model ...\n",
      "new best score!!!!\n",
      "Fine Tuning Epoch: 78 cost time: 51.90306568145752\n",
      "Fine Tuning VALI: Epoch: 78, Steps: 302 | Train Loss: 0.3997994  Vali Loss: 0.4374176 Vali Accuracy: 0.8592731  Vali weighted F1: 0.8548118  Vali macro F1 0.6187861 \n",
      "EarlyStopping counter: 1 out of 5\n",
      "Learning rate adjusting counter: 1 out of 5\n",
      "Fine Tuning Epoch: 79 cost time: 51.95937180519104\n",
      "Fine Tuning VALI: Epoch: 79, Steps: 302 | Train Loss: 0.3984680  Vali Loss: 0.4344373 Vali Accuracy: 0.8595061  Vali weighted F1: 0.8554301  Vali macro F1 0.6298000 \n",
      "EarlyStopping counter: 2 out of 5\n",
      "Learning rate adjusting counter: 2 out of 5\n",
      "Fine Tuning Epoch: 80 cost time: 51.84567451477051\n",
      "Fine Tuning VALI: Epoch: 80, Steps: 302 | Train Loss: 0.3989487  Vali Loss: 0.4364162 Vali Accuracy: 0.8613700  Vali weighted F1: 0.8564933  Vali macro F1 0.6319377 \n",
      "EarlyStopping counter: 3 out of 5\n",
      "Learning rate adjusting counter: 3 out of 5\n",
      "Fine Tuning Epoch: 81 cost time: 51.816195011138916\n",
      "Fine Tuning VALI: Epoch: 81, Steps: 302 | Train Loss: 0.3988469  Vali Loss: 0.4344051 Vali Accuracy: 0.8636999  Vali weighted F1: 0.8580641  Vali macro F1 0.6341825 \n",
      "EarlyStopping counter: 4 out of 5\n",
      "Learning rate adjusting counter: 4 out of 5\n",
      "Fine Tuning Epoch: 82 cost time: 51.95225238800049\n",
      "Fine Tuning VALI: Epoch: 82, Steps: 302 | Train Loss: 0.4011495  Vali Loss: 0.4381373 Vali Accuracy: 0.8597390  Vali weighted F1: 0.8551611  Vali macro F1 0.6282798 \n",
      "EarlyStopping counter: 5 out of 5\n",
      "Early stopping\n",
      "Loading the best finetuned validation model!\n",
      "Fine Tuning Final Test Performance : Test Accuracy: 0.7869285  Test weighted F1: 0.7376141  Test macro F1 0.3184473 \n",
      "================ the 2 th CV Experiment ================ \n",
      "Leave one Out Experiment : The 3 Part as the test\n",
      "[-] Target sampling weights:  [3.53369377e-05 1.54320988e-03 1.60513644e-03 1.60771704e-03\n",
      " 1.64744646e-03 1.33333333e-03 1.39470014e-03 1.89393939e-03\n",
      " 2.02429150e-03 2.71002710e-03 3.11526480e-03 2.92397661e-03\n",
      " 3.23624595e-03 2.27272727e-03 2.38663484e-03 1.29032258e-03\n",
      " 4.19287212e-04 2.08768267e-03]\n",
      "Train data number :  39127\n",
      "The number of classes is :  18\n",
      "The input_length  is :  30\n",
      "The channel_in is :  77\n",
      "Validation data number :  4348\n",
      "Test data number :  72231\n",
      "================Skip the 2 CV Experiment================\n",
      "================Skip the 2 CV Experiment Fine Tuning================\n",
      "================ the 3 th CV Experiment ================ \n",
      "Leave one Out Experiment : The 4 Part as the test\n",
      "[-] Target sampling weights:  [3.41786862e-05 1.52439024e-03 1.43061516e-03 1.58227848e-03\n",
      " 1.53374233e-03 1.23456790e-03 1.40646976e-03 1.82149362e-03\n",
      " 1.95694716e-03 2.68817204e-03 2.97619048e-03 2.76243094e-03\n",
      " 2.97619048e-03 2.16450216e-03 2.18818381e-03 1.42653352e-03\n",
      " 3.93081761e-04 1.88323917e-03]\n",
      "Train data number :  40579\n",
      "The number of classes is :  18\n",
      "The input_length  is :  30\n",
      "The channel_in is :  77\n",
      "Validation data number :  4509\n",
      "Test data number :  64167\n",
      "================Skip the 3 CV Experiment================\n",
      "================Skip the 3 CV Experiment Fine Tuning================\n"
     ]
    }
   ],
   "source": [
    "exp.train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6280dba8",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "db8bc4bd",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "SDIL",
   "language": "python",
   "name": "sdil"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.13"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": true
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
