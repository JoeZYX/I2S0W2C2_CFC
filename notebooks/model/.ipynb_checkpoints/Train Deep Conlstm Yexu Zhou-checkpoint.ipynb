{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "894e2c21",
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "import sys\n",
    "sys.path.append(\"../../\")\n",
    "\n",
    "from experiment import Exp\n",
    "\n",
    "from dataloaders import data_set,data_dict\n",
    "import torch\n",
    "import yaml\n",
    "import os"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bcc56bc7",
   "metadata": {},
   "source": [
    "# 参数设置"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dcc5bcbc",
   "metadata": {},
   "source": [
    "# 训练参数 \n",
    "除了路径 其他不要变"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "86004ce0",
   "metadata": {},
   "outputs": [],
   "source": [
    "class dotdict(dict):\n",
    "    \"\"\"dot.notation access to dictionary attributes\"\"\"\n",
    "    __getattr__ = dict.get\n",
    "    __setattr__ = dict.__setitem__\n",
    "    __delattr__ = dict.__delitem__\n",
    "\n",
    "args = dotdict()   \n",
    "# TODO change the path as relative path\n",
    "args.to_save_path     = r\"E:\\TECO_Works\\Conference\\ISWC2022\\Run_logs\"              \n",
    "args.freq_save_path   = r\"E:\\TECO_Works\\Conference\\ISWC2022\\Freq_data\"\n",
    "args.window_save_path = r\"E:\\TECO_Works\\Conference\\ISWC2022\\Sliding_window\"\n",
    "args.root_path        = r\"E:\\datasets\"\n",
    "\n",
    "\n",
    "args.drop_transition  = False\n",
    "args.datanorm_type    = \"standardization\" # None ,\"standardization\", \"minmax\"\n",
    "\n",
    "\n",
    "args.batch_size       = 256                                                     \n",
    "args.shuffle          = True\n",
    "args.drop_last        = False\n",
    "args.train_vali_quote = 0.90                                           \n",
    "\n",
    "\n",
    "# training setting \n",
    "args.train_epochs            = 150\n",
    "\n",
    "args.learning_rate           = 0.001  \n",
    "args.learning_rate_patience  = 7\n",
    "args.learning_rate_factor    = 0.1\n",
    "\n",
    "\n",
    "args.early_stop_patience     = 15\n",
    "\n",
    "args.use_gpu                 = True if torch.cuda.is_available() else False\n",
    "args.gpu                     = 0\n",
    "args.use_multi_gpu           = False\n",
    "\n",
    "args.optimizer               = \"Adam\"\n",
    "args.criterion               = \"CrossEntropy\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c282cbcb",
   "metadata": {},
   "source": [
    "## 数据参数\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "c6cd147b",
   "metadata": {},
   "outputs": [],
   "source": [
    "args.seed                             = 1\n",
    "\n",
    "\n",
    "args.data_name                        =  \"pamap2\"\n",
    "\n",
    "args.wavelet_filtering                = False\n",
    "args.wavelet_filtering_regularization = False\n",
    "args.wavelet_filtering_finetuning     = False\n",
    "args.wavelet_filtering_finetuning_percent = 0.5\n",
    "args.wavelet_filtering_learnable      = False\n",
    "args.wavelet_filtering_layernorm      = False\n",
    "\n",
    "args.regulatization_tradeoff          = 0\n",
    "args.number_wavelet_filtering         = 6\n",
    "\n",
    "\n",
    "args.difference       = False \n",
    "args.filtering        =  False\n",
    "args.magnitude        =  False\n",
    "args.weighted_sampler = False\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "args.pos_select       = None\n",
    "args.sensor_select    = None\n",
    "\n",
    "\n",
    "args.representation_type = \"time\"\n",
    "args.exp_mode            = \"LOCV\"\n",
    "if args.data_name      ==  \"skodar\":\n",
    "    args.exp_mode            = \"SOCV\"\n",
    "config_file = open('../../configs/data.yaml', mode='r')\n",
    "data_config = yaml.load(config_file, Loader=yaml.FullLoader)\n",
    "config = data_config[args.data_name]\n",
    "\n",
    "args.root_path       = os.path.join(args.root_path,config[\"filename\"])\n",
    "args.sampling_freq   = config[\"sampling_freq\"]\n",
    "args.num_classes     =  config[\"num_classes\"]\n",
    "window_seconds       = config[\"window_seconds\"]\n",
    "args.windowsize      =   int(window_seconds * args.sampling_freq) \n",
    "args.input_length    =  args.windowsize\n",
    "# input information\n",
    "args.c_in            = config[\"num_channels\"]\n",
    "\n",
    "\n",
    "if args.difference:\n",
    "    args.c_in = args.c_in*2\n",
    "\n",
    "if args.wavelet_filtering :\n",
    "    \n",
    "    if args.windowsize%2==1:\n",
    "        N_ds = int(torch.log2(torch.tensor(args.windowsize-1)).floor()) - 2\n",
    "    else:\n",
    "        N_ds = int(torch.log2(torch.tensor(args.windowsize)).floor()) - 2\n",
    "\n",
    "    args.f_in            =  args.number_wavelet_filtering*N_ds+1\n",
    "else:\n",
    "    args.f_in            =  1\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4d435a4c",
   "metadata": {},
   "source": [
    "## 模型参数"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "de2f4d16",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Use GPU: cuda:0\n",
      "Build the DeepConvLSTM model!\n",
      "Done!\n",
      "Parameter : 45596\n",
      "Set the seed as :  1\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "model_builder(\n",
       "  (model): DeepConvLSTM(\n",
       "    (conv_blocks): ModuleList(\n",
       "      (0): ConvBlock(\n",
       "        (conv1): Conv2d(1, 16, kernel_size=(5, 1), stride=(1, 1))\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(16, 16, kernel_size=(5, 1), stride=(2, 1))\n",
       "      )\n",
       "      (1): ConvBlock(\n",
       "        (conv1): Conv2d(16, 16, kernel_size=(5, 1), stride=(1, 1))\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(16, 16, kernel_size=(5, 1), stride=(2, 1))\n",
       "      )\n",
       "    )\n",
       "    (lstm_layers): ModuleList(\n",
       "      (0): LSTM(288, 32, batch_first=True)\n",
       "    )\n",
       "    (dropout): Dropout(p=0.5, inplace=False)\n",
       "    (fc): Linear(in_features=32, out_features=12, bias=True)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "args.filter_scaling_factor = 0.25\n",
    "args.model_type              = \"deepconvlstm\"#\"deepconvlstm\"#\"sahar\" #\"deepconvlstm\"\n",
    "exp = Exp(args)\n",
    "exp.model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "bc1595a6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# cross_channel_interaction_type = \"attn\",    # attn  transformer  identity\n",
    "# cross_channel_aggregation_type = \"filter\",  # filter  naive  FC  \"SFCC\", \"SFCF\"\n",
    "# temporal_info_interaction_type = \"gru\",     # gru  lstm  attn  transformer  identity  conv\n",
    "# temporal_info_aggregation_type = \"FC\",      # naive  filter  FC  tnaive"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cada66dd",
   "metadata": {},
   "source": [
    "# 实验"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "2e3f2fad",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Use GPU: cuda:0\n",
      "Build the TinyHAR model!\n",
      "Done!\n",
      "Parameter : 37114\n",
      "Set the seed as :  1\n"
     ]
    }
   ],
   "source": [
    "# 如果我们设置为 \n",
    "\n",
    "\n",
    "args.model_type              = \"tinyhar\"#\"deepconvlstm\"#\"sahar\" #\"deepconvlstm\"\n",
    "\n",
    "args.cross_channel_interaction_type = \"attn\"\n",
    "args.cross_channel_aggregation_type = \"FC\"\n",
    "args.temporal_info_interaction_type = \"gru\"\n",
    "args.temporal_info_aggregation_type = \"tnaive\"\n",
    "\n",
    "exp = Exp(args)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "20d58f10",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "model_builder(\n",
       "  (model): TinyHAR_Model(\n",
       "    (layers_conv): ModuleList(\n",
       "      (0): Sequential(\n",
       "        (0): Conv2d(1, 20, kernel_size=(5, 1), stride=(2, 1))\n",
       "        (1): ReLU(inplace=True)\n",
       "      )\n",
       "      (1): Sequential(\n",
       "        (0): Conv2d(20, 20, kernel_size=(5, 1), stride=(2, 1))\n",
       "        (1): ReLU(inplace=True)\n",
       "      )\n",
       "      (2): Sequential(\n",
       "        (0): Conv2d(20, 20, kernel_size=(5, 1), stride=(2, 1))\n",
       "        (1): ReLU(inplace=True)\n",
       "      )\n",
       "      (3): Sequential(\n",
       "        (0): Conv2d(20, 20, kernel_size=(5, 1), stride=(2, 1))\n",
       "        (1): ReLU(inplace=True)\n",
       "      )\n",
       "    )\n",
       "    (channel_interaction): SelfAttention_interaction(\n",
       "      (query): Linear(in_features=20, out_features=20, bias=False)\n",
       "      (key): Linear(in_features=20, out_features=20, bias=False)\n",
       "      (value): Linear(in_features=20, out_features=20, bias=False)\n",
       "    )\n",
       "    (channel_fusion): FC(\n",
       "      (fc): Linear(in_features=360, out_features=40, bias=True)\n",
       "    )\n",
       "    (activation): ReLU()\n",
       "    (temporal_interaction): temporal_LSTM(\n",
       "      (lstm): LSTM(40, 40, batch_first=True)\n",
       "    )\n",
       "    (dropout): Dropout(p=0.1, inplace=False)\n",
       "    (temporal_fusion): Temporal_Weighted_Aggregation(\n",
       "      (fc_1): Linear(in_features=40, out_features=40, bias=True)\n",
       "      (weighs_activation): Tanh()\n",
       "      (fc_2): Linear(in_features=40, out_features=1, bias=False)\n",
       "      (sm): Softmax(dim=1)\n",
       "    )\n",
       "    (prediction): Linear(in_features=40, out_features=12, bias=True)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "exp.model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "db55ff30",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " ----------------------- load all the data -------------------\n",
      "-----------------------Sliding file are generated -----------------------\n",
      "-----------------------Sliding file are generated -----------------------\n",
      "================ LOCV Mode ====================\n",
      "================ 9 CV ======================\n",
      "================ the 0 th CV Experiment ================ \n",
      "Leave one Out Experiment : The 1 Part as the test\n",
      "[-] Target sampling weights:  [0.00166667 0.00174825 0.00165837 0.00131062 0.00358423 0.00201207\n",
      " 0.00168634 0.00265957 0.003125   0.00181488 0.00131579 0.00793651]\n",
      "Train data number :  6040\n",
      "The number of classes is :  12\n",
      "The input_length  is :  168\n",
      "The channel_in is :  18\n",
      "Validation data number :  672\n",
      "Test data number :  5207\n",
      "================ Build the model ================ \n",
      "Build the TinyHAR model!\n",
      "Epoch: 1 cost time: 3.6696622371673584\n",
      "VALI: Epoch: 1, Steps: 24 | Train Loss: 2.0301719  Vali Loss: 1.7215954 Vali Accuracy: 0.5654762  Vali weighted F1: 0.4785685  Vali macro F1 0.3824785 \n",
      "Validation loss decreased (inf --> 1.721595).  Saving model ...\n",
      "Epoch: 2 cost time: 2.3505709171295166\n",
      "VALI: Epoch: 2, Steps: 24 | Train Loss: 1.2457244  Vali Loss: 0.9547124 Vali Accuracy: 0.8125000  Vali weighted F1: 0.7725548  Vali macro F1 0.6719618 \n",
      "new best score!!!!\n",
      "Validation loss decreased (1.721595 --> 0.954712).  Saving model ...\n",
      "new best score!!!!\n",
      "Epoch: 3 cost time: 2.3545384407043457\n",
      "VALI: Epoch: 3, Steps: 24 | Train Loss: 0.8093873  Vali Loss: 0.6729685 Vali Accuracy: 0.8735119  Vali weighted F1: 0.8580330  Vali macro F1 0.7839297 \n",
      "new best score!!!!\n",
      "Validation loss decreased (0.954712 --> 0.672968).  Saving model ...\n",
      "new best score!!!!\n",
      "Epoch: 4 cost time: 2.354524850845337\n",
      "VALI: Epoch: 4, Steps: 24 | Train Loss: 0.5820918  Vali Loss: 0.5195670 Vali Accuracy: 0.9122024  Vali weighted F1: 0.9110557  Vali macro F1 0.8867918 \n",
      "new best score!!!!\n",
      "Validation loss decreased (0.672968 --> 0.519567).  Saving model ...\n",
      "new best score!!!!\n",
      "Epoch: 5 cost time: 2.386859893798828\n",
      "VALI: Epoch: 5, Steps: 24 | Train Loss: 0.4448075  Vali Loss: 0.4305859 Vali Accuracy: 0.9181548  Vali weighted F1: 0.9185312  Vali macro F1 0.9007966 \n",
      "new best score!!!!\n",
      "Validation loss decreased (0.519567 --> 0.430586).  Saving model ...\n",
      "new best score!!!!\n",
      "Epoch: 6 cost time: 2.404536008834839\n",
      "VALI: Epoch: 6, Steps: 24 | Train Loss: 0.3678392  Vali Loss: 0.3770993 Vali Accuracy: 0.9241071  Vali weighted F1: 0.9254930  Vali macro F1 0.9145306 \n",
      "new best score!!!!\n",
      "Validation loss decreased (0.430586 --> 0.377099).  Saving model ...\n",
      "new best score!!!!\n",
      "Epoch: 7 cost time: 2.367527723312378\n",
      "VALI: Epoch: 7, Steps: 24 | Train Loss: 0.3149708  Vali Loss: 0.3513177 Vali Accuracy: 0.9196429  Vali weighted F1: 0.9208432  Vali macro F1 0.9104218 \n",
      "new best score!!!!\n",
      "Validation loss decreased (0.377099 --> 0.351318).  Saving model ...\n",
      "new best score!!!!\n",
      "Epoch: 8 cost time: 2.3535244464874268\n",
      "VALI: Epoch: 8, Steps: 24 | Train Loss: 0.2783498  Vali Loss: 0.3171871 Vali Accuracy: 0.9285714  Vali weighted F1: 0.9297134  Vali macro F1 0.9190070 \n",
      "new best score!!!!\n",
      "Validation loss decreased (0.351318 --> 0.317187).  Saving model ...\n",
      "new best score!!!!\n",
      "Epoch: 9 cost time: 2.3535237312316895\n",
      "VALI: Epoch: 9, Steps: 24 | Train Loss: 0.2532418  Vali Loss: 0.2970197 Vali Accuracy: 0.9300595  Vali weighted F1: 0.9313992  Vali macro F1 0.9219799 \n",
      "new best score!!!!\n",
      "Validation loss decreased (0.317187 --> 0.297020).  Saving model ...\n",
      "new best score!!!!\n",
      "Epoch: 10 cost time: 2.35152530670166\n",
      "VALI: Epoch: 10, Steps: 24 | Train Loss: 0.2292826  Vali Loss: 0.2810757 Vali Accuracy: 0.9315476  Vali weighted F1: 0.9322459  Vali macro F1 0.9221949 \n",
      "new best score!!!!\n",
      "Validation loss decreased (0.297020 --> 0.281076).  Saving model ...\n",
      "new best score!!!!\n",
      "Epoch: 11 cost time: 2.3646507263183594\n",
      "VALI: Epoch: 11, Steps: 24 | Train Loss: 0.2136065  Vali Loss: 0.2612590 Vali Accuracy: 0.9360119  Vali weighted F1: 0.9367054  Vali macro F1 0.9257194 \n",
      "new best score!!!!\n",
      "Validation loss decreased (0.281076 --> 0.261259).  Saving model ...\n",
      "new best score!!!!\n",
      "Epoch: 12 cost time: 2.4275901317596436\n",
      "VALI: Epoch: 12, Steps: 24 | Train Loss: 0.1978407  Vali Loss: 0.2503648 Vali Accuracy: 0.9360119  Vali weighted F1: 0.9368284  Vali macro F1 0.9239978 \n",
      "new best score!!!!\n",
      "Validation loss decreased (0.261259 --> 0.250365).  Saving model ...\n",
      "new best score!!!!\n",
      "Epoch: 13 cost time: 2.401553153991699\n",
      "VALI: Epoch: 13, Steps: 24 | Train Loss: 0.1827971  Vali Loss: 0.2427034 Vali Accuracy: 0.9345238  Vali weighted F1: 0.9350353  Vali macro F1 0.9267554 \n",
      "new best score!!!!\n",
      "Validation loss decreased (0.250365 --> 0.242703).  Saving model ...\n",
      "new best score!!!!\n",
      "Epoch: 14 cost time: 2.3548049926757812\n",
      "VALI: Epoch: 14, Steps: 24 | Train Loss: 0.1740288  Vali Loss: 0.2340582 Vali Accuracy: 0.9360119  Vali weighted F1: 0.9364976  Vali macro F1 0.9215839 \n",
      "new best score!!!!\n",
      "Validation loss decreased (0.242703 --> 0.234058).  Saving model ...\n",
      "new best score!!!!\n",
      "Epoch: 15 cost time: 2.414538621902466\n",
      "VALI: Epoch: 15, Steps: 24 | Train Loss: 0.1634680  Vali Loss: 0.2326821 Vali Accuracy: 0.9389881  Vali weighted F1: 0.9399789  Vali macro F1 0.9262957 \n",
      "new best score!!!!\n",
      "Validation loss decreased (0.234058 --> 0.232682).  Saving model ...\n",
      "new best score!!!!\n",
      "Epoch: 16 cost time: 2.3545243740081787\n",
      "VALI: Epoch: 16, Steps: 24 | Train Loss: 0.1556962  Vali Loss: 0.2239476 Vali Accuracy: 0.9389881  Vali weighted F1: 0.9395826  Vali macro F1 0.9244468 \n",
      "new best score!!!!\n",
      "Validation loss decreased (0.232682 --> 0.223948).  Saving model ...\n",
      "new best score!!!!\n",
      "Epoch: 17 cost time: 2.3595261573791504\n",
      "VALI: Epoch: 17, Steps: 24 | Train Loss: 0.1481999  Vali Loss: 0.2133411 Vali Accuracy: 0.9389881  Vali weighted F1: 0.9388419  Vali macro F1 0.9239713 \n",
      "new best score!!!!\n",
      "Validation loss decreased (0.223948 --> 0.213341).  Saving model ...\n",
      "new best score!!!!\n",
      "Epoch: 18 cost time: 2.3535242080688477\n",
      "VALI: Epoch: 18, Steps: 24 | Train Loss: 0.1390161  Vali Loss: 0.2074591 Vali Accuracy: 0.9434524  Vali weighted F1: 0.9434493  Vali macro F1 0.9322172 \n",
      "new best score!!!!\n",
      "Validation loss decreased (0.213341 --> 0.207459).  Saving model ...\n",
      "new best score!!!!\n",
      "Epoch: 19 cost time: 2.3910772800445557\n",
      "VALI: Epoch: 19, Steps: 24 | Train Loss: 0.1376745  Vali Loss: 0.2099886 Vali Accuracy: 0.9449405  Vali weighted F1: 0.9453734  Vali macro F1 0.9303642 \n",
      "EarlyStopping counter: 1 out of 21\n",
      "Learning rate adjusting counter: 1 out of 7\n",
      "Epoch: 20 cost time: 2.3719594478607178\n",
      "VALI: Epoch: 20, Steps: 24 | Train Loss: 0.1268612  Vali Loss: 0.2030356 Vali Accuracy: 0.9449405  Vali weighted F1: 0.9451071  Vali macro F1 0.9338356 \n",
      "new best score!!!!\n",
      "Validation loss decreased (0.207459 --> 0.203036).  Saving model ...\n",
      "new best score!!!!\n",
      "Epoch: 21 cost time: 2.3580267429351807\n",
      "VALI: Epoch: 21, Steps: 24 | Train Loss: 0.1251885  Vali Loss: 0.2217924 Vali Accuracy: 0.9434524  Vali weighted F1: 0.9434166  Vali macro F1 0.9269481 \n",
      "EarlyStopping counter: 1 out of 21\n",
      "Learning rate adjusting counter: 1 out of 7\n",
      "Epoch: 22 cost time: 2.3689801692962646\n",
      "VALI: Epoch: 22, Steps: 24 | Train Loss: 0.1168761  Vali Loss: 0.2089163 Vali Accuracy: 0.9419643  Vali weighted F1: 0.9419752  Vali macro F1 0.9264811 \n",
      "EarlyStopping counter: 2 out of 21\n",
      "Learning rate adjusting counter: 2 out of 7\n",
      "Epoch: 23 cost time: 2.360994815826416\n",
      "VALI: Epoch: 23, Steps: 24 | Train Loss: 0.1091386  Vali Loss: 0.2119951 Vali Accuracy: 0.9449405  Vali weighted F1: 0.9448243  Vali macro F1 0.9278489 \n",
      "EarlyStopping counter: 3 out of 21\n",
      "Learning rate adjusting counter: 3 out of 7\n",
      "Epoch: 24 cost time: 2.353043556213379\n",
      "VALI: Epoch: 24, Steps: 24 | Train Loss: 0.1074055  Vali Loss: 0.1933090 Vali Accuracy: 0.9479167  Vali weighted F1: 0.9476903  Vali macro F1 0.9360003 \n",
      "new best score!!!!\n",
      "Validation loss decreased (0.203036 --> 0.193309).  Saving model ...\n",
      "new best score!!!!\n",
      "Epoch: 25 cost time: 2.3610000610351562\n",
      "VALI: Epoch: 25, Steps: 24 | Train Loss: 0.1087653  Vali Loss: 0.2029733 Vali Accuracy: 0.9449405  Vali weighted F1: 0.9447193  Vali macro F1 0.9305685 \n",
      "EarlyStopping counter: 1 out of 21\n",
      "Learning rate adjusting counter: 1 out of 7\n",
      "Epoch: 26 cost time: 2.4289815425872803\n",
      "VALI: Epoch: 26, Steps: 24 | Train Loss: 0.1007607  Vali Loss: 0.1999261 Vali Accuracy: 0.9434524  Vali weighted F1: 0.9434692  Vali macro F1 0.9310775 \n",
      "EarlyStopping counter: 2 out of 21\n",
      "Learning rate adjusting counter: 2 out of 7\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 27 cost time: 2.3610012531280518\n",
      "VALI: Epoch: 27, Steps: 24 | Train Loss: 0.0926862  Vali Loss: 0.2027270 Vali Accuracy: 0.9494048  Vali weighted F1: 0.9495511  Vali macro F1 0.9405378 \n",
      "EarlyStopping counter: 3 out of 21\n",
      "Learning rate adjusting counter: 3 out of 7\n",
      "Epoch: 28 cost time: 2.3595099449157715\n",
      "VALI: Epoch: 28, Steps: 24 | Train Loss: 0.0941507  Vali Loss: 0.1895100 Vali Accuracy: 0.9479167  Vali weighted F1: 0.9474313  Vali macro F1 0.9359817 \n",
      "new best score!!!!\n",
      "Validation loss decreased (0.193309 --> 0.189510).  Saving model ...\n",
      "new best score!!!!\n",
      "Epoch: 29 cost time: 2.3755300045013428\n",
      "VALI: Epoch: 29, Steps: 24 | Train Loss: 0.0877150  Vali Loss: 0.1859047 Vali Accuracy: 0.9494048  Vali weighted F1: 0.9495127  Vali macro F1 0.9408521 \n",
      "new best score!!!!\n",
      "Validation loss decreased (0.189510 --> 0.185905).  Saving model ...\n",
      "new best score!!!!\n",
      "Epoch: 30 cost time: 2.3565170764923096\n",
      "VALI: Epoch: 30, Steps: 24 | Train Loss: 0.0896597  Vali Loss: 0.1994617 Vali Accuracy: 0.9449405  Vali weighted F1: 0.9448760  Vali macro F1 0.9313300 \n",
      "EarlyStopping counter: 1 out of 21\n",
      "Learning rate adjusting counter: 1 out of 7\n",
      "Epoch: 31 cost time: 2.3905324935913086\n",
      "VALI: Epoch: 31, Steps: 24 | Train Loss: 0.0850537  Vali Loss: 0.2263590 Vali Accuracy: 0.9404762  Vali weighted F1: 0.9399165  Vali macro F1 0.9243076 \n",
      "EarlyStopping counter: 2 out of 21\n",
      "Learning rate adjusting counter: 2 out of 7\n",
      "Epoch: 32 cost time: 2.3645267486572266\n",
      "VALI: Epoch: 32, Steps: 24 | Train Loss: 0.0919342  Vali Loss: 0.2024489 Vali Accuracy: 0.9508929  Vali weighted F1: 0.9508785  Vali macro F1 0.9399364 \n",
      "EarlyStopping counter: 3 out of 21\n",
      "Learning rate adjusting counter: 3 out of 7\n",
      "Epoch: 33 cost time: 2.364535331726074\n",
      "VALI: Epoch: 33, Steps: 24 | Train Loss: 0.0807794  Vali Loss: 0.2075256 Vali Accuracy: 0.9464286  Vali weighted F1: 0.9466544  Vali macro F1 0.9342792 \n",
      "EarlyStopping counter: 4 out of 21\n",
      "Learning rate adjusting counter: 4 out of 7\n",
      "Epoch: 34 cost time: 2.3615269660949707\n",
      "VALI: Epoch: 34, Steps: 24 | Train Loss: 0.0756778  Vali Loss: 0.1982223 Vali Accuracy: 0.9494048  Vali weighted F1: 0.9491847  Vali macro F1 0.9398081 \n",
      "EarlyStopping counter: 5 out of 21\n",
      "Learning rate adjusting counter: 5 out of 7\n",
      "Epoch: 35 cost time: 2.35752534866333\n",
      "VALI: Epoch: 35, Steps: 24 | Train Loss: 0.0705488  Vali Loss: 0.1852137 Vali Accuracy: 0.9508929  Vali weighted F1: 0.9507800  Vali macro F1 0.9420612 \n",
      "new best score!!!!\n",
      "Validation loss decreased (0.185905 --> 0.185214).  Saving model ...\n",
      "new best score!!!!\n",
      "Epoch: 36 cost time: 2.3531980514526367\n",
      "VALI: Epoch: 36, Steps: 24 | Train Loss: 0.0665763  Vali Loss: 0.1907872 Vali Accuracy: 0.9479167  Vali weighted F1: 0.9476125  Vali macro F1 0.9374433 \n",
      "EarlyStopping counter: 1 out of 21\n",
      "Learning rate adjusting counter: 1 out of 7\n",
      "Epoch: 37 cost time: 2.3645730018615723\n",
      "VALI: Epoch: 37, Steps: 24 | Train Loss: 0.0664104  Vali Loss: 0.1953778 Vali Accuracy: 0.9479167  Vali weighted F1: 0.9471399  Vali macro F1 0.9321803 \n",
      "EarlyStopping counter: 2 out of 21\n",
      "Learning rate adjusting counter: 2 out of 7\n",
      "Epoch: 38 cost time: 2.3645379543304443\n",
      "VALI: Epoch: 38, Steps: 24 | Train Loss: 0.0622750  Vali Loss: 0.1890784 Vali Accuracy: 0.9464286  Vali weighted F1: 0.9460455  Vali macro F1 0.9335502 \n",
      "EarlyStopping counter: 3 out of 21\n",
      "Learning rate adjusting counter: 3 out of 7\n",
      "Epoch: 39 cost time: 2.3866915702819824\n",
      "VALI: Epoch: 39, Steps: 24 | Train Loss: 0.0573720  Vali Loss: 0.2018055 Vali Accuracy: 0.9464286  Vali weighted F1: 0.9472765  Vali macro F1 0.9315168 \n",
      "EarlyStopping counter: 4 out of 21\n",
      "Learning rate adjusting counter: 4 out of 7\n",
      "Epoch: 40 cost time: 2.3446762561798096\n",
      "VALI: Epoch: 40, Steps: 24 | Train Loss: 0.0598467  Vali Loss: 0.1937873 Vali Accuracy: 0.9494048  Vali weighted F1: 0.9493640  Vali macro F1 0.9356378 \n",
      "EarlyStopping counter: 5 out of 21\n",
      "Learning rate adjusting counter: 5 out of 7\n",
      "Epoch: 41 cost time: 2.3466317653656006\n",
      "VALI: Epoch: 41, Steps: 24 | Train Loss: 0.0589583  Vali Loss: 0.1947172 Vali Accuracy: 0.9434524  Vali weighted F1: 0.9428664  Vali macro F1 0.9267951 \n",
      "EarlyStopping counter: 6 out of 21\n",
      "Learning rate adjusting counter: 6 out of 7\n",
      "Epoch: 42 cost time: 2.3585264682769775\n",
      "VALI: Epoch: 42, Steps: 24 | Train Loss: 0.0580888  Vali Loss: 0.2170241 Vali Accuracy: 0.9419643  Vali weighted F1: 0.9418152  Vali macro F1 0.9292122 \n",
      "EarlyStopping counter: 7 out of 21\n",
      "Learning rate adjusting counter: 7 out of 7\n",
      "Updating learning rate to 0.0001\n",
      "Epoch: 43 cost time: 2.3435311317443848\n",
      "VALI: Epoch: 43, Steps: 24 | Train Loss: 0.0538190  Vali Loss: 0.1966432 Vali Accuracy: 0.9449405  Vali weighted F1: 0.9444099  Vali macro F1 0.9312734 \n",
      "EarlyStopping counter: 8 out of 21\n",
      "Learning rate adjusting counter: 1 out of 7\n",
      "Epoch: 44 cost time: 2.3367297649383545\n",
      "VALI: Epoch: 44, Steps: 24 | Train Loss: 0.0485479  Vali Loss: 0.1930602 Vali Accuracy: 0.9449405  Vali weighted F1: 0.9443637  Vali macro F1 0.9293261 \n",
      "EarlyStopping counter: 9 out of 21\n",
      "Learning rate adjusting counter: 2 out of 7\n",
      "Epoch: 45 cost time: 2.336381673812866\n",
      "VALI: Epoch: 45, Steps: 24 | Train Loss: 0.0469290  Vali Loss: 0.1915758 Vali Accuracy: 0.9449405  Vali weighted F1: 0.9443874  Vali macro F1 0.9309135 \n",
      "EarlyStopping counter: 10 out of 21\n",
      "Learning rate adjusting counter: 3 out of 7\n",
      "Epoch: 46 cost time: 2.3365120887756348\n",
      "VALI: Epoch: 46, Steps: 24 | Train Loss: 0.0463347  Vali Loss: 0.1901891 Vali Accuracy: 0.9464286  Vali weighted F1: 0.9459493  Vali macro F1 0.9322490 \n",
      "EarlyStopping counter: 11 out of 21\n",
      "Learning rate adjusting counter: 4 out of 7\n",
      "Epoch: 47 cost time: 2.3335201740264893\n",
      "VALI: Epoch: 47, Steps: 24 | Train Loss: 0.0452494  Vali Loss: 0.1887792 Vali Accuracy: 0.9464286  Vali weighted F1: 0.9459736  Vali macro F1 0.9328679 \n",
      "EarlyStopping counter: 12 out of 21\n",
      "Learning rate adjusting counter: 5 out of 7\n",
      "Epoch: 48 cost time: 2.357337713241577\n",
      "VALI: Epoch: 48, Steps: 24 | Train Loss: 0.0455243  Vali Loss: 0.1881570 Vali Accuracy: 0.9479167  Vali weighted F1: 0.9474819  Vali macro F1 0.9341010 \n",
      "EarlyStopping counter: 13 out of 21\n",
      "Learning rate adjusting counter: 6 out of 7\n",
      "Epoch: 49 cost time: 2.3338937759399414\n",
      "VALI: Epoch: 49, Steps: 24 | Train Loss: 0.0451646  Vali Loss: 0.1869377 Vali Accuracy: 0.9464286  Vali weighted F1: 0.9459829  Vali macro F1 0.9330390 \n",
      "EarlyStopping counter: 14 out of 21\n",
      "Learning rate adjusting counter: 7 out of 7\n",
      "Updating learning rate to 1e-05\n",
      "Epoch: 50 cost time: 2.346524715423584\n",
      "VALI: Epoch: 50, Steps: 24 | Train Loss: 0.0439905  Vali Loss: 0.1865502 Vali Accuracy: 0.9464286  Vali weighted F1: 0.9459829  Vali macro F1 0.9330390 \n",
      "EarlyStopping counter: 15 out of 21\n",
      "Learning rate adjusting counter: 1 out of 7\n",
      "Epoch: 51 cost time: 2.3832645416259766\n",
      "VALI: Epoch: 51, Steps: 24 | Train Loss: 0.0451684  Vali Loss: 0.1868442 Vali Accuracy: 0.9479167  Vali weighted F1: 0.9474819  Vali macro F1 0.9341010 \n",
      "EarlyStopping counter: 16 out of 21\n",
      "Learning rate adjusting counter: 2 out of 7\n",
      "Epoch: 52 cost time: 2.3645503520965576\n",
      "VALI: Epoch: 52, Steps: 24 | Train Loss: 0.0457724  Vali Loss: 0.1874469 Vali Accuracy: 0.9479167  Vali weighted F1: 0.9474819  Vali macro F1 0.9341010 \n",
      "EarlyStopping counter: 17 out of 21\n",
      "Learning rate adjusting counter: 3 out of 7\n",
      "Epoch: 53 cost time: 2.3395214080810547\n",
      "VALI: Epoch: 53, Steps: 24 | Train Loss: 0.0439956  Vali Loss: 0.1875157 Vali Accuracy: 0.9479167  Vali weighted F1: 0.9474819  Vali macro F1 0.9341010 \n",
      "EarlyStopping counter: 18 out of 21\n",
      "Learning rate adjusting counter: 4 out of 7\n",
      "Epoch: 54 cost time: 2.348453998565674\n",
      "VALI: Epoch: 54, Steps: 24 | Train Loss: 0.0435705  Vali Loss: 0.1881198 Vali Accuracy: 0.9479167  Vali weighted F1: 0.9474819  Vali macro F1 0.9341010 \n",
      "EarlyStopping counter: 19 out of 21\n",
      "Learning rate adjusting counter: 5 out of 7\n",
      "Epoch: 55 cost time: 2.4065933227539062\n",
      "VALI: Epoch: 55, Steps: 24 | Train Loss: 0.0437440  Vali Loss: 0.1874577 Vali Accuracy: 0.9479167  Vali weighted F1: 0.9474819  Vali macro F1 0.9341010 \n",
      "EarlyStopping counter: 20 out of 21\n",
      "Learning rate adjusting counter: 6 out of 7\n",
      "Epoch: 56 cost time: 2.4165821075439453\n",
      "VALI: Epoch: 56, Steps: 24 | Train Loss: 0.0435928  Vali Loss: 0.1871096 Vali Accuracy: 0.9479167  Vali weighted F1: 0.9474819  Vali macro F1 0.9341010 \n",
      "EarlyStopping counter: 21 out of 21\n",
      "Early stopping\n",
      "Loading the best validation model!\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Final Test Performance : Test Accuracy: 0.8164010  Test weighted F1: 0.8177272  Test macro F1 0.8233604 \n",
      "================ the 1 th CV Experiment ================ \n",
      "Leave one Out Experiment : The 2 Part as the test\n",
      "[-] Target sampling weights:  [0.00165563 0.00171527 0.00167504 0.00134048 0.00315457 0.00203252\n",
      " 0.00181159 0.0027027  0.00316456 0.00179856 0.00136054 0.00793651]\n",
      "Train data number :  5994\n",
      "The number of classes is :  12\n",
      "The input_length  is :  168\n",
      "The channel_in is :  18\n",
      "Validation data number :  666\n",
      "Test data number :  5487\n",
      "================ Build the model ================ \n",
      "Build the TinyHAR model!\n",
      "Epoch: 1 cost time: 2.3811776638031006\n",
      "VALI: Epoch: 1, Steps: 24 | Train Loss: 2.0346323  Vali Loss: 1.7678689 Vali Accuracy: 0.5480480  Vali weighted F1: 0.4682358  Vali macro F1 0.4002561 \n",
      "Validation loss decreased (inf --> 1.767869).  Saving model ...\n",
      "Epoch: 2 cost time: 2.3722190856933594\n",
      "VALI: Epoch: 2, Steps: 24 | Train Loss: 1.2569980  Vali Loss: 1.0456466 Vali Accuracy: 0.7642643  Vali weighted F1: 0.7191204  Vali macro F1 0.6221871 \n",
      "new best score!!!!\n",
      "Validation loss decreased (1.767869 --> 1.045647).  Saving model ...\n",
      "new best score!!!!\n",
      "Epoch: 3 cost time: 2.384976625442505\n",
      "VALI: Epoch: 3, Steps: 24 | Train Loss: 0.8246830  Vali Loss: 0.7647760 Vali Accuracy: 0.8303303  Vali weighted F1: 0.8146788  Vali macro F1 0.7482862 \n",
      "new best score!!!!\n",
      "Validation loss decreased (1.045647 --> 0.764776).  Saving model ...\n",
      "new best score!!!!\n",
      "Epoch: 4 cost time: 2.47412109375\n",
      "VALI: Epoch: 4, Steps: 24 | Train Loss: 0.5950074  Vali Loss: 0.5989097 Vali Accuracy: 0.8738739  Vali weighted F1: 0.8671550  Vali macro F1 0.8073105 \n",
      "new best score!!!!\n",
      "Validation loss decreased (0.764776 --> 0.598910).  Saving model ...\n",
      "new best score!!!!\n",
      "Epoch: 5 cost time: 2.3793246746063232\n",
      "VALI: Epoch: 5, Steps: 24 | Train Loss: 0.4547388  Vali Loss: 0.5064141 Vali Accuracy: 0.8918919  Vali weighted F1: 0.8920575  Vali macro F1 0.8706725 \n",
      "new best score!!!!\n",
      "Validation loss decreased (0.598910 --> 0.506414).  Saving model ...\n",
      "new best score!!!!\n",
      "Epoch: 6 cost time: 2.3743515014648438\n",
      "VALI: Epoch: 6, Steps: 24 | Train Loss: 0.3671371  Vali Loss: 0.4498768 Vali Accuracy: 0.9054054  Vali weighted F1: 0.9063934  Vali macro F1 0.8908344 \n",
      "new best score!!!!\n",
      "Validation loss decreased (0.506414 --> 0.449877).  Saving model ...\n",
      "new best score!!!!\n",
      "Epoch: 7 cost time: 2.363222360610962\n",
      "VALI: Epoch: 7, Steps: 24 | Train Loss: 0.3199005  Vali Loss: 0.4169336 Vali Accuracy: 0.9099099  Vali weighted F1: 0.9117111  Vali macro F1 0.8968846 \n",
      "new best score!!!!\n",
      "Validation loss decreased (0.449877 --> 0.416934).  Saving model ...\n",
      "new best score!!!!\n",
      "Epoch: 8 cost time: 2.3721179962158203\n",
      "VALI: Epoch: 8, Steps: 24 | Train Loss: 0.2826883  Vali Loss: 0.3875062 Vali Accuracy: 0.9159159  Vali weighted F1: 0.9168735  Vali macro F1 0.9028180 \n",
      "new best score!!!!\n",
      "Validation loss decreased (0.416934 --> 0.387506).  Saving model ...\n",
      "new best score!!!!\n",
      "Epoch: 9 cost time: 2.371636390686035\n",
      "VALI: Epoch: 9, Steps: 24 | Train Loss: 0.2526663  Vali Loss: 0.3674570 Vali Accuracy: 0.9174174  Vali weighted F1: 0.9184100  Vali macro F1 0.9032210 \n",
      "new best score!!!!\n",
      "Validation loss decreased (0.387506 --> 0.367457).  Saving model ...\n",
      "new best score!!!!\n",
      "Epoch: 10 cost time: 2.3758156299591064\n",
      "VALI: Epoch: 10, Steps: 24 | Train Loss: 0.2388914  Vali Loss: 0.3550156 Vali Accuracy: 0.9204204  Vali weighted F1: 0.9210915  Vali macro F1 0.9090315 \n",
      "new best score!!!!\n",
      "Validation loss decreased (0.367457 --> 0.355016).  Saving model ...\n",
      "new best score!!!!\n",
      "Epoch: 11 cost time: 2.3893725872039795\n",
      "VALI: Epoch: 11, Steps: 24 | Train Loss: 0.2246723  Vali Loss: 0.3394196 Vali Accuracy: 0.9219219  Vali weighted F1: 0.9226394  Vali macro F1 0.9091424 \n",
      "new best score!!!!\n",
      "Validation loss decreased (0.355016 --> 0.339420).  Saving model ...\n",
      "new best score!!!!\n",
      "Epoch: 12 cost time: 2.374530553817749\n",
      "VALI: Epoch: 12, Steps: 24 | Train Loss: 0.2117751  Vali Loss: 0.3430681 Vali Accuracy: 0.9159159  Vali weighted F1: 0.9171895  Vali macro F1 0.9077495 \n",
      "EarlyStopping counter: 1 out of 21\n",
      "Learning rate adjusting counter: 1 out of 7\n",
      "Epoch: 13 cost time: 2.3697404861450195\n",
      "VALI: Epoch: 13, Steps: 24 | Train Loss: 0.2047593  Vali Loss: 0.3240912 Vali Accuracy: 0.9234234  Vali weighted F1: 0.9238750  Vali macro F1 0.9110163 \n",
      "new best score!!!!\n",
      "Validation loss decreased (0.339420 --> 0.324091).  Saving model ...\n",
      "new best score!!!!\n",
      "Epoch: 14 cost time: 2.4958724975585938\n",
      "VALI: Epoch: 14, Steps: 24 | Train Loss: 0.1922713  Vali Loss: 0.3168322 Vali Accuracy: 0.9219219  Vali weighted F1: 0.9223201  Vali macro F1 0.9112370 \n",
      "new best score!!!!\n",
      "Validation loss decreased (0.324091 --> 0.316832).  Saving model ...\n",
      "new best score!!!!\n",
      "Epoch: 15 cost time: 2.4326534271240234\n",
      "VALI: Epoch: 15, Steps: 24 | Train Loss: 0.1813532  Vali Loss: 0.3090446 Vali Accuracy: 0.9264264  Vali weighted F1: 0.9267221  Vali macro F1 0.9132285 \n",
      "new best score!!!!\n",
      "Validation loss decreased (0.316832 --> 0.309045).  Saving model ...\n",
      "new best score!!!!\n",
      "Epoch: 16 cost time: 2.3566370010375977\n",
      "VALI: Epoch: 16, Steps: 24 | Train Loss: 0.1713664  Vali Loss: 0.3008691 Vali Accuracy: 0.9249249  Vali weighted F1: 0.9253588  Vali macro F1 0.9138568 \n",
      "new best score!!!!\n",
      "Validation loss decreased (0.309045 --> 0.300869).  Saving model ...\n",
      "new best score!!!!\n",
      "Epoch: 17 cost time: 2.3515241146087646\n",
      "VALI: Epoch: 17, Steps: 24 | Train Loss: 0.1648774  Vali Loss: 0.2936511 Vali Accuracy: 0.9249249  Vali weighted F1: 0.9250733  Vali macro F1 0.9142911 \n",
      "new best score!!!!\n",
      "Validation loss decreased (0.300869 --> 0.293651).  Saving model ...\n",
      "new best score!!!!\n",
      "Epoch: 18 cost time: 2.3854949474334717\n",
      "VALI: Epoch: 18, Steps: 24 | Train Loss: 0.1545059  Vali Loss: 0.2935305 Vali Accuracy: 0.9279279  Vali weighted F1: 0.9279014  Vali macro F1 0.9142171 \n",
      "new best score!!!!\n",
      "Validation loss decreased (0.293651 --> 0.293531).  Saving model ...\n",
      "new best score!!!!\n",
      "Epoch: 19 cost time: 2.360534429550171\n",
      "VALI: Epoch: 19, Steps: 24 | Train Loss: 0.1508326  Vali Loss: 0.2780683 Vali Accuracy: 0.9309309  Vali weighted F1: 0.9315521  Vali macro F1 0.9170526 \n",
      "new best score!!!!\n",
      "Validation loss decreased (0.293531 --> 0.278068).  Saving model ...\n",
      "new best score!!!!\n",
      "Epoch: 20 cost time: 2.351576566696167\n",
      "VALI: Epoch: 20, Steps: 24 | Train Loss: 0.1436450  Vali Loss: 0.2827483 Vali Accuracy: 0.9324324  Vali weighted F1: 0.9331877  Vali macro F1 0.9227241 \n",
      "EarlyStopping counter: 1 out of 21\n",
      "Learning rate adjusting counter: 1 out of 7\n",
      "Epoch: 21 cost time: 2.361764907836914\n",
      "VALI: Epoch: 21, Steps: 24 | Train Loss: 0.1328470  Vali Loss: 0.2813866 Vali Accuracy: 0.9264264  Vali weighted F1: 0.9267258  Vali macro F1 0.9127008 \n",
      "EarlyStopping counter: 2 out of 21\n",
      "Learning rate adjusting counter: 2 out of 7\n",
      "Epoch: 22 cost time: 2.3761377334594727\n",
      "VALI: Epoch: 22, Steps: 24 | Train Loss: 0.1338902  Vali Loss: 0.2778034 Vali Accuracy: 0.9324324  Vali weighted F1: 0.9323121  Vali macro F1 0.9178801 \n",
      "new best score!!!!\n",
      "Validation loss decreased (0.278068 --> 0.277803).  Saving model ...\n",
      "new best score!!!!\n",
      "Epoch: 23 cost time: 2.3565807342529297\n",
      "VALI: Epoch: 23, Steps: 24 | Train Loss: 0.1287392  Vali Loss: 0.2585207 Vali Accuracy: 0.9369369  Vali weighted F1: 0.9370010  Vali macro F1 0.9215734 \n",
      "new best score!!!!\n",
      "Validation loss decreased (0.277803 --> 0.258521).  Saving model ...\n",
      "new best score!!!!\n",
      "Epoch: 24 cost time: 2.377537965774536\n",
      "VALI: Epoch: 24, Steps: 24 | Train Loss: 0.1194500  Vali Loss: 0.2753460 Vali Accuracy: 0.9249249  Vali weighted F1: 0.9248701  Vali macro F1 0.9120698 \n",
      "EarlyStopping counter: 1 out of 21\n",
      "Learning rate adjusting counter: 1 out of 7\n",
      "Epoch: 25 cost time: 2.3725364208221436\n",
      "VALI: Epoch: 25, Steps: 24 | Train Loss: 0.1157118  Vali Loss: 0.2849974 Vali Accuracy: 0.9309309  Vali weighted F1: 0.9305913  Vali macro F1 0.9166355 \n",
      "EarlyStopping counter: 2 out of 21\n",
      "Learning rate adjusting counter: 2 out of 7\n",
      "Epoch: 26 cost time: 2.354524850845337\n",
      "VALI: Epoch: 26, Steps: 24 | Train Loss: 0.1129602  Vali Loss: 0.2662312 Vali Accuracy: 0.9294294  Vali weighted F1: 0.9293027  Vali macro F1 0.9163071 \n",
      "EarlyStopping counter: 3 out of 21\n",
      "Learning rate adjusting counter: 3 out of 7\n",
      "Epoch: 27 cost time: 2.3465445041656494\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "VALI: Epoch: 27, Steps: 24 | Train Loss: 0.1179154  Vali Loss: 0.2661587 Vali Accuracy: 0.9294294  Vali weighted F1: 0.9291999  Vali macro F1 0.9140798 \n",
      "EarlyStopping counter: 4 out of 21\n",
      "Learning rate adjusting counter: 4 out of 7\n",
      "Epoch: 28 cost time: 2.3505232334136963\n",
      "VALI: Epoch: 28, Steps: 24 | Train Loss: 0.1111430  Vali Loss: 0.2595508 Vali Accuracy: 0.9309309  Vali weighted F1: 0.9314480  Vali macro F1 0.9192411 \n",
      "EarlyStopping counter: 5 out of 21\n",
      "Learning rate adjusting counter: 5 out of 7\n",
      "Epoch: 29 cost time: 2.3515779972076416\n",
      "VALI: Epoch: 29, Steps: 24 | Train Loss: 0.1061199  Vali Loss: 0.2479389 Vali Accuracy: 0.9369369  Vali weighted F1: 0.9365445  Vali macro F1 0.9212091 \n",
      "new best score!!!!\n",
      "Validation loss decreased (0.258521 --> 0.247939).  Saving model ...\n",
      "new best score!!!!\n",
      "Epoch: 30 cost time: 2.3605382442474365\n",
      "VALI: Epoch: 30, Steps: 24 | Train Loss: 0.1000805  Vali Loss: 0.2511146 Vali Accuracy: 0.9354354  Vali weighted F1: 0.9351867  Vali macro F1 0.9194250 \n",
      "EarlyStopping counter: 1 out of 21\n",
      "Learning rate adjusting counter: 1 out of 7\n",
      "Epoch: 31 cost time: 2.3584933280944824\n",
      "VALI: Epoch: 31, Steps: 24 | Train Loss: 0.0933169  Vali Loss: 0.2655808 Vali Accuracy: 0.9384384  Vali weighted F1: 0.9379684  Vali macro F1 0.9245625 \n",
      "EarlyStopping counter: 2 out of 21\n",
      "Learning rate adjusting counter: 2 out of 7\n",
      "Epoch: 32 cost time: 2.3562204837799072\n",
      "VALI: Epoch: 32, Steps: 24 | Train Loss: 0.0953635  Vali Loss: 0.2643116 Vali Accuracy: 0.9309309  Vali weighted F1: 0.9309571  Vali macro F1 0.9154195 \n",
      "EarlyStopping counter: 3 out of 21\n",
      "Learning rate adjusting counter: 3 out of 7\n",
      "Epoch: 33 cost time: 2.3756203651428223\n",
      "VALI: Epoch: 33, Steps: 24 | Train Loss: 0.0892897  Vali Loss: 0.2565284 Vali Accuracy: 0.9354354  Vali weighted F1: 0.9351679  Vali macro F1 0.9222257 \n",
      "EarlyStopping counter: 4 out of 21\n",
      "Learning rate adjusting counter: 4 out of 7\n",
      "Epoch: 34 cost time: 2.345522880554199\n",
      "VALI: Epoch: 34, Steps: 24 | Train Loss: 0.0900978  Vali Loss: 0.2769604 Vali Accuracy: 0.9294294  Vali weighted F1: 0.9293823  Vali macro F1 0.9173533 \n",
      "EarlyStopping counter: 5 out of 21\n",
      "Learning rate adjusting counter: 5 out of 7\n",
      "Epoch: 35 cost time: 2.3655264377593994\n",
      "VALI: Epoch: 35, Steps: 24 | Train Loss: 0.1068713  Vali Loss: 0.2886358 Vali Accuracy: 0.9324324  Vali weighted F1: 0.9323789  Vali macro F1 0.9174426 \n",
      "EarlyStopping counter: 6 out of 21\n",
      "Learning rate adjusting counter: 6 out of 7\n",
      "Epoch: 36 cost time: 2.346532106399536\n",
      "VALI: Epoch: 36, Steps: 24 | Train Loss: 0.0903281  Vali Loss: 0.2471785 Vali Accuracy: 0.9399399  Vali weighted F1: 0.9398343  Vali macro F1 0.9271539 \n",
      "new best score!!!!\n",
      "Validation loss decreased (0.247939 --> 0.247178).  Saving model ...\n",
      "new best score!!!!\n",
      "Epoch: 37 cost time: 2.3465232849121094\n",
      "VALI: Epoch: 37, Steps: 24 | Train Loss: 0.0797844  Vali Loss: 0.2667241 Vali Accuracy: 0.9384384  Vali weighted F1: 0.9384326  Vali macro F1 0.9218243 \n",
      "EarlyStopping counter: 1 out of 21\n",
      "Learning rate adjusting counter: 1 out of 7\n",
      "Epoch: 38 cost time: 2.3745315074920654\n",
      "VALI: Epoch: 38, Steps: 24 | Train Loss: 0.0793030  Vali Loss: 0.2502203 Vali Accuracy: 0.9369369  Vali weighted F1: 0.9369923  Vali macro F1 0.9235689 \n",
      "EarlyStopping counter: 2 out of 21\n",
      "Learning rate adjusting counter: 2 out of 7\n",
      "Epoch: 39 cost time: 2.365853786468506\n",
      "VALI: Epoch: 39, Steps: 24 | Train Loss: 0.0745436  Vali Loss: 0.2482080 Vali Accuracy: 0.9384384  Vali weighted F1: 0.9386113  Vali macro F1 0.9269419 \n",
      "EarlyStopping counter: 3 out of 21\n",
      "Learning rate adjusting counter: 3 out of 7\n",
      "Epoch: 40 cost time: 2.3780367374420166\n",
      "VALI: Epoch: 40, Steps: 24 | Train Loss: 0.0716373  Vali Loss: 0.2446068 Vali Accuracy: 0.9369369  Vali weighted F1: 0.9367298  Vali macro F1 0.9223939 \n",
      "new best score!!!!\n",
      "Validation loss decreased (0.247178 --> 0.244607).  Saving model ...\n",
      "new best score!!!!\n",
      "Epoch: 41 cost time: 2.434938907623291\n",
      "VALI: Epoch: 41, Steps: 24 | Train Loss: 0.0686835  Vali Loss: 0.2605071 Vali Accuracy: 0.9279279  Vali weighted F1: 0.9280590  Vali macro F1 0.9148206 \n",
      "EarlyStopping counter: 1 out of 21\n",
      "Learning rate adjusting counter: 1 out of 7\n",
      "Epoch: 42 cost time: 2.3621296882629395\n",
      "VALI: Epoch: 42, Steps: 24 | Train Loss: 0.0700533  Vali Loss: 0.2281334 Vali Accuracy: 0.9399399  Vali weighted F1: 0.9403655  Vali macro F1 0.9260437 \n",
      "new best score!!!!\n",
      "Validation loss decreased (0.244607 --> 0.228133).  Saving model ...\n",
      "new best score!!!!\n",
      "Epoch: 43 cost time: 2.3484079837799072\n",
      "VALI: Epoch: 43, Steps: 24 | Train Loss: 0.0669376  Vali Loss: 0.2329732 Vali Accuracy: 0.9399399  Vali weighted F1: 0.9397302  Vali macro F1 0.9255914 \n",
      "EarlyStopping counter: 1 out of 21\n",
      "Learning rate adjusting counter: 1 out of 7\n",
      "Epoch: 44 cost time: 2.360527276992798\n",
      "VALI: Epoch: 44, Steps: 24 | Train Loss: 0.0607642  Vali Loss: 0.2409839 Vali Accuracy: 0.9399399  Vali weighted F1: 0.9395301  Vali macro F1 0.9229205 \n",
      "EarlyStopping counter: 2 out of 21\n",
      "Learning rate adjusting counter: 2 out of 7\n",
      "Epoch: 45 cost time: 2.353524923324585\n",
      "VALI: Epoch: 45, Steps: 24 | Train Loss: 0.0593849  Vali Loss: 0.2513357 Vali Accuracy: 0.9399399  Vali weighted F1: 0.9396691  Vali macro F1 0.9250788 \n",
      "EarlyStopping counter: 3 out of 21\n",
      "Learning rate adjusting counter: 3 out of 7\n",
      "Epoch: 46 cost time: 2.343522548675537\n",
      "VALI: Epoch: 46, Steps: 24 | Train Loss: 0.0565408  Vali Loss: 0.2610859 Vali Accuracy: 0.9384384  Vali weighted F1: 0.9381314  Vali macro F1 0.9233330 \n",
      "EarlyStopping counter: 4 out of 21\n",
      "Learning rate adjusting counter: 4 out of 7\n",
      "Epoch: 47 cost time: 2.3416802883148193\n",
      "VALI: Epoch: 47, Steps: 24 | Train Loss: 0.0550762  Vali Loss: 0.2610995 Vali Accuracy: 0.9369369  Vali weighted F1: 0.9364787  Vali macro F1 0.9224889 \n",
      "EarlyStopping counter: 5 out of 21\n",
      "Learning rate adjusting counter: 5 out of 7\n",
      "Epoch: 48 cost time: 2.330518960952759\n",
      "VALI: Epoch: 48, Steps: 24 | Train Loss: 0.0596390  Vali Loss: 0.2500997 Vali Accuracy: 0.9369369  Vali weighted F1: 0.9377471  Vali macro F1 0.9272277 \n",
      "EarlyStopping counter: 6 out of 21\n",
      "Learning rate adjusting counter: 6 out of 7\n",
      "Epoch: 49 cost time: 2.4200501441955566\n",
      "VALI: Epoch: 49, Steps: 24 | Train Loss: 0.0570225  Vali Loss: 0.2445370 Vali Accuracy: 0.9414414  Vali weighted F1: 0.9413897  Vali macro F1 0.9304432 \n",
      "EarlyStopping counter: 7 out of 21\n",
      "Learning rate adjusting counter: 7 out of 7\n",
      "Updating learning rate to 0.0001\n",
      "Epoch: 50 cost time: 2.365527868270874\n",
      "VALI: Epoch: 50, Steps: 24 | Train Loss: 0.0472345  Vali Loss: 0.2380524 Vali Accuracy: 0.9414414  Vali weighted F1: 0.9415394  Vali macro F1 0.9288999 \n",
      "EarlyStopping counter: 8 out of 21\n",
      "Learning rate adjusting counter: 1 out of 7\n",
      "Epoch: 51 cost time: 2.348055601119995\n",
      "VALI: Epoch: 51, Steps: 24 | Train Loss: 0.0458526  Vali Loss: 0.2401548 Vali Accuracy: 0.9429429  Vali weighted F1: 0.9429733  Vali macro F1 0.9281955 \n",
      "EarlyStopping counter: 9 out of 21\n",
      "Learning rate adjusting counter: 2 out of 7\n",
      "Epoch: 52 cost time: 2.339522123336792\n",
      "VALI: Epoch: 52, Steps: 24 | Train Loss: 0.0457439  Vali Loss: 0.2420873 Vali Accuracy: 0.9429429  Vali weighted F1: 0.9429733  Vali macro F1 0.9281955 \n",
      "EarlyStopping counter: 10 out of 21\n",
      "Learning rate adjusting counter: 3 out of 7\n",
      "Epoch: 53 cost time: 2.3375275135040283\n",
      "VALI: Epoch: 53, Steps: 24 | Train Loss: 0.0448527  Vali Loss: 0.2440799 Vali Accuracy: 0.9414414  Vali weighted F1: 0.9415895  Vali macro F1 0.9267996 \n",
      "EarlyStopping counter: 11 out of 21\n",
      "Learning rate adjusting counter: 4 out of 7\n",
      "Epoch: 54 cost time: 2.3460440635681152\n",
      "VALI: Epoch: 54, Steps: 24 | Train Loss: 0.0415927  Vali Loss: 0.2443592 Vali Accuracy: 0.9414414  Vali weighted F1: 0.9415895  Vali macro F1 0.9267996 \n",
      "EarlyStopping counter: 12 out of 21\n",
      "Learning rate adjusting counter: 5 out of 7\n",
      "Epoch: 55 cost time: 2.3560690879821777\n",
      "VALI: Epoch: 55, Steps: 24 | Train Loss: 0.0439052  Vali Loss: 0.2431392 Vali Accuracy: 0.9399399  Vali weighted F1: 0.9400701  Vali macro F1 0.9246040 \n",
      "EarlyStopping counter: 13 out of 21\n",
      "Learning rate adjusting counter: 6 out of 7\n",
      "Epoch: 56 cost time: 2.339521884918213\n",
      "VALI: Epoch: 56, Steps: 24 | Train Loss: 0.0444955  Vali Loss: 0.2448653 Vali Accuracy: 0.9414414  Vali weighted F1: 0.9415485  Vali macro F1 0.9271908 \n",
      "EarlyStopping counter: 14 out of 21\n",
      "Learning rate adjusting counter: 7 out of 7\n",
      "Updating learning rate to 1e-05\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 57 cost time: 2.340850591659546\n",
      "VALI: Epoch: 57, Steps: 24 | Train Loss: 0.0422322  Vali Loss: 0.2428934 Vali Accuracy: 0.9429429  Vali weighted F1: 0.9429948  Vali macro F1 0.9287866 \n",
      "EarlyStopping counter: 15 out of 21\n",
      "Learning rate adjusting counter: 1 out of 7\n",
      "Epoch: 58 cost time: 2.4152824878692627\n",
      "VALI: Epoch: 58, Steps: 24 | Train Loss: 0.0417191  Vali Loss: 0.2432823 Vali Accuracy: 0.9414414  Vali weighted F1: 0.9415895  Vali macro F1 0.9267996 \n",
      "EarlyStopping counter: 16 out of 21\n",
      "Learning rate adjusting counter: 2 out of 7\n",
      "Epoch: 59 cost time: 2.388746976852417\n",
      "VALI: Epoch: 59, Steps: 24 | Train Loss: 0.0412631  Vali Loss: 0.2429721 Vali Accuracy: 0.9414414  Vali weighted F1: 0.9415895  Vali macro F1 0.9267996 \n",
      "EarlyStopping counter: 17 out of 21\n",
      "Learning rate adjusting counter: 3 out of 7\n",
      "Epoch: 60 cost time: 2.391972303390503\n",
      "VALI: Epoch: 60, Steps: 24 | Train Loss: 0.0419919  Vali Loss: 0.2430688 Vali Accuracy: 0.9414414  Vali weighted F1: 0.9412880  Vali macro F1 0.9244526 \n",
      "EarlyStopping counter: 18 out of 21\n",
      "Learning rate adjusting counter: 4 out of 7\n",
      "Epoch: 61 cost time: 2.38395619392395\n",
      "VALI: Epoch: 61, Steps: 24 | Train Loss: 0.0408630  Vali Loss: 0.2435246 Vali Accuracy: 0.9414414  Vali weighted F1: 0.9415895  Vali macro F1 0.9267996 \n",
      "EarlyStopping counter: 19 out of 21\n",
      "Learning rate adjusting counter: 5 out of 7\n",
      "Epoch: 62 cost time: 2.3756182193756104\n",
      "VALI: Epoch: 62, Steps: 24 | Train Loss: 0.0419735  Vali Loss: 0.2428744 Vali Accuracy: 0.9414414  Vali weighted F1: 0.9412880  Vali macro F1 0.9244526 \n",
      "EarlyStopping counter: 20 out of 21\n",
      "Learning rate adjusting counter: 6 out of 7\n",
      "Epoch: 63 cost time: 2.381531000137329\n",
      "VALI: Epoch: 63, Steps: 24 | Train Loss: 0.0421228  Vali Loss: 0.2436296 Vali Accuracy: 0.9414414  Vali weighted F1: 0.9415895  Vali macro F1 0.9267996 \n",
      "EarlyStopping counter: 21 out of 21\n",
      "Early stopping\n",
      "Loading the best validation model!\n",
      "Final Test Performance : Test Accuracy: 0.8676873  Test weighted F1: 0.8674263  Test macro F1 0.8713510 \n",
      "================ the 2 th CV Experiment ================ \n",
      "Leave one Out Experiment : The 3 Part as the test\n",
      "[-] Target sampling weights:  [0.00164474 0.00179211 0.00160514 0.00133156 0.00285714 0.00169205\n",
      " 0.00150602 0.00259067 0.00322581 0.00183824 0.0013369  0.00568182]\n",
      "Train data number :  6309\n",
      "The number of classes is :  12\n",
      "The input_length  is :  168\n",
      "The channel_in is :  18\n",
      "Validation data number :  702\n",
      "Test data number :  3631\n",
      "================ Build the model ================ \n",
      "Build the TinyHAR model!\n",
      "Epoch: 1 cost time: 2.5228865146636963\n",
      "VALI: Epoch: 1, Steps: 25 | Train Loss: 2.0288315  Vali Loss: 1.6773887 Vali Accuracy: 0.5854701  Vali weighted F1: 0.5342512  Vali macro F1 0.4768150 \n",
      "Validation loss decreased (inf --> 1.677389).  Saving model ...\n",
      "Epoch: 2 cost time: 2.4725518226623535\n",
      "VALI: Epoch: 2, Steps: 25 | Train Loss: 1.2355665  Vali Loss: 0.9523291 Vali Accuracy: 0.7834758  Vali weighted F1: 0.7404194  Vali macro F1 0.6636329 \n",
      "new best score!!!!\n",
      "Validation loss decreased (1.677389 --> 0.952329).  Saving model ...\n",
      "new best score!!!!\n",
      "Epoch: 3 cost time: 2.472550392150879\n",
      "VALI: Epoch: 3, Steps: 25 | Train Loss: 0.8018593  Vali Loss: 0.6522001 Vali Accuracy: 0.8575499  Vali weighted F1: 0.8435538  Vali macro F1 0.7855312 \n",
      "new best score!!!!\n",
      "Validation loss decreased (0.952329 --> 0.652200).  Saving model ...\n",
      "new best score!!!!\n",
      "Epoch: 4 cost time: 2.4675495624542236\n",
      "VALI: Epoch: 4, Steps: 25 | Train Loss: 0.5750101  Vali Loss: 0.4817805 Vali Accuracy: 0.9145299  Vali weighted F1: 0.9165614  Vali macro F1 0.9106866 \n",
      "new best score!!!!\n",
      "Validation loss decreased (0.652200 --> 0.481780).  Saving model ...\n",
      "new best score!!!!\n",
      "Epoch: 5 cost time: 2.4635493755340576\n",
      "VALI: Epoch: 5, Steps: 25 | Train Loss: 0.4443990  Vali Loss: 0.3866675 Vali Accuracy: 0.9301994  Vali weighted F1: 0.9323708  Vali macro F1 0.9264391 \n",
      "new best score!!!!\n",
      "Validation loss decreased (0.481780 --> 0.386667).  Saving model ...\n",
      "new best score!!!!\n",
      "Epoch: 6 cost time: 2.4665629863739014\n",
      "VALI: Epoch: 6, Steps: 25 | Train Loss: 0.3719783  Vali Loss: 0.3401555 Vali Accuracy: 0.9358974  Vali weighted F1: 0.9369925  Vali macro F1 0.9320129 \n",
      "new best score!!!!\n",
      "Validation loss decreased (0.386667 --> 0.340156).  Saving model ...\n",
      "new best score!!!!\n",
      "Epoch: 7 cost time: 2.481553316116333\n",
      "VALI: Epoch: 7, Steps: 25 | Train Loss: 0.3202445  Vali Loss: 0.3018098 Vali Accuracy: 0.9373219  Vali weighted F1: 0.9386805  Vali macro F1 0.9347094 \n",
      "new best score!!!!\n",
      "Validation loss decreased (0.340156 --> 0.301810).  Saving model ...\n",
      "new best score!!!!\n",
      "Epoch: 8 cost time: 2.4803247451782227\n",
      "VALI: Epoch: 8, Steps: 25 | Train Loss: 0.2881604  Vali Loss: 0.2862975 Vali Accuracy: 0.9358974  Vali weighted F1: 0.9379221  Vali macro F1 0.9340768 \n",
      "new best score!!!!\n",
      "Validation loss decreased (0.301810 --> 0.286297).  Saving model ...\n",
      "new best score!!!!\n",
      "Epoch: 9 cost time: 2.471118688583374\n",
      "VALI: Epoch: 9, Steps: 25 | Train Loss: 0.2620629  Vali Loss: 0.2682557 Vali Accuracy: 0.9358974  Vali weighted F1: 0.9375161  Vali macro F1 0.9333025 \n",
      "new best score!!!!\n",
      "Validation loss decreased (0.286297 --> 0.268256).  Saving model ...\n",
      "new best score!!!!\n",
      "Epoch: 10 cost time: 2.464463233947754\n",
      "VALI: Epoch: 10, Steps: 25 | Train Loss: 0.2442369  Vali Loss: 0.2595720 Vali Accuracy: 0.9430199  Vali weighted F1: 0.9441653  Vali macro F1 0.9404219 \n",
      "new best score!!!!\n",
      "Validation loss decreased (0.268256 --> 0.259572).  Saving model ...\n",
      "new best score!!!!\n",
      "Epoch: 11 cost time: 2.4655492305755615\n",
      "VALI: Epoch: 11, Steps: 25 | Train Loss: 0.2275345  Vali Loss: 0.2539926 Vali Accuracy: 0.9387464  Vali weighted F1: 0.9404352  Vali macro F1 0.9371286 \n",
      "new best score!!!!\n",
      "Validation loss decreased (0.259572 --> 0.253993).  Saving model ...\n",
      "new best score!!!!\n",
      "Epoch: 12 cost time: 2.446749687194824\n",
      "VALI: Epoch: 12, Steps: 25 | Train Loss: 0.2140310  Vali Loss: 0.2399583 Vali Accuracy: 0.9472934  Vali weighted F1: 0.9485172  Vali macro F1 0.9448299 \n",
      "new best score!!!!\n",
      "Validation loss decreased (0.253993 --> 0.239958).  Saving model ...\n",
      "new best score!!!!\n",
      "Epoch: 13 cost time: 2.4435534477233887\n",
      "VALI: Epoch: 13, Steps: 25 | Train Loss: 0.1994908  Vali Loss: 0.2289334 Vali Accuracy: 0.9444444  Vali weighted F1: 0.9458598  Vali macro F1 0.9422889 \n",
      "new best score!!!!\n",
      "Validation loss decreased (0.239958 --> 0.228933).  Saving model ...\n",
      "new best score!!!!\n",
      "Epoch: 14 cost time: 2.4399824142456055\n",
      "VALI: Epoch: 14, Steps: 25 | Train Loss: 0.1863773  Vali Loss: 0.2279950 Vali Accuracy: 0.9487179  Vali weighted F1: 0.9497845  Vali macro F1 0.9449715 \n",
      "new best score!!!!\n",
      "Validation loss decreased (0.228933 --> 0.227995).  Saving model ...\n",
      "new best score!!!!\n",
      "Epoch: 15 cost time: 2.4709208011627197\n",
      "VALI: Epoch: 15, Steps: 25 | Train Loss: 0.1770933  Vali Loss: 0.2282218 Vali Accuracy: 0.9458689  Vali weighted F1: 0.9467323  Vali macro F1 0.9426847 \n",
      "EarlyStopping counter: 1 out of 21\n",
      "Learning rate adjusting counter: 1 out of 7\n",
      "Epoch: 16 cost time: 2.458402633666992\n",
      "VALI: Epoch: 16, Steps: 25 | Train Loss: 0.1679392  Vali Loss: 0.2260010 Vali Accuracy: 0.9472934  Vali weighted F1: 0.9483143  Vali macro F1 0.9449047 \n",
      "new best score!!!!\n",
      "Validation loss decreased (0.227995 --> 0.226001).  Saving model ...\n",
      "new best score!!!!\n",
      "Epoch: 17 cost time: 2.471550464630127\n",
      "VALI: Epoch: 17, Steps: 25 | Train Loss: 0.1595787  Vali Loss: 0.2296971 Vali Accuracy: 0.9487179  Vali weighted F1: 0.9497317  Vali macro F1 0.9457311 \n",
      "EarlyStopping counter: 1 out of 21\n",
      "Learning rate adjusting counter: 1 out of 7\n",
      "Epoch: 18 cost time: 2.4545469284057617\n",
      "VALI: Epoch: 18, Steps: 25 | Train Loss: 0.1518383  Vali Loss: 0.2060001 Vali Accuracy: 0.9501425  Vali weighted F1: 0.9513302  Vali macro F1 0.9464232 \n",
      "new best score!!!!\n",
      "Validation loss decreased (0.226001 --> 0.206000).  Saving model ...\n",
      "new best score!!!!\n",
      "Epoch: 19 cost time: 2.439544439315796\n",
      "VALI: Epoch: 19, Steps: 25 | Train Loss: 0.1537236  Vali Loss: 0.2184446 Vali Accuracy: 0.9472934  Vali weighted F1: 0.9486836  Vali macro F1 0.9440153 \n",
      "EarlyStopping counter: 1 out of 21\n",
      "Learning rate adjusting counter: 1 out of 7\n",
      "Epoch: 20 cost time: 2.4654335975646973\n",
      "VALI: Epoch: 20, Steps: 25 | Train Loss: 0.1412451  Vali Loss: 0.2016970 Vali Accuracy: 0.9501425  Vali weighted F1: 0.9510211  Vali macro F1 0.9454849 \n",
      "new best score!!!!\n",
      "Validation loss decreased (0.206000 --> 0.201697).  Saving model ...\n",
      "new best score!!!!\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 21 cost time: 2.53962779045105\n",
      "VALI: Epoch: 21, Steps: 25 | Train Loss: 0.1292850  Vali Loss: 0.2106407 Vali Accuracy: 0.9487179  Vali weighted F1: 0.9498035  Vali macro F1 0.9454781 \n",
      "EarlyStopping counter: 1 out of 21\n",
      "Learning rate adjusting counter: 1 out of 7\n",
      "Epoch: 22 cost time: 2.460038423538208\n",
      "VALI: Epoch: 22, Steps: 25 | Train Loss: 0.1269998  Vali Loss: 0.2074229 Vali Accuracy: 0.9487179  Vali weighted F1: 0.9491192  Vali macro F1 0.9452730 \n",
      "EarlyStopping counter: 2 out of 21\n",
      "Learning rate adjusting counter: 2 out of 7\n",
      "Epoch: 23 cost time: 2.473295211791992\n",
      "VALI: Epoch: 23, Steps: 25 | Train Loss: 0.1204365  Vali Loss: 0.2002267 Vali Accuracy: 0.9529915  Vali weighted F1: 0.9539674  Vali macro F1 0.9484810 \n",
      "new best score!!!!\n",
      "Validation loss decreased (0.201697 --> 0.200227).  Saving model ...\n",
      "new best score!!!!\n",
      "Epoch: 24 cost time: 2.4334218502044678\n",
      "VALI: Epoch: 24, Steps: 25 | Train Loss: 0.1160080  Vali Loss: 0.2274241 Vali Accuracy: 0.9458689  Vali weighted F1: 0.9472681  Vali macro F1 0.9436484 \n",
      "EarlyStopping counter: 1 out of 21\n",
      "Learning rate adjusting counter: 1 out of 7\n",
      "Epoch: 25 cost time: 2.474550247192383\n",
      "VALI: Epoch: 25, Steps: 25 | Train Loss: 0.1173365  Vali Loss: 0.2072615 Vali Accuracy: 0.9458689  Vali weighted F1: 0.9469210  Vali macro F1 0.9447160 \n",
      "EarlyStopping counter: 2 out of 21\n",
      "Learning rate adjusting counter: 2 out of 7\n",
      "Epoch: 26 cost time: 2.4284188747406006\n",
      "VALI: Epoch: 26, Steps: 25 | Train Loss: 0.1108144  Vali Loss: 0.2283381 Vali Accuracy: 0.9501425  Vali weighted F1: 0.9516257  Vali macro F1 0.9471349 \n",
      "EarlyStopping counter: 3 out of 21\n",
      "Learning rate adjusting counter: 3 out of 7\n",
      "Epoch: 27 cost time: 2.4165515899658203\n",
      "VALI: Epoch: 27, Steps: 25 | Train Loss: 0.1055363  Vali Loss: 0.2090589 Vali Accuracy: 0.9515670  Vali weighted F1: 0.9523769  Vali macro F1 0.9489729 \n",
      "EarlyStopping counter: 4 out of 21\n",
      "Learning rate adjusting counter: 4 out of 7\n",
      "Epoch: 28 cost time: 2.4175302982330322\n",
      "VALI: Epoch: 28, Steps: 25 | Train Loss: 0.0997688  Vali Loss: 0.2040007 Vali Accuracy: 0.9515670  Vali weighted F1: 0.9523008  Vali macro F1 0.9487673 \n",
      "EarlyStopping counter: 5 out of 21\n",
      "Learning rate adjusting counter: 5 out of 7\n",
      "Epoch: 29 cost time: 2.4180965423583984\n",
      "VALI: Epoch: 29, Steps: 25 | Train Loss: 0.0963395  Vali Loss: 0.2068478 Vali Accuracy: 0.9515670  Vali weighted F1: 0.9525499  Vali macro F1 0.9482202 \n",
      "EarlyStopping counter: 6 out of 21\n",
      "Learning rate adjusting counter: 6 out of 7\n",
      "Epoch: 30 cost time: 2.416423797607422\n",
      "VALI: Epoch: 30, Steps: 25 | Train Loss: 0.0917202  Vali Loss: 0.2061402 Vali Accuracy: 0.9529915  Vali weighted F1: 0.9536033  Vali macro F1 0.9495938 \n",
      "EarlyStopping counter: 7 out of 21\n",
      "Learning rate adjusting counter: 7 out of 7\n",
      "Updating learning rate to 0.0001\n",
      "Epoch: 31 cost time: 2.428055763244629\n",
      "VALI: Epoch: 31, Steps: 25 | Train Loss: 0.0832105  Vali Loss: 0.1972211 Vali Accuracy: 0.9544160  Vali weighted F1: 0.9551981  Vali macro F1 0.9505377 \n",
      "new best score!!!!\n",
      "Validation loss decreased (0.200227 --> 0.197221).  Saving model ...\n",
      "new best score!!!!\n",
      "Epoch: 32 cost time: 2.397892951965332\n",
      "VALI: Epoch: 32, Steps: 25 | Train Loss: 0.0801540  Vali Loss: 0.1990315 Vali Accuracy: 0.9529915  Vali weighted F1: 0.9539231  Vali macro F1 0.9498196 \n",
      "EarlyStopping counter: 1 out of 21\n",
      "Learning rate adjusting counter: 1 out of 7\n",
      "Epoch: 33 cost time: 2.4232263565063477\n",
      "VALI: Epoch: 33, Steps: 25 | Train Loss: 0.0810705  Vali Loss: 0.2004677 Vali Accuracy: 0.9544160  Vali weighted F1: 0.9551248  Vali macro F1 0.9510185 \n",
      "EarlyStopping counter: 2 out of 21\n",
      "Learning rate adjusting counter: 2 out of 7\n",
      "Epoch: 34 cost time: 2.452547073364258\n",
      "VALI: Epoch: 34, Steps: 25 | Train Loss: 0.0800124  Vali Loss: 0.2001685 Vali Accuracy: 0.9544160  Vali weighted F1: 0.9552093  Vali macro F1 0.9509587 \n",
      "EarlyStopping counter: 3 out of 21\n",
      "Learning rate adjusting counter: 3 out of 7\n",
      "Epoch: 35 cost time: 2.440544843673706\n",
      "VALI: Epoch: 35, Steps: 25 | Train Loss: 0.0799553  Vali Loss: 0.2000129 Vali Accuracy: 0.9544160  Vali weighted F1: 0.9551248  Vali macro F1 0.9510185 \n",
      "EarlyStopping counter: 4 out of 21\n",
      "Learning rate adjusting counter: 4 out of 7\n",
      "Epoch: 36 cost time: 2.4382925033569336\n",
      "VALI: Epoch: 36, Steps: 25 | Train Loss: 0.0767637  Vali Loss: 0.2010087 Vali Accuracy: 0.9544160  Vali weighted F1: 0.9551023  Vali macro F1 0.9510439 \n",
      "EarlyStopping counter: 5 out of 21\n",
      "Learning rate adjusting counter: 5 out of 7\n",
      "Epoch: 37 cost time: 2.419602632522583\n",
      "VALI: Epoch: 37, Steps: 25 | Train Loss: 0.0765197  Vali Loss: 0.1996529 Vali Accuracy: 0.9544160  Vali weighted F1: 0.9552093  Vali macro F1 0.9509587 \n",
      "EarlyStopping counter: 6 out of 21\n",
      "Learning rate adjusting counter: 6 out of 7\n",
      "Epoch: 38 cost time: 2.4222412109375\n",
      "VALI: Epoch: 38, Steps: 25 | Train Loss: 0.0771713  Vali Loss: 0.2030605 Vali Accuracy: 0.9529915  Vali weighted F1: 0.9539231  Vali macro F1 0.9498196 \n",
      "EarlyStopping counter: 7 out of 21\n",
      "Learning rate adjusting counter: 7 out of 7\n",
      "Updating learning rate to 1e-05\n",
      "Epoch: 39 cost time: 2.418458938598633\n",
      "VALI: Epoch: 39, Steps: 25 | Train Loss: 0.0770849  Vali Loss: 0.2010998 Vali Accuracy: 0.9529915  Vali weighted F1: 0.9539231  Vali macro F1 0.9498196 \n",
      "EarlyStopping counter: 8 out of 21\n",
      "Learning rate adjusting counter: 1 out of 7\n",
      "Epoch: 40 cost time: 2.441535711288452\n",
      "VALI: Epoch: 40, Steps: 25 | Train Loss: 0.0757477  Vali Loss: 0.2003794 Vali Accuracy: 0.9529915  Vali weighted F1: 0.9539231  Vali macro F1 0.9498196 \n",
      "EarlyStopping counter: 9 out of 21\n",
      "Learning rate adjusting counter: 2 out of 7\n",
      "Epoch: 41 cost time: 2.410537004470825\n",
      "VALI: Epoch: 41, Steps: 25 | Train Loss: 0.0739575  Vali Loss: 0.1999678 Vali Accuracy: 0.9544160  Vali weighted F1: 0.9552093  Vali macro F1 0.9509587 \n",
      "EarlyStopping counter: 10 out of 21\n",
      "Learning rate adjusting counter: 3 out of 7\n",
      "Epoch: 42 cost time: 2.421539545059204\n",
      "VALI: Epoch: 42, Steps: 25 | Train Loss: 0.0762724  Vali Loss: 0.2006029 Vali Accuracy: 0.9529915  Vali weighted F1: 0.9539231  Vali macro F1 0.9498196 \n",
      "EarlyStopping counter: 11 out of 21\n",
      "Learning rate adjusting counter: 4 out of 7\n",
      "Epoch: 43 cost time: 2.3945255279541016\n",
      "VALI: Epoch: 43, Steps: 25 | Train Loss: 0.0744093  Vali Loss: 0.2010935 Vali Accuracy: 0.9529915  Vali weighted F1: 0.9539231  Vali macro F1 0.9498196 \n",
      "EarlyStopping counter: 12 out of 21\n",
      "Learning rate adjusting counter: 5 out of 7\n",
      "Epoch: 44 cost time: 2.4285409450531006\n",
      "VALI: Epoch: 44, Steps: 25 | Train Loss: 0.0751568  Vali Loss: 0.2007939 Vali Accuracy: 0.9529915  Vali weighted F1: 0.9539231  Vali macro F1 0.9498196 \n",
      "EarlyStopping counter: 13 out of 21\n",
      "Learning rate adjusting counter: 6 out of 7\n",
      "Epoch: 45 cost time: 2.4236207008361816\n",
      "VALI: Epoch: 45, Steps: 25 | Train Loss: 0.0743327  Vali Loss: 0.2004954 Vali Accuracy: 0.9529915  Vali weighted F1: 0.9539231  Vali macro F1 0.9498196 \n",
      "EarlyStopping counter: 14 out of 21\n",
      "Learning rate adjusting counter: 7 out of 7\n",
      "Updating learning rate to 1.0000000000000002e-06\n",
      "Epoch: 46 cost time: 2.4215400218963623\n",
      "VALI: Epoch: 46, Steps: 25 | Train Loss: 0.0752813  Vali Loss: 0.2001700 Vali Accuracy: 0.9529915  Vali weighted F1: 0.9538285  Vali macro F1 0.9498673 \n",
      "EarlyStopping counter: 15 out of 21\n",
      "Learning rate adjusting counter: 1 out of 7\n",
      "Epoch: 47 cost time: 2.4707720279693604\n",
      "VALI: Epoch: 47, Steps: 25 | Train Loss: 0.0734290  Vali Loss: 0.2002197 Vali Accuracy: 0.9544160  Vali weighted F1: 0.9552093  Vali macro F1 0.9509587 \n",
      "EarlyStopping counter: 16 out of 21\n",
      "Learning rate adjusting counter: 2 out of 7\n",
      "Epoch: 48 cost time: 2.4365432262420654\n",
      "VALI: Epoch: 48, Steps: 25 | Train Loss: 0.0747017  Vali Loss: 0.1999954 Vali Accuracy: 0.9529915  Vali weighted F1: 0.9539231  Vali macro F1 0.9498196 \n",
      "EarlyStopping counter: 17 out of 21\n",
      "Learning rate adjusting counter: 3 out of 7\n",
      "Epoch: 49 cost time: 2.4330976009368896\n",
      "VALI: Epoch: 49, Steps: 25 | Train Loss: 0.0755139  Vali Loss: 0.2001239 Vali Accuracy: 0.9544160  Vali weighted F1: 0.9552093  Vali macro F1 0.9509587 \n",
      "EarlyStopping counter: 18 out of 21\n",
      "Learning rate adjusting counter: 4 out of 7\n",
      "Epoch: 50 cost time: 2.452547073364258\n",
      "VALI: Epoch: 50, Steps: 25 | Train Loss: 0.0742005  Vali Loss: 0.2003567 Vali Accuracy: 0.9529915  Vali weighted F1: 0.9539231  Vali macro F1 0.9498196 \n",
      "EarlyStopping counter: 19 out of 21\n",
      "Learning rate adjusting counter: 5 out of 7\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 51 cost time: 2.473170757293701\n",
      "VALI: Epoch: 51, Steps: 25 | Train Loss: 0.0752722  Vali Loss: 0.2002033 Vali Accuracy: 0.9544160  Vali weighted F1: 0.9552093  Vali macro F1 0.9509587 \n",
      "EarlyStopping counter: 20 out of 21\n",
      "Learning rate adjusting counter: 6 out of 7\n",
      "Epoch: 52 cost time: 2.4215316772460938\n",
      "VALI: Epoch: 52, Steps: 25 | Train Loss: 0.0754096  Vali Loss: 0.2003202 Vali Accuracy: 0.9529915  Vali weighted F1: 0.9539231  Vali macro F1 0.9498196 \n",
      "EarlyStopping counter: 21 out of 21\n",
      "Early stopping\n",
      "Loading the best validation model!\n",
      "Final Test Performance : Test Accuracy: 0.9126962  Test weighted F1: 0.9180363  Test macro F1 0.6618003 \n",
      "================ the 3 th CV Experiment ================ \n",
      "Leave one Out Experiment : The 4 Part as the test\n",
      "[-] Target sampling weights:  [0.00165289 0.00173913 0.00167785 0.00136426 0.00282486 0.00199601\n",
      " 0.00176678 0.00273224 0.0031348  0.0017762  0.0013245  0.00571429]\n",
      "Train data number :  6108\n",
      "The number of classes is :  12\n",
      "The input_length  is :  168\n",
      "The channel_in is :  18\n",
      "Validation data number :  679\n",
      "Test data number :  4822\n",
      "================ Build the model ================ \n",
      "Build the TinyHAR model!\n",
      "Epoch: 1 cost time: 2.36240291595459\n",
      "VALI: Epoch: 1, Steps: 24 | Train Loss: 2.0490018  Vali Loss: 1.7324277 Vali Accuracy: 0.5537555  Vali weighted F1: 0.4717104  Vali macro F1 0.4097813 \n",
      "Validation loss decreased (inf --> 1.732428).  Saving model ...\n",
      "Epoch: 2 cost time: 2.3822593688964844\n",
      "VALI: Epoch: 2, Steps: 24 | Train Loss: 1.2675783  Vali Loss: 0.9670103 Vali Accuracy: 0.7893962  Vali weighted F1: 0.7447727  Vali macro F1 0.6636722 \n",
      "new best score!!!!\n",
      "Validation loss decreased (1.732428 --> 0.967010).  Saving model ...\n",
      "new best score!!!!\n",
      "Epoch: 3 cost time: 2.370042562484741\n",
      "VALI: Epoch: 3, Steps: 24 | Train Loss: 0.8452326  Vali Loss: 0.6810372 Vali Accuracy: 0.8483063  Vali weighted F1: 0.8287360  Vali macro F1 0.7650018 \n",
      "new best score!!!!\n",
      "Validation loss decreased (0.967010 --> 0.681037).  Saving model ...\n",
      "new best score!!!!\n",
      "Epoch: 4 cost time: 2.346012830734253\n",
      "VALI: Epoch: 4, Steps: 24 | Train Loss: 0.6099213  Vali Loss: 0.5152138 Vali Accuracy: 0.9072165  Vali weighted F1: 0.9073263  Vali macro F1 0.8991455 \n",
      "new best score!!!!\n",
      "Validation loss decreased (0.681037 --> 0.515214).  Saving model ...\n",
      "new best score!!!!\n",
      "Epoch: 5 cost time: 2.3354578018188477\n",
      "VALI: Epoch: 5, Steps: 24 | Train Loss: 0.4696033  Vali Loss: 0.4257751 Vali Accuracy: 0.9204713  Vali weighted F1: 0.9213974  Vali macro F1 0.9176455 \n",
      "new best score!!!!\n",
      "Validation loss decreased (0.515214 --> 0.425775).  Saving model ...\n",
      "new best score!!!!\n",
      "Epoch: 6 cost time: 2.4225401878356934\n",
      "VALI: Epoch: 6, Steps: 24 | Train Loss: 0.3884943  Vali Loss: 0.3678663 Vali Accuracy: 0.9234168  Vali weighted F1: 0.9243295  Vali macro F1 0.9200326 \n",
      "new best score!!!!\n",
      "Validation loss decreased (0.425775 --> 0.367866).  Saving model ...\n",
      "new best score!!!!\n",
      "Epoch: 7 cost time: 2.389533042907715\n",
      "VALI: Epoch: 7, Steps: 24 | Train Loss: 0.3355235  Vali Loss: 0.3388779 Vali Accuracy: 0.9248895  Vali weighted F1: 0.9273478  Vali macro F1 0.9241091 \n",
      "new best score!!!!\n",
      "Validation loss decreased (0.367866 --> 0.338878).  Saving model ...\n",
      "new best score!!!!\n",
      "Epoch: 8 cost time: 2.3705272674560547\n",
      "VALI: Epoch: 8, Steps: 24 | Train Loss: 0.3020564  Vali Loss: 0.3098815 Vali Accuracy: 0.9263623  Vali weighted F1: 0.9290004  Vali macro F1 0.9252554 \n",
      "new best score!!!!\n",
      "Validation loss decreased (0.338878 --> 0.309881).  Saving model ...\n",
      "new best score!!!!\n",
      "Epoch: 9 cost time: 2.3392860889434814\n",
      "VALI: Epoch: 9, Steps: 24 | Train Loss: 0.2707811  Vali Loss: 0.2846725 Vali Accuracy: 0.9307806  Vali weighted F1: 0.9332562  Vali macro F1 0.9280471 \n",
      "new best score!!!!\n",
      "Validation loss decreased (0.309881 --> 0.284672).  Saving model ...\n",
      "new best score!!!!\n",
      "Epoch: 10 cost time: 2.337188720703125\n",
      "VALI: Epoch: 10, Steps: 24 | Train Loss: 0.2484431  Vali Loss: 0.2724172 Vali Accuracy: 0.9322533  Vali weighted F1: 0.9347560  Vali macro F1 0.9298366 \n",
      "new best score!!!!\n",
      "Validation loss decreased (0.284672 --> 0.272417).  Saving model ...\n",
      "new best score!!!!\n",
      "Epoch: 11 cost time: 2.340881586074829\n",
      "VALI: Epoch: 11, Steps: 24 | Train Loss: 0.2300900  Vali Loss: 0.2586745 Vali Accuracy: 0.9396171  Vali weighted F1: 0.9406679  Vali macro F1 0.9356360 \n",
      "new best score!!!!\n",
      "Validation loss decreased (0.272417 --> 0.258674).  Saving model ...\n",
      "new best score!!!!\n",
      "Epoch: 12 cost time: 2.3455841541290283\n",
      "VALI: Epoch: 12, Steps: 24 | Train Loss: 0.2152869  Vali Loss: 0.2506371 Vali Accuracy: 0.9351988  Vali weighted F1: 0.9369169  Vali macro F1 0.9319359 \n",
      "new best score!!!!\n",
      "Validation loss decreased (0.258674 --> 0.250637).  Saving model ...\n",
      "new best score!!!!\n",
      "Epoch: 13 cost time: 2.3395214080810547\n",
      "VALI: Epoch: 13, Steps: 24 | Train Loss: 0.2007135  Vali Loss: 0.2363968 Vali Accuracy: 0.9396171  Vali weighted F1: 0.9407855  Vali macro F1 0.9346638 \n",
      "new best score!!!!\n",
      "Validation loss decreased (0.250637 --> 0.236397).  Saving model ...\n",
      "new best score!!!!\n",
      "Epoch: 14 cost time: 2.3315205574035645\n",
      "VALI: Epoch: 14, Steps: 24 | Train Loss: 0.1859736  Vali Loss: 0.2324200 Vali Accuracy: 0.9410898  Vali weighted F1: 0.9423365  Vali macro F1 0.9336188 \n",
      "new best score!!!!\n",
      "Validation loss decreased (0.236397 --> 0.232420).  Saving model ...\n",
      "new best score!!!!\n",
      "Epoch: 15 cost time: 2.3235180377960205\n",
      "VALI: Epoch: 15, Steps: 24 | Train Loss: 0.1779586  Vali Loss: 0.2248962 Vali Accuracy: 0.9410898  Vali weighted F1: 0.9423056  Vali macro F1 0.9334334 \n",
      "new best score!!!!\n",
      "Validation loss decreased (0.232420 --> 0.224896).  Saving model ...\n",
      "new best score!!!!\n",
      "Epoch: 16 cost time: 2.34224271774292\n",
      "VALI: Epoch: 16, Steps: 24 | Train Loss: 0.1694975  Vali Loss: 0.2206323 Vali Accuracy: 0.9484536  Vali weighted F1: 0.9493783  Vali macro F1 0.9408710 \n",
      "new best score!!!!\n",
      "Validation loss decreased (0.224896 --> 0.220632).  Saving model ...\n",
      "new best score!!!!\n",
      "Epoch: 17 cost time: 2.338715076446533\n",
      "VALI: Epoch: 17, Steps: 24 | Train Loss: 0.1594478  Vali Loss: 0.2215428 Vali Accuracy: 0.9455081  Vali weighted F1: 0.9457242  Vali macro F1 0.9372587 \n",
      "EarlyStopping counter: 1 out of 21\n",
      "Learning rate adjusting counter: 1 out of 7\n",
      "Epoch: 18 cost time: 2.3389227390289307\n",
      "VALI: Epoch: 18, Steps: 24 | Train Loss: 0.1508363  Vali Loss: 0.2162741 Vali Accuracy: 0.9425626  Vali weighted F1: 0.9427354  Vali macro F1 0.9347705 \n",
      "new best score!!!!\n",
      "Validation loss decreased (0.220632 --> 0.216274).  Saving model ...\n",
      "new best score!!!!\n",
      "Epoch: 19 cost time: 2.321197032928467\n",
      "VALI: Epoch: 19, Steps: 24 | Train Loss: 0.1458830  Vali Loss: 0.2149547 Vali Accuracy: 0.9396171  Vali weighted F1: 0.9395217  Vali macro F1 0.9298998 \n",
      "new best score!!!!\n",
      "Validation loss decreased (0.216274 --> 0.214955).  Saving model ...\n",
      "new best score!!!!\n",
      "Epoch: 20 cost time: 2.3406527042388916\n",
      "VALI: Epoch: 20, Steps: 24 | Train Loss: 0.1394433  Vali Loss: 0.2063548 Vali Accuracy: 0.9455081  Vali weighted F1: 0.9455997  Vali macro F1 0.9364256 \n",
      "new best score!!!!\n",
      "Validation loss decreased (0.214955 --> 0.206355).  Saving model ...\n",
      "new best score!!!!\n",
      "Epoch: 21 cost time: 2.338529586791992\n",
      "VALI: Epoch: 21, Steps: 24 | Train Loss: 0.1309383  Vali Loss: 0.2010411 Vali Accuracy: 0.9499264  Vali weighted F1: 0.9502256  Vali macro F1 0.9401781 \n",
      "new best score!!!!\n",
      "Validation loss decreased (0.206355 --> 0.201041).  Saving model ...\n",
      "new best score!!!!\n",
      "Epoch: 22 cost time: 2.352524518966675\n",
      "VALI: Epoch: 22, Steps: 24 | Train Loss: 0.1248255  Vali Loss: 0.2057439 Vali Accuracy: 0.9425626  Vali weighted F1: 0.9424131  Vali macro F1 0.9299713 \n",
      "EarlyStopping counter: 1 out of 21\n",
      "Learning rate adjusting counter: 1 out of 7\n",
      "Epoch: 23 cost time: 2.359525680541992\n",
      "VALI: Epoch: 23, Steps: 24 | Train Loss: 0.1208157  Vali Loss: 0.1917156 Vali Accuracy: 0.9484536  Vali weighted F1: 0.9487335  Vali macro F1 0.9400892 \n",
      "new best score!!!!\n",
      "Validation loss decreased (0.201041 --> 0.191716).  Saving model ...\n",
      "new best score!!!!\n",
      "Epoch: 24 cost time: 2.3570308685302734\n",
      "VALI: Epoch: 24, Steps: 24 | Train Loss: 0.1133242  Vali Loss: 0.1971787 Vali Accuracy: 0.9513991  Vali weighted F1: 0.9517010  Vali macro F1 0.9452859 \n",
      "EarlyStopping counter: 1 out of 21\n",
      "Learning rate adjusting counter: 1 out of 7\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 25 cost time: 2.3572824001312256\n",
      "VALI: Epoch: 25, Steps: 24 | Train Loss: 0.1127605  Vali Loss: 0.1913873 Vali Accuracy: 0.9513991  Vali weighted F1: 0.9516240  Vali macro F1 0.9446085 \n",
      "new best score!!!!\n",
      "Validation loss decreased (0.191716 --> 0.191387).  Saving model ...\n",
      "new best score!!!!\n",
      "Epoch: 26 cost time: 2.3417625427246094\n",
      "VALI: Epoch: 26, Steps: 24 | Train Loss: 0.1125479  Vali Loss: 0.1975526 Vali Accuracy: 0.9425626  Vali weighted F1: 0.9424497  Vali macro F1 0.9310200 \n",
      "EarlyStopping counter: 1 out of 21\n",
      "Learning rate adjusting counter: 1 out of 7\n",
      "Epoch: 27 cost time: 2.3475229740142822\n",
      "VALI: Epoch: 27, Steps: 24 | Train Loss: 0.1042206  Vali Loss: 0.2003179 Vali Accuracy: 0.9455081  Vali weighted F1: 0.9457915  Vali macro F1 0.9345083 \n",
      "EarlyStopping counter: 2 out of 21\n",
      "Learning rate adjusting counter: 2 out of 7\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-8-21de09e58c74>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mexp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtrain\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32mE:\\TECO_Works\\Conference\\ISWC2022\\I2S0W2C2_CFC\\experiment.py\u001b[0m in \u001b[0;36mtrain\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    277\u001b[0m                     \u001b[0mepoch_time\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtime\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtime\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    278\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 279\u001b[1;33m                     \u001b[1;32mfor\u001b[0m \u001b[0mi\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0mbatch_x1\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mbatch_x2\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mbatch_y\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32min\u001b[0m \u001b[0menumerate\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtrain_loader\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    280\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    281\u001b[0m                         \u001b[1;31m#if \"cross\" in self.args.model_type:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mD:\\anaconda\\lib\\site-packages\\torch\\utils\\data\\dataloader.py\u001b[0m in \u001b[0;36m__next__\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    519\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_sampler_iter\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    520\u001b[0m                 \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_reset\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 521\u001b[1;33m             \u001b[0mdata\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_next_data\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    522\u001b[0m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_num_yielded\u001b[0m \u001b[1;33m+=\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    523\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_dataset_kind\u001b[0m \u001b[1;33m==\u001b[0m \u001b[0m_DatasetKind\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mIterable\u001b[0m \u001b[1;32mand\u001b[0m\u001b[0;31m \u001b[0m\u001b[0;31m\\\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mD:\\anaconda\\lib\\site-packages\\torch\\utils\\data\\dataloader.py\u001b[0m in \u001b[0;36m_next_data\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    559\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m_next_data\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    560\u001b[0m         \u001b[0mindex\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_next_index\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m  \u001b[1;31m# may raise StopIteration\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 561\u001b[1;33m         \u001b[0mdata\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_dataset_fetcher\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfetch\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mindex\u001b[0m\u001b[1;33m)\u001b[0m  \u001b[1;31m# may raise StopIteration\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    562\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_pin_memory\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    563\u001b[0m             \u001b[0mdata\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0m_utils\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpin_memory\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpin_memory\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mD:\\anaconda\\lib\\site-packages\\torch\\utils\\data\\_utils\\fetch.py\u001b[0m in \u001b[0;36mfetch\u001b[1;34m(self, possibly_batched_index)\u001b[0m\n\u001b[0;32m     42\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mfetch\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mpossibly_batched_index\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     43\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mauto_collation\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 44\u001b[1;33m             \u001b[0mdata\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdataset\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0midx\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0midx\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mpossibly_batched_index\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     45\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     46\u001b[0m             \u001b[0mdata\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdataset\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mpossibly_batched_index\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mD:\\anaconda\\lib\\site-packages\\torch\\utils\\data\\_utils\\fetch.py\u001b[0m in \u001b[0;36m<listcomp>\u001b[1;34m(.0)\u001b[0m\n\u001b[0;32m     42\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mfetch\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mpossibly_batched_index\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     43\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mauto_collation\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 44\u001b[1;33m             \u001b[0mdata\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdataset\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0midx\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0midx\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mpossibly_batched_index\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     45\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     46\u001b[0m             \u001b[0mdata\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdataset\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mpossibly_batched_index\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mE:\\TECO_Works\\Conference\\ISWC2022\\I2S0W2C2_CFC\\dataloaders\\__init__.py\u001b[0m in \u001b[0;36m__getitem__\u001b[1;34m(self, index)\u001b[0m\n\u001b[0;32m    166\u001b[0m                 \u001b[0msample_x\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdata_x\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0miloc\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mstart_index\u001b[0m\u001b[1;33m:\u001b[0m\u001b[0mend_index\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m-\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    167\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 168\u001b[1;33m             \u001b[0msample_y\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mclass_transform\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdata_y\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0miloc\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mstart_index\u001b[0m\u001b[1;33m:\u001b[0m\u001b[0mend_index\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmode\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mloc\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    169\u001b[0m             \u001b[1;31m#print(sample_x.shape)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    170\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mD:\\anaconda\\lib\\site-packages\\pandas\\core\\series.py\u001b[0m in \u001b[0;36mmode\u001b[1;34m(self, dropna)\u001b[0m\n\u001b[0;32m   1807\u001b[0m         \"\"\"\n\u001b[0;32m   1808\u001b[0m         \u001b[1;31m# TODO: Add option for bins like value_counts()\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1809\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[0malgorithms\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmode\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdropna\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mdropna\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1810\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1811\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0munique\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mD:\\anaconda\\lib\\site-packages\\pandas\\core\\algorithms.py\u001b[0m in \u001b[0;36mmode\u001b[1;34m(values, dropna)\u001b[0m\n\u001b[0;32m    938\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    939\u001b[0m     \u001b[0mf\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mgetattr\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mhtable\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34mf\"mode_{ndtype}\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 940\u001b[1;33m     \u001b[0mresult\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mf\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mvalues\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdropna\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mdropna\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    941\u001b[0m     \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    942\u001b[0m         \u001b[0mresult\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msort\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mresult\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error in callback <function flush_figures at 0x0000017B440A2040> (for post_execute):\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32mD:\\anaconda\\lib\\site-packages\\ipykernel\\pylab\\backend_inline.py\u001b[0m in \u001b[0;36mflush_figures\u001b[1;34m()\u001b[0m\n\u001b[0;32m    119\u001b[0m         \u001b[1;31m# ignore the tracking, just draw and close all figures\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    120\u001b[0m         \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 121\u001b[1;33m             \u001b[1;32mreturn\u001b[0m \u001b[0mshow\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;32mTrue\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    122\u001b[0m         \u001b[1;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    123\u001b[0m             \u001b[1;31m# safely show traceback if in IPython, else raise\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mD:\\anaconda\\lib\\site-packages\\ipykernel\\pylab\\backend_inline.py\u001b[0m in \u001b[0;36mshow\u001b[1;34m(close, block)\u001b[0m\n\u001b[0;32m     39\u001b[0m     \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     40\u001b[0m         \u001b[1;32mfor\u001b[0m \u001b[0mfigure_manager\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mGcf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget_all_fig_managers\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 41\u001b[1;33m             display(\n\u001b[0m\u001b[0;32m     42\u001b[0m                 \u001b[0mfigure_manager\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcanvas\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfigure\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     43\u001b[0m                 \u001b[0mmetadata\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0m_fetch_figure_metadata\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfigure_manager\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcanvas\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfigure\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mD:\\anaconda\\lib\\site-packages\\IPython\\core\\display.py\u001b[0m in \u001b[0;36mdisplay\u001b[1;34m(include, exclude, metadata, transient, display_id, *objs, **kwargs)\u001b[0m\n\u001b[0;32m    311\u001b[0m             \u001b[0mpublish_display_data\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mobj\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmetadata\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mmetadata\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    312\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 313\u001b[1;33m             \u001b[0mformat_dict\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmd_dict\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mformat\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mobj\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0minclude\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0minclude\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mexclude\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mexclude\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    314\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[0mformat_dict\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    315\u001b[0m                 \u001b[1;31m# nothing to display (e.g. _ipython_display_ took over)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mD:\\anaconda\\lib\\site-packages\\IPython\\core\\formatters.py\u001b[0m in \u001b[0;36mformat\u001b[1;34m(self, obj, include, exclude)\u001b[0m\n\u001b[0;32m    178\u001b[0m             \u001b[0mmd\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    179\u001b[0m             \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 180\u001b[1;33m                 \u001b[0mdata\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mformatter\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mobj\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    181\u001b[0m             \u001b[1;32mexcept\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    182\u001b[0m                 \u001b[1;31m# FIXME: log the exception\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mD:\\anaconda\\lib\\site-packages\\decorator.py\u001b[0m in \u001b[0;36mfun\u001b[1;34m(*args, **kw)\u001b[0m\n\u001b[0;32m    229\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[0mkwsyntax\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    230\u001b[0m                 \u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mkw\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mfix\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mkw\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0msig\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 231\u001b[1;33m             \u001b[1;32mreturn\u001b[0m \u001b[0mcaller\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfunc\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m*\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mextras\u001b[0m \u001b[1;33m+\u001b[0m \u001b[0margs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkw\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    232\u001b[0m     \u001b[0mfun\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m__name__\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mfunc\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m__name__\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    233\u001b[0m     \u001b[0mfun\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m__doc__\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mfunc\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m__doc__\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mD:\\anaconda\\lib\\site-packages\\IPython\\core\\formatters.py\u001b[0m in \u001b[0;36mcatch_format_error\u001b[1;34m(method, self, *args, **kwargs)\u001b[0m\n\u001b[0;32m    222\u001b[0m     \u001b[1;34m\"\"\"show traceback on failed format call\"\"\"\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    223\u001b[0m     \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 224\u001b[1;33m         \u001b[0mr\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mmethod\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    225\u001b[0m     \u001b[1;32mexcept\u001b[0m \u001b[0mNotImplementedError\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    226\u001b[0m         \u001b[1;31m# don't warn on NotImplementedErrors\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mD:\\anaconda\\lib\\site-packages\\IPython\\core\\formatters.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, obj)\u001b[0m\n\u001b[0;32m    339\u001b[0m                 \u001b[1;32mpass\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    340\u001b[0m             \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 341\u001b[1;33m                 \u001b[1;32mreturn\u001b[0m \u001b[0mprinter\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mobj\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    342\u001b[0m             \u001b[1;31m# Finally look for special method names\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    343\u001b[0m             \u001b[0mmethod\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mget_real_method\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mobj\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mprint_method\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mD:\\anaconda\\lib\\site-packages\\IPython\\core\\pylabtools.py\u001b[0m in \u001b[0;36m<lambda>\u001b[1;34m(fig)\u001b[0m\n\u001b[0;32m    246\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    247\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[1;34m'png'\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mformats\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 248\u001b[1;33m         \u001b[0mpng_formatter\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfor_type\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mFigure\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;32mlambda\u001b[0m \u001b[0mfig\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mprint_figure\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfig\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'png'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    249\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[1;34m'retina'\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mformats\u001b[0m \u001b[1;32mor\u001b[0m \u001b[1;34m'png2x'\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mformats\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    250\u001b[0m         \u001b[0mpng_formatter\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfor_type\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mFigure\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;32mlambda\u001b[0m \u001b[0mfig\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mretina_figure\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfig\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mD:\\anaconda\\lib\\site-packages\\IPython\\core\\pylabtools.py\u001b[0m in \u001b[0;36mprint_figure\u001b[1;34m(fig, fmt, bbox_inches, **kwargs)\u001b[0m\n\u001b[0;32m    130\u001b[0m         \u001b[0mFigureCanvasBase\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfig\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    131\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 132\u001b[1;33m     \u001b[0mfig\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcanvas\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mprint_figure\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mbytes_io\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkw\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    133\u001b[0m     \u001b[0mdata\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mbytes_io\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mgetvalue\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    134\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mfmt\u001b[0m \u001b[1;33m==\u001b[0m \u001b[1;34m'svg'\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mD:\\anaconda\\lib\\site-packages\\matplotlib\\backend_bases.py\u001b[0m in \u001b[0;36mprint_figure\u001b[1;34m(self, filename, dpi, facecolor, edgecolor, orientation, format, bbox_inches, pad_inches, bbox_extra_artists, backend, **kwargs)\u001b[0m\n\u001b[0;32m   2208\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2209\u001b[0m             \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 2210\u001b[1;33m                 result = print_method(\n\u001b[0m\u001b[0;32m   2211\u001b[0m                     \u001b[0mfilename\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2212\u001b[0m                     \u001b[0mdpi\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mdpi\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mD:\\anaconda\\lib\\site-packages\\matplotlib\\backend_bases.py\u001b[0m in \u001b[0;36mwrapper\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m   1637\u001b[0m             \u001b[0mkwargs\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpop\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0marg\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1638\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1639\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1640\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1641\u001b[0m     \u001b[1;32mreturn\u001b[0m \u001b[0mwrapper\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mD:\\anaconda\\lib\\site-packages\\matplotlib\\backends\\backend_agg.py\u001b[0m in \u001b[0;36mprint_png\u001b[1;34m(self, filename_or_obj, metadata, pil_kwargs, *args)\u001b[0m\n\u001b[0;32m    507\u001b[0m             \u001b[1;33m*\u001b[0m\u001b[0mmetadata\u001b[0m\u001b[1;33m*\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mincluding\u001b[0m \u001b[0mthe\u001b[0m \u001b[0mdefault\u001b[0m \u001b[1;34m'Software'\u001b[0m \u001b[0mkey\u001b[0m\u001b[1;33m.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    508\u001b[0m         \"\"\"\n\u001b[1;32m--> 509\u001b[1;33m         \u001b[0mFigureCanvasAgg\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdraw\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    510\u001b[0m         mpl.image.imsave(\n\u001b[0;32m    511\u001b[0m             \u001b[0mfilename_or_obj\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mbuffer_rgba\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mformat\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m\"png\"\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0morigin\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m\"upper\"\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mD:\\anaconda\\lib\\site-packages\\matplotlib\\backends\\backend_agg.py\u001b[0m in \u001b[0;36mdraw\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    405\u001b[0m              (self.toolbar._wait_cursor_for_draw_cm() if self.toolbar\n\u001b[0;32m    406\u001b[0m               else nullcontext()):\n\u001b[1;32m--> 407\u001b[1;33m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfigure\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdraw\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mrenderer\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    408\u001b[0m             \u001b[1;31m# A GUI class may be need to update a window using this draw, so\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    409\u001b[0m             \u001b[1;31m# don't forget to call the superclass.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mD:\\anaconda\\lib\\site-packages\\matplotlib\\artist.py\u001b[0m in \u001b[0;36mdraw_wrapper\u001b[1;34m(artist, renderer, *args, **kwargs)\u001b[0m\n\u001b[0;32m     39\u001b[0m                 \u001b[0mrenderer\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mstart_filter\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     40\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 41\u001b[1;33m             \u001b[1;32mreturn\u001b[0m \u001b[0mdraw\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0martist\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mrenderer\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     42\u001b[0m         \u001b[1;32mfinally\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     43\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0martist\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget_agg_filter\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mD:\\anaconda\\lib\\site-packages\\matplotlib\\figure.py\u001b[0m in \u001b[0;36mdraw\u001b[1;34m(self, renderer)\u001b[0m\n\u001b[0;32m   1861\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1862\u001b[0m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpatch\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdraw\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mrenderer\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1863\u001b[1;33m             mimage._draw_list_compositing_images(\n\u001b[0m\u001b[0;32m   1864\u001b[0m                 renderer, self, artists, self.suppressComposite)\n\u001b[0;32m   1865\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mD:\\anaconda\\lib\\site-packages\\matplotlib\\image.py\u001b[0m in \u001b[0;36m_draw_list_compositing_images\u001b[1;34m(renderer, parent, artists, suppress_composite)\u001b[0m\n\u001b[0;32m    129\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mnot_composite\u001b[0m \u001b[1;32mor\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[0mhas_images\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    130\u001b[0m         \u001b[1;32mfor\u001b[0m \u001b[0ma\u001b[0m \u001b[1;32min\u001b[0m \u001b[0martists\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 131\u001b[1;33m             \u001b[0ma\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdraw\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mrenderer\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    132\u001b[0m     \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    133\u001b[0m         \u001b[1;31m# Composite any adjacent images together\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mD:\\anaconda\\lib\\site-packages\\matplotlib\\artist.py\u001b[0m in \u001b[0;36mdraw_wrapper\u001b[1;34m(artist, renderer, *args, **kwargs)\u001b[0m\n\u001b[0;32m     39\u001b[0m                 \u001b[0mrenderer\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mstart_filter\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     40\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 41\u001b[1;33m             \u001b[1;32mreturn\u001b[0m \u001b[0mdraw\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0martist\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mrenderer\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     42\u001b[0m         \u001b[1;32mfinally\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     43\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0martist\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget_agg_filter\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mD:\\anaconda\\lib\\site-packages\\matplotlib\\cbook\\deprecation.py\u001b[0m in \u001b[0;36mwrapper\u001b[1;34m(*inner_args, **inner_kwargs)\u001b[0m\n\u001b[0;32m    409\u001b[0m                          \u001b[1;32melse\u001b[0m \u001b[0mdeprecation_addendum\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    410\u001b[0m                 **kwargs)\n\u001b[1;32m--> 411\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0minner_args\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0minner_kwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    412\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    413\u001b[0m     \u001b[1;32mreturn\u001b[0m \u001b[0mwrapper\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mD:\\anaconda\\lib\\site-packages\\matplotlib\\axes\\_base.py\u001b[0m in \u001b[0;36mdraw\u001b[1;34m(self, renderer, inframe)\u001b[0m\n\u001b[0;32m   2745\u001b[0m             \u001b[0mrenderer\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mstop_rasterizing\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2746\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 2747\u001b[1;33m         \u001b[0mmimage\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_draw_list_compositing_images\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mrenderer\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0martists\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   2748\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2749\u001b[0m         \u001b[0mrenderer\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mclose_group\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'axes'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mD:\\anaconda\\lib\\site-packages\\matplotlib\\image.py\u001b[0m in \u001b[0;36m_draw_list_compositing_images\u001b[1;34m(renderer, parent, artists, suppress_composite)\u001b[0m\n\u001b[0;32m    129\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mnot_composite\u001b[0m \u001b[1;32mor\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[0mhas_images\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    130\u001b[0m         \u001b[1;32mfor\u001b[0m \u001b[0ma\u001b[0m \u001b[1;32min\u001b[0m \u001b[0martists\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 131\u001b[1;33m             \u001b[0ma\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdraw\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mrenderer\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    132\u001b[0m     \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    133\u001b[0m         \u001b[1;31m# Composite any adjacent images together\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mD:\\anaconda\\lib\\site-packages\\matplotlib\\artist.py\u001b[0m in \u001b[0;36mdraw_wrapper\u001b[1;34m(artist, renderer, *args, **kwargs)\u001b[0m\n\u001b[0;32m     39\u001b[0m                 \u001b[0mrenderer\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mstart_filter\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     40\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 41\u001b[1;33m             \u001b[1;32mreturn\u001b[0m \u001b[0mdraw\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0martist\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mrenderer\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     42\u001b[0m         \u001b[1;32mfinally\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     43\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0martist\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget_agg_filter\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mD:\\anaconda\\lib\\site-packages\\matplotlib\\text.py\u001b[0m in \u001b[0;36mdraw\u001b[1;34m(self, renderer)\u001b[0m\n\u001b[0;32m    725\u001b[0m                                           mtext=mtext)\n\u001b[0;32m    726\u001b[0m                 \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 727\u001b[1;33m                     textrenderer.draw_text(gc, x, y, clean_line,\n\u001b[0m\u001b[0;32m    728\u001b[0m                                            \u001b[0mtextobj\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_fontproperties\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mangle\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    729\u001b[0m                                            ismath=ismath, mtext=mtext)\n",
      "\u001b[1;32mD:\\anaconda\\lib\\site-packages\\matplotlib\\backends\\backend_agg.py\u001b[0m in \u001b[0;36mdraw_text\u001b[1;34m(self, gc, x, y, s, prop, angle, ismath, mtext)\u001b[0m\n\u001b[0;32m    193\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    194\u001b[0m         \u001b[0mflags\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mget_hinting_flag\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 195\u001b[1;33m         \u001b[0mfont\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_get_agg_font\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mprop\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    196\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    197\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mfont\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mD:\\anaconda\\lib\\site-packages\\matplotlib\\backends\\backend_agg.py\u001b[0m in \u001b[0;36m_get_agg_font\u001b[1;34m(self, prop)\u001b[0m\n\u001b[0;32m    270\u001b[0m         \u001b[0mGet\u001b[0m \u001b[0mthe\u001b[0m \u001b[0mfont\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mtext\u001b[0m \u001b[0minstance\u001b[0m \u001b[0mt\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcaching\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mefficiency\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    271\u001b[0m         \"\"\"\n\u001b[1;32m--> 272\u001b[1;33m         \u001b[0mfname\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mfindfont\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mprop\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    273\u001b[0m         \u001b[0mfont\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mget_font\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfname\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    274\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mD:\\anaconda\\lib\\site-packages\\matplotlib\\font_manager.py\u001b[0m in \u001b[0;36mfindfont\u001b[1;34m(self, prop, fontext, directory, fallback_to_default, rebuild_if_missing)\u001b[0m\n\u001b[0;32m   1312\u001b[0m             \u001b[0mprop\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfontext\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdirectory\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfallback_to_default\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mrebuild_if_missing\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1313\u001b[0m             rc_params)\n\u001b[1;32m-> 1314\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[0mos\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpath\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mrealpath\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfilename\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1315\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1316\u001b[0m     \u001b[1;33m@\u001b[0m\u001b[0mlru_cache\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mD:\\anaconda\\lib\\ntpath.py\u001b[0m in \u001b[0;36mrealpath\u001b[1;34m(path)\u001b[0m\n\u001b[0;32m    662\u001b[0m             \u001b[1;31m# Ensure that the non-prefixed path resolves to the same path\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    663\u001b[0m             \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 664\u001b[1;33m                 \u001b[1;32mif\u001b[0m \u001b[0m_getfinalpathname\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mspath\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m==\u001b[0m \u001b[0mpath\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    665\u001b[0m                     \u001b[0mpath\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mspath\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    666\u001b[0m             \u001b[1;32mexcept\u001b[0m \u001b[0mOSError\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0mex\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "exp.train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f8aed663",
   "metadata": {},
   "outputs": [],
   "source": [
    "exp.train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "26d97ad8",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "89d6c81d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "86ba8aac",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e2bb5ad4",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9d066180",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7a596b7a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4e7fb08e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "04508e6c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "339ae571",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = data_dict[args.data_name](args)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "779e3397",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cfb6776a",
   "metadata": {},
   "outputs": [],
   "source": [
    "start_index = dataset.train_slidingwindows[0][1]\n",
    "end_index   = dataset.train_slidingwindows[0][2]\n",
    "sample_x_1    = dataset.data_x.iloc[start_index:end_index, 1:-1].values\n",
    "\n",
    "start_index = dataset.train_slidingwindows[100][1]\n",
    "end_index   = dataset.train_slidingwindows[100][2]\n",
    "sample_x_2    = dataset.data_x.iloc[start_index:end_index, 1:-1].values\n",
    "\n",
    "temp_1 = np.expand_dims(sample_x_1,0)\n",
    "temp_2 = np.expand_dims(sample_x_2,0)\n",
    "combined_x = np.concatenate([temp_1,temp_2],axis=0)\n",
    "combined_x = np.expand_dims(combined_x,1)\n",
    "combined_x = torch.tensor(combined_x).double().to(exp.device)\n",
    "print(combined_x.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2af5063a",
   "metadata": {},
   "outputs": [],
   "source": [
    "out = exp.model(combined_x)\n",
    "out = out.cpu().detach().numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fc57c0e2",
   "metadata": {},
   "outputs": [],
   "source": [
    "out.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6f69036a",
   "metadata": {},
   "outputs": [],
   "source": [
    "weight = exp.model.wave_conv.wavelet_conv.weight.cpu().detach().numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d44c070a",
   "metadata": {},
   "outputs": [],
   "source": [
    "for n,p in exp.model.named_parameters():\n",
    "    print(n)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5f19ba6e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "index1 = 0\n",
    "index2 = 0\n",
    "\n",
    "plt.figure()\n",
    "plt.plot(out[0,0,:,index2])\n",
    "plt.plot(out[0,1,:,index2])\n",
    "plt.plot(out[0,2,:,index2])\n",
    "plt.plot(out[0,3,:,index2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a3ae8916",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ffe11eb7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 如果我们设置为 \n",
    "# args.wavelet_filtering_learnable      = True\n",
    "# exp = Exp(args)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5d15a68f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6beec6d1",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "90f99481",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d8700989",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7b222186",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5ae27337",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4506b3e7",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ca5dc27e",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
