{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "894e2c21",
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "import sys\n",
    "sys.path.append(\"../../\")\n",
    "\n",
    "from experiment import Exp\n",
    "\n",
    "from dataloaders import data_set,data_dict\n",
    "import torch\n",
    "import yaml\n",
    "import os"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bcc56bc7",
   "metadata": {},
   "source": [
    "# 参数设置"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dcc5bcbc",
   "metadata": {},
   "source": [
    "# 训练参数 \n",
    "除了路径 其他不要变"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "86004ce0",
   "metadata": {},
   "outputs": [],
   "source": [
    "class dotdict(dict):\n",
    "    \"\"\"dot.notation access to dictionary attributes\"\"\"\n",
    "    __getattr__ = dict.get\n",
    "    __setattr__ = dict.__setitem__\n",
    "    __delattr__ = dict.__delitem__\n",
    "\n",
    "args = dotdict()   \n",
    "# TODO change the path as relative path\n",
    "args.to_save_path     = \"../../../ISWC2022LearnableFilter/Run_logs\"              \n",
    "args.freq_save_path   = \"../../../ISWC2022LearnableFilter/Freq_data\"\n",
    "args.window_save_path = \"../../../ISWC2022LearnableFilter/Sliding_window\"\n",
    "args.root_path        = \"../../../datasets\"\n",
    "\n",
    "\n",
    "args.drop_transition  = False\n",
    "args.datanorm_type    = \"standardization\" # None ,\"standardization\", \"minmax\"\n",
    "\n",
    "\n",
    "args.batch_size       = 256                                                     \n",
    "args.shuffle          = True\n",
    "args.drop_last        = False\n",
    "args.train_vali_quote = 0.90                                           \n",
    "\n",
    "\n",
    "# training setting \n",
    "args.train_epochs            = 150\n",
    "\n",
    "args.learning_rate           = 0.001  \n",
    "args.learning_rate_patience  = 5\n",
    "args.learning_rate_factor    = 0.1\n",
    "\n",
    "\n",
    "args.early_stop_patience     = 15\n",
    "\n",
    "args.use_gpu                 = True if torch.cuda.is_available() else False\n",
    "args.gpu                     = 2\n",
    "args.use_multi_gpu           = False\n",
    "\n",
    "args.optimizer               = \"Adam\"\n",
    "args.criterion               = \"CrossEntropy\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c282cbcb",
   "metadata": {},
   "source": [
    "## 数据参数\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "c6cd147b",
   "metadata": {},
   "outputs": [],
   "source": [
    "args.seed                             = 3\n",
    "\n",
    "\n",
    "args.data_name                        =  \"oppo\"\n",
    "\n",
    "args.wavelet_filtering                = True\n",
    "args.wavelet_filtering_regularization = True\n",
    "args.wavelet_filtering_finetuning     = True\n",
    "args.wavelet_filtering_finetuning_percent = 0.3\n",
    "\n",
    "args.regulatization_tradeoff          = 0.0001\n",
    "args.number_wavelet_filtering         = 10\n",
    "\n",
    "\n",
    "args.difference       = False \n",
    "args.filtering        =  False\n",
    "args.magnitude        =  False\n",
    "args.weighted_sampler = False\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "args.pos_select       = None\n",
    "args.sensor_select    = None\n",
    "\n",
    "\n",
    "args.representation_type = \"time\"\n",
    "args.exp_mode            = \"LOCV\"\n",
    "\n",
    "config_file = open('../../configs/data.yaml', mode='r')\n",
    "data_config = yaml.load(config_file, Loader=yaml.FullLoader)\n",
    "config = data_config[args.data_name]\n",
    "\n",
    "args.root_path       = os.path.join(args.root_path,config[\"filename\"])\n",
    "args.sampling_freq   = config[\"sampling_freq\"]\n",
    "args.num_classes     =  config[\"num_classes\"]\n",
    "window_seconds       = config[\"window_seconds\"]\n",
    "args.windowsize      =   int(window_seconds * args.sampling_freq) \n",
    "args.input_length    =  args.windowsize\n",
    "# input information\n",
    "args.c_in            = config[\"num_channels\"]\n",
    "\n",
    "if args.wavelet_filtering :\n",
    "    \n",
    "    if args.windowsize%2==1:\n",
    "        N_ds = int(torch.log2(torch.tensor(args.windowsize-1)).floor()) - 2\n",
    "    else:\n",
    "        N_ds = int(torch.log2(torch.tensor(args.windowsize)).floor()) - 2\n",
    "\n",
    "    args.f_in            =  args.number_wavelet_filtering*N_ds+1\n",
    "else:\n",
    "    args.f_in            =  1\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4d435a4c",
   "metadata": {},
   "source": [
    "## 模型参数"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "de2f4d16",
   "metadata": {},
   "outputs": [],
   "source": [
    "args.filter_scaling_factor = 0.25\n",
    "args.model_type            = \"deepconvlstm\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cada66dd",
   "metadata": {},
   "source": [
    "# 实验"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "2e3f2fad",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Use GPU: cuda:2\n",
      "Wavelet Filtering Regularization\n",
      "Build the DeepConvLSTM model!\n",
      "Done!\n",
      "Parameter : 5383527\n",
      "Set the seed as :  3\n"
     ]
    }
   ],
   "source": [
    "exp = Exp(args)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "09a011fc",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " ----------------------- load all the data -------------------\n",
      "-----------------------Sliding file are generated -----------------------\n",
      "-----------------------Sliding file are generated -----------------------\n",
      "================ LOCV Mode ====================\n",
      "================ 4 CV ======================\n",
      "================ the 0 th CV Experiment ================ \n",
      "Leave one Out Experiment : The 1 Part as the test\n",
      "[-] Target sampling weights:  [3.63345687e-05 1.65016502e-03 1.61290323e-03 1.80831826e-03\n",
      " 1.67224080e-03 1.17096019e-03 1.34048257e-03 1.81159420e-03\n",
      " 2.08333333e-03 2.68096515e-03 3.26797386e-03 3.14465409e-03\n",
      " 3.75939850e-03 2.51256281e-03 2.50000000e-03 1.28369705e-03\n",
      " 4.54545455e-04 2.04498978e-03]\n",
      "Train data number :  38060\n",
      "The number of classes is :  18\n",
      "The input_length  is :  30\n",
      "The channel_in is :  77\n",
      "Validation data number :  4229\n",
      "Test data number :  78162\n",
      "================Skip the 0 CV Experiment================\n",
      "================Skip the 0 CV Experiment Fine Tuning================\n",
      "================ the 1 th CV Experiment ================ \n",
      "Leave one Out Experiment : The 2 Part as the test\n",
      "[-] Target sampling weights:  [3.58358717e-05 1.49925037e-03 1.50829563e-03 1.59744409e-03\n",
      " 1.63666121e-03 1.28369705e-03 1.40252454e-03 2.14592275e-03\n",
      " 2.27790433e-03 2.89855072e-03 3.02114804e-03 2.78551532e-03\n",
      " 2.97619048e-03 2.28310502e-03 2.34741784e-03 1.62337662e-03\n",
      " 4.07830343e-04 2.19298246e-03]\n",
      "Train data number :  38628\n",
      "The number of classes is :  18\n",
      "The input_length  is :  30\n",
      "The channel_in is :  77\n",
      "Validation data number :  4292\n",
      "Test data number :  75003\n",
      "================Skip the 1 CV Experiment================\n",
      "Wavelet Filtering Regularization\n",
      "Build the DeepConvLSTM model!\n",
      "Wavelet Filtering Regularization\n",
      "Build the DeepConvLSTM model!\n",
      "------------Fine Tuning  :  15   will be pruned   -----------------------------------------\n",
      "old model Parameter : 5383527\n",
      "pruned model Parameter : 5378712\n",
      "----------------------------------------------------------------------------------------\n",
      "Fine Tuning Epoch: 1 cost time: 51.94996976852417\n",
      "Fine Tuning VALI: Epoch: 1, Steps: 302 | Train Loss: 0.3145757  Vali Loss: 0.2988476 Vali Accuracy: 0.9016775  Vali weighted F1: 0.8992045  Vali macro F1 0.7224861 \n",
      "Validation loss decreased (inf --> 0.298848).  Saving model ...\n",
      "Fine Tuning Epoch: 2 cost time: 48.760817527770996\n",
      "Fine Tuning VALI: Epoch: 2, Steps: 302 | Train Loss: 0.3135363  Vali Loss: 0.2983143 Vali Accuracy: 0.9047064  Vali weighted F1: 0.9020265  Vali macro F1 0.7292590 \n",
      "new best score!!!!\n",
      "Validation loss decreased (0.298848 --> 0.298314).  Saving model ...\n",
      "new best score!!!!\n",
      "Fine Tuning Epoch: 3 cost time: 48.81382727622986\n",
      "Fine Tuning VALI: Epoch: 3, Steps: 302 | Train Loss: 0.3157095  Vali Loss: 0.3008470 Vali Accuracy: 0.9033085  Vali weighted F1: 0.9015503  Vali macro F1 0.7354927 \n",
      "EarlyStopping counter: 1 out of 5\n",
      "Learning rate adjusting counter: 1 out of 5\n",
      "Fine Tuning Epoch: 4 cost time: 48.86249279975891\n",
      "Fine Tuning VALI: Epoch: 4, Steps: 302 | Train Loss: 0.3137290  Vali Loss: 0.3020010 Vali Accuracy: 0.9063374  Vali weighted F1: 0.9044914  Vali macro F1 0.7411504 \n",
      "EarlyStopping counter: 2 out of 5\n",
      "Learning rate adjusting counter: 2 out of 5\n",
      "Fine Tuning Epoch: 5 cost time: 48.8574697971344\n",
      "Fine Tuning VALI: Epoch: 5, Steps: 302 | Train Loss: 0.3137063  Vali Loss: 0.3035325 Vali Accuracy: 0.8988816  Vali weighted F1: 0.8974044  Vali macro F1 0.7165358 \n",
      "EarlyStopping counter: 3 out of 5\n",
      "Learning rate adjusting counter: 3 out of 5\n",
      "Fine Tuning Epoch: 6 cost time: 48.85031771659851\n",
      "Fine Tuning VALI: Epoch: 6, Steps: 302 | Train Loss: 0.3085982  Vali Loss: 0.2961650 Vali Accuracy: 0.9035415  Vali weighted F1: 0.9013743  Vali macro F1 0.7270207 \n",
      "new best score!!!!\n",
      "Validation loss decreased (0.298314 --> 0.296165).  Saving model ...\n",
      "new best score!!!!\n",
      "Fine Tuning Epoch: 7 cost time: 49.10799789428711\n",
      "Fine Tuning VALI: Epoch: 7, Steps: 302 | Train Loss: 0.3069401  Vali Loss: 0.2958076 Vali Accuracy: 0.9033085  Vali weighted F1: 0.9009656  Vali macro F1 0.7315646 \n",
      "new best score!!!!\n",
      "Validation loss decreased (0.296165 --> 0.295808).  Saving model ...\n",
      "new best score!!!!\n",
      "Fine Tuning Epoch: 8 cost time: 49.127904415130615\n",
      "Fine Tuning VALI: Epoch: 8, Steps: 302 | Train Loss: 0.3077995  Vali Loss: 0.2959114 Vali Accuracy: 0.9051724  Vali weighted F1: 0.9030738  Vali macro F1 0.7373778 \n",
      "EarlyStopping counter: 1 out of 5\n",
      "Learning rate adjusting counter: 1 out of 5\n",
      "Fine Tuning Epoch: 9 cost time: 49.17051959037781\n",
      "Fine Tuning VALI: Epoch: 9, Steps: 302 | Train Loss: 0.3033038  Vali Loss: 0.2987537 Vali Accuracy: 0.9030755  Vali weighted F1: 0.9018459  Vali macro F1 0.7360978 \n",
      "EarlyStopping counter: 2 out of 5\n",
      "Learning rate adjusting counter: 2 out of 5\n",
      "Fine Tuning Epoch: 10 cost time: 49.25940465927124\n",
      "Fine Tuning VALI: Epoch: 10, Steps: 302 | Train Loss: 0.3041269  Vali Loss: 0.2954452 Vali Accuracy: 0.9035415  Vali weighted F1: 0.9010164  Vali macro F1 0.7299204 \n",
      "new best score!!!!\n",
      "Validation loss decreased (0.295808 --> 0.295445).  Saving model ...\n",
      "new best score!!!!\n",
      "Fine Tuning Epoch: 11 cost time: 49.266199588775635\n",
      "Fine Tuning VALI: Epoch: 11, Steps: 302 | Train Loss: 0.3031024  Vali Loss: 0.2916500 Vali Accuracy: 0.9037745  Vali weighted F1: 0.9017658  Vali macro F1 0.7315049 \n",
      "new best score!!!!\n",
      "Validation loss decreased (0.295445 --> 0.291650).  Saving model ...\n",
      "new best score!!!!\n",
      "Fine Tuning Epoch: 12 cost time: 49.43799686431885\n",
      "Fine Tuning VALI: Epoch: 12, Steps: 302 | Train Loss: 0.3001132  Vali Loss: 0.2925457 Vali Accuracy: 0.9012116  Vali weighted F1: 0.9004027  Vali macro F1 0.7341303 \n",
      "EarlyStopping counter: 1 out of 5\n",
      "Learning rate adjusting counter: 1 out of 5\n",
      "Fine Tuning Epoch: 13 cost time: 49.25649404525757\n",
      "Fine Tuning VALI: Epoch: 13, Steps: 302 | Train Loss: 0.2980710  Vali Loss: 0.2905058 Vali Accuracy: 0.8993476  Vali weighted F1: 0.8981684  Vali macro F1 0.7237756 \n",
      "new best score!!!!\n",
      "Validation loss decreased (0.291650 --> 0.290506).  Saving model ...\n",
      "new best score!!!!\n",
      "Fine Tuning Epoch: 14 cost time: 49.271485328674316\n",
      "Fine Tuning VALI: Epoch: 14, Steps: 302 | Train Loss: 0.2989389  Vali Loss: 0.2885128 Vali Accuracy: 0.9047064  Vali weighted F1: 0.9026764  Vali macro F1 0.7406925 \n",
      "new best score!!!!\n",
      "Validation loss decreased (0.290506 --> 0.288513).  Saving model ...\n",
      "new best score!!!!\n",
      "Fine Tuning Epoch: 15 cost time: 49.37669587135315\n",
      "Fine Tuning VALI: Epoch: 15, Steps: 302 | Train Loss: 0.2954696  Vali Loss: 0.2876064 Vali Accuracy: 0.9047064  Vali weighted F1: 0.9031131  Vali macro F1 0.7512188 \n",
      "new best score!!!!\n",
      "Validation loss decreased (0.288513 --> 0.287606).  Saving model ...\n",
      "new best score!!!!\n",
      "Fine Tuning Epoch: 16 cost time: 49.22511410713196\n",
      "Fine Tuning VALI: Epoch: 16, Steps: 302 | Train Loss: 0.2933495  Vali Loss: 0.2828689 Vali Accuracy: 0.9100652  Vali weighted F1: 0.9081355  Vali macro F1 0.7636580 \n",
      "new best score!!!!\n",
      "Validation loss decreased (0.287606 --> 0.282869).  Saving model ...\n",
      "new best score!!!!\n",
      "Fine Tuning Epoch: 17 cost time: 49.404321908950806\n",
      "Fine Tuning VALI: Epoch: 17, Steps: 302 | Train Loss: 0.2916701  Vali Loss: 0.2858417 Vali Accuracy: 0.9058714  Vali weighted F1: 0.9045505  Vali macro F1 0.7507188 \n",
      "EarlyStopping counter: 1 out of 5\n",
      "Learning rate adjusting counter: 1 out of 5\n",
      "Fine Tuning Epoch: 18 cost time: 49.46497344970703\n",
      "Fine Tuning VALI: Epoch: 18, Steps: 302 | Train Loss: 0.2955219  Vali Loss: 0.2846602 Vali Accuracy: 0.9042404  Vali weighted F1: 0.9025583  Vali macro F1 0.7399022 \n",
      "EarlyStopping counter: 2 out of 5\n",
      "Learning rate adjusting counter: 2 out of 5\n",
      "Fine Tuning Epoch: 19 cost time: 49.38598036766052\n",
      "Fine Tuning VALI: Epoch: 19, Steps: 302 | Train Loss: 0.2939258  Vali Loss: 0.2826332 Vali Accuracy: 0.9070363  Vali weighted F1: 0.9054071  Vali macro F1 0.7506555 \n",
      "new best score!!!!\n",
      "Validation loss decreased (0.282869 --> 0.282633).  Saving model ...\n",
      "new best score!!!!\n",
      "Fine Tuning Epoch: 20 cost time: 49.22216534614563\n",
      "Fine Tuning VALI: Epoch: 20, Steps: 302 | Train Loss: 0.2943451  Vali Loss: 0.2836082 Vali Accuracy: 0.9063374  Vali weighted F1: 0.9043879  Vali macro F1 0.7474344 \n",
      "EarlyStopping counter: 1 out of 5\n",
      "Learning rate adjusting counter: 1 out of 5\n",
      "Fine Tuning Epoch: 21 cost time: 49.4107027053833\n",
      "Fine Tuning VALI: Epoch: 21, Steps: 302 | Train Loss: 0.2906839  Vali Loss: 0.2853080 Vali Accuracy: 0.9068034  Vali weighted F1: 0.9050170  Vali macro F1 0.7490835 \n",
      "EarlyStopping counter: 2 out of 5\n",
      "Learning rate adjusting counter: 2 out of 5\n",
      "Fine Tuning Epoch: 22 cost time: 49.08664917945862\n",
      "Fine Tuning VALI: Epoch: 22, Steps: 302 | Train Loss: 0.2902620  Vali Loss: 0.2855095 Vali Accuracy: 0.9042404  Vali weighted F1: 0.9022730  Vali macro F1 0.7365228 \n",
      "EarlyStopping counter: 3 out of 5\n",
      "Learning rate adjusting counter: 3 out of 5\n",
      "Fine Tuning Epoch: 23 cost time: 49.28383111953735\n",
      "Fine Tuning VALI: Epoch: 23, Steps: 302 | Train Loss: 0.2891350  Vali Loss: 0.2849814 Vali Accuracy: 0.9047064  Vali weighted F1: 0.9029921  Vali macro F1 0.7405624 \n",
      "EarlyStopping counter: 4 out of 5\n",
      "Learning rate adjusting counter: 4 out of 5\n",
      "Fine Tuning Epoch: 24 cost time: 49.17091369628906\n",
      "Fine Tuning VALI: Epoch: 24, Steps: 302 | Train Loss: 0.2891447  Vali Loss: 0.2864763 Vali Accuracy: 0.9079683  Vali weighted F1: 0.9052537  Vali macro F1 0.7483361 \n",
      "EarlyStopping counter: 5 out of 5\n",
      "Early stopping\n",
      "Loading the best finetuned validation model!\n",
      "Fine Tuning Final Test Performance : Test Accuracy: 0.8210738  Test weighted F1: 0.7972523  Test macro F1 0.4960383 \n",
      "================ the 2 th CV Experiment ================ \n",
      "Leave one Out Experiment : The 3 Part as the test\n",
      "[-] Target sampling weights:  [3.52323574e-05 1.57232704e-03 1.63398693e-03 1.64203612e-03\n",
      " 1.58982512e-03 1.32978723e-03 1.41643059e-03 1.87617261e-03\n",
      " 2.10970464e-03 2.63157895e-03 3.03030303e-03 2.93255132e-03\n",
      " 3.28947368e-03 2.35294118e-03 2.42130751e-03 1.27388535e-03\n",
      " 4.24448217e-04 2.17864924e-03]\n",
      "Train data number :  39127\n",
      "The number of classes is :  18\n",
      "The input_length  is :  30\n",
      "The channel_in is :  77\n",
      "Validation data number :  4348\n",
      "Test data number :  72231\n",
      "================Skip the 2 CV Experiment================\n",
      "================Skip the 2 CV Experiment Fine Tuning================\n",
      "================ the 3 th CV Experiment ================ \n",
      "Leave one Out Experiment : The 4 Part as the test\n",
      "[-] Target sampling weights:  [3.42747464e-05 1.52439024e-03 1.41242938e-03 1.56250000e-03\n",
      " 1.50602410e-03 1.24688279e-03 1.39664804e-03 1.76991150e-03\n",
      " 1.95694716e-03 2.61780105e-03 2.94117647e-03 2.77008310e-03\n",
      " 3.04878049e-03 2.17864924e-03 2.24215247e-03 1.41242938e-03\n",
      " 3.87146729e-04 1.87265918e-03]\n",
      "Train data number :  40579\n",
      "The number of classes is :  18\n",
      "The input_length  is :  30\n",
      "The channel_in is :  77\n",
      "Validation data number :  4509\n",
      "Test data number :  64167\n",
      "================Skip the 3 CV Experiment================\n",
      "Wavelet Filtering Regularization\n",
      "Build the DeepConvLSTM model!\n",
      "Wavelet Filtering Regularization\n",
      "Build the DeepConvLSTM model!\n",
      "------------Fine Tuning  :  15   will be pruned   -----------------------------------------\n",
      "old model Parameter : 5383527\n",
      "pruned model Parameter : 5378712\n",
      "----------------------------------------------------------------------------------------\n",
      "Fine Tuning Epoch: 1 cost time: 51.50936317443848\n",
      "Fine Tuning VALI: Epoch: 1, Steps: 318 | Train Loss: 0.4573901  Vali Loss: 0.4197578 Vali Accuracy: 0.8742515  Vali weighted F1: 0.8649761  Vali macro F1 0.6330262 \n",
      "Validation loss decreased (inf --> 0.419758).  Saving model ...\n",
      "Fine Tuning Epoch: 2 cost time: 51.70540380477905\n",
      "Fine Tuning VALI: Epoch: 2, Steps: 318 | Train Loss: 0.4546957  Vali Loss: 0.4201552 Vali Accuracy: 0.8724773  Vali weighted F1: 0.8627956  Vali macro F1 0.6331431 \n",
      "EarlyStopping counter: 1 out of 5\n",
      "Learning rate adjusting counter: 2 out of 5\n",
      "Fine Tuning Epoch: 3 cost time: 51.55855345726013\n",
      "Fine Tuning VALI: Epoch: 3, Steps: 318 | Train Loss: 0.4580690  Vali Loss: 0.4221751 Vali Accuracy: 0.8746951  Vali weighted F1: 0.8655913  Vali macro F1 0.6371850 \n",
      "EarlyStopping counter: 2 out of 5\n",
      "Learning rate adjusting counter: 3 out of 5\n",
      "Fine Tuning Epoch: 4 cost time: 51.65869402885437\n",
      "Fine Tuning VALI: Epoch: 4, Steps: 318 | Train Loss: 0.4539493  Vali Loss: 0.4207603 Vali Accuracy: 0.8722555  Vali weighted F1: 0.8626818  Vali macro F1 0.6276999 \n",
      "EarlyStopping counter: 3 out of 5\n",
      "Learning rate adjusting counter: 4 out of 5\n",
      "Fine Tuning Epoch: 5 cost time: 51.550427198410034\n",
      "Fine Tuning VALI: Epoch: 5, Steps: 318 | Train Loss: 0.4524094  Vali Loss: 0.4222346 Vali Accuracy: 0.8746951  Vali weighted F1: 0.8657197  Vali macro F1 0.6377387 \n",
      "EarlyStopping counter: 4 out of 5\n",
      "Learning rate adjusting counter: 5 out of 5\n",
      "Updating learning rate to 0.0001\n",
      "Fine Tuning Epoch: 6 cost time: 51.62023591995239\n",
      "Fine Tuning VALI: Epoch: 6, Steps: 318 | Train Loss: 0.4501478  Vali Loss: 0.4155033 Vali Accuracy: 0.8760257  Vali weighted F1: 0.8667545  Vali macro F1 0.6368633 \n",
      "new best score!!!!\n",
      "Validation loss decreased (0.419758 --> 0.415503).  Saving model ...\n",
      "new best score!!!!\n",
      "Fine Tuning Epoch: 7 cost time: 51.689024209976196\n",
      "Fine Tuning VALI: Epoch: 7, Steps: 318 | Train Loss: 0.4509564  Vali Loss: 0.4131186 Vali Accuracy: 0.8726990  Vali weighted F1: 0.8633469  Vali macro F1 0.6237044 \n",
      "new best score!!!!\n",
      "Validation loss decreased (0.415503 --> 0.413119).  Saving model ...\n",
      "new best score!!!!\n",
      "Fine Tuning Epoch: 8 cost time: 51.50091290473938\n",
      "Fine Tuning VALI: Epoch: 8, Steps: 318 | Train Loss: 0.4500332  Vali Loss: 0.4109459 Vali Accuracy: 0.8771346  Vali weighted F1: 0.8681742  Vali macro F1 0.6417750 \n",
      "new best score!!!!\n",
      "Validation loss decreased (0.413119 --> 0.410946).  Saving model ...\n",
      "new best score!!!!\n",
      "Fine Tuning Epoch: 9 cost time: 51.71024513244629\n",
      "Fine Tuning VALI: Epoch: 9, Steps: 318 | Train Loss: 0.4455702  Vali Loss: 0.4134763 Vali Accuracy: 0.8751386  Vali weighted F1: 0.8664958  Vali macro F1 0.6312763 \n",
      "EarlyStopping counter: 1 out of 5\n",
      "Learning rate adjusting counter: 1 out of 5\n",
      "Fine Tuning Epoch: 10 cost time: 51.58647418022156\n",
      "Fine Tuning VALI: Epoch: 10, Steps: 318 | Train Loss: 0.4464568  Vali Loss: 0.4067282 Vali Accuracy: 0.8731426  Vali weighted F1: 0.8637381  Vali macro F1 0.6213940 \n",
      "new best score!!!!\n",
      "Validation loss decreased (0.410946 --> 0.406728).  Saving model ...\n",
      "new best score!!!!\n",
      "Fine Tuning Epoch: 11 cost time: 51.60733485221863\n",
      "Fine Tuning VALI: Epoch: 11, Steps: 318 | Train Loss: 0.4427247  Vali Loss: 0.4085272 Vali Accuracy: 0.8742515  Vali weighted F1: 0.8653754  Vali macro F1 0.6310023 \n",
      "EarlyStopping counter: 1 out of 5\n",
      "Learning rate adjusting counter: 1 out of 5\n",
      "Fine Tuning Epoch: 12 cost time: 51.74749255180359\n",
      "Fine Tuning VALI: Epoch: 12, Steps: 318 | Train Loss: 0.4419078  Vali Loss: 0.4067845 Vali Accuracy: 0.8762475  Vali weighted F1: 0.8679012  Vali macro F1 0.6358916 \n",
      "EarlyStopping counter: 2 out of 5\n",
      "Learning rate adjusting counter: 2 out of 5\n",
      "Fine Tuning Epoch: 13 cost time: 51.682950258255005\n",
      "Fine Tuning VALI: Epoch: 13, Steps: 318 | Train Loss: 0.4442621  Vali Loss: 0.4061097 Vali Accuracy: 0.8753604  Vali weighted F1: 0.8671273  Vali macro F1 0.6299072 \n",
      "new best score!!!!\n",
      "Validation loss decreased (0.406728 --> 0.406110).  Saving model ...\n",
      "new best score!!!!\n",
      "Fine Tuning Epoch: 14 cost time: 51.682153940200806\n",
      "Fine Tuning VALI: Epoch: 14, Steps: 318 | Train Loss: 0.4387939  Vali Loss: 0.3994616 Vali Accuracy: 0.8753604  Vali weighted F1: 0.8670383  Vali macro F1 0.6388410 \n",
      "new best score!!!!\n",
      "Validation loss decreased (0.406110 --> 0.399462).  Saving model ...\n",
      "new best score!!!!\n",
      "Fine Tuning Epoch: 15 cost time: 51.50671124458313\n",
      "Fine Tuning VALI: Epoch: 15, Steps: 318 | Train Loss: 0.4381259  Vali Loss: 0.4027044 Vali Accuracy: 0.8715902  Vali weighted F1: 0.8624507  Vali macro F1 0.6204504 \n",
      "EarlyStopping counter: 1 out of 5\n",
      "Learning rate adjusting counter: 1 out of 5\n",
      "Fine Tuning Epoch: 16 cost time: 51.627944231033325\n",
      "Fine Tuning VALI: Epoch: 16, Steps: 318 | Train Loss: 0.4426192  Vali Loss: 0.4037991 Vali Accuracy: 0.8735862  Vali weighted F1: 0.8650490  Vali macro F1 0.6305954 \n",
      "EarlyStopping counter: 2 out of 5\n",
      "Learning rate adjusting counter: 2 out of 5\n",
      "Fine Tuning Epoch: 17 cost time: 51.810205698013306\n",
      "Fine Tuning VALI: Epoch: 17, Steps: 318 | Train Loss: 0.4384013  Vali Loss: 0.4055331 Vali Accuracy: 0.8738079  Vali weighted F1: 0.8646766  Vali macro F1 0.6261162 \n",
      "EarlyStopping counter: 3 out of 5\n",
      "Learning rate adjusting counter: 3 out of 5\n",
      "Fine Tuning Epoch: 18 cost time: 51.587990522384644\n",
      "Fine Tuning VALI: Epoch: 18, Steps: 318 | Train Loss: 0.4344904  Vali Loss: 0.4070978 Vali Accuracy: 0.8742515  Vali weighted F1: 0.8652387  Vali macro F1 0.6302541 \n",
      "EarlyStopping counter: 4 out of 5\n",
      "Learning rate adjusting counter: 4 out of 5\n",
      "Fine Tuning Epoch: 19 cost time: 51.63111662864685\n",
      "Fine Tuning VALI: Epoch: 19, Steps: 318 | Train Loss: 0.4347175  Vali Loss: 0.4083934 Vali Accuracy: 0.8735862  Vali weighted F1: 0.8646611  Vali macro F1 0.6242696 \n",
      "EarlyStopping counter: 5 out of 5\n",
      "Early stopping\n",
      "Loading the best finetuned validation model!\n",
      "Fine Tuning Final Test Performance : Test Accuracy: 0.7330715  Test weighted F1: 0.6203531  Test macro F1 0.0480510 \n"
     ]
    }
   ],
   "source": [
    "exp.train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6280dba8",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "db8bc4bd",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "SDIL",
   "language": "python",
   "name": "sdil"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.13"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": true
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
