{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "894e2c21",
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "import sys\n",
    "sys.path.append(\"../../\")\n",
    "\n",
    "from experiment import Exp\n",
    "\n",
    "from dataloaders import data_set,data_dict\n",
    "import torch\n",
    "import yaml\n",
    "import os"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bcc56bc7",
   "metadata": {},
   "source": [
    "# 参数设置"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dcc5bcbc",
   "metadata": {},
   "source": [
    "# 训练参数 \n",
    "除了路径 其他不要变"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "86004ce0",
   "metadata": {},
   "outputs": [],
   "source": [
    "class dotdict(dict):\n",
    "    \"\"\"dot.notation access to dictionary attributes\"\"\"\n",
    "    __getattr__ = dict.get\n",
    "    __setattr__ = dict.__setitem__\n",
    "    __delattr__ = dict.__delitem__\n",
    "\n",
    "args = dotdict()   \n",
    "# TODO change the path as relative path\n",
    "args.to_save_path     = \"/pfs/data5/home/kit/tm/px3192/ISWC2022LearnableFilter/Run_logs\"              \n",
    "args.freq_save_path   = \"/pfs/data5/home/kit/tm/px3192/ISWC2022LearnableFilter/Freq_data\"\n",
    "args.window_save_path = \"/pfs/data5/home/kit/tm/px3192/ISWC2022LearnableFilter/Sliding_window\"\n",
    "args.root_path        = \"/pfs/data5/home/kit/tm/px3192/datasets\"\n",
    "\n",
    "\n",
    "args.drop_transition  = False\n",
    "args.datanorm_type    = \"standardization\" # None ,\"standardization\", \"minmax\"\n",
    "\n",
    "\n",
    "args.batch_size       = 128                                                     \n",
    "args.shuffle          = True\n",
    "args.drop_last        = False\n",
    "args.train_vali_quote = 0.90                                           \n",
    "\n",
    "\n",
    "# training setting \n",
    "args.train_epochs            = 150\n",
    "\n",
    "args.learning_rate           = 0.001  \n",
    "args.learning_rate_patience  = 5\n",
    "args.learning_rate_factor    = 0.1\n",
    "\n",
    "\n",
    "args.early_stop_patience     = 15\n",
    "\n",
    "args.use_gpu                 = True if torch.cuda.is_available() else False\n",
    "args.gpu                     = 1\n",
    "args.use_multi_gpu           = False\n",
    "\n",
    "args.optimizer               = \"Adam\"\n",
    "args.criterion               = \"CrossEntropy\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c282cbcb",
   "metadata": {},
   "source": [
    "## 数据参数\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "c6cd147b",
   "metadata": {},
   "outputs": [],
   "source": [
    "args.seed                             = 1\n",
    "\n",
    "\n",
    "args.data_name                        =  \"oppo\"\n",
    "\n",
    "args.wavelet_filtering                = True\n",
    "args.wavelet_filtering_regularization = True\n",
    "args.wavelet_filtering_finetuning     = True\n",
    "args.wavelet_filtering_finetuning_percent = 0.3\n",
    "\n",
    "args.regulatization_tradeoff          = 0.0001\n",
    "args.number_wavelet_filtering         = 10\n",
    "\n",
    "\n",
    "args.difference       = False \n",
    "args.filtering        =  False\n",
    "args.magnitude        =  False\n",
    "args.weighted_sampler = False\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "args.pos_select       = None\n",
    "args.sensor_select    = None\n",
    "\n",
    "\n",
    "args.representation_type = \"time\"\n",
    "args.exp_mode            = \"LOCV\"\n",
    "\n",
    "config_file = open('../../configs/data.yaml', mode='r')\n",
    "data_config = yaml.load(config_file, Loader=yaml.FullLoader)\n",
    "config = data_config[args.data_name]\n",
    "\n",
    "args.root_path       = os.path.join(args.root_path,config[\"filename\"])\n",
    "args.sampling_freq   = config[\"sampling_freq\"]\n",
    "args.num_classes     =  config[\"num_classes\"]\n",
    "window_seconds       = config[\"window_seconds\"]\n",
    "args.windowsize      =   int(window_seconds * args.sampling_freq) \n",
    "args.input_length    =  args.windowsize\n",
    "# input information\n",
    "args.c_in            = config[\"num_channels\"]\n",
    "\n",
    "if args.wavelet_filtering :\n",
    "    \n",
    "    if args.windowsize%2==1:\n",
    "        N_ds = int(torch.log2(torch.tensor(args.windowsize-1)).floor()) - 2\n",
    "    else:\n",
    "        N_ds = int(torch.log2(torch.tensor(args.windowsize)).floor()) - 2\n",
    "\n",
    "    args.f_in            =  args.number_wavelet_filtering*N_ds+1\n",
    "else:\n",
    "    args.f_in            =  1\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4d435a4c",
   "metadata": {},
   "source": [
    "## 模型参数"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "de2f4d16",
   "metadata": {},
   "outputs": [],
   "source": [
    "args.filter_scaling_factor = 0.25\n",
    "args.model_type              = \"deepconvlstm\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cada66dd",
   "metadata": {},
   "source": [
    "# 实验"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "2e3f2fad",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Use GPU: cuda:1\n",
      "Wavelet Filtering Regularization\n",
      "Build the DeepConvLSTM model!\n",
      "Done!\n",
      "Parameter : 5383527\n",
      "Set the seed as :  1\n"
     ]
    }
   ],
   "source": [
    "exp = Exp(args)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "09a011fc",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " ----------------------- load all the data -------------------\n",
      "-----------------------Sliding file are generated -----------------------\n",
      "-----------------------Sliding file are generated -----------------------\n",
      "================ LOCV Mode ====================\n",
      "================ 4 CV ======================\n",
      "================ the 0 th CV Experiment ================ \n",
      "Leave one Out Experiment : The 1 Part as the test\n",
      "[-] Target sampling weights:  [3.63609919e-05 1.66666667e-03 1.60513644e-03 1.76991150e-03\n",
      " 1.71232877e-03 1.18343195e-03 1.36054422e-03 1.83486239e-03\n",
      " 2.02020202e-03 2.66666667e-03 3.18471338e-03 3.11526480e-03\n",
      " 3.48432056e-03 2.46913580e-03 2.53164557e-03 1.26103405e-03\n",
      " 4.58295142e-04 2.02429150e-03]\n",
      "================Skip the 0 CV Experiment================\n",
      "================ the 1 th CV Experiment ================ \n",
      "Leave one Out Experiment : The 2 Part as the test\n",
      "[-] Target sampling weights:  [3.57896997e-05 1.50375940e-03 1.49253731e-03 1.61030596e-03\n",
      " 1.63666121e-03 1.30039012e-03 1.43678161e-03 2.20750552e-03\n",
      " 2.26244344e-03 2.90697674e-03 3.00300300e-03 2.77777778e-03\n",
      " 3.03030303e-03 2.25733634e-03 2.38663484e-03 1.60256410e-03\n",
      " 4.11353353e-04 2.10084034e-03]\n",
      "================Skip the 1 CV Experiment================\n",
      "================ the 2 th CV Experiment ================ \n",
      "Leave one Out Experiment : The 3 Part as the test\n",
      "[-] Target sampling weights:  [3.52783462e-05 1.55520995e-03 1.60256410e-03 1.63666121e-03\n",
      " 1.61290323e-03 1.31406045e-03 1.40449438e-03 1.84501845e-03\n",
      " 2.06185567e-03 2.64550265e-03 3.23624595e-03 3.00300300e-03\n",
      " 3.40136054e-03 2.24719101e-03 2.39808153e-03 1.30378096e-03\n",
      " 4.22654269e-04 2.10970464e-03]\n",
      "================ Build the model ================ \n",
      "Wavelet Filtering Regularization\n",
      "Build the DeepConvLSTM model!\n",
      "Train data number :  39127\n",
      "The number of classes is :  18\n",
      "The input_length  is :  30\n",
      "The channel_in is :  77\n",
      "Validation data number :  4348\n",
      "Test data number :  72231\n",
      "Epoch: 1 cost time: 54.07452630996704\n",
      "VALI: Epoch: 1, Steps: 306 | Train Loss: 0.9173660  Vali Loss: 0.6728160 Vali Accuracy: 0.7985281  Vali weighted F1: 0.7517211  Vali macro F1 0.3256005 \n",
      "Validation loss decreased (inf --> 0.672816).  Saving model ...\n",
      "Epoch: 2 cost time: 50.06938576698303\n",
      "VALI: Epoch: 2, Steps: 306 | Train Loss: 0.6444226  Vali Loss: 0.6192784 Vali Accuracy: 0.8015179  Vali weighted F1: 0.7560493  Vali macro F1 0.3527581 \n",
      "new best score!!!!\n",
      "Validation loss decreased (0.672816 --> 0.619278).  Saving model ...\n",
      "new best score!!!!\n",
      "Epoch: 3 cost time: 50.16761350631714\n",
      "VALI: Epoch: 3, Steps: 306 | Train Loss: 0.6172207  Vali Loss: 0.6079749 Vali Accuracy: 0.8166973  Vali weighted F1: 0.7870359  Vali macro F1 0.4283575 \n",
      "new best score!!!!\n",
      "Validation loss decreased (0.619278 --> 0.607975).  Saving model ...\n",
      "new best score!!!!\n",
      "Epoch: 4 cost time: 50.19760251045227\n",
      "VALI: Epoch: 4, Steps: 306 | Train Loss: 0.6167598  Vali Loss: 0.6138072 Vali Accuracy: 0.8051978  Vali weighted F1: 0.7673782  Vali macro F1 0.3697091 \n",
      "EarlyStopping counter: 1 out of 15\n",
      "Learning rate adjusting counter: 1 out of 5\n",
      "Epoch: 5 cost time: 50.11101460456848\n",
      "VALI: Epoch: 5, Steps: 306 | Train Loss: 0.6063601  Vali Loss: 0.5865593 Vali Accuracy: 0.8194572  Vali weighted F1: 0.8034385  Vali macro F1 0.4714809 \n",
      "new best score!!!!\n",
      "Validation loss decreased (0.607975 --> 0.586559).  Saving model ...\n",
      "new best score!!!!\n",
      "Epoch: 6 cost time: 50.175159215927124\n",
      "VALI: Epoch: 6, Steps: 306 | Train Loss: 0.6091673  Vali Loss: 0.6047890 Vali Accuracy: 0.8139374  Vali weighted F1: 0.7918043  Vali macro F1 0.4487081 \n",
      "EarlyStopping counter: 1 out of 15\n",
      "Learning rate adjusting counter: 1 out of 5\n",
      "Epoch: 7 cost time: 50.26760721206665\n",
      "VALI: Epoch: 7, Steps: 306 | Train Loss: 0.6127415  Vali Loss: 0.5928248 Vali Accuracy: 0.8134775  Vali weighted F1: 0.7847732  Vali macro F1 0.4281972 \n",
      "EarlyStopping counter: 2 out of 15\n",
      "Learning rate adjusting counter: 2 out of 5\n",
      "Epoch: 8 cost time: 50.22990679740906\n",
      "VALI: Epoch: 8, Steps: 306 | Train Loss: 0.5939913  Vali Loss: 0.5834296 Vali Accuracy: 0.8203772  Vali weighted F1: 0.7996203  Vali macro F1 0.4690137 \n",
      "new best score!!!!\n",
      "Validation loss decreased (0.586559 --> 0.583430).  Saving model ...\n",
      "new best score!!!!\n",
      "Epoch: 9 cost time: 50.14610409736633\n",
      "VALI: Epoch: 9, Steps: 306 | Train Loss: 0.6139640  Vali Loss: 0.6599412 Vali Accuracy: 0.7971481  Vali weighted F1: 0.7551206  Vali macro F1 0.3532040 \n",
      "EarlyStopping counter: 1 out of 15\n",
      "Learning rate adjusting counter: 1 out of 5\n",
      "Epoch: 10 cost time: 50.162726640701294\n",
      "VALI: Epoch: 10, Steps: 306 | Train Loss: 0.6099838  Vali Loss: 0.5990684 Vali Accuracy: 0.8123275  Vali weighted F1: 0.7872627  Vali macro F1 0.4258068 \n",
      "EarlyStopping counter: 2 out of 15\n",
      "Learning rate adjusting counter: 2 out of 5\n",
      "Epoch: 11 cost time: 50.15401339530945\n",
      "VALI: Epoch: 11, Steps: 306 | Train Loss: 0.6132613  Vali Loss: 0.6005402 Vali Accuracy: 0.8148574  Vali weighted F1: 0.7927119  Vali macro F1 0.4504438 \n",
      "EarlyStopping counter: 3 out of 15\n",
      "Learning rate adjusting counter: 3 out of 5\n",
      "Epoch: 12 cost time: 50.07843852043152\n",
      "VALI: Epoch: 12, Steps: 306 | Train Loss: 0.6221265  Vali Loss: 0.6323024 Vali Accuracy: 0.8028979  Vali weighted F1: 0.7713907  Vali macro F1 0.4004739 \n",
      "EarlyStopping counter: 4 out of 15\n",
      "Learning rate adjusting counter: 4 out of 5\n",
      "Epoch: 13 cost time: 50.19201111793518\n",
      "VALI: Epoch: 13, Steps: 306 | Train Loss: 0.6443786  Vali Loss: 0.7147035 Vali Accuracy: 0.7904784  Vali weighted F1: 0.7618065  Vali macro F1 0.3722170 \n",
      "EarlyStopping counter: 5 out of 15\n",
      "Learning rate adjusting counter: 5 out of 5\n",
      "Updating learning rate to 0.0001\n",
      "Epoch: 14 cost time: 50.099615812301636\n",
      "VALI: Epoch: 14, Steps: 306 | Train Loss: 0.7210136  Vali Loss: 0.6912741 Vali Accuracy: 0.7996780  Vali weighted F1: 0.7756501  Vali macro F1 0.4157173 \n",
      "EarlyStopping counter: 6 out of 15\n",
      "Learning rate adjusting counter: 1 out of 5\n",
      "Epoch: 15 cost time: 50.09111928939819\n",
      "VALI: Epoch: 15, Steps: 306 | Train Loss: 0.7051436  Vali Loss: 0.6708152 Vali Accuracy: 0.8012879  Vali weighted F1: 0.7794070  Vali macro F1 0.4329873 \n",
      "EarlyStopping counter: 7 out of 15\n",
      "Learning rate adjusting counter: 2 out of 5\n",
      "Epoch: 16 cost time: 50.09172034263611\n",
      "VALI: Epoch: 16, Steps: 306 | Train Loss: 0.6871188  Vali Loss: 0.6554119 Vali Accuracy: 0.8047378  Vali weighted F1: 0.7834834  Vali macro F1 0.4440496 \n",
      "EarlyStopping counter: 8 out of 15\n",
      "Learning rate adjusting counter: 3 out of 5\n",
      "Epoch: 17 cost time: 50.08593249320984\n",
      "VALI: Epoch: 17, Steps: 306 | Train Loss: 0.6704910  Vali Loss: 0.6487498 Vali Accuracy: 0.8072677  Vali weighted F1: 0.7873226  Vali macro F1 0.4495183 \n",
      "EarlyStopping counter: 9 out of 15\n",
      "Learning rate adjusting counter: 4 out of 5\n",
      "Epoch: 18 cost time: 50.15542984008789\n",
      "VALI: Epoch: 18, Steps: 306 | Train Loss: 0.6620829  Vali Loss: 0.6356834 Vali Accuracy: 0.8063477  Vali weighted F1: 0.7870017  Vali macro F1 0.4482904 \n",
      "EarlyStopping counter: 10 out of 15\n",
      "Learning rate adjusting counter: 5 out of 5\n",
      "Updating learning rate to 1e-05\n",
      "Epoch: 19 cost time: 50.12511110305786\n",
      "VALI: Epoch: 19, Steps: 306 | Train Loss: 0.6497919  Vali Loss: 0.6331291 Vali Accuracy: 0.8061178  Vali weighted F1: 0.7864351  Vali macro F1 0.4455460 \n",
      "EarlyStopping counter: 11 out of 15\n",
      "Learning rate adjusting counter: 1 out of 5\n",
      "Epoch: 20 cost time: 50.123138666152954\n",
      "VALI: Epoch: 20, Steps: 306 | Train Loss: 0.6526150  Vali Loss: 0.6323170 Vali Accuracy: 0.8077277  Vali weighted F1: 0.7879129  Vali macro F1 0.4481517 \n",
      "EarlyStopping counter: 12 out of 15\n",
      "Learning rate adjusting counter: 2 out of 5\n",
      "Epoch: 21 cost time: 50.16117191314697\n",
      "VALI: Epoch: 21, Steps: 306 | Train Loss: 0.6495330  Vali Loss: 0.6312151 Vali Accuracy: 0.8072677  Vali weighted F1: 0.7877833  Vali macro F1 0.4478305 \n",
      "EarlyStopping counter: 13 out of 15\n",
      "Learning rate adjusting counter: 3 out of 5\n",
      "Epoch: 22 cost time: 50.187045097351074\n",
      "VALI: Epoch: 22, Steps: 306 | Train Loss: 0.6433039  Vali Loss: 0.6293529 Vali Accuracy: 0.8088776  Vali weighted F1: 0.7893857  Vali macro F1 0.4516302 \n",
      "EarlyStopping counter: 14 out of 15\n",
      "Learning rate adjusting counter: 4 out of 5\n",
      "Epoch: 23 cost time: 50.14850378036499\n",
      "VALI: Epoch: 23, Steps: 306 | Train Loss: 0.6481604  Vali Loss: 0.6291835 Vali Accuracy: 0.8068077  Vali weighted F1: 0.7874229  Vali macro F1 0.4450210 \n",
      "EarlyStopping counter: 15 out of 15\n",
      "Early stopping\n",
      "Loading the best validation model!\n",
      "Final Test Performance : Test Accuracy: 0.7065941  Test weighted F1: 0.6877652  Test macro F1 0.2765096 \n",
      "Wavelet Filtering Regularization\n",
      "Build the DeepConvLSTM model!\n",
      "------------Fine Tuning  :  15   will be pruned   -----------------------------------------\n",
      "old model Parameter : 5383527\n",
      "pruned model Parameter : 5378712\n",
      "----------------------------------------------------------------------------------------\n",
      "Fine Tuning Epoch: 1 cost time: 50.706586599349976\n",
      "Fine Tuning VALI: Epoch: 1, Steps: 306 | Train Loss: 0.5743648  Vali Loss: 0.5669829 Vali Accuracy: 0.8291168  Vali weighted F1: 0.8125915  Vali macro F1 0.5150030 \n",
      "Validation loss decreased (inf --> 0.566983).  Saving model ...\n",
      "Fine Tuning Epoch: 2 cost time: 50.61018657684326\n",
      "Fine Tuning VALI: Epoch: 2, Steps: 306 | Train Loss: 0.5676118  Vali Loss: 0.5587280 Vali Accuracy: 0.8307268  Vali weighted F1: 0.8171782  Vali macro F1 0.5325408 \n",
      "new best score!!!!\n",
      "Validation loss decreased (0.566983 --> 0.558728).  Saving model ...\n",
      "new best score!!!!\n",
      "Fine Tuning Epoch: 3 cost time: 50.72703790664673\n",
      "Fine Tuning VALI: Epoch: 3, Steps: 306 | Train Loss: 0.5579851  Vali Loss: 0.5518942 Vali Accuracy: 0.8325667  Vali weighted F1: 0.8176657  Vali macro F1 0.5305621 \n",
      "new best score!!!!\n",
      "Validation loss decreased (0.558728 --> 0.551894).  Saving model ...\n",
      "new best score!!!!\n",
      "Fine Tuning Epoch: 4 cost time: 50.7007954120636\n",
      "Fine Tuning VALI: Epoch: 4, Steps: 306 | Train Loss: 0.5521508  Vali Loss: 0.5463911 Vali Accuracy: 0.8337167  Vali weighted F1: 0.8194767  Vali macro F1 0.5299835 \n",
      "new best score!!!!\n",
      "Validation loss decreased (0.551894 --> 0.546391).  Saving model ...\n",
      "new best score!!!!\n",
      "Fine Tuning Epoch: 5 cost time: 50.61802840232849\n",
      "Fine Tuning VALI: Epoch: 5, Steps: 306 | Train Loss: 0.5463435  Vali Loss: 0.5407588 Vali Accuracy: 0.8371665  Vali weighted F1: 0.8242483  Vali macro F1 0.5428986 \n",
      "new best score!!!!\n",
      "Validation loss decreased (0.546391 --> 0.540759).  Saving model ...\n",
      "new best score!!!!\n",
      "Fine Tuning Epoch: 6 cost time: 50.72279119491577\n",
      "Fine Tuning VALI: Epoch: 6, Steps: 306 | Train Loss: 0.5414471  Vali Loss: 0.5325669 Vali Accuracy: 0.8399264  Vali weighted F1: 0.8268193  Vali macro F1 0.5473696 \n",
      "new best score!!!!\n",
      "Validation loss decreased (0.540759 --> 0.532567).  Saving model ...\n",
      "new best score!!!!\n",
      "Fine Tuning Epoch: 7 cost time: 50.67713642120361\n",
      "Fine Tuning VALI: Epoch: 7, Steps: 306 | Train Loss: 0.5370996  Vali Loss: 0.5323961 Vali Accuracy: 0.8373965  Vali weighted F1: 0.8253632  Vali macro F1 0.5352733 \n",
      "new best score!!!!\n",
      "Validation loss decreased (0.532567 --> 0.532396).  Saving model ...\n",
      "new best score!!!!\n",
      "Fine Tuning Epoch: 8 cost time: 50.66395568847656\n",
      "Fine Tuning VALI: Epoch: 8, Steps: 306 | Train Loss: 0.5345505  Vali Loss: 0.5247478 Vali Accuracy: 0.8399264  Vali weighted F1: 0.8290932  Vali macro F1 0.5545907 \n",
      "new best score!!!!\n",
      "Validation loss decreased (0.532396 --> 0.524748).  Saving model ...\n",
      "new best score!!!!\n",
      "Fine Tuning Epoch: 9 cost time: 50.6803503036499\n",
      "Fine Tuning VALI: Epoch: 9, Steps: 306 | Train Loss: 0.5275031  Vali Loss: 0.5226985 Vali Accuracy: 0.8413063  Vali weighted F1: 0.8295624  Vali macro F1 0.5524452 \n",
      "new best score!!!!\n",
      "Validation loss decreased (0.524748 --> 0.522698).  Saving model ...\n",
      "new best score!!!!\n",
      "Fine Tuning Epoch: 10 cost time: 50.63539910316467\n",
      "Fine Tuning VALI: Epoch: 10, Steps: 306 | Train Loss: 0.5228007  Vali Loss: 0.5191611 Vali Accuracy: 0.8431463  Vali weighted F1: 0.8320578  Vali macro F1 0.5598039 \n",
      "new best score!!!!\n",
      "Validation loss decreased (0.522698 --> 0.519161).  Saving model ...\n",
      "new best score!!!!\n",
      "Fine Tuning Epoch: 11 cost time: 50.622899293899536\n",
      "Fine Tuning VALI: Epoch: 11, Steps: 306 | Train Loss: 0.5222817  Vali Loss: 0.5200370 Vali Accuracy: 0.8401564  Vali weighted F1: 0.8301401  Vali macro F1 0.5532150 \n",
      "EarlyStopping counter: 1 out of 5\n",
      "Learning rate adjusting counter: 1 out of 5\n",
      "Fine Tuning Epoch: 12 cost time: 50.671159505844116\n",
      "Fine Tuning VALI: Epoch: 12, Steps: 306 | Train Loss: 0.5209717  Vali Loss: 0.5185192 Vali Accuracy: 0.8417663  Vali weighted F1: 0.8309385  Vali macro F1 0.5524704 \n",
      "new best score!!!!\n",
      "Validation loss decreased (0.519161 --> 0.518519).  Saving model ...\n",
      "new best score!!!!\n",
      "Fine Tuning Epoch: 13 cost time: 50.772719621658325\n",
      "Fine Tuning VALI: Epoch: 13, Steps: 306 | Train Loss: 0.5184592  Vali Loss: 0.5137564 Vali Accuracy: 0.8415363  Vali weighted F1: 0.8312775  Vali macro F1 0.5545683 \n",
      "new best score!!!!\n",
      "Validation loss decreased (0.518519 --> 0.513756).  Saving model ...\n",
      "new best score!!!!\n",
      "Fine Tuning Epoch: 14 cost time: 50.662171602249146\n",
      "Fine Tuning VALI: Epoch: 14, Steps: 306 | Train Loss: 0.5116794  Vali Loss: 0.5091599 Vali Accuracy: 0.8436063  Vali weighted F1: 0.8333080  Vali macro F1 0.5601145 \n",
      "new best score!!!!\n",
      "Validation loss decreased (0.513756 --> 0.509160).  Saving model ...\n",
      "new best score!!!!\n",
      "Fine Tuning Epoch: 15 cost time: 50.65825128555298\n",
      "Fine Tuning VALI: Epoch: 15, Steps: 306 | Train Loss: 0.5084324  Vali Loss: 0.5064866 Vali Accuracy: 0.8477461  Vali weighted F1: 0.8391137  Vali macro F1 0.5711563 \n",
      "new best score!!!!\n",
      "Validation loss decreased (0.509160 --> 0.506487).  Saving model ...\n",
      "new best score!!!!\n",
      "Fine Tuning Epoch: 16 cost time: 50.79139828681946\n",
      "Fine Tuning VALI: Epoch: 16, Steps: 306 | Train Loss: 0.5050967  Vali Loss: 0.5000215 Vali Accuracy: 0.8449862  Vali weighted F1: 0.8366891  Vali macro F1 0.5696614 \n",
      "new best score!!!!\n",
      "Validation loss decreased (0.506487 --> 0.500021).  Saving model ...\n",
      "new best score!!!!\n",
      "Fine Tuning Epoch: 17 cost time: 50.74047875404358\n",
      "Fine Tuning VALI: Epoch: 17, Steps: 306 | Train Loss: 0.5051056  Vali Loss: 0.5010552 Vali Accuracy: 0.8493560  Vali weighted F1: 0.8416439  Vali macro F1 0.5802848 \n",
      "EarlyStopping counter: 1 out of 5\n",
      "Learning rate adjusting counter: 1 out of 5\n",
      "Fine Tuning Epoch: 18 cost time: 50.7828164100647\n",
      "Fine Tuning VALI: Epoch: 18, Steps: 306 | Train Loss: 0.5018662  Vali Loss: 0.4988872 Vali Accuracy: 0.8498160  Vali weighted F1: 0.8407910  Vali macro F1 0.5822637 \n",
      "new best score!!!!\n",
      "Validation loss decreased (0.500021 --> 0.498887).  Saving model ...\n",
      "new best score!!!!\n",
      "Fine Tuning Epoch: 19 cost time: 50.84662961959839\n",
      "Fine Tuning VALI: Epoch: 19, Steps: 306 | Train Loss: 0.4983416  Vali Loss: 0.4938497 Vali Accuracy: 0.8502760  Vali weighted F1: 0.8424653  Vali macro F1 0.5855519 \n",
      "new best score!!!!\n",
      "Validation loss decreased (0.498887 --> 0.493850).  Saving model ...\n",
      "new best score!!!!\n",
      "Fine Tuning Epoch: 20 cost time: 50.83860111236572\n",
      "Fine Tuning VALI: Epoch: 20, Steps: 306 | Train Loss: 0.4969294  Vali Loss: 0.4901965 Vali Accuracy: 0.8500460  Vali weighted F1: 0.8419843  Vali macro F1 0.5816819 \n",
      "new best score!!!!\n",
      "Validation loss decreased (0.493850 --> 0.490197).  Saving model ...\n",
      "new best score!!!!\n",
      "Fine Tuning Epoch: 21 cost time: 50.78927278518677\n",
      "Fine Tuning VALI: Epoch: 21, Steps: 306 | Train Loss: 0.4944829  Vali Loss: 0.4862691 Vali Accuracy: 0.8521159  Vali weighted F1: 0.8440312  Vali macro F1 0.5873578 \n",
      "new best score!!!!\n",
      "Validation loss decreased (0.490197 --> 0.486269).  Saving model ...\n",
      "new best score!!!!\n",
      "Fine Tuning Epoch: 22 cost time: 50.75490736961365\n",
      "Fine Tuning VALI: Epoch: 22, Steps: 306 | Train Loss: 0.4913875  Vali Loss: 0.4854541 Vali Accuracy: 0.8532659  Vali weighted F1: 0.8466091  Vali macro F1 0.5858772 \n",
      "new best score!!!!\n",
      "Validation loss decreased (0.486269 --> 0.485454).  Saving model ...\n",
      "new best score!!!!\n",
      "Fine Tuning Epoch: 23 cost time: 50.84719753265381\n",
      "Fine Tuning VALI: Epoch: 23, Steps: 306 | Train Loss: 0.4908184  Vali Loss: 0.4825106 Vali Accuracy: 0.8564857  Vali weighted F1: 0.8502603  Vali macro F1 0.6029511 \n",
      "new best score!!!!\n",
      "Validation loss decreased (0.485454 --> 0.482511).  Saving model ...\n",
      "new best score!!!!\n",
      "Fine Tuning Epoch: 24 cost time: 50.670896768569946\n",
      "Fine Tuning VALI: Epoch: 24, Steps: 306 | Train Loss: 0.4863780  Vali Loss: 0.4742547 Vali Accuracy: 0.8537259  Vali weighted F1: 0.8466052  Vali macro F1 0.5911710 \n",
      "new best score!!!!\n",
      "Validation loss decreased (0.482511 --> 0.474255).  Saving model ...\n",
      "new best score!!!!\n",
      "Fine Tuning Epoch: 25 cost time: 50.70487117767334\n",
      "Fine Tuning VALI: Epoch: 25, Steps: 306 | Train Loss: 0.4857834  Vali Loss: 0.4741160 Vali Accuracy: 0.8532659  Vali weighted F1: 0.8475205  Vali macro F1 0.5942293 \n",
      "new best score!!!!\n",
      "Validation loss decreased (0.474255 --> 0.474116).  Saving model ...\n",
      "new best score!!!!\n",
      "Fine Tuning Epoch: 26 cost time: 50.77738904953003\n",
      "Fine Tuning VALI: Epoch: 26, Steps: 306 | Train Loss: 0.4849811  Vali Loss: 0.4731286 Vali Accuracy: 0.8523459  Vali weighted F1: 0.8456342  Vali macro F1 0.5932598 \n",
      "new best score!!!!\n",
      "Validation loss decreased (0.474116 --> 0.473129).  Saving model ...\n",
      "new best score!!!!\n",
      "Fine Tuning Epoch: 27 cost time: 50.710856437683105\n",
      "Fine Tuning VALI: Epoch: 27, Steps: 306 | Train Loss: 0.4833262  Vali Loss: 0.4707539 Vali Accuracy: 0.8548758  Vali weighted F1: 0.8489074  Vali macro F1 0.6026214 \n",
      "new best score!!!!\n",
      "Validation loss decreased (0.473129 --> 0.470754).  Saving model ...\n",
      "new best score!!!!\n",
      "Fine Tuning Epoch: 28 cost time: 50.71297907829285\n",
      "Fine Tuning VALI: Epoch: 28, Steps: 306 | Train Loss: 0.4840272  Vali Loss: 0.4707471 Vali Accuracy: 0.8509660  Vali weighted F1: 0.8454622  Vali macro F1 0.5978816 \n",
      "new best score!!!!\n",
      "Validation loss decreased (0.470754 --> 0.470747).  Saving model ...\n",
      "new best score!!!!\n",
      "Fine Tuning Epoch: 29 cost time: 50.77679896354675\n",
      "Fine Tuning VALI: Epoch: 29, Steps: 306 | Train Loss: 0.4806322  Vali Loss: 0.4700105 Vali Accuracy: 0.8553358  Vali weighted F1: 0.8499371  Vali macro F1 0.6172908 \n",
      "new best score!!!!\n",
      "Validation loss decreased (0.470747 --> 0.470010).  Saving model ...\n",
      "new best score!!!!\n",
      "Fine Tuning Epoch: 30 cost time: 50.670292139053345\n",
      "Fine Tuning VALI: Epoch: 30, Steps: 306 | Train Loss: 0.4811835  Vali Loss: 0.4690975 Vali Accuracy: 0.8532659  Vali weighted F1: 0.8474568  Vali macro F1 0.5896002 \n",
      "new best score!!!!\n",
      "Validation loss decreased (0.470010 --> 0.469098).  Saving model ...\n",
      "new best score!!!!\n",
      "Fine Tuning Epoch: 31 cost time: 50.55093240737915\n",
      "Fine Tuning VALI: Epoch: 31, Steps: 306 | Train Loss: 0.4770127  Vali Loss: 0.4664117 Vali Accuracy: 0.8548758  Vali weighted F1: 0.8483648  Vali macro F1 0.6031213 \n",
      "new best score!!!!\n",
      "Validation loss decreased (0.469098 --> 0.466412).  Saving model ...\n",
      "new best score!!!!\n",
      "Fine Tuning Epoch: 32 cost time: 50.63461136817932\n",
      "Fine Tuning VALI: Epoch: 32, Steps: 306 | Train Loss: 0.4761093  Vali Loss: 0.4659081 Vali Accuracy: 0.8523459  Vali weighted F1: 0.8460898  Vali macro F1 0.5984154 \n",
      "new best score!!!!\n",
      "Validation loss decreased (0.466412 --> 0.465908).  Saving model ...\n",
      "new best score!!!!\n",
      "Fine Tuning Epoch: 33 cost time: 50.55083394050598\n",
      "Fine Tuning VALI: Epoch: 33, Steps: 306 | Train Loss: 0.4741360  Vali Loss: 0.4663107 Vali Accuracy: 0.8534959  Vali weighted F1: 0.8483241  Vali macro F1 0.6005734 \n",
      "EarlyStopping counter: 1 out of 5\n",
      "Learning rate adjusting counter: 1 out of 5\n",
      "Fine Tuning Epoch: 34 cost time: 50.39251947402954\n",
      "Fine Tuning VALI: Epoch: 34, Steps: 306 | Train Loss: 0.4719960  Vali Loss: 0.4635606 Vali Accuracy: 0.8532659  Vali weighted F1: 0.8474101  Vali macro F1 0.5951659 \n",
      "new best score!!!!\n",
      "Validation loss decreased (0.465908 --> 0.463561).  Saving model ...\n",
      "new best score!!!!\n",
      "Fine Tuning Epoch: 35 cost time: 50.4153733253479\n",
      "Fine Tuning VALI: Epoch: 35, Steps: 306 | Train Loss: 0.4703526  Vali Loss: 0.4624731 Vali Accuracy: 0.8539558  Vali weighted F1: 0.8493175  Vali macro F1 0.6071837 \n",
      "new best score!!!!\n",
      "Validation loss decreased (0.463561 --> 0.462473).  Saving model ...\n",
      "new best score!!!!\n",
      "Fine Tuning Epoch: 36 cost time: 50.49924325942993\n",
      "Fine Tuning VALI: Epoch: 36, Steps: 306 | Train Loss: 0.4698521  Vali Loss: 0.4630997 Vali Accuracy: 0.8548758  Vali weighted F1: 0.8492652  Vali macro F1 0.5977149 \n",
      "EarlyStopping counter: 1 out of 5\n",
      "Learning rate adjusting counter: 1 out of 5\n",
      "Fine Tuning Epoch: 37 cost time: 50.42752766609192\n",
      "Fine Tuning VALI: Epoch: 37, Steps: 306 | Train Loss: 0.4702803  Vali Loss: 0.4630620 Vali Accuracy: 0.8511960  Vali weighted F1: 0.8465384  Vali macro F1 0.5929145 \n",
      "EarlyStopping counter: 2 out of 5\n",
      "Learning rate adjusting counter: 2 out of 5\n",
      "Fine Tuning Epoch: 38 cost time: 50.45091652870178\n",
      "Fine Tuning VALI: Epoch: 38, Steps: 306 | Train Loss: 0.4666613  Vali Loss: 0.4567217 Vali Accuracy: 0.8553358  Vali weighted F1: 0.8513671  Vali macro F1 0.6057757 \n",
      "new best score!!!!\n",
      "Validation loss decreased (0.462473 --> 0.456722).  Saving model ...\n",
      "new best score!!!!\n",
      "Fine Tuning Epoch: 39 cost time: 50.4261736869812\n",
      "Fine Tuning VALI: Epoch: 39, Steps: 306 | Train Loss: 0.4654124  Vali Loss: 0.4586929 Vali Accuracy: 0.8553358  Vali weighted F1: 0.8511207  Vali macro F1 0.6038767 \n",
      "EarlyStopping counter: 1 out of 5\n",
      "Learning rate adjusting counter: 1 out of 5\n"
     ]
    }
   ],
   "source": [
    "exp.train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6280dba8",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "db8bc4bd",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "SDIL",
   "language": "python",
   "name": "sdil"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.13"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": true
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
