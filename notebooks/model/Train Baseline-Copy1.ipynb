{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "894e2c21",
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "import sys\n",
    "sys.path.append(\"../../\")\n",
    "\n",
    "from experiment import Exp\n",
    "\n",
    "from dataloaders import data_set,data_dict\n",
    "import torch\n",
    "import yaml\n",
    "import os"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bcc56bc7",
   "metadata": {},
   "source": [
    "# 参数设置"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dcc5bcbc",
   "metadata": {
    "tags": []
   },
   "source": [
    "# 训练参数 \n",
    "除了路径 其他不要变"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "86004ce0",
   "metadata": {},
   "outputs": [],
   "source": [
    "class dotdict(dict):\n",
    "    \"\"\"dot.notation access to dictionary attributes\"\"\"\n",
    "    __getattr__ = dict.get\n",
    "    __setattr__ = dict.__setitem__\n",
    "    __delattr__ = dict.__delitem__\n",
    "\n",
    "args = dotdict()   \n",
    "# TODO change the path as relative path\n",
    "args.to_save_path     = \"../../../ISWC2022LearnableFilter/Run_logs\"              \n",
    "args.freq_save_path   = \"../../../ISWC2022LearnableFilter/Freq_data\"\n",
    "args.window_save_path = \"../../../ISWC2022LearnableFilter/Sliding_window\"\n",
    "args.root_path        = \"../../../datasets\"\n",
    "\n",
    "\n",
    "args.drop_transition  = False\n",
    "args.datanorm_type    = \"standardization\" # None ,\"standardization\", \"minmax\"\n",
    "\n",
    "\n",
    "args.batch_size       = 256                                                    \n",
    "args.shuffle          = True\n",
    "args.drop_last        = False\n",
    "args.train_vali_quote = 0.90                                           \n",
    "\n",
    "\n",
    "# training setting \n",
    "args.train_epochs            = 150\n",
    "\n",
    "args.learning_rate           = 0.001  \n",
    "args.learning_rate_patience  = 5\n",
    "args.learning_rate_factor    = 0.1\n",
    "\n",
    "\n",
    "args.early_stop_patience     = 15\n",
    "\n",
    "args.use_gpu                 = True if torch.cuda.is_available() else False\n",
    "args.gpu                     = 1\n",
    "args.use_multi_gpu           = False\n",
    "\n",
    "args.optimizer               = \"Adam\"\n",
    "args.criterion               = \"CrossEntropy\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c282cbcb",
   "metadata": {},
   "source": [
    "## 数据参数\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "c6cd147b",
   "metadata": {},
   "outputs": [],
   "source": [
    "args.data_name                        =  \"rw\"\n",
    "\n",
    "args.wavelet_filtering                = False\n",
    "args.wavelet_filtering_regularization = False\n",
    "args.wavelet_filtering_finetuning     = False\n",
    "\n",
    "\n",
    "args.difference       = False \n",
    "args.filtering        = False\n",
    "args.magnitude        = False\n",
    "args.weighted_sampler = False\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "args.pos_select       = None\n",
    "args.sensor_select    = None\n",
    "\n",
    "\n",
    "args.representation_type = \"time\"\n",
    "args.exp_mode            = \"LOCV\"\n",
    "if args.data_name      ==  \"skodar\":\n",
    "    args.exp_mode            = \"SOCV\"\n",
    "\n",
    "config_file = open('../../configs/data.yaml', mode='r')\n",
    "data_config = yaml.load(config_file, Loader=yaml.FullLoader)\n",
    "config = data_config[args.data_name]\n",
    "\n",
    "args.root_path       = os.path.join(args.root_path,config[\"filename\"])\n",
    "args.sampling_freq   = config[\"sampling_freq\"]\n",
    "args.num_classes     =  config[\"num_classes\"]\n",
    "window_seconds       = config[\"window_seconds\"]\n",
    "args.windowsize      =   int(window_seconds * args.sampling_freq) \n",
    "args.input_length    =  args.windowsize\n",
    "# input information\n",
    "args.c_in            = config[\"num_channels\"]\n",
    "\n",
    "if args.wavelet_filtering :\n",
    "    \n",
    "    if args.windowsize%2==1:\n",
    "        N_ds = int(torch.log2(torch.tensor(args.windowsize-1)).floor()) - 2\n",
    "    else:\n",
    "        N_ds = int(torch.log2(torch.tensor(args.windowsize)).floor()) - 2\n",
    "\n",
    "    args.f_in            =  args.number_wavelet_filtering*N_ds+1\n",
    "else:\n",
    "    args.f_in            =  1"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4d435a4c",
   "metadata": {},
   "source": [
    "## 模型参数"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "de2f4d16",
   "metadata": {},
   "outputs": [],
   "source": [
    "args.filter_scaling_factor = 0.5\n",
    "args.model_type            = \"deepconvlstm\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cada66dd",
   "metadata": {},
   "source": [
    "# 实验"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2e3f2fad",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Use GPU: cuda:1\n",
      "Build the DeepConvLSTM model!\n",
      "Done!\n",
      "Parameter : 205096\n",
      "Set the seed as :  1\n",
      " ----------------------- load all the data -------------------\n",
      "-----------------------Sliding file are generated -----------------------\n",
      "-----------------------Sliding file are generated -----------------------\n",
      "================ LOCV Mode ====================\n",
      "================ 15 CV ======================\n",
      "================ the 0 th CV Experiment ================ \n",
      "Leave one Out Experiment : The 1 Part as the test\n",
      "[-] Target sampling weights:  [0.00023935 0.00020614 0.00114025 0.00015751 0.00014501 0.00015934\n",
      " 0.00016038 0.00015716]\n",
      "Train data number :  42025\n",
      "The number of classes is :  8\n",
      "The input_length  is :  128\n",
      "The channel_in is :  21\n",
      "Validation data number :  4670\n",
      "Test data number :  17903\n",
      "================Skip the 0 CV Experiment================\n",
      "================ the 1 th CV Experiment ================ \n",
      "Leave one Out Experiment : The 2 Part as the test\n",
      "[-] Target sampling weights:  [0.00024073 0.00019051 0.00113122 0.00015868 0.00014059 0.0001578\n",
      " 0.00016046 0.0001562 ]\n",
      "Train data number :  42673\n",
      "The number of classes is :  8\n",
      "The input_length  is :  128\n",
      "The channel_in is :  21\n",
      "Validation data number :  4742\n",
      "Test data number :  14069\n",
      "================Skip the 1 CV Experiment================\n",
      "================ the 2 th CV Experiment ================ \n",
      "Leave one Out Experiment : The 3 Part as the test\n",
      "[-] Target sampling weights:  [0.00024301 0.00020777 0.00113636 0.00015751 0.00014678 0.00015913\n",
      " 0.00015995 0.00015785]\n",
      "Train data number :  41841\n",
      "The number of classes is :  8\n",
      "The input_length  is :  128\n",
      "The channel_in is :  21\n",
      "Validation data number :  4649\n",
      "Test data number :  18998\n",
      "================Skip the 2 CV Experiment================\n",
      "================ the 3 th CV Experiment ================ \n",
      "Leave one Out Experiment : The 4 Part as the test\n",
      "[-] Target sampling weights:  [0.00022904 0.00019885 0.00112994 0.0001581  0.00015142 0.00015954\n",
      " 0.00015972 0.00015659]\n",
      "Train data number :  42124\n",
      "The number of classes is :  8\n",
      "The input_length  is :  128\n",
      "The channel_in is :  21\n",
      "Validation data number :  4681\n",
      "Test data number :  17311\n",
      "================Skip the 3 CV Experiment================\n",
      "================ the 4 th CV Experiment ================ \n",
      "Leave one Out Experiment : The 5 Part as the test\n",
      "[-] Target sampling weights:  [0.00023923 0.00020855 0.00113379 0.00015848 0.00015242 0.00015893\n",
      " 0.00015967 0.00015868]\n",
      "Train data number :  41585\n",
      "The number of classes is :  8\n",
      "The input_length  is :  128\n",
      "The channel_in is :  21\n",
      "Validation data number :  4621\n",
      "Test data number :  20508\n",
      "================Skip the 4 CV Experiment================\n",
      "================ the 5 th CV Experiment ================ \n",
      "Leave one Out Experiment : The 6 Part as the test\n",
      "[-] Target sampling weights:  [0.00023946 0.00020589 0.0010582  0.00015758 0.00014535 0.00015936\n",
      " 0.00016054 0.00015718]\n",
      "Train data number :  42070\n",
      "The number of classes is :  8\n",
      "The input_length  is :  128\n",
      "The channel_in is :  21\n",
      "Validation data number :  4675\n",
      "Test data number :  17641\n",
      "================Skip the 5 CV Experiment================\n",
      "================ the 6 th CV Experiment ================ \n",
      "Leave one Out Experiment : The 7 Part as the test\n",
      "[-] Target sampling weights:  [0.00022862 0.00019631 0.00113122 0.00015765 0.00014656 0.00015985\n",
      " 0.00015987 0.00015738]\n",
      "Train data number :  42383\n",
      "The number of classes is :  8\n",
      "The input_length  is :  128\n",
      "The channel_in is :  21\n",
      "Validation data number :  4710\n",
      "Test data number :  15785\n",
      "================Skip the 6 CV Experiment================\n",
      "================ the 7 th CV Experiment ================ \n",
      "Leave one Out Experiment : The 8 Part as the test\n",
      "[-] Target sampling weights:  [0.00023663 0.0002265  0.00114025 0.00015843 0.00014397 0.00015954\n",
      " 0.00016108 0.00015731]\n",
      "Train data number :  41609\n",
      "The number of classes is :  8\n",
      "The input_length  is :  128\n",
      "The channel_in is :  21\n",
      "Validation data number :  4624\n",
      "Test data number :  20366\n",
      "================ Build the model ================ \n",
      "Build the DeepConvLSTM model!\n",
      "Epoch: 1 cost time: 17.175698041915894\n",
      "VALI: Epoch: 1, Steps: 163 | Train Loss: 0.6490976  Vali Loss: 0.2607967 Vali Accuracy: 0.9323097  Vali weighted F1: 0.9325463  Vali macro F1 0.9314825 \n",
      "Validation loss decreased (inf --> 0.260797).  Saving model ...\n",
      "Epoch: 2 cost time: 13.13497257232666\n",
      "VALI: Epoch: 2, Steps: 163 | Train Loss: 0.2187397  Vali Loss: 0.1760076 Vali Accuracy: 0.9530709  Vali weighted F1: 0.9531982  Vali macro F1 0.9527386 \n",
      "new best score!!!!\n",
      "Validation loss decreased (0.260797 --> 0.176008).  Saving model ...\n",
      "new best score!!!!\n",
      "Epoch: 3 cost time: 13.16868543624878\n",
      "VALI: Epoch: 3, Steps: 163 | Train Loss: 0.1582201  Vali Loss: 0.1591154 Vali Accuracy: 0.9537197  Vali weighted F1: 0.9539065  Vali macro F1 0.9544448 \n",
      "new best score!!!!\n",
      "Validation loss decreased (0.176008 --> 0.159115).  Saving model ...\n",
      "new best score!!!!\n",
      "Epoch: 4 cost time: 13.327173709869385\n",
      "VALI: Epoch: 4, Steps: 163 | Train Loss: 0.1275795  Vali Loss: 0.1173954 Vali Accuracy: 0.9705882  Vali weighted F1: 0.9706457  Vali macro F1 0.9705206 \n",
      "new best score!!!!\n",
      "Validation loss decreased (0.159115 --> 0.117395).  Saving model ...\n",
      "new best score!!!!\n",
      "Epoch: 5 cost time: 13.133317947387695\n",
      "VALI: Epoch: 5, Steps: 163 | Train Loss: 0.1037042  Vali Loss: 0.1001758 Vali Accuracy: 0.9751298  Vali weighted F1: 0.9751752  Vali macro F1 0.9754531 \n",
      "new best score!!!!\n",
      "Validation loss decreased (0.117395 --> 0.100176).  Saving model ...\n",
      "new best score!!!!\n",
      "Epoch: 6 cost time: 13.122422456741333\n",
      "VALI: Epoch: 6, Steps: 163 | Train Loss: 0.0885592  Vali Loss: 0.1048592 Vali Accuracy: 0.9705882  Vali weighted F1: 0.9706463  Vali macro F1 0.9708700 \n",
      "EarlyStopping counter: 1 out of 15\n",
      "Learning rate adjusting counter: 1 out of 5\n",
      "Epoch: 7 cost time: 13.28372859954834\n",
      "VALI: Epoch: 7, Steps: 163 | Train Loss: 0.0761659  Vali Loss: 0.0832109 Vali Accuracy: 0.9794550  Vali weighted F1: 0.9794857  Vali macro F1 0.9790075 \n",
      "new best score!!!!\n",
      "Validation loss decreased (0.100176 --> 0.083211).  Saving model ...\n",
      "new best score!!!!\n",
      "Epoch: 8 cost time: 13.147744178771973\n",
      "VALI: Epoch: 8, Steps: 163 | Train Loss: 0.0686336  Vali Loss: 0.0665740 Vali Accuracy: 0.9835640  Vali weighted F1: 0.9835694  Vali macro F1 0.9829768 \n",
      "new best score!!!!\n",
      "Validation loss decreased (0.083211 --> 0.066574).  Saving model ...\n",
      "new best score!!!!\n",
      "Epoch: 9 cost time: 13.064875364303589\n",
      "VALI: Epoch: 9, Steps: 163 | Train Loss: 0.0579641  Vali Loss: 0.0647781 Vali Accuracy: 0.9818339  Vali weighted F1: 0.9818675  Vali macro F1 0.9818209 \n",
      "new best score!!!!\n",
      "Validation loss decreased (0.066574 --> 0.064778).  Saving model ...\n",
      "new best score!!!!\n",
      "Epoch: 10 cost time: 13.233744859695435\n",
      "VALI: Epoch: 10, Steps: 163 | Train Loss: 0.0511890  Vali Loss: 0.0539782 Vali Accuracy: 0.9850779  Vali weighted F1: 0.9850845  Vali macro F1 0.9846798 \n",
      "new best score!!!!\n",
      "Validation loss decreased (0.064778 --> 0.053978).  Saving model ...\n",
      "new best score!!!!\n",
      "Epoch: 11 cost time: 13.135483741760254\n",
      "VALI: Epoch: 11, Steps: 163 | Train Loss: 0.0471119  Vali Loss: 0.0466731 Vali Accuracy: 0.9876730  Vali weighted F1: 0.9876835  Vali macro F1 0.9873929 \n",
      "new best score!!!!\n",
      "Validation loss decreased (0.053978 --> 0.046673).  Saving model ...\n",
      "new best score!!!!\n",
      "Epoch: 12 cost time: 13.087057113647461\n",
      "VALI: Epoch: 12, Steps: 163 | Train Loss: 0.0409260  Vali Loss: 0.0463271 Vali Accuracy: 0.9874567  Vali weighted F1: 0.9874650  Vali macro F1 0.9873131 \n",
      "new best score!!!!\n",
      "Validation loss decreased (0.046673 --> 0.046327).  Saving model ...\n",
      "new best score!!!!\n",
      "Epoch: 13 cost time: 13.188916683197021\n",
      "VALI: Epoch: 13, Steps: 163 | Train Loss: 0.0370815  Vali Loss: 0.0406938 Vali Accuracy: 0.9870242  Vali weighted F1: 0.9870403  Vali macro F1 0.9869575 \n",
      "new best score!!!!\n",
      "Validation loss decreased (0.046327 --> 0.040694).  Saving model ...\n",
      "new best score!!!!\n",
      "Epoch: 14 cost time: 13.162806510925293\n",
      "VALI: Epoch: 14, Steps: 163 | Train Loss: 0.0340098  Vali Loss: 0.0403055 Vali Accuracy: 0.9872405  Vali weighted F1: 0.9872488  Vali macro F1 0.9877069 \n",
      "new best score!!!!\n",
      "Validation loss decreased (0.040694 --> 0.040305).  Saving model ...\n",
      "new best score!!!!\n",
      "Epoch: 15 cost time: 13.11728572845459\n",
      "VALI: Epoch: 15, Steps: 163 | Train Loss: 0.0313037  Vali Loss: 0.0434569 Vali Accuracy: 0.9861592  Vali weighted F1: 0.9861663  Vali macro F1 0.9861019 \n",
      "EarlyStopping counter: 1 out of 15\n",
      "Learning rate adjusting counter: 1 out of 5\n",
      "Epoch: 16 cost time: 13.139008045196533\n",
      "VALI: Epoch: 16, Steps: 163 | Train Loss: 0.0262281  Vali Loss: 0.0375018 Vali Accuracy: 0.9881055  Vali weighted F1: 0.9881079  Vali macro F1 0.9881299 \n",
      "new best score!!!!\n",
      "Validation loss decreased (0.040305 --> 0.037502).  Saving model ...\n",
      "new best score!!!!\n",
      "Epoch: 17 cost time: 13.20457124710083\n",
      "VALI: Epoch: 17, Steps: 163 | Train Loss: 0.0250029  Vali Loss: 0.0372857 Vali Accuracy: 0.9898356  Vali weighted F1: 0.9898320  Vali macro F1 0.9888762 \n",
      "new best score!!!!\n",
      "Validation loss decreased (0.037502 --> 0.037286).  Saving model ...\n",
      "new best score!!!!\n",
      "Epoch: 18 cost time: 13.133164882659912\n",
      "VALI: Epoch: 18, Steps: 163 | Train Loss: 0.0221442  Vali Loss: 0.0404128 Vali Accuracy: 0.9891869  Vali weighted F1: 0.9891951  Vali macro F1 0.9879543 \n",
      "EarlyStopping counter: 1 out of 15\n",
      "Learning rate adjusting counter: 1 out of 5\n",
      "Epoch: 19 cost time: 13.118735551834106\n",
      "VALI: Epoch: 19, Steps: 163 | Train Loss: 0.0215796  Vali Loss: 0.0334602 Vali Accuracy: 0.9891869  Vali weighted F1: 0.9891915  Vali macro F1 0.9881941 \n",
      "new best score!!!!\n",
      "Validation loss decreased (0.037286 --> 0.033460).  Saving model ...\n",
      "new best score!!!!\n",
      "Epoch: 20 cost time: 13.249674558639526\n",
      "VALI: Epoch: 20, Steps: 163 | Train Loss: 0.0191577  Vali Loss: 0.0338943 Vali Accuracy: 0.9902682  Vali weighted F1: 0.9902741  Vali macro F1 0.9899855 \n",
      "EarlyStopping counter: 1 out of 15\n",
      "Learning rate adjusting counter: 1 out of 5\n",
      "Epoch: 21 cost time: 13.127135753631592\n",
      "VALI: Epoch: 21, Steps: 163 | Train Loss: 0.0191564  Vali Loss: 0.0341344 Vali Accuracy: 0.9904844  Vali weighted F1: 0.9904901  Vali macro F1 0.9899031 \n",
      "EarlyStopping counter: 2 out of 15\n",
      "Learning rate adjusting counter: 2 out of 5\n",
      "Epoch: 22 cost time: 13.18932056427002\n",
      "VALI: Epoch: 22, Steps: 163 | Train Loss: 0.0173792  Vali Loss: 0.0245151 Vali Accuracy: 0.9926471  Vali weighted F1: 0.9926466  Vali macro F1 0.9922599 \n",
      "new best score!!!!\n",
      "Validation loss decreased (0.033460 --> 0.024515).  Saving model ...\n",
      "new best score!!!!\n",
      "Epoch: 23 cost time: 13.255413055419922\n",
      "VALI: Epoch: 23, Steps: 163 | Train Loss: 0.0150238  Vali Loss: 0.0263694 Vali Accuracy: 0.9915657  Vali weighted F1: 0.9915691  Vali macro F1 0.9912311 \n",
      "EarlyStopping counter: 1 out of 15\n",
      "Learning rate adjusting counter: 1 out of 5\n",
      "Epoch: 24 cost time: 13.067655563354492\n",
      "VALI: Epoch: 24, Steps: 163 | Train Loss: 0.0149553  Vali Loss: 0.0263099 Vali Accuracy: 0.9911332  Vali weighted F1: 0.9911377  Vali macro F1 0.9903173 \n",
      "EarlyStopping counter: 2 out of 15\n",
      "Learning rate adjusting counter: 2 out of 5\n",
      "Epoch: 25 cost time: 13.107312202453613\n",
      "VALI: Epoch: 25, Steps: 163 | Train Loss: 0.0117040  Vali Loss: 0.0356274 Vali Accuracy: 0.9885381  Vali weighted F1: 0.9885222  Vali macro F1 0.9879493 \n",
      "EarlyStopping counter: 3 out of 15\n",
      "Learning rate adjusting counter: 3 out of 5\n",
      "Epoch: 26 cost time: 13.190274953842163\n",
      "VALI: Epoch: 26, Steps: 163 | Train Loss: 0.0120208  Vali Loss: 0.0242643 Vali Accuracy: 0.9911332  Vali weighted F1: 0.9911372  Vali macro F1 0.9909140 \n",
      "new best score!!!!\n",
      "Validation loss decreased (0.024515 --> 0.024264).  Saving model ...\n",
      "new best score!!!!\n",
      "Epoch: 27 cost time: 13.02735948562622\n",
      "VALI: Epoch: 27, Steps: 163 | Train Loss: 0.0133948  Vali Loss: 0.0213406 Vali Accuracy: 0.9926471  Vali weighted F1: 0.9926441  Vali macro F1 0.9921251 \n",
      "new best score!!!!\n",
      "Validation loss decreased (0.024264 --> 0.021341).  Saving model ...\n",
      "new best score!!!!\n",
      "Epoch: 28 cost time: 13.0414297580719\n",
      "VALI: Epoch: 28, Steps: 163 | Train Loss: 0.0092628  Vali Loss: 0.0183230 Vali Accuracy: 0.9943772  Vali weighted F1: 0.9943788  Vali macro F1 0.9943175 \n",
      "new best score!!!!\n",
      "Validation loss decreased (0.021341 --> 0.018323).  Saving model ...\n",
      "new best score!!!!\n",
      "Epoch: 29 cost time: 13.219112157821655\n",
      "VALI: Epoch: 29, Steps: 163 | Train Loss: 0.0088320  Vali Loss: 0.0211569 Vali Accuracy: 0.9935121  Vali weighted F1: 0.9935125  Vali macro F1 0.9923724 \n",
      "EarlyStopping counter: 1 out of 15\n",
      "Learning rate adjusting counter: 1 out of 5\n",
      "Epoch: 30 cost time: 13.085091829299927\n",
      "VALI: Epoch: 30, Steps: 163 | Train Loss: 0.0114200  Vali Loss: 0.0307166 Vali Accuracy: 0.9913495  Vali weighted F1: 0.9913570  Vali macro F1 0.9897942 \n",
      "EarlyStopping counter: 2 out of 15\n",
      "Learning rate adjusting counter: 2 out of 5\n",
      "Epoch: 31 cost time: 13.06719446182251\n",
      "VALI: Epoch: 31, Steps: 163 | Train Loss: 0.0114057  Vali Loss: 0.0222079 Vali Accuracy: 0.9939446  Vali weighted F1: 0.9939443  Vali macro F1 0.9934732 \n",
      "EarlyStopping counter: 3 out of 15\n",
      "Learning rate adjusting counter: 3 out of 5\n",
      "Epoch: 32 cost time: 13.259568452835083\n",
      "VALI: Epoch: 32, Steps: 163 | Train Loss: 0.0062094  Vali Loss: 0.0197450 Vali Accuracy: 0.9945934  Vali weighted F1: 0.9945928  Vali macro F1 0.9939441 \n",
      "EarlyStopping counter: 4 out of 15\n",
      "Learning rate adjusting counter: 4 out of 5\n"
     ]
    }
   ],
   "source": [
    "for seed in [1,2,3,4,5]:\n",
    "    args.seed = seed\n",
    "    exp = Exp(args)\n",
    "    exp.train()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "SDIL",
   "language": "python",
   "name": "sdil"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.13"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": true
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
