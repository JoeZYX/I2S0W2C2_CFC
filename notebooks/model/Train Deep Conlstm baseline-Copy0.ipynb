{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "894e2c21",
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "import sys\n",
    "sys.path.append(\"../../\")\n",
    "\n",
    "from experiment import Exp\n",
    "\n",
    "from dataloaders import data_set,data_dict\n",
    "import torch\n",
    "import yaml\n",
    "import os"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bcc56bc7",
   "metadata": {},
   "source": [
    "# 参数设置"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dcc5bcbc",
   "metadata": {
    "tags": []
   },
   "source": [
    "# 训练参数 \n",
    "除了路径 其他不要变"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "86004ce0",
   "metadata": {},
   "outputs": [],
   "source": [
    "class dotdict(dict):\n",
    "    \"\"\"dot.notation access to dictionary attributes\"\"\"\n",
    "    __getattr__ = dict.get\n",
    "    __setattr__ = dict.__setitem__\n",
    "    __delattr__ = dict.__delitem__\n",
    "\n",
    "args = dotdict()   \n",
    "# TODO change the path as relative path\n",
    "args.to_save_path     = \"../../../ISWC2022LearnableFilter/Run_logs\"              \n",
    "args.freq_save_path   = \"../../../ISWC2022LearnableFilter/Freq_data\"\n",
    "args.window_save_path = \"../../../ISWC2022LearnableFilter/Sliding_window\"\n",
    "args.root_path        = \"../../../datasets\"\n",
    "\n",
    "\n",
    "args.drop_transition  = False\n",
    "args.datanorm_type    = \"standardization\" # None ,\"standardization\", \"minmax\"\n",
    "\n",
    "\n",
    "args.batch_size       = 256                                                    \n",
    "args.shuffle          = True\n",
    "args.drop_last        = False\n",
    "args.train_vali_quote = 0.90                                           \n",
    "\n",
    "\n",
    "# training setting \n",
    "args.train_epochs            = 150\n",
    "\n",
    "args.learning_rate           = 0.001  \n",
    "args.learning_rate_patience  = 5\n",
    "args.learning_rate_factor    = 0.1\n",
    "\n",
    "\n",
    "args.early_stop_patience     = 15\n",
    "\n",
    "args.use_gpu                 = True if torch.cuda.is_available() else False\n",
    "args.gpu                     = 0\n",
    "args.use_multi_gpu           = False\n",
    "\n",
    "args.optimizer               = \"Adam\"\n",
    "args.criterion               = \"CrossEntropy\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c282cbcb",
   "metadata": {},
   "source": [
    "## 数据参数\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "c6cd147b",
   "metadata": {},
   "outputs": [],
   "source": [
    "args.seed                             = 1\n",
    "\n",
    "\n",
    "args.data_name                        =  \"hapt\"\n",
    "\n",
    "args.wavelet_filtering                = False\n",
    "args.wavelet_filtering_regularization = False\n",
    "args.wavelet_filtering_finetuning     = False\n",
    "\n",
    "\n",
    "args.difference       = False \n",
    "args.filtering        = False\n",
    "args.magnitude        = False\n",
    "args.weighted_sampler = False\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "args.pos_select       = None\n",
    "args.sensor_select    = None\n",
    "\n",
    "\n",
    "args.representation_type = \"time\"\n",
    "args.exp_mode            = \"LOCV\"\n",
    "\n",
    "config_file = open('../../configs/data.yaml', mode='r')\n",
    "data_config = yaml.load(config_file, Loader=yaml.FullLoader)\n",
    "config = data_config[args.data_name]\n",
    "\n",
    "args.root_path       = os.path.join(args.root_path,config[\"filename\"])\n",
    "args.sampling_freq   = config[\"sampling_freq\"]\n",
    "args.num_classes     =  config[\"num_classes\"]\n",
    "window_seconds       = config[\"window_seconds\"]\n",
    "args.windowsize      =   int(window_seconds * args.sampling_freq) \n",
    "args.input_length    =  args.windowsize\n",
    "# input information\n",
    "args.c_in            = config[\"num_channels\"]\n",
    "\n",
    "if args.wavelet_filtering :\n",
    "    \n",
    "    if args.windowsize%2==1:\n",
    "        N_ds = int(torch.log2(torch.tensor(args.windowsize-1)).floor()) - 2\n",
    "    else:\n",
    "        N_ds = int(torch.log2(torch.tensor(args.windowsize)).floor()) - 2\n",
    "\n",
    "    args.f_in            =  args.number_wavelet_filtering*N_ds+1\n",
    "else:\n",
    "    args.f_in            =  1"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4d435a4c",
   "metadata": {},
   "source": [
    "## 模型参数"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "de2f4d16",
   "metadata": {},
   "outputs": [],
   "source": [
    "args.filter_scaling_factor = 1\n",
    "args.model_type            = \"attend\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cada66dd",
   "metadata": {},
   "source": [
    "# 实验"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "2e3f2fad",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Use GPU: cuda:0\n",
      "Build the AttendDiscriminate model!\n",
      "Done!\n",
      "Parameter : 372430\n",
      "Set the seed as :  1\n"
     ]
    }
   ],
   "source": [
    "exp = Exp(args)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "09a011fc",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " ----------------------- load all the data -------------------\n",
      "-----------------------Sliding file are generated -----------------------\n",
      "-----------------------Sliding file are generated -----------------------\n",
      "================ LOCV Mode ====================\n",
      "================ 30 CV ======================\n",
      "================ the 0 th CV Experiment ================ \n",
      "Leave one Out Experiment : The 1 Part as the test\n",
      "[-] Target sampling weights:  [0.00067114 0.00068353 0.00073529 0.00061125 0.00056211 0.00056948\n",
      " 0.00740741 0.01020408 0.00636943 0.00735294 0.00537634 0.00699301]\n",
      "Train data number :  10339\n",
      "The number of classes is :  12\n",
      "The input_length  is :  128\n",
      "The channel_in is :  6\n",
      "Validation data number :  1149\n",
      "Test data number :  6632\n",
      "================Skip the 0 CV Experiment================\n",
      "================ the 1 th CV Experiment ================ \n",
      "Leave one Out Experiment : The 2 Part as the test\n",
      "[-] Target sampling weights:  [0.00064851 0.00068446 0.00073046 0.000612   0.0005637  0.00056433\n",
      " 0.00775194 0.01052632 0.00625    0.00694444 0.00581395 0.0070922 ]\n",
      "Train data number :  10393\n",
      "The number of classes is :  12\n",
      "The input_length  is :  128\n",
      "The channel_in is :  6\n",
      "Validation data number :  1155\n",
      "Test data number :  6311\n",
      "================Skip the 1 CV Experiment================\n",
      "================ the 2 th CV Experiment ================ \n",
      "Leave one Out Experiment : The 3 Part as the test\n",
      "[-] Target sampling weights:  [0.00063613 0.00066756 0.00072098 0.00061387 0.00056275 0.00056786\n",
      " 0.00724638 0.01010101 0.00684932 0.00746269 0.00537634 0.00724638]\n",
      "Train data number :  10465\n",
      "The number of classes is :  12\n",
      "The input_length  is :  128\n",
      "The channel_in is :  6\n",
      "Validation data number :  1163\n",
      "Test data number :  5897\n",
      "================Skip the 2 CV Experiment================\n",
      "================ the 3 th CV Experiment ================ \n",
      "Leave one Out Experiment : The 4 Part as the test\n",
      "[-] Target sampling weights:  [0.00064599 0.00066979 0.00072833 0.00062073 0.00055991 0.00057307\n",
      " 0.0075188  0.01041667 0.00632911 0.00671141 0.00515464 0.00740741]\n",
      "Train data number :  10421\n",
      "The number of classes is :  12\n",
      "The input_length  is :  128\n",
      "The channel_in is :  6\n",
      "Validation data number :  1158\n",
      "Test data number :  6195\n",
      "================Skip the 3 CV Experiment================\n",
      "================ the 4 th CV Experiment ================ \n",
      "Leave one Out Experiment : The 5 Part as the test\n",
      "[-] Target sampling weights:  [0.00064475 0.00067981 0.00072833 0.00061538 0.00056433 0.00057803\n",
      " 0.00763359 0.01041667 0.00649351 0.00735294 0.00540541 0.0075188 ]\n",
      "Train data number :  10357\n",
      "The number of classes is :  12\n",
      "The input_length  is :  128\n",
      "The channel_in is :  6\n",
      "Validation data number :  1151\n",
      "Test data number :  6522\n",
      "================Skip the 4 CV Experiment================\n",
      "================ the 5 th CV Experiment ================ \n",
      "Leave one Out Experiment : The 6 Part as the test\n",
      "[-] Target sampling weights:  [0.00064475 0.00067522 0.00072727 0.00063171 0.00057904 0.00059067\n",
      " 0.00813008 0.01030928 0.00641026 0.00763359 0.00546448 0.00746269]\n",
      "Train data number :  10234\n",
      "The number of classes is :  12\n",
      "The input_length  is :  128\n",
      "The channel_in is :  6\n",
      "Validation data number :  1138\n",
      "Test data number :  7257\n",
      "================Skip the 5 CV Experiment================\n",
      "================ the 6 th CV Experiment ================ \n",
      "Leave one Out Experiment : The 7 Part as the test\n",
      "[-] Target sampling weights:  [0.00063816 0.00066756 0.00072886 0.00064144 0.00058893 0.00058824\n",
      " 0.0078125  0.01020408 0.00636943 0.00719424 0.00609756 0.00719424]\n",
      "Train data number :  10219\n",
      "The number of classes is :  12\n",
      "The input_length  is :  128\n",
      "The channel_in is :  6\n",
      "Validation data number :  1136\n",
      "Test data number :  7352\n",
      "================Skip the 6 CV Experiment================\n",
      "================ the 7 th CV Experiment ================ \n",
      "Leave one Out Experiment : The 8 Part as the test\n",
      "[-] Target sampling weights:  [0.00065746 0.00067522 0.00072727 0.0006402  0.00056883 0.00057904\n",
      " 0.00746269 0.01010101 0.00649351 0.0070922  0.00555556 0.00704225]\n",
      "Train data number :  10274\n",
      "The number of classes is :  12\n",
      "The input_length  is :  128\n",
      "The channel_in is :  6\n",
      "Validation data number :  1142\n",
      "Test data number :  7032\n",
      "================Skip the 7 CV Experiment================\n",
      "================ the 8 th CV Experiment ================ \n",
      "Leave one Out Experiment : The 9 Part as the test\n",
      "[-] Target sampling weights:  [0.00065746 0.000693   0.00073801 0.00063898 0.00057803 0.00057971\n",
      " 0.00763359 0.01030928 0.00641026 0.00735294 0.00531915 0.00719424]\n",
      "Train data number :  10186\n",
      "The number of classes is :  12\n",
      "The input_length  is :  128\n",
      "The channel_in is :  6\n",
      "Validation data number :  1132\n",
      "Test data number :  7568\n",
      "================Skip the 8 CV Experiment================\n",
      "================ the 9 th CV Experiment ================ \n",
      "Leave one Out Experiment : The 10 Part as the test\n",
      "[-] Target sampling weights:  [0.00064977 0.00067935 0.00074571 0.0006192  0.0005787  0.00058548\n",
      " 0.00763359 0.01030928 0.00657895 0.00689655 0.00543478 0.00704225]\n",
      "Train data number :  10254\n",
      "The number of classes is :  12\n",
      "The input_length  is :  128\n",
      "The channel_in is :  6\n",
      "Validation data number :  1140\n",
      "Test data number :  7165\n",
      "================Skip the 9 CV Experiment================\n",
      "================ the 10 th CV Experiment ================ \n",
      "Leave one Out Experiment : The 11 Part as the test\n",
      "[-] Target sampling weights:  [0.0005963  0.00063532 0.00069156 0.00058038 0.00052329 0.00053362\n",
      " 0.0070922  0.00990099 0.00606061 0.00684932 0.00507614 0.00657895]\n",
      "Train data number :  11107\n",
      "The number of classes is :  12\n",
      "The input_length  is :  128\n",
      "The channel_in is :  6\n",
      "Validation data number :  1235\n",
      "Test data number :  2102\n",
      "================ Build the model ================ \n",
      "Build the AttendDiscriminate model!\n",
      "Epoch: 1 cost time: 63.85411190986633\n",
      "VALI: Epoch: 1, Steps: 44 | Train Loss: 1.3240148  Vali Loss: 0.7133268 Vali Accuracy: 0.7797571  Vali weighted F1: 0.7557719  Vali macro F1 0.4791628 \n",
      "Validation loss decreased (inf --> 0.713327).  Saving model ...\n",
      "Epoch: 2 cost time: 64.38948106765747\n",
      "VALI: Epoch: 2, Steps: 44 | Train Loss: 0.5556155  Vali Loss: 0.4289535 Vali Accuracy: 0.8542510  Vali weighted F1: 0.8364610  Vali macro F1 0.5452484 \n",
      "new best score!!!!\n",
      "Validation loss decreased (0.713327 --> 0.428954).  Saving model ...\n",
      "new best score!!!!\n",
      "Epoch: 3 cost time: 65.48853063583374\n",
      "VALI: Epoch: 3, Steps: 44 | Train Loss: 0.3409965  Vali Loss: 0.3664971 Vali Accuracy: 0.8623482  Vali weighted F1: 0.8513478  Vali macro F1 0.6206418 \n",
      "new best score!!!!\n",
      "Validation loss decreased (0.428954 --> 0.366497).  Saving model ...\n",
      "new best score!!!!\n",
      "Epoch: 4 cost time: 65.10723853111267\n",
      "VALI: Epoch: 4, Steps: 44 | Train Loss: 0.2715989  Vali Loss: 0.2610284 Vali Accuracy: 0.8987854  Vali weighted F1: 0.8916438  Vali macro F1 0.6786646 \n",
      "new best score!!!!\n",
      "Validation loss decreased (0.366497 --> 0.261028).  Saving model ...\n",
      "new best score!!!!\n",
      "Epoch: 5 cost time: 65.14057540893555\n",
      "VALI: Epoch: 5, Steps: 44 | Train Loss: 0.2414325  Vali Loss: 0.2784494 Vali Accuracy: 0.8955466  Vali weighted F1: 0.8870301  Vali macro F1 0.6859743 \n",
      "EarlyStopping counter: 1 out of 15\n",
      "Learning rate adjusting counter: 1 out of 5\n",
      "Epoch: 6 cost time: 86.03474569320679\n",
      "VALI: Epoch: 6, Steps: 44 | Train Loss: 0.2196800  Vali Loss: 0.2196486 Vali Accuracy: 0.9238866  Vali weighted F1: 0.9209695  Vali macro F1 0.7996902 \n",
      "new best score!!!!\n",
      "Validation loss decreased (0.261028 --> 0.219649).  Saving model ...\n",
      "new best score!!!!\n",
      "Epoch: 7 cost time: 96.74538850784302\n",
      "VALI: Epoch: 7, Steps: 44 | Train Loss: 0.2024456  Vali Loss: 0.2953231 Vali Accuracy: 0.8890688  Vali weighted F1: 0.8860900  Vali macro F1 0.7386632 \n",
      "EarlyStopping counter: 1 out of 15\n",
      "Learning rate adjusting counter: 1 out of 5\n",
      "Epoch: 8 cost time: 96.98621916770935\n",
      "VALI: Epoch: 8, Steps: 44 | Train Loss: 0.2134325  Vali Loss: 0.2369767 Vali Accuracy: 0.9165992  Vali weighted F1: 0.9134200  Vali macro F1 0.7851603 \n",
      "EarlyStopping counter: 2 out of 15\n",
      "Learning rate adjusting counter: 2 out of 5\n",
      "Epoch: 9 cost time: 96.52289319038391\n",
      "VALI: Epoch: 9, Steps: 44 | Train Loss: 0.1879328  Vali Loss: 0.2244741 Vali Accuracy: 0.9125506  Vali weighted F1: 0.9086218  Vali macro F1 0.7469250 \n",
      "EarlyStopping counter: 3 out of 15\n",
      "Learning rate adjusting counter: 3 out of 5\n",
      "Epoch: 10 cost time: 97.39476704597473\n",
      "VALI: Epoch: 10, Steps: 44 | Train Loss: 0.1754057  Vali Loss: 0.1982204 Vali Accuracy: 0.9303644  Vali weighted F1: 0.9295057  Vali macro F1 0.8111412 \n",
      "new best score!!!!\n",
      "Validation loss decreased (0.219649 --> 0.198220).  Saving model ...\n",
      "new best score!!!!\n",
      "Epoch: 11 cost time: 96.66658854484558\n",
      "VALI: Epoch: 11, Steps: 44 | Train Loss: 0.1569136  Vali Loss: 0.1906142 Vali Accuracy: 0.9246964  Vali weighted F1: 0.9223002  Vali macro F1 0.7753032 \n",
      "new best score!!!!\n",
      "Validation loss decreased (0.198220 --> 0.190614).  Saving model ...\n",
      "new best score!!!!\n",
      "Epoch: 12 cost time: 96.11942720413208\n",
      "VALI: Epoch: 12, Steps: 44 | Train Loss: 0.1399818  Vali Loss: 0.2239306 Vali Accuracy: 0.9222672  Vali weighted F1: 0.9216308  Vali macro F1 0.8064763 \n",
      "EarlyStopping counter: 1 out of 15\n",
      "Learning rate adjusting counter: 1 out of 5\n",
      "Epoch: 13 cost time: 96.38539385795593\n",
      "VALI: Epoch: 13, Steps: 44 | Train Loss: 0.1480087  Vali Loss: 0.1801720 Vali Accuracy: 0.9360324  Vali weighted F1: 0.9330924  Vali macro F1 0.8058655 \n",
      "new best score!!!!\n",
      "Validation loss decreased (0.190614 --> 0.180172).  Saving model ...\n",
      "new best score!!!!\n",
      "Epoch: 14 cost time: 97.49175596237183\n",
      "VALI: Epoch: 14, Steps: 44 | Train Loss: 0.1337391  Vali Loss: 0.1887982 Vali Accuracy: 0.9255061  Vali weighted F1: 0.9235436  Vali macro F1 0.7855613 \n",
      "EarlyStopping counter: 1 out of 15\n",
      "Learning rate adjusting counter: 1 out of 5\n",
      "Epoch: 15 cost time: 97.55133771896362\n",
      "VALI: Epoch: 15, Steps: 44 | Train Loss: 0.1186091  Vali Loss: 0.1485501 Vali Accuracy: 0.9417004  Vali weighted F1: 0.9399887  Vali macro F1 0.8155217 \n",
      "new best score!!!!\n",
      "Validation loss decreased (0.180172 --> 0.148550).  Saving model ...\n",
      "new best score!!!!\n",
      "Epoch: 16 cost time: 96.25348615646362\n",
      "VALI: Epoch: 16, Steps: 44 | Train Loss: 0.1200324  Vali Loss: 0.1788527 Vali Accuracy: 0.9368421  Vali weighted F1: 0.9340474  Vali macro F1 0.7855985 \n",
      "EarlyStopping counter: 1 out of 15\n",
      "Learning rate adjusting counter: 1 out of 5\n",
      "Epoch: 17 cost time: 96.69109559059143\n",
      "VALI: Epoch: 17, Steps: 44 | Train Loss: 0.1140393  Vali Loss: 0.1502602 Vali Accuracy: 0.9457490  Vali weighted F1: 0.9443669  Vali macro F1 0.8238137 \n",
      "EarlyStopping counter: 2 out of 15\n",
      "Learning rate adjusting counter: 2 out of 5\n",
      "Epoch: 18 cost time: 95.60327386856079\n",
      "VALI: Epoch: 18, Steps: 44 | Train Loss: 0.1047235  Vali Loss: 0.1659899 Vali Accuracy: 0.9368421  Vali weighted F1: 0.9339222  Vali macro F1 0.7914083 \n",
      "EarlyStopping counter: 3 out of 15\n",
      "Learning rate adjusting counter: 3 out of 5\n",
      "Epoch: 19 cost time: 96.85673975944519\n",
      "VALI: Epoch: 19, Steps: 44 | Train Loss: 0.0992506  Vali Loss: 0.1629923 Vali Accuracy: 0.9441296  Vali weighted F1: 0.9427855  Vali macro F1 0.8042795 \n",
      "EarlyStopping counter: 4 out of 15\n",
      "Learning rate adjusting counter: 4 out of 5\n",
      "Epoch: 20 cost time: 96.39772152900696\n",
      "VALI: Epoch: 20, Steps: 44 | Train Loss: 0.0923326  Vali Loss: 0.1373948 Vali Accuracy: 0.9497976  Vali weighted F1: 0.9485386  Vali macro F1 0.8199409 \n",
      "new best score!!!!\n",
      "Validation loss decreased (0.148550 --> 0.137395).  Saving model ...\n",
      "new best score!!!!\n",
      "Epoch: 21 cost time: 96.28122448921204\n",
      "VALI: Epoch: 21, Steps: 44 | Train Loss: 0.0851664  Vali Loss: 0.1418344 Vali Accuracy: 0.9514170  Vali weighted F1: 0.9502957  Vali macro F1 0.8448600 \n",
      "EarlyStopping counter: 1 out of 15\n",
      "Learning rate adjusting counter: 1 out of 5\n",
      "Epoch: 22 cost time: 93.7360908985138\n",
      "VALI: Epoch: 22, Steps: 44 | Train Loss: 0.1210232  Vali Loss: 0.1274057 Vali Accuracy: 0.9497976  Vali weighted F1: 0.9486925  Vali macro F1 0.8218556 \n",
      "new best score!!!!\n",
      "Validation loss decreased (0.137395 --> 0.127406).  Saving model ...\n",
      "new best score!!!!\n",
      "Epoch: 23 cost time: 94.51259589195251\n",
      "VALI: Epoch: 23, Steps: 44 | Train Loss: 0.0927862  Vali Loss: 0.1326449 Vali Accuracy: 0.9562753  Vali weighted F1: 0.9551730  Vali macro F1 0.8386468 \n",
      "EarlyStopping counter: 1 out of 15\n",
      "Learning rate adjusting counter: 1 out of 5\n",
      "Epoch: 24 cost time: 95.18512797355652\n",
      "VALI: Epoch: 24, Steps: 44 | Train Loss: 0.0900954  Vali Loss: 0.1386786 Vali Accuracy: 0.9449393  Vali weighted F1: 0.9445115  Vali macro F1 0.8267918 \n",
      "EarlyStopping counter: 2 out of 15\n",
      "Learning rate adjusting counter: 2 out of 5\n",
      "Epoch: 25 cost time: 94.34121513366699\n",
      "VALI: Epoch: 25, Steps: 44 | Train Loss: 0.0832081  Vali Loss: 0.1351638 Vali Accuracy: 0.9473684  Vali weighted F1: 0.9460902  Vali macro F1 0.8250842 \n",
      "EarlyStopping counter: 3 out of 15\n",
      "Learning rate adjusting counter: 3 out of 5\n",
      "Epoch: 26 cost time: 95.02738237380981\n",
      "VALI: Epoch: 26, Steps: 44 | Train Loss: 0.0769214  Vali Loss: 0.1526908 Vali Accuracy: 0.9457490  Vali weighted F1: 0.9441837  Vali macro F1 0.8095182 \n",
      "EarlyStopping counter: 4 out of 15\n",
      "Learning rate adjusting counter: 4 out of 5\n",
      "Epoch: 27 cost time: 94.63722133636475\n",
      "VALI: Epoch: 27, Steps: 44 | Train Loss: 0.0779366  Vali Loss: 0.1500811 Vali Accuracy: 0.9425101  Vali weighted F1: 0.9423263  Vali macro F1 0.8133454 \n",
      "EarlyStopping counter: 5 out of 15\n",
      "Learning rate adjusting counter: 5 out of 5\n",
      "Updating learning rate to 0.0001\n",
      "Epoch: 28 cost time: 94.39440369606018\n",
      "VALI: Epoch: 28, Steps: 44 | Train Loss: 0.0650942  Vali Loss: 0.1400020 Vali Accuracy: 0.9489879  Vali weighted F1: 0.9473721  Vali macro F1 0.8253307 \n",
      "EarlyStopping counter: 6 out of 15\n",
      "Learning rate adjusting counter: 1 out of 5\n",
      "Epoch: 29 cost time: 94.38784074783325\n",
      "VALI: Epoch: 29, Steps: 44 | Train Loss: 0.0544281  Vali Loss: 0.1381691 Vali Accuracy: 0.9465587  Vali weighted F1: 0.9453419  Vali macro F1 0.8193689 \n",
      "EarlyStopping counter: 7 out of 15\n",
      "Learning rate adjusting counter: 2 out of 5\n",
      "Epoch: 30 cost time: 94.4971694946289\n",
      "VALI: Epoch: 30, Steps: 44 | Train Loss: 0.0528916  Vali Loss: 0.1392780 Vali Accuracy: 0.9481781  Vali weighted F1: 0.9468305  Vali macro F1 0.8279863 \n",
      "EarlyStopping counter: 8 out of 15\n",
      "Learning rate adjusting counter: 3 out of 5\n",
      "Epoch: 31 cost time: 94.48219347000122\n",
      "VALI: Epoch: 31, Steps: 44 | Train Loss: 0.0527112  Vali Loss: 0.1433356 Vali Accuracy: 0.9465587  Vali weighted F1: 0.9455046  Vali macro F1 0.8247533 \n",
      "EarlyStopping counter: 9 out of 15\n",
      "Learning rate adjusting counter: 4 out of 5\n",
      "Epoch: 32 cost time: 94.22545742988586\n",
      "VALI: Epoch: 32, Steps: 44 | Train Loss: 0.0512466  Vali Loss: 0.1444401 Vali Accuracy: 0.9465587  Vali weighted F1: 0.9451640  Vali macro F1 0.8200279 \n",
      "EarlyStopping counter: 10 out of 15\n",
      "Learning rate adjusting counter: 5 out of 5\n",
      "Updating learning rate to 1e-05\n",
      "Epoch: 33 cost time: 94.66746258735657\n",
      "VALI: Epoch: 33, Steps: 44 | Train Loss: 0.0497848  Vali Loss: 0.1462980 Vali Accuracy: 0.9465587  Vali weighted F1: 0.9452797  Vali macro F1 0.8210112 \n",
      "EarlyStopping counter: 11 out of 15\n",
      "Learning rate adjusting counter: 1 out of 5\n",
      "Epoch: 34 cost time: 94.65048289299011\n",
      "VALI: Epoch: 34, Steps: 44 | Train Loss: 0.0482125  Vali Loss: 0.1465569 Vali Accuracy: 0.9465587  Vali weighted F1: 0.9452797  Vali macro F1 0.8210112 \n",
      "EarlyStopping counter: 12 out of 15\n",
      "Learning rate adjusting counter: 2 out of 5\n",
      "Epoch: 35 cost time: 94.57666993141174\n",
      "VALI: Epoch: 35, Steps: 44 | Train Loss: 0.0467678  Vali Loss: 0.1466001 Vali Accuracy: 0.9465587  Vali weighted F1: 0.9452797  Vali macro F1 0.8210112 \n",
      "EarlyStopping counter: 13 out of 15\n",
      "Learning rate adjusting counter: 3 out of 5\n",
      "Epoch: 36 cost time: 94.55987429618835\n",
      "VALI: Epoch: 36, Steps: 44 | Train Loss: 0.0465395  Vali Loss: 0.1468510 Vali Accuracy: 0.9465587  Vali weighted F1: 0.9452797  Vali macro F1 0.8210112 \n",
      "EarlyStopping counter: 14 out of 15\n",
      "Learning rate adjusting counter: 4 out of 5\n",
      "Epoch: 37 cost time: 94.55117273330688\n",
      "VALI: Epoch: 37, Steps: 44 | Train Loss: 0.0486596  Vali Loss: 0.1468936 Vali Accuracy: 0.9465587  Vali weighted F1: 0.9452797  Vali macro F1 0.8210112 \n",
      "EarlyStopping counter: 15 out of 15\n",
      "Early stopping\n",
      "Loading the best validation model!\n",
      "Final Test Performance : Test Accuracy: 0.9747859  Test weighted F1: 0.9741575  Test macro F1 0.9021347 \n",
      "================ the 11 th CV Experiment ================ \n",
      "Leave one Out Experiment : The 12 Part as the test\n",
      "[-] Target sampling weights:  [0.00060132 0.00062814 0.00067751 0.00058241 0.00053333 0.00053648\n",
      " 0.00724638 0.00925926 0.00584795 0.00632911 0.00518135 0.00689655]\n",
      "Train data number :  11100\n",
      "The number of classes is :  12\n",
      "The input_length  is :  128\n",
      "The channel_in is :  6\n",
      "Validation data number :  1234\n",
      "Test data number :  2144\n",
      "================ Build the model ================ \n",
      "Build the AttendDiscriminate model!\n",
      "Epoch: 1 cost time: 106.23627424240112\n",
      "VALI: Epoch: 1, Steps: 44 | Train Loss: 1.3061492  Vali Loss: 0.6361055 Vali Accuracy: 0.7965964  Vali weighted F1: 0.7712834  Vali macro F1 0.4549820 \n",
      "Validation loss decreased (inf --> 0.636105).  Saving model ...\n",
      "Epoch: 2 cost time: 113.73299932479858\n",
      "VALI: Epoch: 2, Steps: 44 | Train Loss: 0.4975042  Vali Loss: 0.3204601 Vali Accuracy: 0.8954619  Vali weighted F1: 0.8782305  Vali macro F1 0.5878350 \n",
      "new best score!!!!\n",
      "Validation loss decreased (0.636105 --> 0.320460).  Saving model ...\n",
      "new best score!!!!\n",
      "Epoch: 3 cost time: 114.11789298057556\n",
      "VALI: Epoch: 3, Steps: 44 | Train Loss: 0.3187308  Vali Loss: 0.3031602 Vali Accuracy: 0.8784441  Vali weighted F1: 0.8674594  Vali macro F1 0.5978179 \n",
      "new best score!!!!\n",
      "Validation loss decreased (0.320460 --> 0.303160).  Saving model ...\n",
      "new best score!!!!\n",
      "Epoch: 4 cost time: 113.30271482467651\n",
      "VALI: Epoch: 4, Steps: 44 | Train Loss: 0.2648479  Vali Loss: 0.2419978 Vali Accuracy: 0.9051864  Vali weighted F1: 0.9027828  Vali macro F1 0.7272120 \n",
      "new best score!!!!\n",
      "Validation loss decreased (0.303160 --> 0.241998).  Saving model ...\n",
      "new best score!!!!\n",
      "Epoch: 5 cost time: 113.27177333831787\n",
      "VALI: Epoch: 5, Steps: 44 | Train Loss: 0.2429705  Vali Loss: 0.2221104 Vali Accuracy: 0.9108590  Vali weighted F1: 0.9071272  Vali macro F1 0.7279439 \n",
      "new best score!!!!\n",
      "Validation loss decreased (0.241998 --> 0.222110).  Saving model ...\n",
      "new best score!!!!\n",
      "Epoch: 6 cost time: 111.54301857948303\n",
      "VALI: Epoch: 6, Steps: 44 | Train Loss: 0.2234794  Vali Loss: 0.2032859 Vali Accuracy: 0.9222042  Vali weighted F1: 0.9210432  Vali macro F1 0.7816005 \n",
      "new best score!!!!\n",
      "Validation loss decreased (0.222110 --> 0.203286).  Saving model ...\n",
      "new best score!!!!\n",
      "Epoch: 7 cost time: 113.00071978569031\n",
      "VALI: Epoch: 7, Steps: 44 | Train Loss: 0.2086430  Vali Loss: 0.1910223 Vali Accuracy: 0.9246353  Vali weighted F1: 0.9221767  Vali macro F1 0.7507544 \n",
      "new best score!!!!\n",
      "Validation loss decreased (0.203286 --> 0.191022).  Saving model ...\n",
      "new best score!!!!\n",
      "Epoch: 8 cost time: 111.5559618473053\n",
      "VALI: Epoch: 8, Steps: 44 | Train Loss: 0.1913008  Vali Loss: 0.1860485 Vali Accuracy: 0.9246353  Vali weighted F1: 0.9229215  Vali macro F1 0.7618492 \n",
      "new best score!!!!\n",
      "Validation loss decreased (0.191022 --> 0.186048).  Saving model ...\n",
      "new best score!!!!\n",
      "Epoch: 9 cost time: 111.74815225601196\n",
      "VALI: Epoch: 9, Steps: 44 | Train Loss: 0.1873518  Vali Loss: 0.1801293 Vali Accuracy: 0.9343598  Vali weighted F1: 0.9325378  Vali macro F1 0.7943223 \n",
      "new best score!!!!\n",
      "Validation loss decreased (0.186048 --> 0.180129).  Saving model ...\n",
      "new best score!!!!\n",
      "Epoch: 10 cost time: 109.60235977172852\n",
      "VALI: Epoch: 10, Steps: 44 | Train Loss: 0.1694467  Vali Loss: 0.1568027 Vali Accuracy: 0.9343598  Vali weighted F1: 0.9310461  Vali macro F1 0.7670491 \n",
      "new best score!!!!\n",
      "Validation loss decreased (0.180129 --> 0.156803).  Saving model ...\n",
      "new best score!!!!\n",
      "Epoch: 11 cost time: 110.27341485023499\n",
      "VALI: Epoch: 11, Steps: 44 | Train Loss: 0.1543405  Vali Loss: 0.1464476 Vali Accuracy: 0.9343598  Vali weighted F1: 0.9322915  Vali macro F1 0.7540582 \n",
      "new best score!!!!\n",
      "Validation loss decreased (0.156803 --> 0.146448).  Saving model ...\n",
      "new best score!!!!\n",
      "Epoch: 12 cost time: 108.4757149219513\n",
      "VALI: Epoch: 12, Steps: 44 | Train Loss: 0.1408333  Vali Loss: 0.1520737 Vali Accuracy: 0.9408428  Vali weighted F1: 0.9396126  Vali macro F1 0.7906054 \n",
      "EarlyStopping counter: 1 out of 15\n",
      "Learning rate adjusting counter: 1 out of 5\n",
      "Epoch: 13 cost time: 108.62763261795044\n",
      "VALI: Epoch: 13, Steps: 44 | Train Loss: 0.1438403  Vali Loss: 0.1461061 Vali Accuracy: 0.9384117  Vali weighted F1: 0.9378963  Vali macro F1 0.7980476 \n",
      "new best score!!!!\n",
      "Validation loss decreased (0.146448 --> 0.146106).  Saving model ...\n",
      "new best score!!!!\n",
      "Epoch: 14 cost time: 109.03551769256592\n",
      "VALI: Epoch: 14, Steps: 44 | Train Loss: 0.1238002  Vali Loss: 0.1447745 Vali Accuracy: 0.9457050  Vali weighted F1: 0.9454704  Vali macro F1 0.8258469 \n",
      "new best score!!!!\n",
      "Validation loss decreased (0.146106 --> 0.144775).  Saving model ...\n",
      "new best score!!!!\n",
      "Epoch: 15 cost time: 108.7803418636322\n",
      "VALI: Epoch: 15, Steps: 44 | Train Loss: 0.1169084  Vali Loss: 0.1606741 Vali Accuracy: 0.9384117  Vali weighted F1: 0.9351210  Vali macro F1 0.7991934 \n",
      "EarlyStopping counter: 1 out of 15\n",
      "Learning rate adjusting counter: 1 out of 5\n",
      "Epoch: 16 cost time: 109.6059079170227\n",
      "VALI: Epoch: 16, Steps: 44 | Train Loss: 0.1107705  Vali Loss: 0.1264789 Vali Accuracy: 0.9513776  Vali weighted F1: 0.9510452  Vali macro F1 0.8126792 \n",
      "new best score!!!!\n",
      "Validation loss decreased (0.144775 --> 0.126479).  Saving model ...\n",
      "new best score!!!!\n",
      "Epoch: 17 cost time: 108.77280163764954\n",
      "VALI: Epoch: 17, Steps: 44 | Train Loss: 0.1080734  Vali Loss: 0.1433284 Vali Accuracy: 0.9448947  Vali weighted F1: 0.9434319  Vali macro F1 0.7958452 \n",
      "EarlyStopping counter: 1 out of 15\n",
      "Learning rate adjusting counter: 1 out of 5\n",
      "Epoch: 18 cost time: 109.18960642814636\n",
      "VALI: Epoch: 18, Steps: 44 | Train Loss: 0.0990696  Vali Loss: 0.1517750 Vali Accuracy: 0.9432739  Vali weighted F1: 0.9412079  Vali macro F1 0.8043761 \n",
      "EarlyStopping counter: 2 out of 15\n",
      "Learning rate adjusting counter: 2 out of 5\n",
      "Epoch: 19 cost time: 109.11261892318726\n",
      "VALI: Epoch: 19, Steps: 44 | Train Loss: 0.1117032  Vali Loss: 0.1465969 Vali Accuracy: 0.9408428  Vali weighted F1: 0.9403030  Vali macro F1 0.7967457 \n",
      "EarlyStopping counter: 3 out of 15\n",
      "Learning rate adjusting counter: 3 out of 5\n",
      "Epoch: 20 cost time: 110.23654747009277\n",
      "VALI: Epoch: 20, Steps: 44 | Train Loss: 0.1032575  Vali Loss: 0.1174042 Vali Accuracy: 0.9538088  Vali weighted F1: 0.9530443  Vali macro F1 0.8374946 \n",
      "new best score!!!!\n",
      "Validation loss decreased (0.126479 --> 0.117404).  Saving model ...\n",
      "new best score!!!!\n",
      "Epoch: 21 cost time: 108.47892880439758\n",
      "VALI: Epoch: 21, Steps: 44 | Train Loss: 0.0876268  Vali Loss: 0.1111282 Vali Accuracy: 0.9586710  Vali weighted F1: 0.9583510  Vali macro F1 0.8469610 \n",
      "new best score!!!!\n",
      "Validation loss decreased (0.117404 --> 0.111128).  Saving model ...\n",
      "new best score!!!!\n",
      "Epoch: 22 cost time: 108.56198120117188\n",
      "VALI: Epoch: 22, Steps: 44 | Train Loss: 0.0833669  Vali Loss: 0.1495005 Vali Accuracy: 0.9465154  Vali weighted F1: 0.9458651  Vali macro F1 0.8240267 \n",
      "EarlyStopping counter: 1 out of 15\n",
      "Learning rate adjusting counter: 1 out of 5\n",
      "Epoch: 23 cost time: 107.77888679504395\n",
      "VALI: Epoch: 23, Steps: 44 | Train Loss: 0.0864997  Vali Loss: 0.1324714 Vali Accuracy: 0.9538088  Vali weighted F1: 0.9534639  Vali macro F1 0.8584682 \n",
      "EarlyStopping counter: 2 out of 15\n",
      "Learning rate adjusting counter: 2 out of 5\n",
      "Epoch: 24 cost time: 108.26661038398743\n",
      "VALI: Epoch: 24, Steps: 44 | Train Loss: 0.0819425  Vali Loss: 0.1188528 Vali Accuracy: 0.9521880  Vali weighted F1: 0.9515387  Vali macro F1 0.8090318 \n",
      "EarlyStopping counter: 3 out of 15\n",
      "Learning rate adjusting counter: 3 out of 5\n",
      "Epoch: 25 cost time: 107.83711838722229\n",
      "VALI: Epoch: 25, Steps: 44 | Train Loss: 0.0905979  Vali Loss: 0.1295274 Vali Accuracy: 0.9513776  Vali weighted F1: 0.9506806  Vali macro F1 0.8152149 \n",
      "EarlyStopping counter: 4 out of 15\n",
      "Learning rate adjusting counter: 4 out of 5\n",
      "Epoch: 26 cost time: 107.64811253547668\n",
      "VALI: Epoch: 26, Steps: 44 | Train Loss: 0.0778404  Vali Loss: 0.1236424 Vali Accuracy: 0.9578606  Vali weighted F1: 0.9573022  Vali macro F1 0.8333572 \n",
      "EarlyStopping counter: 5 out of 15\n",
      "Learning rate adjusting counter: 5 out of 5\n",
      "Updating learning rate to 0.0001\n"
     ]
    }
   ],
   "source": [
    "exp.train()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "SDIL",
   "language": "python",
   "name": "sdil"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.13"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": true
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
