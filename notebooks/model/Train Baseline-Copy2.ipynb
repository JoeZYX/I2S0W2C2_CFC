{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "894e2c21",
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "import sys\n",
    "sys.path.append(\"../../\")\n",
    "\n",
    "from experiment import Exp\n",
    "\n",
    "from dataloaders import data_set,data_dict\n",
    "import torch\n",
    "import yaml\n",
    "import os"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bcc56bc7",
   "metadata": {},
   "source": [
    "# 参数设置"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dcc5bcbc",
   "metadata": {
    "tags": []
   },
   "source": [
    "# 训练参数 \n",
    "除了路径 其他不要变"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "86004ce0",
   "metadata": {},
   "outputs": [],
   "source": [
    "class dotdict(dict):\n",
    "    \"\"\"dot.notation access to dictionary attributes\"\"\"\n",
    "    __getattr__ = dict.get\n",
    "    __setattr__ = dict.__setitem__\n",
    "    __delattr__ = dict.__delitem__\n",
    "\n",
    "args = dotdict()   \n",
    "# TODO change the path as relative path\n",
    "args.to_save_path     = \"../../../ISWC2022LearnableFilter/Run_logs\"              \n",
    "args.freq_save_path   = \"../../../ISWC2022LearnableFilter/Freq_data\"\n",
    "args.window_save_path = \"../../../ISWC2022LearnableFilter/Sliding_window\"\n",
    "args.root_path        = \"../../../datasets\"\n",
    "\n",
    "\n",
    "args.drop_transition  = False\n",
    "args.datanorm_type    = \"standardization\" # None ,\"standardization\", \"minmax\"\n",
    "\n",
    "\n",
    "args.batch_size       = 256                                                    \n",
    "args.shuffle          = True\n",
    "args.drop_last        = False\n",
    "args.train_vali_quote = 0.90                                           \n",
    "\n",
    "\n",
    "# training setting \n",
    "args.train_epochs            = 150\n",
    "\n",
    "args.learning_rate           = 0.001  \n",
    "args.learning_rate_patience  = 5\n",
    "args.learning_rate_factor    = 0.1\n",
    "\n",
    "\n",
    "args.early_stop_patience     = 15\n",
    "\n",
    "args.use_gpu                 = True if torch.cuda.is_available() else False\n",
    "args.gpu                     = 2\n",
    "args.use_multi_gpu           = False\n",
    "\n",
    "args.optimizer               = \"Adam\"\n",
    "args.criterion               = \"CrossEntropy\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c282cbcb",
   "metadata": {},
   "source": [
    "## 数据参数\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "c6cd147b",
   "metadata": {},
   "outputs": [],
   "source": [
    "args.data_name                        =  \"dg\"\n",
    "\n",
    "args.wavelet_filtering                = False\n",
    "args.wavelet_filtering_regularization = False\n",
    "args.wavelet_filtering_finetuning     = False\n",
    "\n",
    "\n",
    "args.difference       = False \n",
    "args.filtering        = False\n",
    "args.magnitude        = False\n",
    "args.weighted_sampler = False\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "args.pos_select       = None\n",
    "args.sensor_select    = None\n",
    "\n",
    "\n",
    "args.representation_type = \"time\"\n",
    "args.exp_mode            = \"LOCV\"\n",
    "if args.data_name      ==  \"skodar\":\n",
    "    args.exp_mode            = \"SOCV\"\n",
    "\n",
    "config_file = open('../../configs/data.yaml', mode='r')\n",
    "data_config = yaml.load(config_file, Loader=yaml.FullLoader)\n",
    "config = data_config[args.data_name]\n",
    "\n",
    "args.root_path       = os.path.join(args.root_path,config[\"filename\"])\n",
    "args.sampling_freq   = config[\"sampling_freq\"]\n",
    "args.num_classes     =  config[\"num_classes\"]\n",
    "window_seconds       = config[\"window_seconds\"]\n",
    "args.windowsize      =   int(window_seconds * args.sampling_freq) \n",
    "args.input_length    =  args.windowsize\n",
    "# input information\n",
    "args.c_in            = config[\"num_channels\"]\n",
    "\n",
    "if args.wavelet_filtering :\n",
    "    \n",
    "    if args.windowsize%2==1:\n",
    "        N_ds = int(torch.log2(torch.tensor(args.windowsize-1)).floor()) - 2\n",
    "    else:\n",
    "        N_ds = int(torch.log2(torch.tensor(args.windowsize)).floor()) - 2\n",
    "\n",
    "    args.f_in            =  args.number_wavelet_filtering*N_ds+1\n",
    "else:\n",
    "    args.f_in            =  1"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4d435a4c",
   "metadata": {},
   "source": [
    "## 模型参数"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "de2f4d16",
   "metadata": {},
   "outputs": [],
   "source": [
    "args.filter_scaling_factor = 0.75\n",
    "args.model_type            = \"deepconvlstm\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cada66dd",
   "metadata": {},
   "source": [
    "# 实验"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2e3f2fad",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Use GPU: cuda:2\n",
      "Build the DeepConvLSTM model!\n",
      "Done!\n",
      "Parameter : 238706\n",
      "Set the seed as :  1\n",
      " ----------------------- load all the data -------------------\n",
      "-----------------------Sliding file are generated -----------------------\n",
      "-----------------------Sliding file are generated -----------------------\n",
      "================ LOCV Mode ====================\n",
      "================ 10 CV ======================\n",
      "================ the 0 th CV Experiment ================ \n",
      "Leave one Out Experiment : The 1 Part as the test\n",
      "[-] Target sampling weights:  [3.88198758e-05 3.44234079e-04]\n",
      "Train data number :  28665\n",
      "The number of classes is :  2\n",
      "The input_length  is :  64\n",
      "The channel_in is :  9\n",
      "Validation data number :  3185\n",
      "Test data number :  20267\n",
      "================Skip the 0 CV Experiment================\n",
      "================ the 1 th CV Experiment ================ \n",
      "Leave one Out Experiment : The 2 Part as the test\n",
      "[-] Target sampling weights:  [3.73566439e-05 3.61141206e-04]\n",
      "Train data number :  29538\n",
      "The number of classes is :  2\n",
      "The input_length  is :  64\n",
      "The channel_in is :  9\n",
      "Validation data number :  3282\n",
      "Test data number :  15093\n",
      "================Skip the 1 CV Experiment================\n",
      "================ the 2 th CV Experiment ================ \n",
      "Leave one Out Experiment : The 3 Part as the test\n",
      "[-] Target sampling weights:  [3.86100386e-05 3.89559797e-04]\n",
      "Train data number :  28467\n",
      "The number of classes is :  2\n",
      "The input_length  is :  64\n",
      "The channel_in is :  9\n",
      "Validation data number :  3163\n",
      "Test data number :  21440\n",
      "================Skip the 2 CV Experiment================\n",
      "================ the 3 th CV Experiment ================ \n",
      "Leave one Out Experiment : The 4 Part as the test\n",
      "[-] Target sampling weights:  [3.95600918e-05 3.24569945e-04]\n",
      "Train data number :  28359\n",
      "The number of classes is :  2\n",
      "The input_length  is :  64\n",
      "The channel_in is :  9\n",
      "Validation data number :  3151\n",
      "Test data number :  22080\n",
      "================Skip the 3 CV Experiment================\n",
      "================ the 4 th CV Experiment ================ \n",
      "Leave one Out Experiment : The 5 Part as the test\n",
      "[-] Target sampling weights:  [3.83420881e-05 4.46030330e-04]\n",
      "Train data number :  28323\n",
      "The number of classes is :  2\n",
      "The input_length  is :  64\n",
      "The channel_in is :  9\n",
      "Validation data number :  3147\n",
      "Test data number :  22294\n",
      "================Skip the 4 CV Experiment================\n",
      "================ the 5 th CV Experiment ================ \n",
      "Leave one Out Experiment : The 6 Part as the test\n",
      "[-] Target sampling weights:  [3.89741991e-05 3.51493849e-04]\n",
      "Train data number :  28503\n",
      "The number of classes is :  2\n",
      "The input_length  is :  64\n",
      "The channel_in is :  9\n",
      "Validation data number :  3167\n",
      "Test data number :  21227\n",
      "================Skip the 5 CV Experiment================\n",
      "================ the 6 th CV Experiment ================ \n",
      "Leave one Out Experiment : The 7 Part as the test\n",
      "[-] Target sampling weights:  [3.81271923e-05 3.37952011e-04]\n",
      "Train data number :  29187\n",
      "The number of classes is :  2\n",
      "The input_length  is :  64\n",
      "The channel_in is :  9\n",
      "Validation data number :  3243\n",
      "Test data number :  17173\n",
      "================Skip the 6 CV Experiment================\n",
      "================ the 7 th CV Experiment ================ \n",
      "Leave one Out Experiment : The 8 Part as the test\n",
      "[-] Target sampling weights:  [3.57347055e-05 3.68324125e-04]\n",
      "Train data number :  30699\n",
      "The number of classes is :  2\n",
      "The input_length  is :  64\n",
      "The channel_in is :  9\n",
      "Validation data number :  3411\n",
      "Test data number :  8214\n",
      "================Skip the 7 CV Experiment================\n",
      "================ the 8 th CV Experiment ================ \n",
      "Leave one Out Experiment : The 9 Part as the test\n",
      "[-] Target sampling weights:  [3.79650721e-05 3.82701875e-04]\n",
      "Train data number :  28953\n",
      "The number of classes is :  2\n",
      "The input_length  is :  64\n",
      "The channel_in is :  9\n",
      "Validation data number :  3217\n",
      "Test data number :  18560\n",
      "================Skip the 8 CV Experiment================\n",
      "================ the 9 th CV Experiment ================ \n",
      "Leave one Out Experiment : The 10 Part as the test\n",
      "[-] Target sampling weights:  [4.00432467e-05 3.22788896e-04]\n",
      "Train data number :  28071\n",
      "The number of classes is :  2\n",
      "The input_length  is :  64\n",
      "The channel_in is :  9\n",
      "Validation data number :  3119\n",
      "Test data number :  23786\n",
      "================Skip the 9 CV Experiment================\n",
      "Use GPU: cuda:2\n",
      "Build the DeepConvLSTM model!\n",
      "Done!\n",
      "Parameter : 238706\n",
      "Set the seed as :  2\n",
      " ----------------------- load all the data -------------------\n",
      "-----------------------Sliding file are generated -----------------------\n",
      "-----------------------Sliding file are generated -----------------------\n",
      "================ LOCV Mode ====================\n",
      "================ 10 CV ======================\n",
      "================ the 0 th CV Experiment ================ \n",
      "Leave one Out Experiment : The 1 Part as the test\n",
      "[-] Target sampling weights:  [3.88485296e-05 3.41997264e-04]\n",
      "Train data number :  28665\n",
      "The number of classes is :  2\n",
      "The input_length  is :  64\n",
      "The channel_in is :  9\n",
      "Validation data number :  3185\n",
      "Test data number :  20267\n",
      "================ Build the model ================ \n",
      "Build the DeepConvLSTM model!\n",
      "Epoch: 1 cost time: 12.222505569458008\n",
      "VALI: Epoch: 1, Steps: 112 | Train Loss: 0.3087239  Vali Loss: 0.2345397 Vali Accuracy: 0.9014129  Vali weighted F1: 0.8576368  Vali macro F1 0.4982490 \n",
      "Validation loss decreased (inf --> 0.234540).  Saving model ...\n",
      "Epoch: 2 cost time: 8.150200843811035\n",
      "VALI: Epoch: 2, Steps: 112 | Train Loss: 0.2091966  Vali Loss: 0.1736598 Vali Accuracy: 0.9233909  Vali weighted F1: 0.9188713  Vali macro F1 0.7634323 \n",
      "new best score!!!!\n",
      "Validation loss decreased (0.234540 --> 0.173660).  Saving model ...\n",
      "new best score!!!!\n",
      "Epoch: 3 cost time: 8.128341674804688\n",
      "VALI: Epoch: 3, Steps: 112 | Train Loss: 0.1778723  Vali Loss: 0.1685990 Vali Accuracy: 0.9237049  Vali weighted F1: 0.9263540  Vali macro F1 0.8037702 \n",
      "new best score!!!!\n",
      "Validation loss decreased (0.173660 --> 0.168599).  Saving model ...\n",
      "new best score!!!!\n",
      "Epoch: 4 cost time: 8.147747993469238\n",
      "VALI: Epoch: 4, Steps: 112 | Train Loss: 0.1670814  Vali Loss: 0.1551739 Vali Accuracy: 0.9315542  Vali weighted F1: 0.9292884  Vali macro F1 0.7982364 \n",
      "new best score!!!!\n",
      "Validation loss decreased (0.168599 --> 0.155174).  Saving model ...\n",
      "new best score!!!!\n",
      "Epoch: 5 cost time: 8.140263557434082\n",
      "VALI: Epoch: 5, Steps: 112 | Train Loss: 0.1604384  Vali Loss: 0.1511209 Vali Accuracy: 0.9321821  Vali weighted F1: 0.9316050  Vali macro F1 0.8092167 \n",
      "new best score!!!!\n",
      "Validation loss decreased (0.155174 --> 0.151121).  Saving model ...\n",
      "new best score!!!!\n",
      "Epoch: 6 cost time: 8.174117088317871\n",
      "VALI: Epoch: 6, Steps: 112 | Train Loss: 0.1524854  Vali Loss: 0.1539514 Vali Accuracy: 0.9318681  Vali weighted F1: 0.9333412  Vali macro F1 0.8197365 \n",
      "EarlyStopping counter: 1 out of 15\n",
      "Learning rate adjusting counter: 1 out of 5\n",
      "Epoch: 7 cost time: 8.134803771972656\n",
      "VALI: Epoch: 7, Steps: 112 | Train Loss: 0.1471838  Vali Loss: 0.1510702 Vali Accuracy: 0.9321821  Vali weighted F1: 0.9335219  Vali macro F1 0.8198586 \n",
      "new best score!!!!\n",
      "Validation loss decreased (0.151121 --> 0.151070).  Saving model ...\n",
      "new best score!!!!\n",
      "Epoch: 8 cost time: 8.128470420837402\n",
      "VALI: Epoch: 8, Steps: 112 | Train Loss: 0.1430749  Vali Loss: 0.1394270 Vali Accuracy: 0.9394035  Vali weighted F1: 0.9395289  Vali macro F1 0.8330722 \n",
      "new best score!!!!\n",
      "Validation loss decreased (0.151070 --> 0.139427).  Saving model ...\n",
      "new best score!!!!\n",
      "Epoch: 9 cost time: 8.122644424438477\n",
      "VALI: Epoch: 9, Steps: 112 | Train Loss: 0.1405903  Vali Loss: 0.1435240 Vali Accuracy: 0.9365777  Vali weighted F1: 0.9372624  Vali macro F1 0.8283607 \n",
      "EarlyStopping counter: 1 out of 15\n",
      "Learning rate adjusting counter: 1 out of 5\n",
      "Epoch: 10 cost time: 8.138257503509521\n",
      "VALI: Epoch: 10, Steps: 112 | Train Loss: 0.1383869  Vali Loss: 0.1456092 Vali Accuracy: 0.9372057  Vali weighted F1: 0.9368520  Vali macro F1 0.8243445 \n",
      "EarlyStopping counter: 2 out of 15\n",
      "Learning rate adjusting counter: 2 out of 5\n",
      "Epoch: 11 cost time: 8.148239612579346\n",
      "VALI: Epoch: 11, Steps: 112 | Train Loss: 0.1342906  Vali Loss: 0.1374933 Vali Accuracy: 0.9437991  Vali weighted F1: 0.9422551  Vali macro F1 0.8360561 \n",
      "new best score!!!!\n",
      "Validation loss decreased (0.139427 --> 0.137493).  Saving model ...\n",
      "new best score!!!!\n",
      "Epoch: 12 cost time: 8.11387324333191\n",
      "VALI: Epoch: 12, Steps: 112 | Train Loss: 0.1300412  Vali Loss: 0.1370173 Vali Accuracy: 0.9387755  Vali weighted F1: 0.9380307  Vali macro F1 0.8265338 \n",
      "new best score!!!!\n",
      "Validation loss decreased (0.137493 --> 0.137017).  Saving model ...\n",
      "new best score!!!!\n",
      "Epoch: 13 cost time: 8.127058506011963\n",
      "VALI: Epoch: 13, Steps: 112 | Train Loss: 0.1284324  Vali Loss: 0.1334097 Vali Accuracy: 0.9419152  Vali weighted F1: 0.9423501  Vali macro F1 0.8417367 \n",
      "new best score!!!!\n",
      "Validation loss decreased (0.137017 --> 0.133410).  Saving model ...\n",
      "new best score!!!!\n",
      "Epoch: 14 cost time: 8.09164571762085\n",
      "VALI: Epoch: 14, Steps: 112 | Train Loss: 0.1266546  Vali Loss: 0.1338092 Vali Accuracy: 0.9428571  Vali weighted F1: 0.9435487  Vali macro F1 0.8457708 \n",
      "EarlyStopping counter: 1 out of 15\n",
      "Learning rate adjusting counter: 1 out of 5\n",
      "Epoch: 15 cost time: 8.097544193267822\n",
      "VALI: Epoch: 15, Steps: 112 | Train Loss: 0.1238654  Vali Loss: 0.1389857 Vali Accuracy: 0.9397174  Vali weighted F1: 0.9406801  Vali macro F1 0.8385973 \n",
      "EarlyStopping counter: 2 out of 15\n",
      "Learning rate adjusting counter: 2 out of 5\n",
      "Epoch: 16 cost time: 8.136037826538086\n",
      "VALI: Epoch: 16, Steps: 112 | Train Loss: 0.1217700  Vali Loss: 0.1308239 Vali Accuracy: 0.9441130  Vali weighted F1: 0.9437983  Vali macro F1 0.8436666 \n",
      "new best score!!!!\n",
      "Validation loss decreased (0.133410 --> 0.130824).  Saving model ...\n",
      "new best score!!!!\n",
      "Epoch: 17 cost time: 8.102339029312134\n",
      "VALI: Epoch: 17, Steps: 112 | Train Loss: 0.1224970  Vali Loss: 0.1311300 Vali Accuracy: 0.9425432  Vali weighted F1: 0.9434240  Vali macro F1 0.8459580 \n",
      "EarlyStopping counter: 1 out of 15\n",
      "Learning rate adjusting counter: 1 out of 5\n",
      "Epoch: 18 cost time: 8.083308219909668\n",
      "VALI: Epoch: 18, Steps: 112 | Train Loss: 0.1175972  Vali Loss: 0.1471782 Vali Accuracy: 0.9277865  Vali weighted F1: 0.9325806  Vali macro F1 0.8273991 \n",
      "EarlyStopping counter: 2 out of 15\n",
      "Learning rate adjusting counter: 2 out of 5\n",
      "Epoch: 19 cost time: 8.058298587799072\n",
      "VALI: Epoch: 19, Steps: 112 | Train Loss: 0.1177423  Vali Loss: 0.1310348 Vali Accuracy: 0.9422292  Vali weighted F1: 0.9435848  Vali macro F1 0.8477480 \n",
      "EarlyStopping counter: 3 out of 15\n",
      "Learning rate adjusting counter: 3 out of 5\n",
      "Epoch: 20 cost time: 8.080353021621704\n",
      "VALI: Epoch: 20, Steps: 112 | Train Loss: 0.1140096  Vali Loss: 0.1288481 Vali Accuracy: 0.9459969  Vali weighted F1: 0.9470638  Vali macro F1 0.8565541 \n",
      "new best score!!!!\n",
      "Validation loss decreased (0.130824 --> 0.128848).  Saving model ...\n",
      "new best score!!!!\n",
      "Epoch: 21 cost time: 8.09449553489685\n",
      "VALI: Epoch: 21, Steps: 112 | Train Loss: 0.1125791  Vali Loss: 0.1270419 Vali Accuracy: 0.9447410  Vali weighted F1: 0.9454097  Vali macro F1 0.8508552 \n",
      "new best score!!!!\n",
      "Validation loss decreased (0.128848 --> 0.127042).  Saving model ...\n",
      "new best score!!!!\n",
      "Epoch: 22 cost time: 8.109595537185669\n",
      "VALI: Epoch: 22, Steps: 112 | Train Loss: 0.1123547  Vali Loss: 0.1264309 Vali Accuracy: 0.9466248  Vali weighted F1: 0.9467719  Vali macro F1 0.8531679 \n",
      "new best score!!!!\n",
      "Validation loss decreased (0.127042 --> 0.126431).  Saving model ...\n",
      "new best score!!!!\n",
      "Epoch: 23 cost time: 8.085407733917236\n",
      "VALI: Epoch: 23, Steps: 112 | Train Loss: 0.1086045  Vali Loss: 0.1235025 Vali Accuracy: 0.9469388  Vali weighted F1: 0.9477522  Vali macro F1 0.8577426 \n",
      "new best score!!!!\n",
      "Validation loss decreased (0.126431 --> 0.123502).  Saving model ...\n",
      "new best score!!!!\n",
      "Epoch: 24 cost time: 8.098540544509888\n",
      "VALI: Epoch: 24, Steps: 112 | Train Loss: 0.1071248  Vali Loss: 0.1228956 Vali Accuracy: 0.9497645  Vali weighted F1: 0.9497645  Vali macro F1 0.8610384 \n",
      "new best score!!!!\n",
      "Validation loss decreased (0.123502 --> 0.122896).  Saving model ...\n",
      "new best score!!!!\n",
      "Epoch: 25 cost time: 8.118300437927246\n",
      "VALI: Epoch: 25, Steps: 112 | Train Loss: 0.1057850  Vali Loss: 0.1250420 Vali Accuracy: 0.9450549  Vali weighted F1: 0.9459674  Vali macro F1 0.8530836 \n",
      "EarlyStopping counter: 1 out of 15\n",
      "Learning rate adjusting counter: 1 out of 5\n",
      "Epoch: 26 cost time: 8.092426776885986\n",
      "VALI: Epoch: 26, Steps: 112 | Train Loss: 0.1016334  Vali Loss: 0.1270284 Vali Accuracy: 0.9459969  Vali weighted F1: 0.9467205  Vali macro F1 0.8546357 \n",
      "EarlyStopping counter: 2 out of 15\n",
      "Learning rate adjusting counter: 2 out of 5\n",
      "Epoch: 27 cost time: 8.133722066879272\n",
      "VALI: Epoch: 27, Steps: 112 | Train Loss: 0.0988555  Vali Loss: 0.1215381 Vali Accuracy: 0.9469388  Vali weighted F1: 0.9474066  Vali macro F1 0.8558168 \n",
      "new best score!!!!\n",
      "Validation loss decreased (0.122896 --> 0.121538).  Saving model ...\n",
      "new best score!!!!\n",
      "Epoch: 28 cost time: 8.104863405227661\n",
      "VALI: Epoch: 28, Steps: 112 | Train Loss: 0.0976076  Vali Loss: 0.1301691 Vali Accuracy: 0.9441130  Vali weighted F1: 0.9448619  Vali macro F1 0.8495648 \n",
      "EarlyStopping counter: 1 out of 15\n",
      "Learning rate adjusting counter: 1 out of 5\n",
      "Epoch: 29 cost time: 8.083375692367554\n",
      "VALI: Epoch: 29, Steps: 112 | Train Loss: 0.0982946  Vali Loss: 0.1317833 Vali Accuracy: 0.9475667  Vali weighted F1: 0.9485698  Vali macro F1 0.8605403 \n",
      "EarlyStopping counter: 2 out of 15\n",
      "Learning rate adjusting counter: 2 out of 5\n",
      "Epoch: 30 cost time: 8.079034090042114\n",
      "VALI: Epoch: 30, Steps: 112 | Train Loss: 0.0944254  Vali Loss: 0.1225224 Vali Accuracy: 0.9485086  Vali weighted F1: 0.9495900  Vali macro F1 0.8635852 \n",
      "EarlyStopping counter: 3 out of 15\n",
      "Learning rate adjusting counter: 3 out of 5\n",
      "Epoch: 31 cost time: 8.092876434326172\n",
      "VALI: Epoch: 31, Steps: 112 | Train Loss: 0.0937266  Vali Loss: 0.1275596 Vali Accuracy: 0.9481947  Vali weighted F1: 0.9476406  Vali macro F1 0.8536397 \n",
      "EarlyStopping counter: 4 out of 15\n",
      "Learning rate adjusting counter: 4 out of 5\n",
      "Epoch: 32 cost time: 8.1268630027771\n",
      "VALI: Epoch: 32, Steps: 112 | Train Loss: 0.0898012  Vali Loss: 0.1234192 Vali Accuracy: 0.9491366  Vali weighted F1: 0.9495513  Vali macro F1 0.8616011 \n",
      "EarlyStopping counter: 5 out of 15\n",
      "Learning rate adjusting counter: 5 out of 5\n",
      "Updating learning rate to 0.0001\n",
      "Epoch: 33 cost time: 8.123522281646729\n",
      "VALI: Epoch: 33, Steps: 112 | Train Loss: 0.0813145  Vali Loss: 0.1206161 Vali Accuracy: 0.9491366  Vali weighted F1: 0.9496857  Vali macro F1 0.8623487 \n",
      "new best score!!!!\n",
      "Validation loss decreased (0.121538 --> 0.120616).  Saving model ...\n",
      "new best score!!!!\n",
      "Epoch: 34 cost time: 8.107835531234741\n",
      "VALI: Epoch: 34, Steps: 112 | Train Loss: 0.0792516  Vali Loss: 0.1212985 Vali Accuracy: 0.9488226  Vali weighted F1: 0.9494086  Vali macro F1 0.8616856 \n",
      "EarlyStopping counter: 1 out of 15\n",
      "Learning rate adjusting counter: 1 out of 5\n",
      "Epoch: 35 cost time: 8.09264612197876\n",
      "VALI: Epoch: 35, Steps: 112 | Train Loss: 0.0779333  Vali Loss: 0.1222928 Vali Accuracy: 0.9510204  Vali weighted F1: 0.9517399  Vali macro F1 0.8685102 \n",
      "EarlyStopping counter: 2 out of 15\n",
      "Learning rate adjusting counter: 2 out of 5\n",
      "Epoch: 36 cost time: 8.089589595794678\n",
      "VALI: Epoch: 36, Steps: 112 | Train Loss: 0.0769740  Vali Loss: 0.1221225 Vali Accuracy: 0.9485086  Vali weighted F1: 0.9488597  Vali macro F1 0.8595105 \n",
      "EarlyStopping counter: 3 out of 15\n",
      "Learning rate adjusting counter: 3 out of 5\n",
      "Epoch: 37 cost time: 8.11991286277771\n",
      "VALI: Epoch: 37, Steps: 112 | Train Loss: 0.0784496  Vali Loss: 0.1210459 Vali Accuracy: 0.9513344  Vali weighted F1: 0.9519550  Vali macro F1 0.8688273 \n",
      "EarlyStopping counter: 4 out of 15\n",
      "Learning rate adjusting counter: 4 out of 5\n",
      "Epoch: 38 cost time: 8.112169981002808\n",
      "VALI: Epoch: 38, Steps: 112 | Train Loss: 0.0760090  Vali Loss: 0.1215825 Vali Accuracy: 0.9513344  Vali weighted F1: 0.9519550  Vali macro F1 0.8688273 \n",
      "EarlyStopping counter: 5 out of 15\n",
      "Learning rate adjusting counter: 5 out of 5\n",
      "Updating learning rate to 1e-05\n",
      "Epoch: 39 cost time: 8.083556652069092\n",
      "VALI: Epoch: 39, Steps: 112 | Train Loss: 0.0749361  Vali Loss: 0.1216963 Vali Accuracy: 0.9519623  Vali weighted F1: 0.9526988  Vali macro F1 0.8712108 \n",
      "EarlyStopping counter: 6 out of 15\n",
      "Learning rate adjusting counter: 1 out of 5\n",
      "Epoch: 40 cost time: 8.094244718551636\n",
      "VALI: Epoch: 40, Steps: 112 | Train Loss: 0.0752519  Vali Loss: 0.1215342 Vali Accuracy: 0.9519623  Vali weighted F1: 0.9526988  Vali macro F1 0.8712108 \n",
      "EarlyStopping counter: 7 out of 15\n",
      "Learning rate adjusting counter: 2 out of 5\n",
      "Epoch: 41 cost time: 8.11610460281372\n",
      "VALI: Epoch: 41, Steps: 112 | Train Loss: 0.0742618  Vali Loss: 0.1216101 Vali Accuracy: 0.9519623  Vali weighted F1: 0.9526988  Vali macro F1 0.8712108 \n",
      "EarlyStopping counter: 8 out of 15\n",
      "Learning rate adjusting counter: 3 out of 5\n",
      "Epoch: 42 cost time: 8.106061935424805\n",
      "VALI: Epoch: 42, Steps: 112 | Train Loss: 0.0743990  Vali Loss: 0.1215592 Vali Accuracy: 0.9522763  Vali weighted F1: 0.9529158  Vali macro F1 0.8715385 \n",
      "EarlyStopping counter: 9 out of 15\n",
      "Learning rate adjusting counter: 4 out of 5\n",
      "Epoch: 43 cost time: 8.099796056747437\n",
      "VALI: Epoch: 43, Steps: 112 | Train Loss: 0.0745979  Vali Loss: 0.1215792 Vali Accuracy: 0.9519623  Vali weighted F1: 0.9525749  Vali macro F1 0.8705198 \n",
      "EarlyStopping counter: 10 out of 15\n",
      "Learning rate adjusting counter: 5 out of 5\n",
      "Updating learning rate to 1.0000000000000002e-06\n",
      "Epoch: 44 cost time: 8.070825815200806\n",
      "VALI: Epoch: 44, Steps: 112 | Train Loss: 0.0747544  Vali Loss: 0.1216099 Vali Accuracy: 0.9522763  Vali weighted F1: 0.9529158  Vali macro F1 0.8715385 \n",
      "EarlyStopping counter: 11 out of 15\n",
      "Learning rate adjusting counter: 1 out of 5\n",
      "Epoch: 45 cost time: 8.0926194190979\n",
      "VALI: Epoch: 45, Steps: 112 | Train Loss: 0.0749141  Vali Loss: 0.1216216 Vali Accuracy: 0.9522763  Vali weighted F1: 0.9529158  Vali macro F1 0.8715385 \n",
      "EarlyStopping counter: 12 out of 15\n",
      "Learning rate adjusting counter: 2 out of 5\n",
      "Epoch: 46 cost time: 8.077637434005737\n",
      "VALI: Epoch: 46, Steps: 112 | Train Loss: 0.0737505  Vali Loss: 0.1216035 Vali Accuracy: 0.9522763  Vali weighted F1: 0.9529158  Vali macro F1 0.8715385 \n",
      "EarlyStopping counter: 13 out of 15\n",
      "Learning rate adjusting counter: 3 out of 5\n",
      "Epoch: 47 cost time: 8.0870361328125\n",
      "VALI: Epoch: 47, Steps: 112 | Train Loss: 0.0741647  Vali Loss: 0.1216314 Vali Accuracy: 0.9522763  Vali weighted F1: 0.9529158  Vali macro F1 0.8715385 \n",
      "EarlyStopping counter: 14 out of 15\n",
      "Learning rate adjusting counter: 4 out of 5\n",
      "Epoch: 48 cost time: 8.064819574356079\n",
      "VALI: Epoch: 48, Steps: 112 | Train Loss: 0.0740022  Vali Loss: 0.1216238 Vali Accuracy: 0.9522763  Vali weighted F1: 0.9529158  Vali macro F1 0.8715385 \n",
      "EarlyStopping counter: 15 out of 15\n",
      "Early stopping\n",
      "Loading the best validation model!\n",
      "Final Test Performance : Test Accuracy: 0.9200671  Test weighted F1: 0.9237925  Test macro F1 0.6505202 \n",
      "================ the 1 th CV Experiment ================ \n",
      "Leave one Out Experiment : The 2 Part as the test\n",
      "[-] Target sampling weights:  [3.73636228e-05 3.60490267e-04]\n",
      "Train data number :  29538\n",
      "The number of classes is :  2\n",
      "The input_length  is :  64\n",
      "The channel_in is :  9\n",
      "Validation data number :  3282\n",
      "Test data number :  15093\n",
      "================ Build the model ================ \n",
      "Build the DeepConvLSTM model!\n",
      "Epoch: 1 cost time: 8.39802861213684\n",
      "VALI: Epoch: 1, Steps: 116 | Train Loss: 0.2869580  Vali Loss: 0.2378490 Vali Accuracy: 0.8957952  Vali weighted F1: 0.8768853  Vali macro F1 0.5953611 \n",
      "Validation loss decreased (inf --> 0.237849).  Saving model ...\n",
      "Epoch: 2 cost time: 8.43644642829895\n",
      "VALI: Epoch: 2, Steps: 116 | Train Loss: 0.2074121  Vali Loss: 0.1835122 Vali Accuracy: 0.9171237  Vali weighted F1: 0.9185787  Vali macro F1 0.7702856 \n",
      "new best score!!!!\n",
      "Validation loss decreased (0.237849 --> 0.183512).  Saving model ...\n",
      "new best score!!!!\n",
      "Epoch: 3 cost time: 8.373862266540527\n",
      "VALI: Epoch: 3, Steps: 116 | Train Loss: 0.1757385  Vali Loss: 0.1531349 Vali Accuracy: 0.9363193  Vali weighted F1: 0.9342240  Vali macro F1 0.8050911 \n",
      "new best score!!!!\n",
      "Validation loss decreased (0.183512 --> 0.153135).  Saving model ...\n",
      "new best score!!!!\n",
      "Epoch: 4 cost time: 8.386411905288696\n",
      "VALI: Epoch: 4, Steps: 116 | Train Loss: 0.1613764  Vali Loss: 0.1441698 Vali Accuracy: 0.9363193  Vali weighted F1: 0.9364536  Vali macro F1 0.8178078 \n",
      "new best score!!!!\n",
      "Validation loss decreased (0.153135 --> 0.144170).  Saving model ...\n",
      "new best score!!!!\n",
      "Epoch: 5 cost time: 8.340693712234497\n",
      "VALI: Epoch: 5, Steps: 116 | Train Loss: 0.1512308  Vali Loss: 0.1379507 Vali Accuracy: 0.9393662  Vali weighted F1: 0.9388853  Vali macro F1 0.8230322 \n",
      "new best score!!!!\n",
      "Validation loss decreased (0.144170 --> 0.137951).  Saving model ...\n",
      "new best score!!!!\n",
      "Epoch: 6 cost time: 8.353710889816284\n",
      "VALI: Epoch: 6, Steps: 116 | Train Loss: 0.1444707  Vali Loss: 0.1350466 Vali Accuracy: 0.9424132  Vali weighted F1: 0.9425346  Vali macro F1 0.8352425 \n",
      "new best score!!!!\n",
      "Validation loss decreased (0.137951 --> 0.135047).  Saving model ...\n",
      "new best score!!!!\n",
      "Epoch: 7 cost time: 8.347061157226562\n",
      "VALI: Epoch: 7, Steps: 116 | Train Loss: 0.1410028  Vali Loss: 0.1367894 Vali Accuracy: 0.9378428  Vali weighted F1: 0.9392502  Vali macro F1 0.8295528 \n",
      "EarlyStopping counter: 1 out of 15\n",
      "Learning rate adjusting counter: 1 out of 5\n",
      "Epoch: 8 cost time: 8.345649719238281\n",
      "VALI: Epoch: 8, Steps: 116 | Train Loss: 0.1367514  Vali Loss: 0.1332455 Vali Accuracy: 0.9405850  Vali weighted F1: 0.9396688  Vali macro F1 0.8240472 \n",
      "new best score!!!!\n",
      "Validation loss decreased (0.135047 --> 0.133245).  Saving model ...\n",
      "new best score!!!!\n",
      "Epoch: 9 cost time: 8.406227827072144\n",
      "VALI: Epoch: 9, Steps: 116 | Train Loss: 0.1340478  Vali Loss: 0.1304440 Vali Accuracy: 0.9439366  Vali weighted F1: 0.9447752  Vali macro F1 0.8437604 \n",
      "new best score!!!!\n",
      "Validation loss decreased (0.133245 --> 0.130444).  Saving model ...\n",
      "new best score!!!!\n",
      "Epoch: 10 cost time: 8.352460384368896\n",
      "VALI: Epoch: 10, Steps: 116 | Train Loss: 0.1296924  Vali Loss: 0.1286180 Vali Accuracy: 0.9472882  Vali weighted F1: 0.9471759  Vali macro F1 0.8479056 \n",
      "new best score!!!!\n",
      "Validation loss decreased (0.130444 --> 0.128618).  Saving model ...\n",
      "new best score!!!!\n"
     ]
    }
   ],
   "source": [
    "for seed in [1,2,3,4,5]:\n",
    "    args.seed = seed\n",
    "    exp = Exp(args)\n",
    "    exp.train()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "SDIL",
   "language": "python",
   "name": "sdil"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.13"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": true
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
